import os
import json
import pandas as pd
import io
from llama_cpp import Llama, LlamaGrammar
from dotenv import load_dotenv
import logging

# --- 1. Configure logging and environment variables ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(name)s - %(message)s')
logger = logging.getLogger("POC_TableQA_Hybrid")
load_dotenv()

# --- 2. Load model path ---
MODEL_PATH = os.getenv("LOCAL_LLM_GGUF_MODEL_PATH")

if not MODEL_PATH or not os.path.exists(MODEL_PATH) or "Qwen3-1.7B" not in MODEL_PATH:
    logger.error("="*50)
    logger.error("é”™è¯¯ï¼šè¯·ç¡®ä¿æ‚¨çš„ .env æ–‡ä»¶ä¸­çš„ LOCAL_LLM_GGUF_MODEL_PATH")
    logger.error(f"æ­£ç¡®æŒ‡å‘äº† Qwen3-1.7B æ¨¡å‹ã€‚å½“å‰è·¯å¾„: {MODEL_PATH}")
    logger.error("="*50)
    exit(1)

# --- 3. Define the Prompt for "Instruction Generation" ---
# This Prompt is very direct, telling the model its only task is to "fill in the blanks".
TABLE_QA_INSTRUCTION_PROMPT_TEMPLATE = """
# æŒ‡ä»¤
ä½ æ˜¯ä¸€ä¸ªä¸“é—¨ä»ç”¨æˆ·é—®é¢˜ä¸­æå–è¡¨æ ¼æŸ¥è¯¢æŒ‡ä»¤çš„AIã€‚ä½ çš„å”¯ä¸€ä»»åŠ¡æ˜¯åˆ†æã€ç”¨æˆ·é—®é¢˜ã€‘å’Œã€è¡¨æ ¼åˆ—åã€‘ï¼Œç„¶åè¾“å‡ºä¸€ä¸ªåŒ…å«`row_identifier`å’Œ`column_identifier`çš„JSONå¯¹è±¡ã€‚

## è¡¨æ ¼ä¿¡æ¯
ã€è¡¨æ ¼åˆ—åã€‘: {column_names}

## ç”¨æˆ·é—®é¢˜
ã€ç”¨æˆ·é—®é¢˜ã€‘: "{user_query}"

## è¾“å‡ºè¦æ±‚
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºä¸€ä¸ªJSONå¯¹è±¡ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—æˆ–è§£é‡Šã€‚
```json
{{
  "row_identifier": "string, ç”¨æˆ·é—®é¢˜ä¸­æåˆ°çš„å…·ä½“è¡Œå",
  "column_identifier": "string, ç”¨æˆ·é—®é¢˜ä¸­æåˆ°çš„å…·ä½“åˆ—å"
}}
```
ä½ çš„JSONè¾“å‡º:
"""

# --- 4. é‡‡ç”¨ä¸»é¡¹ç›®ä¸­æœ€ç»ˆéªŒè¯é€šè¿‡çš„ã€æœ€å¥å£®çš„é€šç”¨JSON GBNF Schema ---
INSTRUCTION_JSON_GBNF_SCHEMA = r'''
root   ::= object
value  ::= object | array | string | number | "true" | "false" | "null"
ws ::= ([ \t\n\r])*
object ::= "{" ws ( member ("," ws member)* )? ws "}"
member ::= string ws ":" ws value
array  ::= "[" ws ( value ("," ws value)* )? ws "]"
string ::= "\"" ( [^"\\\x7F\x00-\x1F] | "\\" ( ["\\/bfnrt] | "u" [0-9a-fA-F]{4} ) )* "\""
number ::= "-"? ([0-9] | [1-9] [0-9]*) ("." [0-9]+)? ([eE] [-+]? [0-9]+)?
'''

def run_table_qa_poc():
    """Execute the "Instruction Generation + Code Execution" PoC"""
    logger.info("--- å¼€å§‹æ‰§è¡Œâ€œæŒ‡ä»¤ç”Ÿæˆ+ä»£ç æ‰§è¡Œâ€PoC ---")

    # --- 5. Simulate input data ---
    user_query = "äº§å“Bçš„ä»·æ ¼æ˜¯å¤šå°‘ï¼Ÿ"
    table_markdown_context = """
äº§å“|ä»·æ ¼|åº“å­˜
---|---|---
äº§å“A|3500|120
äº§å“B|4800|80
äº§å“C|5200|95"""

    logger.info(f"ç”¨æˆ·é—®é¢˜: {user_query}")
    logger.info(f"è¡¨æ ¼ä¸Šä¸‹æ–‡:\n{table_markdown_context}")

    # --- 6. Initialize LLM and GBNF ---
    try:
        grammar = LlamaGrammar.from_string(INSTRUCTION_JSON_GBNF_SCHEMA)
        llm = Llama(model_path=MODEL_PATH, n_gpu_layers=-1, n_ctx=2048, verbose=False)
        logger.info("Llamaæ¨¡å‹å’ŒGBNFè¯­æ³•å·²æˆåŠŸåŠ è½½ã€‚")
    except Exception as e:
        logger.error(f"åˆå§‹åŒ–Llamaæˆ–GBNFæ—¶å‡ºé”™: {e}", exc_info=True)
        return

    # --- 7. Convert Markdown table to Pandas DataFrame ---
    try:
        # Use io.StringIO to simulate a file from the string, allowing pandas to read it.
        # skipinitialspace=True is used to handle spaces between '|' symbols and column names.
        df = pd.read_csv(io.StringIO(table_markdown_context), sep='|', skipinitialspace=True).dropna(axis=1, how='all').iloc[1:]
        # Clean up spaces in column names.
        df.columns = [col.strip() for col in df.columns]
        # Set the first column as the index for easy lookup by row name.
        df = df.set_index(df.columns[0].strip())
        logger.info("æˆåŠŸå°†Markdownè¡¨æ ¼è½¬æ¢ä¸ºPandas DataFrame:\n" + str(df))
    except Exception as e:
        logger.error(f"è½¬æ¢Markdownåˆ°DataFrameæ—¶å‡ºé”™: {e}", exc_info=True)
        return

    # --- 8. Execute LLM call to generate instructions ---
    column_names_for_prompt = ", ".join(df.columns.tolist())
    prompt = TABLE_QA_INSTRUCTION_PROMPT_TEMPLATE.format(
        column_names=column_names_for_prompt,
        user_query=user_query
    )

    logger.info("--- æ­£åœ¨è°ƒç”¨LLMç”ŸæˆæŸ¥è¯¢æŒ‡ä»¤... ---")
    try:
        response = llm.create_completion(
            prompt=prompt,
            grammar=grammar,
            max_tokens=256,
            temperature=0.0 # For instruction extraction, no randomness is needed.
        )
        instruction_str = response['choices'][0]['text']
        logger.info(f"LLMæˆåŠŸè¿”å›æŒ‡ä»¤å­—ç¬¦ä¸²: {instruction_str}")
    except Exception as e:
        logger.error(f"è°ƒç”¨LLMç”ŸæˆæŒ‡ä»¤æ—¶å‡ºé”™: {e}", exc_info=True)
        return

    # --- 9. Execute code lookup ---
    logger.info("--- æ­£åœ¨æ‰§è¡Œä»£ç è¿›è¡Œè¡¨æ ¼æŸ¥æ‰¾... ---")
    try:
        instruction_json = json.loads(instruction_str)
        row_id = instruction_json.get("row_identifier")
        col_id = instruction_json.get("column_identifier")

        if not row_id or not col_id:
            logger.error("LLMç”Ÿæˆçš„æŒ‡ä»¤ä¸­ç¼ºå°‘'row_identifier'æˆ–'column_identifier'ã€‚")
            return

        # Lookup in DataFrame
        # .at[] is the fastest way to access a single value.
        answer = df.at[row_id, col_id]

        logger.info("="*50)
        logger.info(f"ğŸ‰ PoCæˆåŠŸï¼")
        logger.info(f"   - LLMç”Ÿæˆçš„æŒ‡ä»¤: {instruction_json}")
        logger.info(f"   - Pythonä»£ç æŸ¥æ‰¾åˆ°çš„æœ€ç»ˆç­”æ¡ˆ: {answer}")
        logger.info("="*50)
    except (json.JSONDecodeError, KeyError, IndexError) as e:
        logger.error("="*50)
        logger.error(f"PoCå¤±è´¥ï¼šå¤„ç†LLMæŒ‡ä»¤æˆ–æŸ¥æ‰¾DataFrameæ—¶å‡ºé”™: {e}")
        logger.error(f"LLMåŸå§‹è¾“å‡º: {instruction_str}")
        logger.error("="*50)

if __name__ == "__main__":
    run_table_qa_poc()
