Project Root: /home/zhz/zhz_agent
--- Project Structure and File Contents ---

Directory: /home/zhz/zhz_agent/
  File (skipped, extension not included): .env
  File (skipped, extension not included): .envrc
  File (skipped, extension not included): .gitignore
  File: README.md
    --- START OF FILE CONTENT ---
# zhz_agent
后端：RAG增强+多agent+dagster

    --- END OF FILE CONTENT ---

  File: __init__.py
    --- File is empty ---

  File: agent_orchestrator_service.py
    --- START OF FILE CONTENT ---
# /home/zhz/zhz_agent/agent_orchestrator_service.py

import os
import asyncio
import traceback
import json
from typing import List, Dict, Any, Optional, Union
from contextlib import asynccontextmanager
import re
import uvicorn
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from datetime import datetime 

# --- CrewAI ---
from crewai import Agent, Task, Crew, Process
from crewai.tools import BaseTool

# --- 自定义模块导入 ---
from core.llm_manager import get_llm_instance, CustomLiteLLMWrapper

# --- 导入我们新创建的工具 ---
from core.tools.enhanced_rag_tool import EnhancedRAGTool
from core.tools.excel_tool import ExcelOperationTool
from core.tools.search_tool import WebSearchTool

# --- 配置 ---
AGENT_SERVICE_PORT = int(os.getenv("AGENT_SERVICE_PORT", 8090))
AGENT_SERVICE_HOST = "0.0.0.0"

# --- Pydantic 模型定义 ---
# 沿用之前的 AgentTaskRequest 和 AgentTaskResponse
class AgentTaskRequest(BaseModel):
    user_query: str = Field(description="用户的原始文本查询。")

class AgentTaskResponse(BaseModel):
    answer: str = Field(description="Agent 系统生成的最终答案或响应。")
    status: str = Field(default="success", description="执行状态: 'success', 'needs_clarification', 'error', 'processing_plan', 'task_created'.")
    intermediate_plan: Optional[Dict[str, Any]] = Field(None, description="如果status是'processing_plan', 这里包含Manager Agent的规划结果。")
    task_id: Optional[str] = Field(None, description="如果任务是异步的，返回任务ID。")
    error_message: Optional[str] = Field(None, description="如果发生错误，此字段包含错误信息。")
    debug_info: Optional[Dict[str, Any]] = Field(None, description="包含执行过程中的调试信息。")
    token_usage: Optional[Dict[str, Any]] = Field(None, description="LLM token 使用情况统计。")

# 与 zhzai-agent/models.py 中 SubTaskDefinition 一致的结构，用于 Manager Agent 的输出
class SubTaskDefinitionForManagerOutput(BaseModel):
    task_description: str = Field(description="用户的原始请求原文。")
    reasoning_for_plan: Optional[str] = Field(None, description="Manager Agent的决策思考过程。")
    selected_tool_names: List[str] = Field(description="选定的工具名称列表。如果直接回答，则为空列表。")
    direct_answer_content: Optional[str] = Field(None, description="如果选择直接回答，这里是答案内容。")
    tool_input_args: Optional[Dict[str, Any]] = Field(None, description="如果选择使用非Excel工具，这里是传递给该工具的参数。")
    excel_sqo_payload: Optional[List[Dict[str, Any]]] = Field(None, description="如果选择使用Excel工具，这里是SQO操作字典的列表。")


# --- 全局变量 ---
manager_llm: Optional[CustomLiteLLMWrapper] = None
worker_llm: Optional[CustomLiteLLMWrapper] = None
manager_agent_instance: Optional[Agent] = None
worker_agent_instance: Optional[Agent] = None

core_tools_instances: List[BaseTool] = [] # BaseTool 是 CrewAI 工具的基类

# 我们新的核心工具名称 (与 zhzai-agent 不同)
CORE_TOOLS_ZHZ_AGENT = {
    "enhanced_rag_tool": "【核心RAG工具】用于从本地知识库查找信息、回答复杂问题，整合了向量、关键词和图谱检索。",
    "excel_operation_tool": "【Excel操作工具】通过结构化查询对象(SQO)对Excel文件执行复杂的数据查询、筛选、聚合等操作。",
    "web_search_tool": "【网络搜索工具】使用DuckDuckGo搜索引擎在互联网上查找与用户查询相关的信息。"
}
CORE_TOOL_NAMES_LIST = list(CORE_TOOLS_ZHZ_AGENT.keys())

# 将工具描述格式化为字符串，供Manager Prompt使用
TOOL_OPTIONS_STR_FOR_MANAGER = "\n".join(
    [f"- '{name}': {desc}" for name, desc in CORE_TOOLS_ZHZ_AGENT.items()]
)


@asynccontextmanager
async def lifespan(app: FastAPI):
    global manager_llm, worker_llm, manager_agent_instance, worker_agent_instance, core_tools_instances
    print("--- Agent Orchestrator Service: Lifespan startup ---")

    # --- 步骤 1: 初始化 LLM 实例 (保持不变) ---
    print("Initializing LLM instances...")
    try:
        gemini_tool_config = {"function_calling_config": {"mode": "AUTO"}}
        manager_llm = get_llm_instance(
            llm_type="cloud_gemini", temperature=0.1, max_tokens=4096, tool_config=gemini_tool_config
        )
        if not manager_llm:
            print("Failed to initialize Manager LLM (Cloud Gemini). Attempting fallback...")
            manager_llm = get_llm_instance(
                llm_type="local_qwen", temperature=0.1, max_tokens=3072, tool_config=gemini_tool_config
            )
        
        worker_llm = get_llm_instance(llm_type="local_qwen", temperature=0.6, max_tokens=3072)

        if manager_llm: print(f"Manager LLM initialized: {manager_llm.model_name}")
        else: print("CRITICAL: Failed to initialize Manager LLM.")
        if worker_llm: print(f"Worker LLM initialized: {worker_llm.model_name}")
        else: print("CRITICAL: Failed to initialize Worker LLM.")
    except Exception as e:
        print(f"FATAL ERROR during LLM initialization: {e}", exc_info=True)
        manager_llm = None; worker_llm = None

    # --- 步骤 2: 初始化核心工具实例 ---
    print("Initializing core tool instances...")
    try:
        enhanced_rag_tool_instance = EnhancedRAGTool()
        excel_operation_tool_instance = ExcelOperationTool()
        web_search_tool_instance = WebSearchTool()
        
        core_tools_instances = [
            enhanced_rag_tool_instance,
            excel_operation_tool_instance,
            web_search_tool_instance,
        ]
        print(f"Core tools initialized: {[tool.name for tool in core_tools_instances]}")
    except Exception as e:
        print(f"ERROR during core tool initialization: {e}", exc_info=True)
        core_tools_instances = []

    # 初始化 Agent 实例
    if manager_llm:
        manager_agent_instance = Agent(
            role='资深AI任务分解与Excel查询规划师 (Senior AI Task Decomposition and Excel Query Planner)',
            goal=f"""【深入理解并分解】用户提出的复杂请求 (当前请求将通过任务描述提供) 成为一系列逻辑子任务。
【核心决策1 - 优先自主回答】：在选择任何工具之前，请首先判断你是否能基于自身知识库和推理能力【直接回答】用户的全部或核心部分请求。如果可以，你的主要输出应是包含直接答案的JSON。
【核心决策2 - Excel复杂查询处理】：如果用户的请求涉及到对Excel文件进行一个或多个复杂的数据查询、筛选、聚合或排序等操作，并且你无法直接回答，你【必须】选择 "{CORE_TOOL_NAMES_LIST[CORE_TOOL_NAMES_LIST.index('excel_operation_tool')]}" 工具。并且，你【必须】为这些Excel操作【构建一个结构化查询对象 (SQO) 的JSON列表】，并将其作为输出JSON中 `excel_sqo_payload` 字段的值。列表中的【每一个SQO字典】都需要包含一个明确的 "operation_type" 和该操作对应的参数，但【不要包含 "file_path" 或 "sheet_name"】。
【核心决策3 - 其他工具选择】：如果需要从本地知识库获取深度信息，选择 "{CORE_TOOL_NAMES_LIST[CORE_TOOL_NAMES_LIST.index('enhanced_rag_tool')]}"。如果需要网络实时信息，选择 "{CORE_TOOL_NAMES_LIST[CORE_TOOL_NAMES_LIST.index('web_search_tool')]}"。选择工具后，你需要准备好传递给该工具的参数，并将其放在输出JSON的 `tool_input_args` 字段中。
【核心决策4 - 通用请求/无适用工具】：如果用户请求是生成通用文本、编写简单代码、回答一般性知识问题，并且你已判断可以【直接回答】，则无需选择任何特定功能性工具。此时输出JSON中 `selected_tool_names` 应为空列表，`excel_sqo_payload` 和 `tool_input_args` 为null，答案内容在 `direct_answer_content` 字段。

最终，【严格按照指定的JSON格式】（即符合 `SubTaskDefinitionForManagerOutput` Pydantic模型）输出一个包含你的决策理由、用户原始请求、以及根据你的决策填充的 `direct_answer_content` 或 `selected_tool_names`、`tool_input_args`、`excel_sqo_payload` 的对象。

【可供选择的本系统核心工具及其描述】:
{TOOL_OPTIONS_STR_FOR_MANAGER}
""",
            backstory="""我是一位经验丰富的AI任务调度官和数据查询规划专家。我的核心工作流程如下：
1.  **【深度理解与CoD规划 (内部进行)】**：我会对用户请求进行彻底分析，优先判断是否能直接利用我的知识库和推理能力给出完整答案。
2.  **【工具选择与参数准备（如果无法直接回答）】**：
    a.  **Excel复杂查询**: 当识别出需要对Excel执行复杂操作时，我选择 "{CORE_TOOL_NAMES_LIST[CORE_TOOL_NAMES_LIST.index('excel_operation_tool')]}" 工具，并为其生成包含多个SQO操作定义的【JSON列表】作为 `excel_sqo_payload`。每个SQO包含 `operation_type` 和所需参数，但不含 `file_path` 或 `sheet_name`。
    b.  **RAG查询**: 若需从知识库获取信息，选择 "{CORE_TOOL_NAMES_LIST[CORE_TOOL_NAMES_LIST.index('enhanced_rag_tool')]}"，并准备 `tool_input_args`（例如 `{{ "query": "用户原始问题", "top_k_vector": 5, ... }}`）。
    c.  **网络搜索**: 若需实时网络信息，选择 "{CORE_TOOL_NAMES_LIST[CORE_TOOL_NAMES_LIST.index('web_search_tool')]}"，并准备 `tool_input_args`（例如 `{{ "query": "搜索关键词" }}`）。
    d.  **最简必要原则**: 只选择绝对必要的工具。
3.  **【严格的输出格式】**: 我的唯一输出是一个JSON对象，该对象必须符合本服务定义的 `SubTaskDefinitionForManagerOutput` Pydantic模型结构，包含 `task_description` (用户原始请求), `reasoning_for_plan`, 以及根据决策填充的 `selected_tool_names` (可为空), `direct_answer_content` (如果直接回答), `tool_input_args` (如果使用非Excel工具), 和 `excel_sqo_payload` (如果使用Excel工具)。

我【不】自己执行任何工具操作。我的职责是精准规划并输出结构化的任务定义。""",
            llm=manager_llm,
            verbose=True,
            allow_delegation=False,
            tools=[]
        )
        print(f"Manager Agent initialized with LLM: {manager_llm.model_name}")

    if worker_llm:
        # Worker Agent 现在拥有所有核心工具
        worker_agent_instance = Agent(
            role='任务执行专家 (Task Execution Expert)',
            goal="根据Manager分配的具体任务描述和指定的工具，高效地执行任务并提供结果。",
            backstory="""我是一个AI执行者，专注于使用【Manager明确授权给我的工具】来解决问题。
                        我会严格遵循任务指令。如果任务是调用Excel工具并提供了SQO列表，我会按顺序迭代处理这些SQO，并整合结果。
                        我会使用工具的名称（例如 'enhanced_rag_tool', 'excel_operation_tool', 'web_search_tool'）来调用它们。""",
            llm=worker_llm,
            verbose=True,
            allow_delegation=False,
            tools=core_tools_instances # <--- 将实例化的工具列表传递给 Worker Agent
        )
        print(f"Worker Agent initialized with LLM: {worker_llm.model_name} and tools: {[t.name for t in core_tools_instances]}")

    if not manager_agent_instance or not worker_agent_instance:
        print("CRITICAL: One or more core agents failed to initialize. Service functionality will be severely limited.")
    elif not core_tools_instances and worker_agent_instance : # 如果 Worker Agent 初始化了但没有工具
        print("WARNING: Worker Agent initialized, but no core tools were successfully instantiated. Tool-based tasks will fail.")

    print("--- Agent Orchestrator Service: Lifespan startup complete ---")
    yield
    print("--- Agent Orchestrator Service: Lifespan shutdown ---")

app = FastAPI(
    title="Agent Orchestrator Service",
    description="接收用户请求，通过Manager/Worker Agent模型进行任务规划和执行。",
    version="0.1.1", # 版本更新
    lifespan=lifespan
)

@app.post("/v1/execute_task", response_model=AgentTaskResponse)
async def execute_task_endpoint(request: AgentTaskRequest):
    global manager_agent_instance, worker_agent_instance, core_tools_instances # 确保能访问全局 Agent 和工具实例
    
    print(f"Received agent task request: User Query='{request.user_query}'") # 使用 print 替代 logger

    if not manager_agent_instance or not worker_agent_instance:
        print("CRITICAL ERROR: Core agents are not initialized. Cannot process task.")
        raise HTTPException(status_code=503, detail="Service not ready: Core agents failed to initialize.")
    if not core_tools_instances:
        print("WARNING: Core tools are not initialized. Tool-based tasks may fail.")
    # --- 构建 Manager Task 的描述 ---
    # 我们将用户请求和可用的核心工具列表传递给 Manager Agent
    # Manager Agent 的 goal 和 backstory 已经包含了大部分指令
    # Task 的 description 主要用于传递动态信息，如当前用户查询
    manager_task_description_for_crewai = f"""
    请仔细分析以下用户请求：
    '{request.user_query}'

    你的目标是：
    1.  理解用户的核心意图。
    2.  **优先判断**：你能否基于你现有的知识直接、准确地回答这个问题？
        - 如果是，请在输出的JSON中填充 `direct_answer_content` 字段，并将 `selected_tool_names` 设为空列表。
    3.  **如果不能直接回答**：判断解决这个问题最核心的工具是什么。从你已知的核心工具 ({', '.join(CORE_TOOL_NAMES_LIST)}) 中选择【一个或多个必要】工具。
    4.  如果选择了 '{CORE_TOOL_NAMES_LIST[CORE_TOOL_NAMES_LIST.index('excel_operation_tool')]}'，请为Excel操作构建一个或多个SQO的【列表】，并将其放入 `excel_sqo_payload` 字段。
    5.  如果选择了其他工具（如 '{CORE_TOOL_NAMES_LIST[CORE_TOOL_NAMES_LIST.index('enhanced_rag_tool')]}' 或 '{CORE_TOOL_NAMES_LIST[CORE_TOOL_NAMES_LIST.index('web_search_tool')]}'），请准备好传递给该工具的参数，并将其放入 `tool_input_args` 字段。
    6.  严格按照 `SubTaskDefinitionForManagerOutput` 的JSON格式输出你的规划。`task_description` 字段必须是用户的原始请求原文: '{request.user_query}'。同时提供你的 `reasoning_for_plan`。
    """
    
    # --- Manager Task 的期望输出格式说明 ---
    # 这个 expected_output 对于指导LLM以正确的JSON格式返回至关重要
    manager_task_expected_output_description = f"""一个JSON对象，必须严格符合以下Pydantic模型的结构（你不需要输出 "SubTaskDefinitionForManagerOutput" 这个词本身）：
    {{
      "task_description": "string (固定为用户的原始请求: '{request.user_query}')",
      "reasoning_for_plan": "string (你的决策思考过程)",
      "selected_tool_names": ["list of strings (选定的工具名称列表。如果直接回答，则为空列表)"],
      "direct_answer_content": "string (可选, 仅当 selected_tool_names 为空列表时，这里是你的答案内容)",
      "tool_input_args": {{ "key": "value" }} (可选, 仅当 selected_tool_names 包含非Excel工具时，这里是给该工具的参数字典),
      "excel_sqo_payload": "[{{...}}, {{...}}] (可选, 仅当 selected_tool_names 包含'{CORE_TOOL_NAMES_LIST[CORE_TOOL_NAMES_LIST.index('excel_operation_tool')]}'时，这里是SQO操作字典的列表)"
    }}

    【重要输出规则】:
    - 如果你选择【直接回答】：`selected_tool_names` 必须是空列表 `[]`，`direct_answer_content` 必须包含你的答案，`tool_input_args` 和 `excel_sqo_payload` 应该为 `null` 或不存在。
    - 如果你选择使用【非Excel工具】(例如 RAG 或 Web Search)：`selected_tool_names` 必须包含该工具的名称，`direct_answer_content` 应该为 `null` 或不存在，`tool_input_args` 必须包含调用该工具所需的参数 (例如 `{{ "query": "{request.user_query}" }}` )，`excel_sqo_payload` 应该为 `null` 或不存在。
    - 如果你选择使用【Excel工具】 ('{CORE_TOOL_NAMES_LIST[CORE_TOOL_NAMES_LIST.index('excel_operation_tool')]}')：`selected_tool_names` 必须包含 `"{CORE_TOOL_NAMES_LIST[CORE_TOOL_NAMES_LIST.index('excel_operation_tool')]}"`，`direct_answer_content` 和 `tool_input_args` 应该为 `null` 或不存在，`excel_sqo_payload` 【必须】包含一个SQO操作定义的列表。

    示例输出 (直接回答):
    {{
      "task_description": "{request.user_query}",
      "reasoning_for_plan": "这是一个常识性问题，我可以根据我的内部知识直接回答。",
      "selected_tool_names": [],
      "direct_answer_content": "中国的首都是北京。",
      "tool_input_args": null,
      "excel_sqo_payload": null
    }}

    示例输出 (使用RAG工具):
    {{
      "task_description": "{request.user_query}",
      "reasoning_for_plan": "用户询问关于公司政策的问题，这需要从知识库中查找。",
      "selected_tool_names": ["{CORE_TOOL_NAMES_LIST[CORE_TOOL_NAMES_LIST.index('enhanced_rag_tool')]}"],
      "direct_answer_content": null,
      "tool_input_args": {{"query": "{request.user_query}", "top_k_vector": 5, "top_k_kg": 3, "top_k_bm25": 3}},
      "excel_sqo_payload": null
    }}
    
    示例输出 (使用Excel工具，假设用户问“test.xlsx中有哪些区域以及每个区域的平均销售额”):
    {{
      "task_description": "test.xlsx中有哪些区域以及每个区域的平均销售额",
      "reasoning_for_plan": "用户需要从Excel文件中获取唯一区域列表，并对销售额按区域进行聚合计算平均值。这需要两个SQO操作。",
      "selected_tool_names": ["{CORE_TOOL_NAMES_LIST[CORE_TOOL_NAMES_LIST.index('excel_operation_tool')]}"],
      "direct_answer_content": null,
      "tool_input_args": null, 
      "excel_sqo_payload": [
        {{
          "operation_type": "get_unique_values",
          "parameters": {{ "column_name": "区域" }}
        }},
        {{
          "operation_type": "group_by_aggregate",
          "parameters": {{ "group_by_columns": ["区域"], "aggregation_column": "销售额", "aggregation_function": "mean" }}
        }}
      ]
    }}
    请严格按照此JSON格式输出。
    """

    manager_task = Task(
        description=manager_task_description_for_crewai,
        expected_output=manager_task_expected_output_description,
        agent=manager_agent_instance,
        async_execution=False,
        output_pydantic=SubTaskDefinitionForManagerOutput
    )

    # --- 步骤 2: 执行 Manager Task ---
    print("Executing Manager Task...")
    manager_plan_object: Optional[SubTaskDefinitionForManagerOutput] = None
    manager_raw_output: Optional[str] = None

    try:
        manager_crew = Crew(
            agents=[manager_agent_instance],
            tasks=[manager_task],
            process=Process.sequential,
            verbose=True 
        )
        print(f"[{datetime.now()}] About to call manager_crew.kickoff()...") # <--- 添加日志
        manager_task_raw_result = manager_crew.kickoff(inputs={})
        print(f"[{datetime.now()}] manager_crew.kickoff() returned.") # <--- 添加日志

        # --- 新的解析逻辑，处理 CrewOutput ---
        actual_task_output: Optional[Any] = None # 用于存储实际的 TaskOutput 或字符串

        if hasattr(manager_task_raw_result, 'tasks_output') and isinstance(manager_task_raw_result.tasks_output, list) and manager_task_raw_result.tasks_output:
            # CrewOutput.tasks_output 是一个 TaskOutput 对象的列表
            actual_task_output = manager_task_raw_result.tasks_output[0] # 我们只有一个 manager_task
            print(f"Extracted TaskOutput from CrewOutput: {type(actual_task_output)}")
        elif hasattr(manager_task_raw_result, 'raw_output'): # 兼容直接返回 TaskOutput 的情况 (旧版或特定配置)
            actual_task_output = manager_task_raw_result
            print(f"kickoff returned a TaskOutput-like object directly: {type(actual_task_output)}")
        elif isinstance(manager_task_raw_result, str): # 直接返回字符串
            actual_task_output = manager_task_raw_result
            print(f"kickoff returned a raw string.")
        else:
            print(f"Warning: manager_crew.kickoff() returned an unexpected type: {type(manager_task_raw_result)}")
            actual_task_output = str(manager_task_raw_result)
        # --- 结束新的解析逻辑 ---


        # --- 后续的解析逻辑，现在基于 actual_task_output ---
        print(f"DEBUG: Type of actual_task_output: {type(actual_task_output)}")
        
        manager_raw_llm_output_str: Optional[str] = None
        if hasattr(actual_task_output, 'raw') and isinstance(actual_task_output.raw, str):
            manager_raw_llm_output_str = actual_task_output.raw.strip()
            print(f"DEBUG: actual_task_output.raw (LLM's original string output) IS:\n---\n{manager_raw_llm_output_str}\n---")
        else:
            print(f"DEBUG: actual_task_output.raw is not a string or does not exist. Value: {getattr(actual_task_output, 'raw', 'Attribute .raw not found')}")
            manager_raw_llm_output_str = str(actual_task_output) # Fallback

        # 优先尝试使用 CrewAI 已经解析好的 Pydantic 对象
        if hasattr(actual_task_output, 'pydantic_output') and \
           actual_task_output.pydantic_output is not None and \
           isinstance(actual_task_output.pydantic_output, SubTaskDefinitionForManagerOutput):
            print("DEBUG: Successfully using actual_task_output.pydantic_output.")
            manager_plan_object = actual_task_output.pydantic_output
        
        # 如果 Pydantic 对象不可用，但我们从 .raw 成功获取了字符串，则尝试解析它
        # 并且确保 manager_plan_object 之前没有被成功赋值
        elif manager_plan_object is None and manager_raw_llm_output_str: # <--- 添加 manager_plan_object is None 条件
            print(f"DEBUG: pydantic_output not available. Attempting to parse string from actual_task_output.raw:\n---\n{manager_raw_llm_output_str}\n---")
            json_to_parse_from_raw = manager_raw_llm_output_str # 使用我们从 .raw 获取的
            try:
                final_answer_marker = "## Final Answer:" # 虽然日志显示Qwen没输出这个，但保留以防万一
                if final_answer_marker in json_to_parse_from_raw:
                    json_to_parse_from_raw = json_to_parse_from_raw.split(final_answer_marker, 1)[-1].strip()
                
                cleaned_json_str = json_to_parse_from_raw.strip()
                if cleaned_json_str.startswith("```json"): cleaned_json_str = cleaned_json_str[len("```json"):].strip()
                if cleaned_json_str.endswith("```"): cleaned_json_str = cleaned_json_str[:-len("```")].strip()
                
                if not cleaned_json_str: raise ValueError("Cleaned JSON string (from .raw) is empty.")
                manager_plan_object = SubTaskDefinitionForManagerOutput(**json.loads(cleaned_json_str))
                print(f"Parsed Manager Plan (from actual_task_output.raw): {manager_plan_object.model_dump_json(indent=2)}")
            except (json.JSONDecodeError, ValueError, Exception) as e:
                print(f"Error parsing JSON from actual_task_output.raw: {e}. Raw content used: {json_to_parse_from_raw}")
        
        # 在所有尝试之后，如果 manager_plan_object 仍然是 None，才报告最终的解析失败
        if not manager_plan_object:
             # manager_raw_output 现在应该引用我们尝试过的 manager_raw_llm_output_str
             final_raw_output_for_debug = manager_raw_llm_output_str if manager_raw_llm_output_str else str(actual_task_output)
             print(f"Manager Task did not produce a valid Pydantic object after all attempts. Final Raw for debug: {final_raw_output_for_debug}")
             return AgentTaskResponse(answer="无法解析Manager Agent的规划结果。", status="error",
                                      error_message="Failed to parse manager plan after all attempts.",
                                      debug_info={"manager_raw_output_tried": final_raw_output_for_debug})
        
        # 如果 manager_plan_object 成功解析，则打印日志（这行已经在您的代码中）
        print(f"Parsed Manager Plan: {manager_plan_object.model_dump_json(indent=2)}")
        
    except Exception as e:
        print(f"Error executing Manager Task or its Crew: {e}") # <--- 修改后的第一行
        traceback.print_exc() # <--- 修改后的第二行
        return AgentTaskResponse(
            answer="执行Manager Agent任务时发生错误。", status="error", error_message=str(e),
            debug_info={"traceback": traceback.format_exc(), "manager_raw_output": manager_raw_output}
        )

    # --- 步骤 2: 根据 Manager 的规划执行后续操作 ---
    if not manager_plan_object.selected_tool_names and manager_plan_object.direct_answer_content:
        print(f"Manager decided to answer directly. Answer: {manager_plan_object.direct_answer_content}")
        return AgentTaskResponse(
            answer=manager_plan_object.direct_answer_content,
            status="success",
            debug_info={"manager_plan": manager_plan_object.model_dump()}
        )
    elif not manager_plan_object.selected_tool_names and not manager_plan_object.direct_answer_content:
        # 如果 Manager 既没有选择工具，也没有提供直接答案，这可能是一个规划错误
         print(f"Manager Warning: No tool selected and no direct answer provided. Reasoning: {manager_plan_object.reasoning_for_plan}")
         return AgentTaskResponse(
            answer=manager_plan_object.reasoning_for_plan or "Manager 未能提供明确的行动计划或答案。",
            status="success", # 或者 "error" 取决于您如何定义这种情况
            debug_info={"manager_plan": manager_plan_object.model_dump()}
        )

    # --- 步骤 3: 如果 Manager 规划使用工具，则创建并执行 Worker Task ---
    selected_tool_name = manager_plan_object.selected_tool_names[0] if manager_plan_object.selected_tool_names else None

    if not selected_tool_name:
        return AgentTaskResponse(
            answer="Manager规划使用工具但未在selected_tool_names中指定工具名称。", status="error",
            error_message="Tool name missing in manager plan's selected_tool_names.",
            debug_info={"manager_plan": manager_plan_object.model_dump()}
        )

    # 找到对应的工具实例
    tool_instance_for_worker = next((tool for tool in core_tools_instances if tool.name == selected_tool_name), None)

    if not tool_instance_for_worker:
        return AgentTaskResponse(
            answer=f"系统中未找到Manager规划使用的工具: {selected_tool_name}。", status="error",
            error_message=f"Tool '{selected_tool_name}' not found in core_tools_instances.",
            debug_info={"manager_plan": manager_plan_object.model_dump(), "available_tools": [t.name for t in core_tools_instances]}
        )

    print(f"Manager planned to use tool: {selected_tool_name}. Instance found: {tool_instance_for_worker is not None}")

    worker_task_description = ""
    worker_task_inputs = {} # 用于传递给 task.execute(inputs=...)

    if selected_tool_name == "enhanced_rag_tool":
        rag_query = manager_plan_object.tool_input_args.get("query", request.user_query) if manager_plan_object.tool_input_args else request.user_query
        top_k_v = manager_plan_object.tool_input_args.get("top_k_vector", 5) if manager_plan_object.tool_input_args else 5
        top_k_kg = manager_plan_object.tool_input_args.get("top_k_kg", 3) if manager_plan_object.tool_input_args else 3
        top_k_b = manager_plan_object.tool_input_args.get("top_k_bm25", 3) if manager_plan_object.tool_input_args else 3
        
        worker_task_description = f"请使用增强RAG工具回答以下问题：'{rag_query}'。\n使用以下参数进行检索：top_k_vector={top_k_v}, top_k_kg={top_k_kg}, top_k_bm25={top_k_b}。"
        worker_task_inputs = {
            "query": rag_query, 
            "top_k_vector": top_k_v, 
            "top_k_kg": top_k_kg, 
            "top_k_bm25": top_k_b
        }

    elif selected_tool_name == "excel_operation_tool":
        excel_sqo_list = manager_plan_object.excel_sqo_payload
        if not excel_sqo_list:
            return AgentTaskResponse(
                answer="Manager选择Excel工具但未提供SQO列表。", status="error",
                error_message="excel_sqo_payload is missing for excel_operation_tool.",
                debug_info={"manager_plan": manager_plan_object.model_dump()}
            )
        
        # TODO: 从用户原始请求 manager_plan_object.task_description 中提取 file_path 和 sheet_name
        # 这里我们先用一个占位符/默认值，您需要实现提取逻辑
        # 例如，使用正则表达式从 manager_plan_object.task_description 查找文件路径
        # file_path_match = re.search(r"文件\s*['\"]?([^'\"]+\.(?:xlsx|xls|csv))['\"]?", manager_plan_object.task_description)
        # excel_file_path = file_path_match.group(1) if file_path_match else "YOUR_DEFAULT_TEST_EXCEL_PATH.xlsx"
        excel_file_path = "/home/zhz/zhz_agent/data/test.xlsx" # 临时硬编码，后续需要动态获取
        excel_sheet_name: Union[str, int] = 0 # 临时硬编码

        worker_task_description = (
            f"你需要处理一个Excel文件相关的任务。文件路径是 '{excel_file_path}'，工作表是 '{excel_sheet_name}'。\n"
            f"请严格按照以下SQO操作列表，顺序执行每一个操作，并整合所有操作的结果形成最终答案。\n"
            f"SQO操作列表: {json.dumps(excel_sqo_list, ensure_ascii=False)}\n\n"
            f"对于列表中的每一个SQO字典，你需要调用 '{tool_instance_for_worker.name}' 工具一次，"
            f"将该SQO字典作为 'sqo_dict' 参数，同时传递 'file_path': '{excel_file_path}' 和 'sheet_name': '{excel_sheet_name}'。"
        )
        # Worker Task的inputs将是整个SQO列表以及文件和工作表信息
        # Worker Agent的Prompt需要指导它如何迭代处理这个列表
        worker_task_inputs = {
            "excel_sqo_list_to_execute": excel_sqo_list,
            "target_excel_file_path": excel_file_path,
            "target_excel_sheet_name": excel_sheet_name
        }
        
    elif selected_tool_name == "web_search_tool":
        search_query = manager_plan_object.tool_input_args.get("query", request.user_query) if manager_plan_object.tool_input_args else request.user_query
        max_results = manager_plan_object.tool_input_args.get("max_results", 5) if manager_plan_object.tool_input_args else 5

        worker_task_description = f"请使用网络搜索工具查找关于 '{search_query}' 的信息，返回最多 {max_results} 条结果。"
        worker_task_inputs = {"query": search_query, "max_results": max_results}
        
    else:
        return AgentTaskResponse(
            answer=f"未知的工具名称 '{selected_tool_name}' 被Manager规划。", status="error",
            error_message=f"Unknown tool '{selected_tool_name}' planned by manager.",
            debug_info={"manager_plan": manager_plan_object.model_dump()}
        )

    # 创建 Worker Task
    worker_task = Task(
        description=worker_task_description,
        expected_output="任务的执行结果，通常是一个字符串，其中包含答案或操作的状态。",
        agent=worker_agent_instance,
        tools=[tool_instance_for_worker], # 只给 Worker 当前任务需要的工具
        async_execution=False # Worker Task 通常也是同步的
    )

    print(f"Executing Worker Task with tool: {selected_tool_name}")
    print(f"Worker Task Description: {worker_task_description}")
    print(f"Worker Task Inputs: {worker_task_inputs}")
    
    worker_final_result: str = ""
    try:
        # 如果 worker_task_inputs 为空，则不传递 inputs 参数
        task_execution_args = {}
        if worker_task_inputs:
            task_execution_args['inputs'] = worker_task_inputs
            
        worker_output = worker_task.execute(**task_execution_args)

        if isinstance(worker_output, str):
            worker_final_result = worker_output
        elif hasattr(worker_output, 'raw_output'): # CrewAI 0.30.0+
            worker_final_result = worker_output.raw_output
        elif hasattr(worker_output, 'raw'): # Older CrewAI
            worker_final_result = worker_output.raw
        else:
            worker_final_result = str(worker_output)
            
        print(f"Worker Task executed. Result: {worker_final_result}")
        
        # (可选) 获取 Worker Crew 的 token usage
        worker_token_usage = None
        if hasattr(worker_task, 'agent') and hasattr(worker_task.agent, 'crew') and worker_task.agent.crew and hasattr(worker_task.agent.crew, 'usage_metrics'):
             worker_token_usage = worker_task.agent.crew.usage_metrics
             print(f"Worker Crew token usage: {worker_token_usage}")


        return AgentTaskResponse(
            answer=worker_final_result,
            status="success",
            debug_info={
                "manager_plan": manager_plan_object.model_dump(),
                "worker_tool_used": selected_tool_name,
                "worker_task_inputs": worker_task_inputs
            },
            token_usage=worker_token_usage.model_dump() if worker_token_usage else None
        )

    except Exception as e:
        print(f"Error executing Worker Task for tool {selected_tool_name}: {e}", exc_info=True)
        return AgentTaskResponse(
            answer=f"执行工具 '{selected_tool_name}' 时发生错误。",
            status="error",
            error_message=str(e),
            debug_info={
                "manager_plan": manager_plan_object.model_dump(),
                "worker_tool_used": selected_tool_name,
                "worker_task_inputs": worker_task_inputs,
                "traceback": traceback.format_exc()
            }
        )

if __name__ == "__main__":
    print(f"--- Starting Agent Orchestrator FastAPI Service on {AGENT_SERVICE_HOST}:{AGENT_SERVICE_PORT} ---")
    uvicorn.run("agent_orchestrator_service:app", host=AGENT_SERVICE_HOST, port=AGENT_SERVICE_PORT, reload=True) # 确保模块名正确
    --- END OF FILE CONTENT ---

  File: config.yaml
    --- START OF FILE CONTENT ---
# config.yaml

model_list:
  - model_name: gemini/gemini-1.5-flash-latest # 您已有的 Gemini 配置 (如果存在)
    litellm_params:
      model: gemini/gemini-1.5-flash-latest
      api_key: os.environ/GEMINI_API_KEY
      # api_base: http://localhost:YOUR_CLASH_PORT # 如果需要

  # --- 修改我们本地的 Qwen3 1.7B 模型配置 ---
  - model_name: local/qwen3-1.7b-gguf
    litellm_params:
      model: openai/my-local-qwen # 使用 "openai/" 前缀，后面可以跟一个自定义的描述符
      api_base: http://localhost:8088/v1
      api_key: nokey

# ... (其他 LiteLLM 配置) ...
    --- END OF FILE CONTENT ---

  File: debug_kuzu_visibility.py
    --- START OF FILE CONTENT ---
# debug_kuzu_visibility.py
import kuzu
import os
import shutil
import time
import pandas as pd

DB_PATH = "./zhz_rag/stored_data/kuzu_test_visibility_db" # 使用一个新的测试路径

def setup_and_verify_schema():
    print(f"--- Phase 1: Setup and Initial Verification ---")
    if os.path.exists(DB_PATH):
        print(f"Removing existing database at {DB_PATH}")
        shutil.rmtree(DB_PATH)
    
    db_setup = None
    conn_setup = None
    try:
        print(f"Creating new database at {DB_PATH}")
        db_setup = kuzu.Database(DB_PATH, read_only=False)
        conn_setup = kuzu.Connection(db_setup)
        print("Database and connection created for setup.")

        ddl_queries = [
            "CREATE NODE TABLE IF NOT EXISTS ExtractedEntity (id_prop STRING, text STRING, label STRING, PRIMARY KEY (id_prop))",
            "CREATE REL TABLE IF NOT EXISTS WorksAt (FROM ExtractedEntity TO ExtractedEntity)",
            "CREATE REL TABLE IF NOT EXISTS AssignedTo (FROM ExtractedEntity TO ExtractedEntity)"
        ]
        for query in ddl_queries:
            print(f"Executing DDL: {query}")
            conn_setup.execute(query)
        print("DDL execution complete.")

        print("Executing CHECKPOINT...")
        conn_setup.execute("CHECKPOINT;")
        print("CHECKPOINT complete.")

        # Phase 1 Verification
        print("Verifying tables immediately after creation (same session)...")
        try:
            # 尝试 SHOW TABLES;
            print("Attempting 'SHOW TABLES;' in Phase 1...")
            result = conn_setup.execute("SHOW TABLES;") # <--- 修改这里
            df = pd.DataFrame(result.get_as_df())
            print(f"Tables found using 'SHOW TABLES;' (Phase 1):\n{df}")
            # 检查 'name' 列是否存在，并且 'ExtractedEntity' 是否在其中
            if not df.empty and 'name' in df.columns and "ExtractedEntity" in df["name"].tolist():
                print("Phase 1 Verification (SHOW TABLES;): ExtractedEntity table FOUND.")
            elif not df.empty and 'name' not in df.columns:
                print("Phase 1 Verification (SHOW TABLES;): 'name' column not found in SHOW TABLES result.")
                print(f"Columns available in SHOW TABLES result: {df.columns.tolist()}")
            else: # df is empty or ExtractedEntity not in name column
                print("Phase 1 Verification (SHOW TABLES;): ExtractedEntity table NOT FOUND or result was empty.")
        except Exception as e:
            print(f"Error during Phase 1 verification with 'SHOW TABLES;': {e}")
            print("Falling back to direct query for ExtractedEntity in Phase 1...")
            try:
                result_direct = conn_setup.execute("MATCH (e:ExtractedEntity) RETURN count(e) AS entity_count;")
                df_direct = pd.DataFrame(result_direct.get_as_df())
                print(f"Direct query result (Phase 1):\n{df_direct}")
                count_val = df_direct['entity_count'].iloc[0] if not df_direct.empty else -1
                print(f"Phase 1 Verification (Direct Query): ExtractedEntity table SEEMS TO EXIST (count: {count_val}).")
            except Exception as e_direct_phase1:
                print(f"Error during Phase 1 direct query verification: {e_direct_phase1}")

    except Exception as e:
        print(f"Error during Phase 1 setup: {e}")
    finally:
        if conn_setup:
            print("Closing setup connection.")
            # conn_setup.close() # Kuzu Connection 没有显式 close
        if db_setup:
            print("Deleting setup database instance reference (will trigger close).")
            del db_setup # 依赖 __del__
        print("--- Phase 1 Complete ---")

def verify_in_new_session():
    print(f"\n--- Phase 2: Verification in a New Session ---")
    if not os.path.exists(DB_PATH):
        print(f"Database at {DB_PATH} does not exist. Cannot perform Phase 2.")
        return

    db_verify = None
    conn_verify = None
    try:
        print(f"Opening existing database at {DB_PATH} for verification.")
        db_verify = kuzu.Database(DB_PATH, read_only=False) # 打开同一个数据库
        conn_verify = kuzu.Connection(db_verify)
        print("Database and connection created for verification.")

        # Phase 2 Verification
        print("Verifying tables in new session...")
        try:
            # 尝试 SHOW TABLES;
            print("Attempting 'SHOW TABLES;' in Phase 2...")
            result = conn_verify.execute("SHOW TABLES;") # <--- 修改这里
            df = pd.DataFrame(result.get_as_df())
            print(f"Tables found using 'SHOW TABLES;' (Phase 2):\n{df}")
            if not df.empty and 'name' in df.columns and "ExtractedEntity" in df["name"].tolist():
                print("Phase 2 Verification (SHOW TABLES;): ExtractedEntity table FOUND.")
            elif not df.empty and 'name' not in df.columns:
                print("Phase 2 Verification (SHOW TABLES;): 'name' column not found in SHOW TABLES result.")
                print(f"Columns available in SHOW TABLES result: {df.columns.tolist()}")
            else: # df is empty or ExtractedEntity not in name column
                print("Phase 2 Verification (SHOW TABLES;): ExtractedEntity table NOT FOUND or result was empty.")
        except Exception as e:
            print(f"Error during Phase 2 verification with 'SHOW TABLES;': {e}")
            print("Falling back to direct query for ExtractedEntity in Phase 2...")
            try:
                result_direct = conn_verify.execute("MATCH (e:ExtractedEntity) RETURN count(e) AS entity_count;")
                df_direct = pd.DataFrame(result_direct.get_as_df())
                print(f"Direct query result (Phase 2):\n{df_direct}")
                count_val = df_direct['entity_count'].iloc[0] if not df_direct.empty else -1
                print(f"Phase 2 Verification (Direct Query): ExtractedEntity table SEEMS TO EXIST (count: {count_val}).")
            except Exception as e_direct_phase2:
                print(f"Error during Phase 2 direct query verification: {e_direct_phase2}")

    except Exception as e:
        print(f"Error during Phase 2 setup: {e}")
    finally:
        if conn_verify:
            print("Closing verification connection.")
        if db_verify:
            print("Deleting verification database instance reference.")
            del db_verify
        print("--- Phase 2 Complete ---")

if __name__ == "__main__":
    print(f"Kuzu Python client version: {kuzu.__version__}")
    setup_and_verify_schema()
    print("\nWaiting a moment before trying to open in a new session (simulating process switch)...")
    time.sleep(2) # 短暂等待，模拟进程切换的间隙
    verify_in_new_session()
    --- END OF FILE CONTENT ---

  File: llm_setup.py
    --- START OF FILE CONTENT ---
# /home/zhz/zhz_agent/llm_setup.py

import os
from typing import Any, Optional, List, Dict

# LiteLLM 本身通常是直接调用其 API，例如 litellm.completion
# 如果要将其适配给 CrewAI 的 Agent，我们需要将其包装成一个符合 CrewAI BaseLLM 接口的类。
# CrewAI 自身也提供了通过 LiteLLM 使用各种模型的集成，我们也可以研究直接使用 CrewAI 的方式。
# 为简化起见，我们先创建一个函数，返回配置好的 LiteLLM 调用参数，或者一个简单的包装器。

# --- 从 agent_orchestrator_service.py 中获取的配置常量 ---
# 本地 LLM 服务地址 (Qwen3)
LOCAL_QWEN_API_BASE = os.getenv("LOCAL_LLM_API_BASE", "http://localhost:8088/v1") # 确保与 local_llm_service.py 的端口一致
LOCAL_QWEN_MODEL_NAME_FOR_LITELLM = os.getenv("LOCAL_LLM_MODEL_NAME", "local/qwen3-1.7b-gguf") # 这个是给 litellm 的 model 参数，需要与 LiteLLM 配置或调用方式对应

# 云端 LiteLLM 网关地址 (用于 Gemini 等)
CLOUD_LITELLM_GW_API_BASE = os.getenv("CLOUD_LITELLM_GW_API_BASE", "YOUR_CLOUD_LITELLM_GATEWAY_URL_HERE/v1") # 假设您的网关也提供 /v1 路径
GEMINI_MODEL_NAME_FOR_LITELLM = os.getenv("CLOUD_LLM_MODEL_NAME", "gemini/gemini-1.5-flash-latest") # 或您希望通过网关调用的模型

# API Keys (通常 LiteLLM 会在其自己的配置或环境变量中处理，但这里可以作为参考)
# GEMINI_API_KEY = os.getenv("GEMINI_API_KEY") # 如果直接调用 Gemini 而非通过网关
# 注意：本地模型的 API Key 通常是 "nokey" 或在服务中不强制

# --- CrewAI LLM 包装器 (如果需要直接传递给 CrewAI Agent) ---
# CrewAI 期望一个 LLM 对象，我们可以创建一个简单的包装器，或者使用 CrewAI 提供的 LiteLLM 集成
# from crewai.llms.base_llm import BaseLLM as CrewAIBaseLLM
# import litellm
#
# class LiteLLMWrapperForCrewAI(CrewAIBaseLLM):
#     model: str
#     api_base: Optional[str] = None
#     api_key: Optional[str] = None
#     custom_llm_provider: Optional[str] = None # 例如 "openai" for OpenAI-compatible endpoints
#     litellm_kwargs: Dict[str, Any] = {}
#
#     def __init__(self, model: str, api_base: Optional[str] = None, api_key: Optional[str] = None, custom_llm_provider: Optional[str] = None, **kwargs):
#         super().__init__(model=model) # CrewAI BaseLLM 需要 model 参数
#         self.model = model
#         self.api_base = api_base
#         self.api_key = api_key
#         self.custom_llm_provider = custom_llm_provider
#         self.litellm_kwargs = kwargs
#
#     def call(self, messages: List[Dict[str, str]], **kwargs: Any) -> str:
#         # CrewAI 的 BaseLLM.call 方法通常期望返回一个字符串
#         # LiteLLM 的 completion 返回一个 ModelResponse 对象
#         params = {
#             "model": self.model,
#             "messages": messages,
#             "api_base": self.api_base,
#             "api_key": self.api_key,
#             "custom_llm_provider": self.custom_llm_provider,
#             **self.litellm_kwargs, # 包含 temperature, max_tokens 等
#             **kwargs # 运行时可能传递的额外参数
#         }
#         # 移除值为 None 的参数，因为 litellm.completion 不喜欢 None 的 api_key 等
#         params_cleaned = {k: v for k, v in params.items() if v is not None}
#
#         response = litellm.completion(**params_cleaned)
#
#         # 从 LiteLLM 响应中提取内容
#         content = ""
#         if response.choices and response.choices[0].message and response.choices[0].message.content:
#             content = response.choices[0].message.content
#         return content
#
#     def get_token_ids(self, text: str) -> List[int]:
#         # LiteLLM 通常不直接暴露 tokenizer，但可以尝试通过 litellm.token_counter (如果它返回ids)
#         # 或者如果使用特定模型，可以尝试加载其 tokenizer
#         # 为简单起见，我们先返回空列表或引发 NotImplementedError
#         # return litellm.encode(model=self.model, text=text) # 如果 litellm.encode 可用
#         raise NotImplementedError("get_token_ids is not implemented for this LiteLLM wrapper.")


def get_local_qwen_llm_instance(
    temperature: float = 0.7,
    max_tokens: int = 2048,
    # crewai_wrapper: bool = False # 是否返回 CrewAI 兼容的包装器
) -> Any: # 返回 Any 以便后续决定是直接返回配置字典还是包装器实例
    """
    获取配置好的本地 Qwen3 LLM 实例（通过 LiteLLM 调用）。
    """
    print(f"LLM Setup: Configuring Local Qwen LLM via LiteLLM.")
    print(f"  Model: {LOCAL_QWEN_MODEL_NAME_FOR_LITELLM}")
    print(f"  API Base: {LOCAL_QWEN_API_BASE}")
    # if crewai_wrapper:
    #     return LiteLLMWrapperForCrewAI(
    #         model=LOCAL_QWEN_MODEL_NAME_FOR_LITELLM,
    #         api_base=LOCAL_QWEN_API_BASE,
    #         api_key="nokey", # 本地服务通常不需要 key
    #         custom_llm_provider="openai", # 因为我们的本地服务是 OpenAI 兼容的
    #         temperature=temperature,
    #         max_tokens=max_tokens
    #     )
    # else:
    # 返回一个配置字典，调用方可以使用 litellm.completion(**config, messages=...)
    return {
        "model": LOCAL_QWEN_MODEL_NAME_FOR_LITELLM,
        "api_base": LOCAL_QWEN_API_BASE,
        "api_key": "nokey",
        "custom_llm_provider": "openai",
        "temperature": temperature,
        "max_tokens": max_tokens
    }


def get_cloud_gemini_llm_instance(
    temperature: float = 0.5,
    max_tokens: int = 4096,
    # crewai_wrapper: bool = False
) -> Any:
    """
    获取配置好的云端 Gemini LLM 实例（通过云端 LiteLLM 网关调用）。
    """
    print(f"LLM Setup: Configuring Cloud Gemini LLM via LiteLLM Gateway.")
    print(f"  Model: {GEMINI_MODEL_NAME_FOR_LITELLM}")
    print(f"  API Base (Gateway): {CLOUD_LITELLM_GW_API_BASE}")

    if CLOUD_LITELLM_GW_API_BASE == "YOUR_CLOUD_LITELLM_GATEWAY_URL_HERE/v1":
        print("LLM Setup WARNING: CLOUD_LITELLM_GW_API_BASE is not configured. Cloud LLM calls will likely fail.")
        # 可以选择返回 None 或者一个无效的配置，让调用方处理
        return None

    # if crewai_wrapper:
    #     return LiteLLMWrapperForCrewAI(
    #         model=GEMINI_MODEL_NAME_FOR_LITELLM,
    #         api_base=CLOUD_LITELLM_GW_API_BASE,
    #         # API Key 通常由云端 LiteLLM 网关管理，客户端调用网关时可能不需要直接提供
    #         # 或者网关本身可能需要某种形式的认证 key
    #         api_key=os.getenv("CLOUD_LITELLM_GATEWAY_API_KEY"), # 假设网关可能需要一个 key
    #         # custom_llm_provider 可能不需要，因为网关会处理到具体云服务的转换
    #         temperature=temperature,
    #         max_tokens=max_tokens
    #     )
    # else:
    return {
        "model": GEMINI_MODEL_NAME_FOR_LITELLM,
        "api_base": CLOUD_LITELLM_GW_API_BASE,
        "api_key": os.getenv("CLOUD_LITELLM_GATEWAY_API_KEY"), # 网关本身的key
        "temperature": temperature,
        "max_tokens": max_tokens
    }

# --- 示例用法 (可选，用于测试此文件) ---
async def main_test_llm_setup():
    print("--- Testing LLM Setup ---")

    print("\n--- Getting Local Qwen Config ---")
    local_qwen_config = get_local_qwen_llm_instance()
    if local_qwen_config:
        print(f"Local Qwen Config: {local_qwen_config}")
        # 模拟调用
        try:
            messages = [{"role": "user", "content": "你好！"}]
            print(f"Simulating LiteLLM call with local Qwen config for: {messages}")
            # response = await litellm.acompletion(**local_qwen_config, messages=messages)
            # print(f"Simulated local Qwen response (first choice): {response.choices[0].message.content if response.choices else 'No response'}")
            print("Actual LiteLLM call commented out for setup test.")
        except Exception as e:
            print(f"Error simulating local Qwen call: {e}")
    else:
        print("Failed to get local Qwen config.")

    print("\n--- Getting Cloud Gemini Config ---")
    cloud_gemini_config = get_cloud_gemini_llm_instance()
    if cloud_gemini_config:
        print(f"Cloud Gemini Config: {cloud_gemini_config}")
        if cloud_gemini_config.get("api_base") == "YOUR_CLOUD_LITELLM_GATEWAY_URL_HERE/v1":
            print("Skipping simulated cloud Gemini call as gateway URL is a placeholder.")
        else:
            try:
                messages = [{"role": "user", "content": "Hello!"}]
                print(f"Simulating LiteLLM call with cloud Gemini config for: {messages}")
                # response = await litellm.acompletion(**cloud_gemini_config, messages=messages)
                # print(f"Simulated cloud Gemini response (first choice): {response.choices[0].message.content if response.choices else 'No response'}")
                print("Actual LiteLLM call commented out for setup test.")
            except Exception as e:
                print(f"Error simulating cloud Gemini call: {e}")
    else:
        print("Failed to get cloud Gemini config (likely due to placeholder URL).")

if __name__ == "__main__":
    # 为了运行异步的 main_test_llm_setup
    # import asyncio
    # asyncio.run(main_test_llm_setup())
    pass
    --- END OF FILE CONTENT ---

  File: local_llm_service.py
    --- START OF FILE CONTENT ---
# /home/zhz/zhz_agent/local_llm_service.py
import os
import time
import uuid
import traceback
from contextlib import asynccontextmanager
from typing import List, Dict, Any, Optional, Union
import json # <--- 确保导入 json

import uvicorn
from fastapi import FastAPI, HTTPException
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
from llama_cpp import Llama # LlamaGrammar 不再需要从这里导入
import re

# --- 配置 ---
MODEL_DIR = os.getenv("LOCAL_LLM_MODEL_DIR", "/home/zhz/models/Qwen3-1.7B-GGUF")
MODEL_FILENAME = os.getenv("LOCAL_LLM_MODEL_FILENAME")
N_GPU_LAYERS = int(os.getenv("LOCAL_LLM_N_GPU_LAYERS", 0))
N_CTX = int(os.getenv("LOCAL_LLM_N_CTX", 4096))
N_BATCH = int(os.getenv("LOCAL_LLM_N_BATCH", 512))
SERVICE_PORT = int(os.getenv("LOCAL_LLM_SERVICE_PORT", 8088))
SERVICE_HOST = "0.0.0.0"

# --- 全局变量 ---
llama_model: Optional[Llama] = None
model_path_global: Optional[str] = None
# cypher_grammar: Optional[LlamaGrammar] = None # <--- 移除全局 GBNF 对象

# --- Pydantic 模型定义 (保持不变) ---
class ChatMessage(BaseModel):
    role: str
    content: str

class ChatCompletionRequest(BaseModel):
    model: str
    messages: List[ChatMessage]
    temperature: float = 0.7
    max_tokens: Optional[int] = 512 # 稍后可能需要调整这个默认值以容纳JSON输出
    stream: bool = False
    stop: Optional[Union[str, List[str]]] = None
    # 可以考虑在这里添加一个可选字段来控制是否使用JSON Schema约束，
    # 但 llama-cpp-python 的 create_chat_completion 的 response_format 参数是更标准的方式
    # use_cypher_json_schema: bool = False 

class ChatCompletionMessage(BaseModel):
    role: str
    content: Optional[str] = None # LLM的输出内容

class ChatCompletionChoice(BaseModel):
    index: int
    message: ChatCompletionMessage
    finish_reason: Optional[str] = "stop"

class UsageInfo(BaseModel):
    prompt_tokens: int
    completion_tokens: int
    total_tokens: int

class ChatCompletionResponse(BaseModel):
    id: str = Field(default_factory=lambda: f"chatcmpl-{uuid.uuid4().hex}")
    object: str = "chat.completion"
    created: int = Field(default_factory=lambda: int(time.time()))
    model: str
    choices: List[ChatCompletionChoice]
    usage: UsageInfo
    system_fingerprint: Optional[str] = None

# --- FastAPI 应用和生命周期管理 ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    global llama_model, model_path_global # <--- 移除 cypher_grammar
    print("--- Local LLM Service: Lifespan startup ---")

    model_file_to_load = MODEL_FILENAME
    if not model_file_to_load:
        try:
            gguf_files = [f for f in os.listdir(MODEL_DIR) if f.endswith(".gguf")]
            if not gguf_files:
                raise RuntimeError(f"No GGUF models found in {MODEL_DIR}")
            if len(gguf_files) > 1:
                print(f"Warning: Multiple GGUF models found in {MODEL_DIR}. Using the first one: {gguf_files[0]}")
            model_file_to_load = gguf_files[0]
        except FileNotFoundError:
            raise RuntimeError(f"Model directory not found: {MODEL_DIR}")

    model_path_global = os.path.join(MODEL_DIR, model_file_to_load)
    print(f"Attempting to load Llama model from: {model_path_global}")
    print(f"Parameters: n_gpu_layers={N_GPU_LAYERS}, n_ctx={N_CTX}, n_batch={N_BATCH}")

    try:
        llama_model = Llama(
            model_path=model_path_global,
            n_gpu_layers=N_GPU_LAYERS,
            n_ctx=N_CTX,
            n_batch=N_BATCH,
            verbose=True
        )
        print("Llama model loaded successfully.")
        # --- 移除 GBNF 文件加载逻辑 ---
    except Exception as e:
        print(f"FATAL: Failed to load Llama model: {e}")
        raise RuntimeError(f"Failed to load Llama model: {e}") from e
    
    yield
    
    print("--- Local LLM Service: Lifespan shutdown ---")

app = FastAPI(
    title="Local LLM Service (OpenAI Compatible)",
    description="Provides an OpenAI-compatible API for a locally hosted GGUF model via llama-cpp-python. Now supports JSON Schema output constraint.",
    version="0.1.1", # 版本更新
    lifespan=lifespan
)

# --- 辅助函数 (post_process_llm_output 保持不变) ---
def post_process_llm_output(content: Optional[str], finish_reason: Optional[str]) -> Optional[str]:
    # ... (此函数内容保持不变，它负责移除 <think> 标签)
    if content is None:
        return None
    print(f"DEBUG_POST_PROCESS: Input to post_process_llm_output:\n---\n{content}\n---")
    print(f"DEBUG_POST_PROCESS: Finish reason: {finish_reason}")
    processed_content = content
    think_block_pattern = re.compile(r"<think[^>]*>.*?</think>\s*", flags=re.DOTALL | re.IGNORECASE)
    processed_content = think_block_pattern.sub("", processed_content)
    print(f"DEBUG_POST_PROCESS: After think_block_pattern.sub:\n---\n{processed_content}\n---")
    if finish_reason == "length" and \
      re.match(r"<think[^>]*>", processed_content.strip(), flags=re.IGNORECASE) and \
      not re.search(r"</think\s*>", processed_content, flags=re.IGNORECASE):
        print("DEBUG_POST_PROCESS: Incomplete think block due to length, returning empty or placeholder.")
    stray_think_tag_pattern = re.compile(r"</?\s*think[^>]*?>\s*", flags=re.IGNORECASE)
    processed_content = stray_think_tag_pattern.sub("", processed_content)
    print(f"DEBUG_POST_PROCESS: After stray_think_tag_pattern.sub:\n---\n{processed_content}\n---")
    final_stripped_content = processed_content.strip()
    print(f"DEBUG_POST_PROCESS: After final strip:\n---\n{final_stripped_content}\n---")
    return final_stripped_content

# --- API 端点 ---
@app.post("/v1/chat/completions", response_model=ChatCompletionResponse)
async def create_chat_completion_endpoint(request: ChatCompletionRequest): # 函数名保持您的修改
    global llama_model, model_path_global # <--- 移除 cypher_grammar
    if llama_model is None:
        raise HTTPException(status_code=503, detail="Llama model is not loaded or failed to load.")

    if request.stream:
        raise HTTPException(status_code=400, detail="Streaming responses are not yet supported by this service.")

    # --- 定义我们期望的 JSON Schema (用于 Cypher 生成) ---
    # 这个 Schema 应该与 NEW_KG_SCHEMA_DESCRIPTION 中引导 LLM 输出的 JSON 结构一致
    CYPHER_OUTPUT_JSON_SCHEMA = {
        "type": "object",
        "properties": {
            "status": {"type": "string", "enum": ["success", "unable_to_generate"]},
            "query": {"type": "string"}, 
        },
        "required": ["status", "query"]
    }

    response_content_raw: Optional[str] = None
    # final_content_for_response: Optional[str] = None # 重命名以更清晰
    prompt_tokens = 0
    completion_tokens = 0
    total_tokens = 0
    finish_reason = "stop"
    
    request_model_name = request.model

    # --- Token 预估和超限检查 (可选但推荐) ---
    # 此处可以添加逻辑：
    # 1. 将 request.messages 转换为单个 prompt 字符串 (如果 llama_model.tokenize 需要)
    # 2. 调用 llama_model.tokenize() 获取输入 token 数
    # 3. 如果 prompt_tokens + request.max_tokens > N_CTX，则提前返回错误
    # 例如:
    # temp_prompt_str_for_token_count = convert_messages_to_prompt_for_token_count(request.messages) # 你需要实现这个函数
    # current_prompt_tokens = len(llama_model.tokenize(temp_prompt_str_for_token_count.encode('utf-8')))
    # if current_prompt_tokens + (request.max_tokens or llama_model.n_ctx_train() // 3 ) > N_CTX: # 粗略估计输出
    #     print(f"ERROR: Estimated tokens ({current_prompt_tokens} + ~{request.max_tokens}) exceed context window {N_CTX}")
    #     raise HTTPException(status_code=400, detail=f"Requested tokens ({current_prompt_tokens} + completion) would exceed context window of {N_CTX}")
    # --- 结束 Token 预估 ---

    if hasattr(llama_model, "create_chat_completion"):
        try:
            dict_messages = [msg.model_dump() for msg in request.messages]
            
            completion_params = {
                "messages": dict_messages,
                "temperature": request.temperature,
                "max_tokens": request.max_tokens or 512, # 确保有默认值
                "stop": request.stop,
            }

            # --- 关键修改：使用 response_format 参数 ---
            # 我们需要一种方式来判断当前请求是否是用于 Cypher 生成的，
            # 以便只在那种情况下应用 JSON Schema 约束。
            # 临时方案：检查 system prompt 是否包含特定的关键词。
            # 更好的方案：客户端（即 sglang_wrapper.py）在请求中添加一个额外参数。
            # 我们先假设，如果 prompt 包含 "KNOWLEDGE GRAPH SCHEMA (KuzuDB) & CYPHER GENERATION RULES"，
            # 那么它就是 Cypher 生成任务。
            is_cypher_gen_task = False
            if dict_messages and dict_messages[0]["role"] == "system":
                if "KNOWLEDGE GRAPH SCHEMA (KuzuDB) & CYPHER GENERATION RULES" in dict_messages[0]["content"]:
                    is_cypher_gen_task = True
            
            if is_cypher_gen_task:
                print("DEBUG_FastAPI: Detected Cypher generation task. Applying JSON Schema constraint.")
                completion_params["response_format"] = {
                    "type": "json_object",
                    "schema": CYPHER_OUTPUT_JSON_SCHEMA
                }
            else:
                print("DEBUG_FastAPI: Not a Cypher generation task (or schema keyword not found). Proceeding without JSON schema constraint.")

            print(f"DEBUG_FastAPI: Calling llama_model.create_chat_completion with params (excluding messages): { {k:v for k,v in completion_params.items() if k != 'messages'} }")
            completion = llama_model.create_chat_completion(**completion_params)
            
            response_content_raw = completion['choices'][0]['message']['content']
            # 对于JSON模式，response_content_raw 应该是一个JSON字符串
            print(f"DEBUG_FastAPI: Raw content from llama_model: '{response_content_raw}'")

            prompt_tokens = completion['usage']['prompt_tokens']
            completion_tokens = completion['usage']['completion_tokens']
            total_tokens = completion['usage']['total_tokens']
            finish_reason = completion['choices'][0].get('finish_reason', 'stop')

        except Exception as e:
            print(f"Error during llama_model.create_chat_completion: {e}")
            traceback.print_exc() # 打印完整堆栈
            raise HTTPException(status_code=500, detail=f"Error generating completion: {str(e)}")
    else:
        # ... (直接调用 llama_model() 的逻辑，如果需要保留，也应该考虑如何应用 JSON Schema 或 GBNF)
        # 对于 JSON Schema，它通常是 create_chat_completion 的特性。
        # 直接调用 llm() 可能不支持 response_format。
        # 因此，我们应该优先确保使用 create_chat_completion。
        print("CRITICAL_ERROR: llama_model.create_chat_completion method not found. This service relies on it.")
        raise HTTPException(status_code=500, detail="LLM service misconfiguration: create_chat_completion not available.")

    # post_process_llm_output 应该在尝试解析 JSON 之前，以移除可能存在的 <think> 标签
    final_content_for_response = post_process_llm_output(response_content_raw, finish_reason)
    
    # 如果是 Cypher 生成任务并且成功获取了 JSON，我们不需要进一步处理 final_content_for_response
    # 因为调用者 (sglang_wrapper.py) 会解析这个 JSON。
    # 如果不是 Cypher 生成任务，或者 JSON 解析失败（虽然理论上 GBNF/JSON Schema 会保证格式），
    # final_content_for_response 就是最终的文本。

    print(f"DEBUG_FastAPI: Final content to be returned to client: '{final_content_for_response}'")

    response_id = f"chatcmpl-{uuid.uuid4().hex}"
    created_time = int(time.time())
    
    effective_model_name = request_model_name
    if not effective_model_name and model_path_global:
        effective_model_name = model_path_global.split('/')[-1]
    elif not effective_model_name:
        effective_model_name = "local-llm-unknown"

    return ChatCompletionResponse(
        id=response_id,
        object="chat.completion",
        created=created_time,
        model=effective_model_name,
        choices=[
            ChatCompletionChoice(
                index=0,
                message=ChatCompletionMessage(role="assistant", content=final_content_for_response), # 返回清理后的内容
                finish_reason=finish_reason
            )
        ],
        usage=UsageInfo(
            prompt_tokens=prompt_tokens,
            completion_tokens=completion_tokens,
            total_tokens=total_tokens
        )
    )

# ... (@app.get("/v1/models") 和 if __name__ == "__main__": 部分保持不变) ...
@app.get("/v1/models", response_model=Dict[str, Any])
async def list_models():
    global model_path_global
    model_id_for_clients = "qwen3local"
    return {
        "object": "list",
        "data": [
            {
                "id": model_id_for_clients,
                "object": "model",
                "created": int(os.path.getctime(model_path_global)) if model_path_global and os.path.exists(model_path_global) else int(time.time()),
                "owned_by": "user",
            }
        ]
    }

if __name__ == "__main__":
    print(f"--- Starting Local LLM FastAPI Service on {SERVICE_HOST}:{SERVICE_PORT} ---")
    print(f"--- Model will be loaded from DIR: {MODEL_DIR}, FILE: {MODEL_FILENAME or 'Auto-detected GGUF'} ---")
    uvicorn.run(app, host=SERVICE_HOST, port=SERVICE_PORT) # 移除 reload=True，因为它在 __main__ 中通常用于开发，但在生产或由 mcpo 管理时可能不需要
    --- END OF FILE CONTENT ---

  File: project_snapshot.txt
    --- START OF FILE CONTENT ---
Project Root: /home/zhz/zhz_agent
--- Project Structure and File Contents ---

Directory: /home/zhz/zhz_agent/
  File (skipped, extension not included): .env
  File (skipped, extension not included): .envrc
  File (skipped, extension not included): .gitignore
  File: README.md
    --- START OF FILE CONTENT ---
# zhz_agent
后端：RAG增强+多agent+dagster

    --- END OF FILE CONTENT ---

  File: __init__.py
    --- File is empty ---

  File: agent_orchestrator_service.py
    --- START OF FILE CONTENT ---
# /home/zhz/zhz_agent/agent_orchestrator_service.py

import os
import asyncio
import traceback
import json
from typing import List, Dict, Any, Optional, Union
from contextlib import asynccontextmanager
import re
import uvicorn
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from datetime import datetime 

# --- CrewAI ---
from crewai import Agent, Task, Crew, Process
from crewai.tools import BaseTool

# --- 自定义模块导入 ---
from core.llm_manager import get_llm_instance, CustomLiteLLMWrapper

# --- 导入我们新创建的工具 ---
from core.tools.enhanced_rag_tool import EnhancedRAGTool
from core.tools.excel_tool import ExcelOperationTool
from core.tools.search_tool import WebSearchTool

# --- 配置 ---
AGENT_SERVICE_PORT = int(os.getenv("AGENT_SERVICE_PORT", 8090))
AGENT_SERVICE_HOST = "0.0.0.0"

# --- Pydantic 模型定义 ---
# 沿用之前的 AgentTaskRequest 和 AgentTaskResponse
class AgentTaskRequest(BaseModel):
    user_query: str = Field(description="用户的原始文本查询。")

class AgentTaskResponse(BaseModel):
    answer: str = Field(description="Agent 系统生成的最终答案或响应。")
    status: str = Field(default="success", description="执行状态: 'success', 'needs_clarification', 'error', 'processing_plan', 'task_created'.")
    intermediate_plan: Optional[Dict[str, Any]] = Field(None, description="如果status是'processing_plan', 这里包含Manager Agent的规划结果。")
    task_id: Optional[str] = Field(None, description="如果任务是异步的，返回任务ID。")
    error_message: Optional[str] = Field(None, description="如果发生错误，此字段包含错误信息。")
    debug_info: Optional[Dict[str, Any]] = Field(None, description="包含执行过程中的调试信息。")
    token_usage: Optional[Dict[str, Any]] = Field(None, description="LLM token 使用情况统计。")

# 与 zhzai-agent/models.py 中 SubTaskDefinition 一致的结构，用于 Manager Agent 的输出
class SubTaskDefinitionForManagerOutput(BaseModel):
    task_description: str = Field(description="用户的原始请求原文。")
    reasoning_for_plan: Optional[str] = Field(None, description="Manager Agent的决策思考过程。")
    selected_tool_names: List[str] = Field(description="选定的工具名称列表。如果直接回答，则为空列表。")
    direct_answer_content: Optional[str] = Field(None, description="如果选择直接回答，这里是答案内容。")
    tool_input_args: Optional[Dict[str, Any]] = Field(None, description="如果选择使用非Excel工具，这里是传递给该工具的参数。")
    excel_sqo_payload: Optional[List[Dict[str, Any]]] = Field(None, description="如果选择使用Excel工具，这里是SQO操作字典的列表。")


# --- 全局变量 ---
manager_llm: Optional[CustomLiteLLMWrapper] = None
worker_llm: Optional[CustomLiteLLMWrapper] = None
manager_agent_instance: Optional[Agent] = None
worker_agent_instance: Optional[Agent] = None

core_tools_instances: List[BaseTool] = [] # BaseTool 是 CrewAI 工具的基类

# 我们新的核心工具名称 (与 zhzai-agent 不同)
CORE_TOOLS_ZHZ_AGENT = {
    "enhanced_rag_tool": "【核心RAG工具】用于从本地知识库查找信息、回答复杂问题，整合了向量、关键词和图谱检索。",
    "excel_operation_tool": "【Excel操作工具】通过结构化查询对象(SQO)对Excel文件执行复杂的数据查询、筛选、聚合等操作。",
    "web_search_tool": "【网络搜索工具】使用DuckDuckGo搜索引擎在互联网上查找与用户查询相关的信息。"
}
CORE_TOOL_NAMES_LIST = list(CORE_TOOLS_ZHZ_AGENT.keys())

# 将工具描述格式化为字符串，供Manager Prompt使用
TOOL_OPTIONS_STR_FOR_MANAGER = "\n".join(
    [f"- '{name}': {desc}" for name, desc in CORE_TOOLS_ZHZ_AGENT.items()]
)


@asynccontextmanager
async def lifespan(app: FastAPI):
    global manager_llm, worker_llm, manager_agent_instance, worker_agent_instance, core_tools_instances
    print("--- Agent Orchestrator Service: Lifespan startup ---")

    # --- 步骤 1: 初始化 LLM 实例 (保持不变) ---
    print("Initializing LLM instances...")
    try:
        gemini_tool_config = {"function_calling_config": {"mode": "AUTO"}}
        manager_llm = get_llm_instance(
            llm_type="cloud_gemini", temperature=0.1, max_tokens=4096, tool_config=gemini_tool_config
        )
        if not manager_llm:
            print("Failed to initialize Manager LLM (Cloud Gemini). Attempting fallback...")
            manager_llm = get_llm_instance(
                llm_type="local_qwen", temperature=0.1, max_tokens=3072, tool_config=gemini_tool_config
            )
        
        worker_llm = get_llm_instance(llm_type="local_qwen", temperature=0.6, max_tokens=3072)

        if manager_llm: print(f"Manager LLM initialized: {manager_llm.model_name}")
        else: print("CRITICAL: Failed to initialize Manager LLM.")
        if worker_llm: print(f"Worker LLM initialized: {worker_llm.model_name}")
        else: print("CRITICAL: Failed to initialize Worker LLM.")
    except Exception as e:
        print(f"FATAL ERROR during LLM initialization: {e}", exc_info=True)
        manager_llm = None; worker_llm = None

    # --- 步骤 2: 初始化核心工具实例 ---
    print("Initializing core tool instances...")
    try:
        enhanced_rag_tool_instance = EnhancedRAGTool()
        excel_operation_tool_instance = ExcelOperationTool()
        web_search_tool_instance = WebSearchTool()
        
        core_tools_instances = [
            enhanced_rag_tool_instance,
            excel_operation_tool_instance,
            web_search_tool_instance,
        ]
        print(f"Core tools initialized: {[tool.name for tool in core_tools_instances]}")
    except Exception as e:
        print(f"ERROR during core tool initialization: {e}", exc_info=True)
        core_tools_instances = []

    # 初始化 Agent 实例
    if manager_llm:
        manager_agent_instance = Agent(
            role='资深AI任务分解与Excel查询规划师 (Senior AI Task Decomposition and Excel Query Planner)',
            goal=f"""【深入理解并分解】用户提出的复杂请求 (当前请求将通过任务描述提供) 成为一系列逻辑子任务。
【核心决策1 - 优先自主回答】：在选择任何工具之前，请首先判断你是否能基于自身知识库和推理能力【直接回答】用户的全部或核心部分请求。如果可以，你的主要输出应是包含直接答案的JSON。
【核心决策2 - Excel复杂查询处理】：如果用户的请求涉及到对Excel文件进行一个或多个复杂的数据查询、筛选、聚合或排序等操作，并且你无法直接回答，你【必须】选择 "{CORE_TOOL_NAMES_LIST[CORE_TOOL_NAMES_LIST.index('excel_operation_tool')]}" 工具。并且，你【必须】为这些Excel操作【构建一个结构化查询对象 (SQO) 的JSON列表】，并将其作为输出JSON中 `excel_sqo_payload` 字段的值。列表中的【每一个SQO字典】都需要包含一个明确的 "operation_type" 和该操作对应的参数，但【不要包含 "file_path" 或 "sheet_name"】。
【核心决策3 - 其他工具选择】：如果需要从本地知识库获取深度信息，选择 "{CORE_TOOL_NAMES_LIST[CORE_TOOL_NAMES_LIST.index('enhanced_rag_tool')]}"。如果需要网络实时信息，选择 "{CORE_TOOL_NAMES_LIST[CORE_TOOL_NAMES_LIST.index('web_search_tool')]}"。选择工具后，你需要准备好传递给该工具的参数，并将其放在输出JSON的 `tool_input_args` 字段中。
【核心决策4 - 通用请求/无适用工具】：如果用户请求是生成通用文本、编写简单代码、回答一般性知识问题，并且你已判断可以【直接回答】，则无需选择任何特定功能性工具。此时输出JSON中 `selected_tool_names` 应为空列表，`excel_sqo_payload` 和 `tool_input_args` 为null，答案内容在 `direct_answer_content` 字段。

最终，【严格按照指定的JSON格式】（即符合 `SubTaskDefinitionForManagerOutput` Pydantic模型）输出一个包含你的决策理由、用户原始请求、以及根据你的决策填充的 `direct_answer_content` 或 `selected_tool_names`、`tool_input_args`、`excel_sqo_payload` 的对象。

【可供选择的本系统核心工具及其描述】:
{TOOL_OPTIONS_STR_FOR_MANAGER}
""",
            backstory="""我是一位经验丰富的AI任务调度官和数据查询规划专家。我的核心工作流程如下：
1.  **【深度理解与CoD规划 (内部进行)】**：我会对用户请求进行彻底分析，优先判断是否能直接利用我的知识库和推理能力给出完整答案。
2.  **【工具选择与参数准备（如果无法直接回答）】**：
    a.  **Excel复杂查询**: 当识别出需要对Excel执行复杂操作时，我选择 "{CORE_TOOL_NAMES_LIST[CORE_TOOL_NAMES_LIST.index('excel_operation_tool')]}" 工具，并为其生成包含多个SQO操作定义的【JSON列表】作为 `excel_sqo_payload`。每个SQO包含 `operation_type` 和所需参数，但不含 `file_path` 或 `sheet_name`。
    b.  **RAG查询**: 若需从知识库获取信息，选择 "{CORE_TOOL_NAMES_LIST[CORE_TOOL_NAMES_LIST.index('enhanced_rag_tool')]}"，并准备 `tool_input_args`（例如 `{{ "query": "用户原始问题", "top_k_vector": 5, ... }}`）。
    c.  **网络搜索**: 若需实时网络信息，选择 "{CORE_TOOL_NAMES_LIST[CORE_TOOL_NAMES_LIST.index('web_search_tool')]}"，并准备 `tool_input_args`（例如 `{{ "query": "搜索关键词" }}`）。
    d.  **最简必要原则**: 只选择绝对必要的工具。
3.  **【严格的输出格式】**: 我的唯一输出是一个JSON对象，该对象必须符合本服务定义的 `SubTaskDefinitionForManagerOutput` Pydantic模型结构，包含 `task_description` (用户原始请求), `reasoning_for_plan`, 以及根据决策填充的 `selected_tool_names` (可为空), `direct_answer_content` (如果直接回答), `tool_input_args` (如果使用非Excel工具), 和 `excel_sqo_payload` (如果使用Excel工具)。

我【不】自己执行任何工具操作。我的职责是精准规划并输出结构化的任务定义。""",
            llm=manager_llm,
            verbose=True,
            allow_delegation=False,
            tools=[]
        )
        print(f"Manager Agent initialized with LLM: {manager_llm.model_name}")

    if worker_llm:
        # Worker Agent 现在拥有所有核心工具
        worker_agent_instance = Agent(
            role='任务执行专家 (Task Execution Expert)',
            goal="根据Manager分配的具体任务描述和指定的工具，高效地执行任务并提供结果。",
            backstory="""我是一个AI执行者，专注于使用【Manager明确授权给我的工具】来解决问题。
                        我会严格遵循任务指令。如果任务是调用Excel工具并提供了SQO列表，我会按顺序迭代处理这些SQO，并整合结果。
                        我会使用工具的名称（例如 'enhanced_rag_tool', 'excel_operation_tool', 'web_search_tool'）来调用它们。""",
            llm=worker_llm,
            verbose=True,
            allow_delegation=False,
            tools=core_tools_instances # <--- 将实例化的工具列表传递给 Worker Agent
        )
        print(f"Worker Agent initialized with LLM: {worker_llm.model_name} and tools: {[t.name for t in core_tools_instances]}")

    if not manager_agent_instance or not worker_agent_instance:
        print("CRITICAL: One or more core agents failed to initialize. Service functionality will be severely limited.")
    elif not core_tools_instances and worker_agent_instance : # 如果 Worker Agent 初始化了但没有工具
        print("WARNING: Worker Agent initialized, but no core tools were successfully instantiated. Tool-based tasks will fail.")

    print("--- Agent Orchestrator Service: Lifespan startup complete ---")
    yield
    print("--- Agent Orchestrator Service: Lifespan shutdown ---")

app = FastAPI(
    title="Agent Orchestrator Service",
    description="接收用户请求，通过Manager/Worker Agent模型进行任务规划和执行。",
    version="0.1.1", # 版本更新
    lifespan=lifespan
)

@app.post("/v1/execute_task", response_model=AgentTaskResponse)
async def execute_task_endpoint(request: AgentTaskRequest):
    global manager_agent_instance, worker_agent_instance, core_tools_instances # 确保能访问全局 Agent 和工具实例
    
    print(f"Received agent task request: User Query='{request.user_query}'") # 使用 print 替代 logger

    if not manager_agent_instance or not worker_agent_instance:
        print("CRITICAL ERROR: Core agents are not initialized. Cannot process task.")
        raise HTTPException(status_code=503, detail="Service not ready: Core agents failed to initialize.")
    if not core_tools_instances:
        print("WARNING: Core tools are not initialized. Tool-based tasks may fail.")
    # --- 构建 Manager Task 的描述 ---
    # 我们将用户请求和可用的核心工具列表传递给 Manager Agent
    # Manager Agent 的 goal 和 backstory 已经包含了大部分指令
    # Task 的 description 主要用于传递动态信息，如当前用户查询
    manager_task_description_for_crewai = f"""
    请仔细分析以下用户请求：
    '{request.user_query}'

    你的目标是：
    1.  理解用户的核心意图。
    2.  **优先判断**：你能否基于你现有的知识直接、准确地回答这个问题？
        - 如果是，请在输出的JSON中填充 `direct_answer_content` 字段，并将 `selected_tool_names` 设为空列表。
    3.  **如果不能直接回答**：判断解决这个问题最核心的工具是什么。从你已知的核心工具 ({', '.join(CORE_TOOL_NAMES_LIST)}) 中选择【一个或多个必要】工具。
    4.  如果选择了 '{CORE_TOOL_NAMES_LIST[CORE_TOOL_NAMES_LIST.index('excel_operation_tool')]}'，请为Excel操作构建一个或多个SQO的【列表】，并将其放入 `excel_sqo_payload` 字段。
    5.  如果选择了其他工具（如 '{CORE_TOOL_NAMES_LIST[CORE_TOOL_NAMES_LIST.index('enhanced_rag_tool')]}' 或 '{CORE_TOOL_NAMES_LIST[CORE_TOOL_NAMES_LIST.index('web_search_tool')]}'），请准备好传递给该工具的参数，并将其放入 `tool_input_args` 字段。
    6.  严格按照 `SubTaskDefinitionForManagerOutput` 的JSON格式输出你的规划。`task_description` 字段必须是用户的原始请求原文: '{request.user_query}'。同时提供你的 `reasoning_for_plan`。
    """
    
    # --- Manager Task 的期望输出格式说明 ---
    # 这个 expected_output 对于指导LLM以正确的JSON格式返回至关重要
    manager_task_expected_output_description = f"""一个JSON对象，必须严格符合以下Pydantic模型的结构（你不需要输出 "SubTaskDefinitionForManagerOutput" 这个词本身）：
    {{
      "task_description": "string (固定为用户的原始请求: '{request.user_query}')",
      "reasoning_for_plan": "string (你的决策思考过程)",
      "selected_tool_names": ["list of strings (选定的工具名称列表。如果直接回答，则为空列表)"],
      "direct_answer_content": "string (可选, 仅当 selected_tool_names 为空列表时，这里是你的答案内容)",
      "tool_input_args": {{ "key": "value" }} (可选, 仅当 selected_tool_names 包含非Excel工具时，这里是给该工具的参数字典),
      "excel_sqo_payload": "[{{...}}, {{...}}] (可选, 仅当 selected_tool_names 包含'{CORE_TOOL_NAMES_LIST[CORE_TOOL_NAMES_LIST.index('excel_operation_tool')]}'时，这里是SQO操作字典的列表)"
    }}

    【重要输出规则】:
    - 如果你选择【直接回答】：`selected_tool_names` 必须是空列表 `[]`，`direct_answer_content` 必须包含你的答案，`tool_input_args` 和 `excel_sqo_payload` 应该为 `null` 或不存在。
    - 如果你选择使用【非Excel工具】(例如 RAG 或 Web Search)：`selected_tool_names` 必须包含该工具的名称，`direct_answer_content` 应该为 `null` 或不存在，`tool_input_args` 必须包含调用该工具所需的参数 (例如 `{{ "query": "{request.user_query}" }}` )，`excel_sqo_payload` 应该为 `null` 或不存在。
    - 如果你选择使用【Excel工具】 ('{CORE_TOOL_NAMES_LIST[CORE_TOOL_NAMES_LIST.index('excel_operation_tool')]}')：`selected_tool_names` 必须包含 `"{CORE_TOOL_NAMES_LIST[CORE_TOOL_NAMES_LIST.index('excel_operation_tool')]}"`，`direct_answer_content` 和 `tool_input_args` 应该为 `null` 或不存在，`excel_sqo_payload` 【必须】包含一个SQO操作定义的列表。

    示例输出 (直接回答):
    {{
      "task_description": "{request.user_query}",
      "reasoning_for_plan": "这是一个常识性问题，我可以根据我的内部知识直接回答。",
      "selected_tool_names": [],
      "direct_answer_content": "中国的首都是北京。",
      "tool_input_args": null,
      "excel_sqo_payload": null
    }}

    示例输出 (使用RAG工具):
    {{
      "task_description": "{request.user_query}",
      "reasoning_for_plan": "用户询问关于公司政策的问题，这需要从知识库中查找。",
      "selected_tool_names": ["{CORE_TOOL_NAMES_LIST[CORE_TOOL_NAMES_LIST.index('enhanced_rag_tool')]}"],
      "direct_answer_content": null,
      "tool_input_args": {{"query": "{request.user_query}", "top_k_vector": 5, "top_k_kg": 3, "top_k_bm25": 3}},
      "excel_sqo_payload": null
    }}
    
    示例输出 (使用Excel工具，假设用户问“test.xlsx中有哪些区域以及每个区域的平均销售额”):
    {{
      "task_description": "test.xlsx中有哪些区域以及每个区域的平均销售额",
      "reasoning_for_plan": "用户需要从Excel文件中获取唯一区域列表，并对销售额按区域进行聚合计算平均值。这需要两个SQO操作。",
      "selected_tool_names": ["{CORE_TOOL_NAMES_LIST[CORE_TOOL_NAMES_LIST.index('excel_operation_tool')]}"],
      "direct_answer_content": null,
      "tool_input_args": null, 
      "excel_sqo_payload": [
        {{
          "operation_type": "get_unique_values",
          "parameters": {{ "column_name": "区域" }}
        }},
        {{
          "operation_type": "group_by_aggregate",
          "parameters": {{ "group_by_columns": ["区域"], "aggregation_column": "销售额", "aggregation_function": "mean" }}
        }}
      ]
    }}
    请严格按照此JSON格式输出。
    """

    manager_task = Task(
        description=manager_task_description_for_crewai,
        expected_output=manager_task_expected_output_description,
        agent=manager_agent_instance,
        async_execution=False,
        output_pydantic=SubTaskDefinitionForManagerOutput
    )

    # --- 步骤 2: 执行 Manager Task ---
    print("Executing Manager Task...")
    manager_plan_object: Optional[SubTaskDefinitionForManagerOutput] = None
    manager_raw_output: Optional[str] = None

    try:
        manager_crew = Crew(
            agents=[manager_agent_instance],
            tasks=[manager_task],
            process=Process.sequential,
            verbose=True 
        )
        print(f"[{datetime.now()}] About to call manager_crew.kickoff()...") # <--- 添加日志
        manager_task_raw_result = manager_crew.kickoff(inputs={})
        print(f"[{datetime.now()}] manager_crew.kickoff() returned.") # <--- 添加日志

        # --- 新的解析逻辑，处理 CrewOutput ---
        actual_task_output: Optional[Any] = None # 用于存储实际的 TaskOutput 或字符串

        if hasattr(manager_task_raw_result, 'tasks_output') and isinstance(manager_task_raw_result.tasks_output, list) and manager_task_raw_result.tasks_output:
            # CrewOutput.tasks_output 是一个 TaskOutput 对象的列表
            actual_task_output = manager_task_raw_result.tasks_output[0] # 我们只有一个 manager_task
            print(f"Extracted TaskOutput from CrewOutput: {type(actual_task_output)}")
        elif hasattr(manager_task_raw_result, 'raw_output'): # 兼容直接返回 TaskOutput 的情况 (旧版或特定配置)
            actual_task_output = manager_task_raw_result
            print(f"kickoff returned a TaskOutput-like object directly: {type(actual_task_output)}")
        elif isinstance(manager_task_raw_result, str): # 直接返回字符串
            actual_task_output = manager_task_raw_result
            print(f"kickoff returned a raw string.")
        else:
            print(f"Warning: manager_crew.kickoff() returned an unexpected type: {type(manager_task_raw_result)}")
            actual_task_output = str(manager_task_raw_result)
        # --- 结束新的解析逻辑 ---


        # --- 后续的解析逻辑，现在基于 actual_task_output ---
        print(f"DEBUG: Type of actual_task_output: {type(actual_task_output)}")
        
        manager_raw_llm_output_str: Optional[str] = None
        if hasattr(actual_task_output, 'raw') and isinstance(actual_task_output.raw, str):
            manager_raw_llm_output_str = actual_task_output.raw.strip()
            print(f"DEBUG: actual_task_output.raw (LLM's original string output) IS:\n---\n{manager_raw_llm_output_str}\n---")
        else:
            print(f"DEBUG: actual_task_output.raw is not a string or does not exist. Value: {getattr(actual_task_output, 'raw', 'Attribute .raw not found')}")
            manager_raw_llm_output_str = str(actual_task_output) # Fallback

        # 优先尝试使用 CrewAI 已经解析好的 Pydantic 对象
        if hasattr(actual_task_output, 'pydantic_output') and \
           actual_task_output.pydantic_output is not None and \
           isinstance(actual_task_output.pydantic_output, SubTaskDefinitionForManagerOutput):
            print("DEBUG: Successfully using actual_task_output.pydantic_output.")
            manager_plan_object = actual_task_output.pydantic_output
        
        # 如果 Pydantic 对象不可用，但我们从 .raw 成功获取了字符串，则尝试解析它
        # 并且确保 manager_plan_object 之前没有被成功赋值
        elif manager_plan_object is None and manager_raw_llm_output_str: # <--- 添加 manager_plan_object is None 条件
            print(f"DEBUG: pydantic_output not available. Attempting to parse string from actual_task_output.raw:\n---\n{manager_raw_llm_output_str}\n---")
            json_to_parse_from_raw = manager_raw_llm_output_str # 使用我们从 .raw 获取的
            try:
                final_answer_marker = "## Final Answer:" # 虽然日志显示Qwen没输出这个，但保留以防万一
                if final_answer_marker in json_to_parse_from_raw:
                    json_to_parse_from_raw = json_to_parse_from_raw.split(final_answer_marker, 1)[-1].strip()
                
                cleaned_json_str = json_to_parse_from_raw.strip()
                if cleaned_json_str.startswith("```json"): cleaned_json_str = cleaned_json_str[len("```json"):].strip()
                if cleaned_json_str.endswith("```"): cleaned_json_str = cleaned_json_str[:-len("```")].strip()
                
                if not cleaned_json_str: raise ValueError("Cleaned JSON string (from .raw) is empty.")
                manager_plan_object = SubTaskDefinitionForManagerOutput(**json.loads(cleaned_json_str))
                print(f"Parsed Manager Plan (from actual_task_output.raw): {manager_plan_object.model_dump_json(indent=2)}")
            except (json.JSONDecodeError, ValueError, Exception) as e:
                print(f"Error parsing JSON from actual_task_output.raw: {e}. Raw content used: {json_to_parse_from_raw}")
        
        # 在所有尝试之后，如果 manager_plan_object 仍然是 None，才报告最终的解析失败
        if not manager_plan_object:
             # manager_raw_output 现在应该引用我们尝试过的 manager_raw_llm_output_str
             final_raw_output_for_debug = manager_raw_llm_output_str if manager_raw_llm_output_str else str(actual_task_output)
             print(f"Manager Task did not produce a valid Pydantic object after all attempts. Final Raw for debug: {final_raw_output_for_debug}")
             return AgentTaskResponse(answer="无法解析Manager Agent的规划结果。", status="error",
                                      error_message="Failed to parse manager plan after all attempts.",
                                      debug_info={"manager_raw_output_tried": final_raw_output_for_debug})
        
        # 如果 manager_plan_object 成功解析，则打印日志（这行已经在您的代码中）
        print(f"Parsed Manager Plan: {manager_plan_object.model_dump_json(indent=2)}")
        
    except Exception as e:
        print(f"Error executing Manager Task or its Crew: {e}") # <--- 修改后的第一行
        traceback.print_exc() # <--- 修改后的第二行
        return AgentTaskResponse(
            answer="执行Manager Agent任务时发生错误。", status="error", error_message=str(e),
            debug_info={"traceback": traceback.format_exc(), "manager_raw_output": manager_raw_output}
        )

    # --- 步骤 2: 根据 Manager 的规划执行后续操作 ---
    if not manager_plan_object.selected_tool_names and manager_plan_object.direct_answer_content:
        print(f"Manager decided to answer directly. Answer: {manager_plan_object.direct_answer_content}")
        return AgentTaskResponse(
            answer=manager_plan_object.direct_answer_content,
            status="success",
            debug_info={"manager_plan": manager_plan_object.model_dump()}
        )
    elif not manager_plan_object.selected_tool_names and not manager_plan_object.direct_answer_content:
        # 如果 Manager 既没有选择工具，也没有提供直接答案，这可能是一个规划错误
         print(f"Manager Warning: No tool selected and no direct answer provided. Reasoning: {manager_plan_object.reasoning_for_plan}")
         return AgentTaskResponse(
            answer=manager_plan_object.reasoning_for_plan or "Manager 未能提供明确的行动计划或答案。",
            status="success", # 或者 "error" 取决于您如何定义这种情况
            debug_info={"manager_plan": manager_plan_object.model_dump()}
        )

    # --- 步骤 3: 如果 Manager 规划使用工具，则创建并执行 Worker Task ---
    selected_tool_name = manager_plan_object.selected_tool_names[0] if manager_plan_object.selected_tool_names else None

    if not selected_tool_name:
        return AgentTaskResponse(
            answer="Manager规划使用工具但未在selected_tool_names中指定工具名称。", status="error",
            error_message="Tool name missing in manager plan's selected_tool_names.",
            debug_info={"manager_plan": manager_plan_object.model_dump()}
        )

    # 找到对应的工具实例
    tool_instance_for_worker = next((tool for tool in core_tools_instances if tool.name == selected_tool_name), None)

    if not tool_instance_for_worker:
        return AgentTaskResponse(
            answer=f"系统中未找到Manager规划使用的工具: {selected_tool_name}。", status="error",
            error_message=f"Tool '{selected_tool_name}' not found in core_tools_instances.",
            debug_info={"manager_plan": manager_plan_object.model_dump(), "available_tools": [t.name for t in core_tools_instances]}
        )

    print(f"Manager planned to use tool: {selected_tool_name}. Instance found: {tool_instance_for_worker is not None}")

    worker_task_description = ""
    worker_task_inputs = {} # 用于传递给 task.execute(inputs=...)

    if selected_tool_name == "enhanced_rag_tool":
        rag_query = manager_plan_object.tool_input_args.get("query", request.user_query) if manager_plan_object.tool_input_args else request.user_query
        top_k_v = manager_plan_object.tool_input_args.get("top_k_vector", 5) if manager_plan_object.tool_input_args else 5
        top_k_kg = manager_plan_object.tool_input_args.get("top_k_kg", 3) if manager_plan_object.tool_input_args else 3
        top_k_b = manager_plan_object.tool_input_args.get("top_k_bm25", 3) if manager_plan_object.tool_input_args else 3
        
        worker_task_description = f"请使用增强RAG工具回答以下问题：'{rag_query}'。\n使用以下参数进行检索：top_k_vector={top_k_v}, top_k_kg={top_k_kg}, top_k_bm25={top_k_b}。"
        worker_task_inputs = {
            "query": rag_query, 
            "top_k_vector": top_k_v, 
            "top_k_kg": top_k_kg, 
            "top_k_bm25": top_k_b
        }

    elif selected_tool_name == "excel_operation_tool":
        excel_sqo_list = manager_plan_object.excel_sqo_payload
        if not excel_sqo_list:
            return AgentTaskResponse(
                answer="Manager选择Excel工具但未提供SQO列表。", status="error",
                error_message="excel_sqo_payload is missing for excel_operation_tool.",
                debug_info={"manager_plan": manager_plan_object.model_dump()}
            )
        
        # TODO: 从用户原始请求 manager_plan_object.task_description 中提取 file_path 和 sheet_name
        # 这里我们先用一个占位符/默认值，您需要实现提取逻辑
        # 例如，使用正则表达式从 manager_plan_object.task_description 查找文件路径
        # file_path_match = re.search(r"文件\s*['\"]?([^'\"]+\.(?:xlsx|xls|csv))['\"]?", manager_plan_object.task_description)
        # excel_file_path = file_path_match.group(1) if file_path_match else "YOUR_DEFAULT_TEST_EXCEL_PATH.xlsx"
        excel_file_path = "/home/zhz/zhz_agent/data/test.xlsx" # 临时硬编码，后续需要动态获取
        excel_sheet_name: Union[str, int] = 0 # 临时硬编码

        worker_task_description = (
            f"你需要处理一个Excel文件相关的任务。文件路径是 '{excel_file_path}'，工作表是 '{excel_sheet_name}'。\n"
            f"请严格按照以下SQO操作列表，顺序执行每一个操作，并整合所有操作的结果形成最终答案。\n"
            f"SQO操作列表: {json.dumps(excel_sqo_list, ensure_ascii=False)}\n\n"
            f"对于列表中的每一个SQO字典，你需要调用 '{tool_instance_for_worker.name}' 工具一次，"
            f"将该SQO字典作为 'sqo_dict' 参数，同时传递 'file_path': '{excel_file_path}' 和 'sheet_name': '{excel_sheet_name}'。"
        )
        # Worker Task的inputs将是整个SQO列表以及文件和工作表信息
        # Worker Agent的Prompt需要指导它如何迭代处理这个列表
        worker_task_inputs = {
            "excel_sqo_list_to_execute": excel_sqo_list,
            "target_excel_file_path": excel_file_path,
            "target_excel_sheet_name": excel_sheet_name
        }
        
    elif selected_tool_name == "web_search_tool":
        search_query = manager_plan_object.tool_input_args.get("query", request.user_query) if manager_plan_object.tool_input_args else request.user_query
        max_results = manager_plan_object.tool_input_args.get("max_results", 5) if manager_plan_object.tool_input_args else 5

        worker_task_description = f"请使用网络搜索工具查找关于 '{search_query}' 的信息，返回最多 {max_results} 条结果。"
        worker_task_inputs = {"query": search_query, "max_results": max_results}
        
    else:
        return AgentTaskResponse(
            answer=f"未知的工具名称 '{selected_tool_name}' 被Manager规划。", status="error",
            error_message=f"Unknown tool '{selected_tool_name}' planned by manager.",
            debug_info={"manager_plan": manager_plan_object.model_dump()}
        )

    # 创建 Worker Task
    worker_task = Task(
        description=worker_task_description,
        expected_output="任务的执行结果，通常是一个字符串，其中包含答案或操作的状态。",
        agent=worker_agent_instance,
        tools=[tool_instance_for_worker], # 只给 Worker 当前任务需要的工具
        async_execution=False # Worker Task 通常也是同步的
    )

    print(f"Executing Worker Task with tool: {selected_tool_name}")
    print(f"Worker Task Description: {worker_task_description}")
    print(f"Worker Task Inputs: {worker_task_inputs}")
    
    worker_final_result: str = ""
    try:
        # 如果 worker_task_inputs 为空，则不传递 inputs 参数
        task_execution_args = {}
        if worker_task_inputs:
            task_execution_args['inputs'] = worker_task_inputs
            
        worker_output = worker_task.execute(**task_execution_args)

        if isinstance(worker_output, str):
            worker_final_result = worker_output
        elif hasattr(worker_output, 'raw_output'): # CrewAI 0.30.0+
            worker_final_result = worker_output.raw_output
        elif hasattr(worker_output, 'raw'): # Older CrewAI
            worker_final_result = worker_output.raw
        else:
            worker_final_result = str(worker_output)
            
        print(f"Worker Task executed. Result: {worker_final_result}")
        
        # (可选) 获取 Worker Crew 的 token usage
        worker_token_usage = None
        if hasattr(worker_task, 'agent') and hasattr(worker_task.agent, 'crew') and worker_task.agent.crew and hasattr(worker_task.agent.crew, 'usage_metrics'):
             worker_token_usage = worker_task.agent.crew.usage_metrics
             print(f"Worker Crew token usage: {worker_token_usage}")


        return AgentTaskResponse(
            answer=worker_final_result,
            status="success",
            debug_info={
                "manager_plan": manager_plan_object.model_dump(),
                "worker_tool_used": selected_tool_name,
                "worker_task_inputs": worker_task_inputs
            },
            token_usage=worker_token_usage.model_dump() if worker_token_usage else None
        )

    except Exception as e:
        print(f"Error executing Worker Task for tool {selected_tool_name}: {e}", exc_info=True)
        return AgentTaskResponse(
            answer=f"执行工具 '{selected_tool_name}' 时发生错误。",
            status="error",
            error_message=str(e),
            debug_info={
                "manager_plan": manager_plan_object.model_dump(),
                "worker_tool_used": selected_tool_name,
                "worker_task_inputs": worker_task_inputs,
                "traceback": traceback.format_exc()
            }
        )

if __name__ == "__main__":
    print(f"--- Starting Agent Orchestrator FastAPI Service on {AGENT_SERVICE_HOST}:{AGENT_SERVICE_PORT} ---")
    uvicorn.run("agent_orchestrator_service:app", host=AGENT_SERVICE_HOST, port=AGENT_SERVICE_PORT, reload=True) # 确保模块名正确
    --- END OF FILE CONTENT ---

  File: config.yaml
    --- START OF FILE CONTENT ---
# config.yaml

model_list:
  - model_name: gemini/gemini-1.5-flash-latest # 您已有的 Gemini 配置 (如果存在)
    litellm_params:
      model: gemini/gemini-1.5-flash-latest
      api_key: os.environ/GEMINI_API_KEY
      # api_base: http://localhost:YOUR_CLASH_PORT # 如果需要

  # --- 修改我们本地的 Qwen3 1.7B 模型配置 ---
  - model_name: local/qwen3-1.7b-gguf
    litellm_params:
      model: openai/my-local-qwen # 使用 "openai/" 前缀，后面可以跟一个自定义的描述符
      api_base: http://localhost:8088/v1
      api_key: nokey

# ... (其他 LiteLLM 配置) ...
    --- END OF FILE CONTENT ---

  File: debug_kuzu_visibility.py
    --- START OF FILE CONTENT ---
# debug_kuzu_visibility.py
import kuzu
import os
import shutil
import time
import pandas as pd

DB_PATH = "./zhz_rag/stored_data/kuzu_test_visibility_db" # 使用一个新的测试路径

def setup_and_verify_schema():
    print(f"--- Phase 1: Setup and Initial Verification ---")
    if os.path.exists(DB_PATH):
        print(f"Removing existing database at {DB_PATH}")
        shutil.rmtree(DB_PATH)
    
    db_setup = None
    conn_setup = None
    try:
        print(f"Creating new database at {DB_PATH}")
        db_setup = kuzu.Database(DB_PATH, read_only=False)
        conn_setup = kuzu.Connection(db_setup)
        print("Database and connection created for setup.")

        ddl_queries = [
            "CREATE NODE TABLE IF NOT EXISTS ExtractedEntity (id_prop STRING, text STRING, label STRING, PRIMARY KEY (id_prop))",
            "CREATE REL TABLE IF NOT EXISTS WorksAt (FROM ExtractedEntity TO ExtractedEntity)",
            "CREATE REL TABLE IF NOT EXISTS AssignedTo (FROM ExtractedEntity TO ExtractedEntity)"
        ]
        for query in ddl_queries:
            print(f"Executing DDL: {query}")
            conn_setup.execute(query)
        print("DDL execution complete.")

        print("Executing CHECKPOINT...")
        conn_setup.execute("CHECKPOINT;")
        print("CHECKPOINT complete.")

        # Phase 1 Verification
        print("Verifying tables immediately after creation (same session)...")
        try:
            # 尝试 SHOW TABLES;
            print("Attempting 'SHOW TABLES;' in Phase 1...")
            result = conn_setup.execute("SHOW TABLES;") # <--- 修改这里
            df = pd.DataFrame(result.get_as_df())
            print(f"Tables found using 'SHOW TABLES;' (Phase 1):\n{df}")
            # 检查 'name' 列是否存在，并且 'ExtractedEntity' 是否在其中
            if not df.empty and 'name' in df.columns and "ExtractedEntity" in df["name"].tolist():
                print("Phase 1 Verification (SHOW TABLES;): ExtractedEntity table FOUND.")
            elif not df.empty and 'name' not in df.columns:
                print("Phase 1 Verification (SHOW TABLES;): 'name' column not found in SHOW TABLES result.")
                print(f"Columns available in SHOW TABLES result: {df.columns.tolist()}")
            else: # df is empty or ExtractedEntity not in name column
                print("Phase 1 Verification (SHOW TABLES;): ExtractedEntity table NOT FOUND or result was empty.")
        except Exception as e:
            print(f"Error during Phase 1 verification with 'SHOW TABLES;': {e}")
            print("Falling back to direct query for ExtractedEntity in Phase 1...")
            try:
                result_direct = conn_setup.execute("MATCH (e:ExtractedEntity) RETURN count(e) AS entity_count;")
                df_direct = pd.DataFrame(result_direct.get_as_df())
                print(f"Direct query result (Phase 1):\n{df_direct}")
                count_val = df_direct['entity_count'].iloc[0] if not df_direct.empty else -1
                print(f"Phase 1 Verification (Direct Query): ExtractedEntity table SEEMS TO EXIST (count: {count_val}).")
            except Exception as e_direct_phase1:
                print(f"Error during Phase 1 direct query verification: {e_direct_phase1}")

    except Exception as e:
        print(f"Error during Phase 1 setup: {e}")
    finally:
        if conn_setup:
            print("Closing setup connection.")
            # conn_setup.close() # Kuzu Connection 没有显式 close
        if db_setup:
            print("Deleting setup database instance reference (will trigger close).")
            del db_setup # 依赖 __del__
        print("--- Phase 1 Complete ---")

def verify_in_new_session():
    print(f"\n--- Phase 2: Verification in a New Session ---")
    if not os.path.exists(DB_PATH):
        print(f"Database at {DB_PATH} does not exist. Cannot perform Phase 2.")
        return

    db_verify = None
    conn_verify = None
    try:
        print(f"Opening existing database at {DB_PATH} for verification.")
        db_verify = kuzu.Database(DB_PATH, read_only=False) # 打开同一个数据库
        conn_verify = kuzu.Connection(db_verify)
        print("Database and connection created for verification.")

        # Phase 2 Verification
        print("Verifying tables in new session...")
        try:
            # 尝试 SHOW TABLES;
            print("Attempting 'SHOW TABLES;' in Phase 2...")
            result = conn_verify.execute("SHOW TABLES;") # <--- 修改这里
            df = pd.DataFrame(result.get_as_df())
            print(f"Tables found using 'SHOW TABLES;' (Phase 2):\n{df}")
            if not df.empty and 'name' in df.columns and "ExtractedEntity" in df["name"].tolist():
                print("Phase 2 Verification (SHOW TABLES;): ExtractedEntity table FOUND.")
            elif not df.empty and 'name' not in df.columns:
                print("Phase 2 Verification (SHOW TABLES;): 'name' column not found in SHOW TABLES result.")
                print(f"Columns available in SHOW TABLES result: {df.columns.tolist()}")
            else: # df is empty or ExtractedEntity not in name column
                print("Phase 2 Verification (SHOW TABLES;): ExtractedEntity table NOT FOUND or result was empty.")
        except Exception as e:
            print(f"Error during Phase 2 verification with 'SHOW TABLES;': {e}")
            print("Falling back to direct query for ExtractedEntity in Phase 2...")
            try:
                result_direct = conn_verify.execute("MATCH (e:ExtractedEntity) RETURN count(e) AS entity_count;")
                df_direct = pd.DataFrame(result_direct.get_as_df())
                print(f"Direct query result (Phase 2):\n{df_direct}")
                count_val = df_direct['entity_count'].iloc[0] if not df_direct.empty else -1
                print(f"Phase 2 Verification (Direct Query): ExtractedEntity table SEEMS TO EXIST (count: {count_val}).")
            except Exception as e_direct_phase2:
                print(f"Error during Phase 2 direct query verification: {e_direct_phase2}")

    except Exception as e:
        print(f"Error during Phase 2 setup: {e}")
    finally:
        if conn_verify:
            print("Closing verification connection.")
        if db_verify:
            print("Deleting verification database instance reference.")
            del db_verify
        print("--- Phase 2 Complete ---")

if __name__ == "__main__":
    print(f"Kuzu Python client version: {kuzu.__version__}")
    setup_and_verify_schema()
    print("\nWaiting a moment before trying to open in a new session (simulating process switch)...")
    time.sleep(2) # 短暂等待，模拟进程切换的间隙
    verify_in_new_session()
    --- END OF FILE CONTENT ---

  File: llm_setup.py
    --- START OF FILE CONTENT ---
# /home/zhz/zhz_agent/llm_setup.py

import os
from typing import Any, Optional, List, Dict

# LiteLLM 本身通常是直接调用其 API，例如 litellm.completion
# 如果要将其适配给 CrewAI 的 Agent，我们需要将其包装成一个符合 CrewAI BaseLLM 接口的类。
# CrewAI 自身也提供了通过 LiteLLM 使用各种模型的集成，我们也可以研究直接使用 CrewAI 的方式。
# 为简化起见，我们先创建一个函数，返回配置好的 LiteLLM 调用参数，或者一个简单的包装器。

# --- 从 agent_orchestrator_service.py 中获取的配置常量 ---
# 本地 LLM 服务地址 (Qwen3)
LOCAL_QWEN_API_BASE = os.getenv("LOCAL_LLM_API_BASE", "http://localhost:8088/v1") # 确保与 local_llm_service.py 的端口一致
LOCAL_QWEN_MODEL_NAME_FOR_LITELLM = os.getenv("LOCAL_LLM_MODEL_NAME", "local/qwen3-1.7b-gguf") # 这个是给 litellm 的 model 参数，需要与 LiteLLM 配置或调用方式对应

# 云端 LiteLLM 网关地址 (用于 Gemini 等)
CLOUD_LITELLM_GW_API_BASE = os.getenv("CLOUD_LITELLM_GW_API_BASE", "YOUR_CLOUD_LITELLM_GATEWAY_URL_HERE/v1") # 假设您的网关也提供 /v1 路径
GEMINI_MODEL_NAME_FOR_LITELLM = os.getenv("CLOUD_LLM_MODEL_NAME", "gemini/gemini-1.5-flash-latest") # 或您希望通过网关调用的模型

# API Keys (通常 LiteLLM 会在其自己的配置或环境变量中处理，但这里可以作为参考)
# GEMINI_API_KEY = os.getenv("GEMINI_API_KEY") # 如果直接调用 Gemini 而非通过网关
# 注意：本地模型的 API Key 通常是 "nokey" 或在服务中不强制

# --- CrewAI LLM 包装器 (如果需要直接传递给 CrewAI Agent) ---
# CrewAI 期望一个 LLM 对象，我们可以创建一个简单的包装器，或者使用 CrewAI 提供的 LiteLLM 集成
# from crewai.llms.base_llm import BaseLLM as CrewAIBaseLLM
# import litellm
#
# class LiteLLMWrapperForCrewAI(CrewAIBaseLLM):
#     model: str
#     api_base: Optional[str] = None
#     api_key: Optional[str] = None
#     custom_llm_provider: Optional[str] = None # 例如 "openai" for OpenAI-compatible endpoints
#     litellm_kwargs: Dict[str, Any] = {}
#
#     def __init__(self, model: str, api_base: Optional[str] = None, api_key: Optional[str] = None, custom_llm_provider: Optional[str] = None, **kwargs):
#         super().__init__(model=model) # CrewAI BaseLLM 需要 model 参数
#         self.model = model
#         self.api_base = api_base
#         self.api_key = api_key
#         self.custom_llm_provider = custom_llm_provider
#         self.litellm_kwargs = kwargs
#
#     def call(self, messages: List[Dict[str, str]], **kwargs: Any) -> str:
#         # CrewAI 的 BaseLLM.call 方法通常期望返回一个字符串
#         # LiteLLM 的 completion 返回一个 ModelResponse 对象
#         params = {
#             "model": self.model,
#             "messages": messages,
#             "api_base": self.api_base,
#             "api_key": self.api_key,
#             "custom_llm_provider": self.custom_llm_provider,
#             **self.litellm_kwargs, # 包含 temperature, max_tokens 等
#             **kwargs # 运行时可能传递的额外参数
#         }
#         # 移除值为 None 的参数，因为 litellm.completion 不喜欢 None 的 api_key 等
#         params_cleaned = {k: v for k, v in params.items() if v is not None}
#
#         response = litellm.completion(**params_cleaned)
#
#         # 从 LiteLLM 响应中提取内容
#         content = ""
#         if response.choices and response.choices[0].message and response.choices[0].message.content:
#             content = response.choices[0].message.content
#         return content
#
#     def get_token_ids(self, text: str) -> List[int]:
#         # LiteLLM 通常不直接暴露 tokenizer，但可以尝试通过 litellm.token_counter (如果它返回ids)
#         # 或者如果使用特定模型，可以尝试加载其 tokenizer
#         # 为简单起见，我们先返回空列表或引发 NotImplementedError
#         # return litellm.encode(model=self.model, text=text) # 如果 litellm.encode 可用
#         raise NotImplementedError("get_token_ids is not implemented for this LiteLLM wrapper.")


def get_local_qwen_llm_instance(
    temperature: float = 0.7,
    max_tokens: int = 2048,
    # crewai_wrapper: bool = False # 是否返回 CrewAI 兼容的包装器
) -> Any: # 返回 Any 以便后续决定是直接返回配置字典还是包装器实例
    """
    获取配置好的本地 Qwen3 LLM 实例（通过 LiteLLM 调用）。
    """
    print(f"LLM Setup: Configuring Local Qwen LLM via LiteLLM.")
    print(f"  Model: {LOCAL_QWEN_MODEL_NAME_FOR_LITELLM}")
    print(f"  API Base: {LOCAL_QWEN_API_BASE}")
    # if crewai_wrapper:
    #     return LiteLLMWrapperForCrewAI(
    #         model=LOCAL_QWEN_MODEL_NAME_FOR_LITELLM,
    #         api_base=LOCAL_QWEN_API_BASE,
    #         api_key="nokey", # 本地服务通常不需要 key
    #         custom_llm_provider="openai", # 因为我们的本地服务是 OpenAI 兼容的
    #         temperature=temperature,
    #         max_tokens=max_tokens
    #     )
    # else:
    # 返回一个配置字典，调用方可以使用 litellm.completion(**config, messages=...)
    return {
        "model": LOCAL_QWEN_MODEL_NAME_FOR_LITELLM,
        "api_base": LOCAL_QWEN_API_BASE,
        "api_key": "nokey",
        "custom_llm_provider": "openai",
        "temperature": temperature,
        "max_tokens": max_tokens
    }


def get_cloud_gemini_llm_instance(
    temperature: float = 0.5,
    max_tokens: int = 4096,
    # crewai_wrapper: bool = False
) -> Any:
    """
    获取配置好的云端 Gemini LLM 实例（通过云端 LiteLLM 网关调用）。
    """
    print(f"LLM Setup: Configuring Cloud Gemini LLM via LiteLLM Gateway.")
    print(f"  Model: {GEMINI_MODEL_NAME_FOR_LITELLM}")
    print(f"  API Base (Gateway): {CLOUD_LITELLM_GW_API_BASE}")

    if CLOUD_LITELLM_GW_API_BASE == "YOUR_CLOUD_LITELLM_GATEWAY_URL_HERE/v1":
        print("LLM Setup WARNING: CLOUD_LITELLM_GW_API_BASE is not configured. Cloud LLM calls will likely fail.")
        # 可以选择返回 None 或者一个无效的配置，让调用方处理
        return None

    # if crewai_wrapper:
    #     return LiteLLMWrapperForCrewAI(
    #         model=GEMINI_MODEL_NAME_FOR_LITELLM,
    #         api_base=CLOUD_LITELLM_GW_API_BASE,
    #         # API Key 通常由云端 LiteLLM 网关管理，客户端调用网关时可能不需要直接提供
    #         # 或者网关本身可能需要某种形式的认证 key
    #         api_key=os.getenv("CLOUD_LITELLM_GATEWAY_API_KEY"), # 假设网关可能需要一个 key
    #         # custom_llm_provider 可能不需要，因为网关会处理到具体云服务的转换
    #         temperature=temperature,
    #         max_tokens=max_tokens
    #     )
    # else:
    return {
        "model": GEMINI_MODEL_NAME_FOR_LITELLM,
        "api_base": CLOUD_LITELLM_GW_API_BASE,
        "api_key": os.getenv("CLOUD_LITELLM_GATEWAY_API_KEY"), # 网关本身的key
        "temperature": temperature,
        "max_tokens": max_tokens
    }

# --- 示例用法 (可选，用于测试此文件) ---
async def main_test_llm_setup():
    print("--- Testing LLM Setup ---")

    print("\n--- Getting Local Qwen Config ---")
    local_qwen_config = get_local_qwen_llm_instance()
    if local_qwen_config:
        print(f"Local Qwen Config: {local_qwen_config}")
        # 模拟调用
        try:
            messages = [{"role": "user", "content": "你好！"}]
            print(f"Simulating LiteLLM call with local Qwen config for: {messages}")
            # response = await litellm.acompletion(**local_qwen_config, messages=messages)
            # print(f"Simulated local Qwen response (first choice): {response.choices[0].message.content if response.choices else 'No response'}")
            print("Actual LiteLLM call commented out for setup test.")
        except Exception as e:
            print(f"Error simulating local Qwen call: {e}")
    else:
        print("Failed to get local Qwen config.")

    print("\n--- Getting Cloud Gemini Config ---")
    cloud_gemini_config = get_cloud_gemini_llm_instance()
    if cloud_gemini_config:
        print(f"Cloud Gemini Config: {cloud_gemini_config}")
        if cloud_gemini_config.get("api_base") == "YOUR_CLOUD_LITELLM_GATEWAY_URL_HERE/v1":
            print("Skipping simulated cloud Gemini call as gateway URL is a placeholder.")
        else:
            try:
                messages = [{"role": "user", "content": "Hello!"}]
                print(f"Simulating LiteLLM call with cloud Gemini config for: {messages}")
                # response = await litellm.acompletion(**cloud_gemini_config, messages=messages)
                # print(f"Simulated cloud Gemini response (first choice): {response.choices[0].message.content if response.choices else 'No response'}")
                print("Actual LiteLLM call commented out for setup test.")
            except Exception as e:
                print(f"Error simulating cloud Gemini call: {e}")
    else:
        print("Failed to get cloud Gemini config (likely due to placeholder URL).")

if __name__ == "__main__":
    # 为了运行异步的 main_test_llm_setup
    # import asyncio
    # asyncio.run(main_test_llm_setup())
    pass
    --- END OF FILE CONTENT ---

  File: local_llm_service.py
    --- START OF FILE CONTENT ---
# /home/zhz/zhz_agent/local_llm_service.py
import os
import time
import uuid
import traceback
from contextlib import asynccontextmanager
from typing import List, Dict, Any, Optional, Union
import json # <--- 确保导入 json

import uvicorn
from fastapi import FastAPI, HTTPException
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
from llama_cpp import Llama # LlamaGrammar 不再需要从这里导入
import re

# --- 配置 ---
MODEL_DIR = os.getenv("LOCAL_LLM_MODEL_DIR", "/home/zhz/models/Qwen3-1.7B-GGUF")
MODEL_FILENAME = os.getenv("LOCAL_LLM_MODEL_FILENAME")
N_GPU_LAYERS = int(os.getenv("LOCAL_LLM_N_GPU_LAYERS", 0))
N_CTX = int(os.getenv("LOCAL_LLM_N_CTX", 4096))
N_BATCH = int(os.getenv("LOCAL_LLM_N_BATCH", 512))
SERVICE_PORT = int(os.getenv("LOCAL_LLM_SERVICE_PORT", 8088))
SERVICE_HOST = "0.0.0.0"

# --- 全局变量 ---
llama_model: Optional[Llama] = None
model_path_global: Optional[str] = None
# cypher_grammar: Optional[LlamaGrammar] = None # <--- 移除全局 GBNF 对象

# --- Pydantic 模型定义 (保持不变) ---
class ChatMessage(BaseModel):
    role: str
    content: str

class ChatCompletionRequest(BaseModel):
    model: str
    messages: List[ChatMessage]
    temperature: float = 0.7
    max_tokens: Optional[int] = 512 # 稍后可能需要调整这个默认值以容纳JSON输出
    stream: bool = False
    stop: Optional[Union[str, List[str]]] = None
    # 可以考虑在这里添加一个可选字段来控制是否使用JSON Schema约束，
    # 但 llama-cpp-python 的 create_chat_completion 的 response_format 参数是更标准的方式
    # use_cypher_json_schema: bool = False 

class ChatCompletionMessage(BaseModel):
    role: str
    content: Optional[str] = None # LLM的输出内容

class ChatCompletionChoice(BaseModel):
    index: int
    message: ChatCompletionMessage
    finish_reason: Optional[str] = "stop"

class UsageInfo(BaseModel):
    prompt_tokens: int
    completion_tokens: int
    total_tokens: int

class ChatCompletionResponse(BaseModel):
    id: str = Field(default_factory=lambda: f"chatcmpl-{uuid.uuid4().hex}")
    object: str = "chat.completion"
    created: int = Field(default_factory=lambda: int(time.time()))
    model: str
    choices: List[ChatCompletionChoice]
    usage: UsageInfo
    system_fingerprint: Optional[str] = None

# --- FastAPI 应用和生命周期管理 ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    global llama_model, model_path_global # <--- 移除 cypher_grammar
    print("--- Local LLM Service: Lifespan startup ---")

    model_file_to_load = MODEL_FILENAME
    if not model_file_to_load:
        try:
            gguf_files = [f for f in os.listdir(MODEL_DIR) if f.endswith(".gguf")]
            if not gguf_files:
                raise RuntimeError(f"No GGUF models found in {MODEL_DIR}")
            if len(gguf_files) > 1:
                print(f"Warning: Multiple GGUF models found in {MODEL_DIR}. Using the first one: {gguf_files[0]}")
            model_file_to_load = gguf_files[0]
        except FileNotFoundError:
            raise RuntimeError(f"Model directory not found: {MODEL_DIR}")

    model_path_global = os.path.join(MODEL_DIR, model_file_to_load)
    print(f"Attempting to load Llama model from: {model_path_global}")
    print(f"Parameters: n_gpu_layers={N_GPU_LAYERS}, n_ctx={N_CTX}, n_batch={N_BATCH}")

    try:
        llama_model = Llama(
            model_path=model_path_global,
            n_gpu_layers=N_GPU_LAYERS,
            n_ctx=N_CTX,
            n_batch=N_BATCH,
            verbose=True
        )
        print("Llama model loaded successfully.")
        # --- 移除 GBNF 文件加载逻辑 ---
    except Exception as e:
        print(f"FATAL: Failed to load Llama model: {e}")
        raise RuntimeError(f"Failed to load Llama model: {e}") from e
    
    yield
    
    print("--- Local LLM Service: Lifespan shutdown ---")

app = FastAPI(
    title="Local LLM Service (OpenAI Compatible)",
    description="Provides an OpenAI-compatible API for a locally hosted GGUF model via llama-cpp-python. Now supports JSON Schema output constraint.",
    version="0.1.1", # 版本更新
    lifespan=lifespan
)

# --- 辅助函数 (post_process_llm_output 保持不变) ---
def post_process_llm_output(content: Optional[str], finish_reason: Optional[str]) -> Optional[str]:
    # ... (此函数内容保持不变，它负责移除 <think> 标签)
    if content is None:
        return None
    print(f"DEBUG_POST_PROCESS: Input to post_process_llm_output:\n---\n{content}\n---")
    print(f"DEBUG_POST_PROCESS: Finish reason: {finish_reason}")
    processed_content = content
    think_block_pattern = re.compile(r"<think[^>]*>.*?</think>\s*", flags=re.DOTALL | re.IGNORECASE)
    processed_content = think_block_pattern.sub("", processed_content)
    print(f"DEBUG_POST_PROCESS: After think_block_pattern.sub:\n---\n{processed_content}\n---")
    if finish_reason == "length" and \
      re.match(r"<think[^>]*>", processed_content.strip(), flags=re.IGNORECASE) and \
      not re.search(r"</think\s*>", processed_content, flags=re.IGNORECASE):
        print("DEBUG_POST_PROCESS: Incomplete think block due to length, returning empty or placeholder.")
    stray_think_tag_pattern = re.compile(r"</?\s*think[^>]*?>\s*", flags=re.IGNORECASE)
    processed_content = stray_think_tag_pattern.sub("", processed_content)
    print(f"DEBUG_POST_PROCESS: After stray_think_tag_pattern.sub:\n---\n{processed_content}\n---")
    final_stripped_content = processed_content.strip()
    print(f"DEBUG_POST_PROCESS: After final strip:\n---\n{final_stripped_content}\n---")
    return final_stripped_content

# --- API 端点 ---
@app.post("/v1/chat/completions", response_model=ChatCompletionResponse)
async def create_chat_completion_endpoint(request: ChatCompletionRequest): # 函数名保持您的修改
    global llama_model, model_path_global # <--- 移除 cypher_grammar
    if llama_model is None:
        raise HTTPException(status_code=503, detail="Llama model is not loaded or failed to load.")

    if request.stream:
        raise HTTPException(status_code=400, detail="Streaming responses are not yet supported by this service.")

    # --- 定义我们期望的 JSON Schema (用于 Cypher 生成) ---
    # 这个 Schema 应该与 NEW_KG_SCHEMA_DESCRIPTION 中引导 LLM 输出的 JSON 结构一致
    CYPHER_OUTPUT_JSON_SCHEMA = {
        "type": "object",
        "properties": {
            "status": {"type": "string", "enum": ["success", "unable_to_generate"]},
            "query": {"type": "string"}, 
        },
        "required": ["status", "query"]
    }

    response_content_raw: Optional[str] = None
    # final_content_for_response: Optional[str] = None # 重命名以更清晰
    prompt_tokens = 0
    completion_tokens = 0
    total_tokens = 0
    finish_reason = "stop"
    
    request_model_name = request.model

    # --- Token 预估和超限检查 (可选但推荐) ---
    # 此处可以添加逻辑：
    # 1. 将 request.messages 转换为单个 prompt 字符串 (如果 llama_model.tokenize 需要)
    # 2. 调用 llama_model.tokenize() 获取输入 token 数
    # 3. 如果 prompt_tokens + request.max_tokens > N_CTX，则提前返回错误
    # 例如:
    # temp_prompt_str_for_token_count = convert_messages_to_prompt_for_token_count(request.messages) # 你需要实现这个函数
    # current_prompt_tokens = len(llama_model.tokenize(temp_prompt_str_for_token_count.encode('utf-8')))
    # if current_prompt_tokens + (request.max_tokens or llama_model.n_ctx_train() // 3 ) > N_CTX: # 粗略估计输出
    #     print(f"ERROR: Estimated tokens ({current_prompt_tokens} + ~{request.max_tokens}) exceed context window {N_CTX}")
    #     raise HTTPException(status_code=400, detail=f"Requested tokens ({current_prompt_tokens} + completion) would exceed context window of {N_CTX}")
    # --- 结束 Token 预估 ---

    if hasattr(llama_model, "create_chat_completion"):
        try:
            dict_messages = [msg.model_dump() for msg in request.messages]
            
            completion_params = {
                "messages": dict_messages,
                "temperature": request.temperature,
                "max_tokens": request.max_tokens or 512, # 确保有默认值
                "stop": request.stop,
            }

            # --- 关键修改：使用 response_format 参数 ---
            # 我们需要一种方式来判断当前请求是否是用于 Cypher 生成的，
            # 以便只在那种情况下应用 JSON Schema 约束。
            # 临时方案：检查 system prompt 是否包含特定的关键词。
            # 更好的方案：客户端（即 sglang_wrapper.py）在请求中添加一个额外参数。
            # 我们先假设，如果 prompt 包含 "KNOWLEDGE GRAPH SCHEMA (KuzuDB) & CYPHER GENERATION RULES"，
            # 那么它就是 Cypher 生成任务。
            is_cypher_gen_task = False
            if dict_messages and dict_messages[0]["role"] == "system":
                if "KNOWLEDGE GRAPH SCHEMA (KuzuDB) & CYPHER GENERATION RULES" in dict_messages[0]["content"]:
                    is_cypher_gen_task = True
            
            if is_cypher_gen_task:
                print("DEBUG_FastAPI: Detected Cypher generation task. Applying JSON Schema constraint.")
                completion_params["response_format"] = {
                    "type": "json_object",
                    "schema": CYPHER_OUTPUT_JSON_SCHEMA
                }
            else:
                print("DEBUG_FastAPI: Not a Cypher generation task (or schema keyword not found). Proceeding without JSON schema constraint.")

            print(f"DEBUG_FastAPI: Calling llama_model.create_chat_completion with params (excluding messages): { {k:v for k,v in completion_params.items() if k != 'messages'} }")
            completion = llama_model.create_chat_completion(**completion_params)
            
            response_content_raw = completion['choices'][0]['message']['content']
            # 对于JSON模式，response_content_raw 应该是一个JSON字符串
            print(f"DEBUG_FastAPI: Raw content from llama_model: '{response_content_raw}'")

            prompt_tokens = completion['usage']['prompt_tokens']
            completion_tokens = completion['usage']['completion_tokens']
            total_tokens = completion['usage']['total_tokens']
            finish_reason = completion['choices'][0].get('finish_reason', 'stop')

        except Exception as e:
            print(f"Error during llama_model.create_chat_completion: {e}")
            traceback.print_exc() # 打印完整堆栈
            raise HTTPException(status_code=500, detail=f"Error generating completion: {str(e)}")
    else:
        # ... (直接调用 llama_model() 的逻辑，如果需要保留，也应该考虑如何应用 JSON Schema 或 GBNF)
        # 对于 JSON Schema，它通常是 create_chat_completion 的特性。
        # 直接调用 llm() 可能不支持 response_format。
        # 因此，我们应该优先确保使用 create_chat_completion。
        print("CRITICAL_ERROR: llama_model.create_chat_completion method not found. This service relies on it.")
        raise HTTPException(status_code=500, detail="LLM service misconfiguration: create_chat_completion not available.")

    # post_process_llm_output 应该在尝试解析 JSON 之前，以移除可能存在的 <think> 标签
    final_content_for_response = post_process_llm_output(response_content_raw, finish_reason)
    
    # 如果是 Cypher 生成任务并且成功获取了 JSON，我们不需要进一步处理 final_content_for_response
    # 因为调用者 (sglang_wrapper.py) 会解析这个 JSON。
    # 如果不是 Cypher 生成任务，或者 JSON 解析失败（虽然理论上 GBNF/JSON Schema 会保证格式），
    # final_content_for_response 就是最终的文本。

    print(f"DEBUG_FastAPI: Final content to be returned to client: '{final_content_for_response}'")

    response_id = f"chatcmpl-{uuid.uuid4().hex}"
    created_time = int(time.time())
    
    effective_model_name = request_model_name
    if not effective_model_name and model_path_global:
        effective_model_name = model_path_global.split('/')[-1]
    elif not effective_model_name:
        effective_model_name = "local-llm-unknown"

    return ChatCompletionResponse(
        id=response_id,
        object="chat.completion",
        created=created_time,
        model=effective_model_name,
        choices=[
            ChatCompletionChoice(
                index=0,
                message=ChatCompletionMessage(role="assistant", content=final_content_for_response), # 返回清理后的内容
                finish_reason=finish_reason
            )
        ],
        usage=UsageInfo(
            prompt_tokens=prompt_tokens,
            completion_tokens=completion_tokens,
            total_tokens=total_tokens
        )
    )

# ... (@app.get("/v1/models") 和 if __name__ == "__main__": 部分保持不变) ...
@app.get("/v1/models", response_model=Dict[str, Any])
async def list_models():
    global model_path_global
    model_id_for_clients = "qwen3local"
    return {
        "object": "list",
        "data": [
            {
                "id": model_id_for_clients,
                "object": "model",
                "created": int(os.path.getctime(model_path_global)) if model_path_global and os.path.exists(model_path_global) else int(time.time()),
                "owned_by": "user",
            }
        ]
    }

if __name__ == "__main__":
    print(f"--- Starting Local LLM FastAPI Service on {SERVICE_HOST}:{SERVICE_PORT} ---")
    print(f"--- Model will be loaded from DIR: {MODEL_DIR}, FILE: {MODEL_FILENAME or 'Auto-detected GGUF'} ---")
    uvicorn.run(app, host=SERVICE_HOST, port=SERVICE_PORT) # 移除 reload=True，因为它在 __main__ 中通常用于开发，但在生产或由 mcpo 管理时可能不需要
    --- END OF FILE CONTENT ---

  File: requirements.txt
    --- START OF FILE CONTENT ---
# /home/zhz/zhz_agent/requirements.txt

# --- Core Application & Agent Framework ---
pydantic==2.11.5
crewai==0.121.0  # 您当前使用的版本，假设它兼容 Pydantic 2.11.5
crewai-tools==0.0.1 # 您当前使用的版本

# --- LLM Interaction & Management ---
litellm==1.68.0
openai==1.75.0 # 通常与 LiteLLM 一起使用

# --- Web Framework ---
fastapi==0.115.12
uvicorn[standard]==0.34.2 # [standard] 包含 websockets 和 httptools

# --- Data Storage & RAG ---
chromadb==0.6.3
sentence-transformers==4.1.0 # 您 freeze 输出中的版本，如果希望更新可以调整
transformers==4.52.3         # 您 freeze 输出中的版本，如果希望固定为 4.38.2 可以改回
torch==2.7.0                 # 您 freeze 输出中的版本
numpy==2.2.6                 # 您 freeze 输出中的版本 (注意：如果导致问题，可能需要回退到 <2.0)
kuzu # 让 uv 选择最新兼容版，或根据 Dagster 需求指定
portalocker # KuzuDB 可能需要

# --- Dagster Workflow ---
dagster==1.10.17             # 您当前使用的版本，假设兼容 Pydantic V2
dagster-webserver==1.10.17
dagster-graphql==1.10.17
dagster-pipes==1.10.17
dagster_shared==0.26.17

# --- Other Important Libraries from your freeze ---
aiohttp==3.12.0
aiosqlite==0.21.0
APScheduler==3.11.0
databases[aiosqlite]==0.9.0 # 确保包含 extras
httpx==0.28.1
jieba==0.42.1
langchain==0.3.25 # 这是一个元包，可能拉取很多 langchain-* 组件
langchain-core==0.3.61
langchain-community==0.3.24
langchain-text-splitters==0.3.8
neo4j==5.28.1
pandas==2.2.3
protobuf==5.29.4 # 确保这个版本与 opentelemetry 兼容
python-dotenv==1.1.0
pytz==2025.2
SQLAlchemy==2.0.41
bm25s==0.2.13

# --- OpenTelemetry (让 crewai 自动拉取，如果还有问题再显式指定) ---
# opentelemetry-api
# opentelemetry-sdk
# opentelemetry-exporter-otlp-proto-http
# opentelemetry-exporter-otlp-proto-grpc
# opentelemetry-proto
# opentelemetry-instrumentation
# opentelemetry-instrumentation-asgi
# opentelemetry-instrumentation-fastapi
# opentelemetry-semantic-conventions
# opentelemetry-util-http

# --- Potentially problematic or less critical (review if needed) ---
# 以下是一些在您 freeze 输出中但可能不需要严格固定，或者可以由其他包间接依赖的
# 如果遇到问题，可以考虑注释掉它们，让 uv 重新解析
# annotated-types==0.7.0 # 通常由 pydantic 依赖
# anyio==4.9.0 # 通常由 fastapi/starlette 依赖
# ... (您可以根据需要审查和删减 freeze 输出中的其他包) ...

# --- Editable local packages (uv pip install -e <path> 来安装) ---
# -e ./zhz_rag
# -e ./zhz_rag_pipeline_dagster
    --- END OF FILE CONTENT ---

  File: test_local_llm_cypher_gen.py
    --- START OF FILE CONTENT ---
# test_local_llm_cypher_gen.py
import httpx
import json
import os

# 从 zhz_rag.config.constants 导入 NEW_KG_SCHEMA_DESCRIPTION
# 这需要确保 PYTHONPATH 正确设置，或者脚本与 zhz_agent 在同一父目录下然后使用相对导入
# 为了简单，我们直接复制 Schema 描述到这里进行测试，或者确保能导入
try:
    from zhz_rag.config.constants import NEW_KG_SCHEMA_DESCRIPTION
except ImportError:
    print("WARNING: Could not import NEW_KG_SCHEMA_DESCRIPTION. Using a placeholder.")
    NEW_KG_SCHEMA_DESCRIPTION = "Node: :ExtractedEntity(text, label), Rel: :WorksAt, :AssignedTo"


LOCAL_LLM_URL = "http://localhost:8088/v1/chat/completions"

def construct_cypher_gen_messages(user_question: str, schema: str) -> list:
    # 使用您在 sglang_wrapper.py 中为 Cypher 生成构造的 messages 格式
    # 或者更直接地，使用 Qwen3 的标准聊天模板
    # 例如，一个简化的版本：
    # 注意：这里的 system prompt 应该与您 NEW_KG_SCHEMA_DESCRIPTION 的意图一致
    # 并且包含我们最新优化的指令
    system_prompt = NEW_KG_SCHEMA_DESCRIPTION # 使用我们优化后的完整 Schema 和指令

    return [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"用户问题: {user_question}"}
    ]

async def call_llm_for_cypher(question: str):
    print(f"\n--- Testing Cypher Generation for: {question} ---")
    messages = construct_cypher_gen_messages(question, NEW_KG_SCHEMA_DESCRIPTION)
    
    payload = {
        "model": "qwen3-1.7b-gguf", # 与 local_llm_service.py 中 ChatCompletionRequest.model 一致
        "messages": messages,
        "temperature": 0.0, # 对于代码生成，低temperature
        "max_tokens": 200,   # 限制输出长度，避免因长度导致的其他问题
        "stop": ["<|im_end|>", "无法生成Cypher查询."] 
        # 注意：如果GBNF生效，stop可能不是主要控制因素了
    }
    
    # 打印将要发送的 messages 的 token 估算（如果可以的话）
    # from llama_cpp import Llama
    # temp_tokenizer_model = Llama(model_path="/path/to/your/qwen3-1.7b.gguf", verbose=False) # 需要实际模型路径
    # prompt_str_for_token_count = ""
    # for msg in messages:
    #     prompt_str_for_token_count += f"{msg['role']}\n{msg['content']}\n"
    # token_count = len(temp_tokenizer_model.tokenize(prompt_str_for_token_count.encode('utf-8')))
    # print(f"Estimated prompt tokens (approx): {token_count}")
    # del temp_tokenizer_model

    async with httpx.AsyncClient(timeout=60.0) as client:
        try:
            response = await client.post(LOCAL_LLM_URL, json=payload)
            print(f"Status Code: {response.status_code}")
            if response.status_code == 200:
                response_data = response.json()
                print("LLM Response JSON:")
                print(json.dumps(response_data, indent=2, ensure_ascii=False))
                if response_data.get("choices") and response_data["choices"][0].get("message"):
                    content = response_data["choices"][0]["message"].get("content")
                    print(f"Extracted Content:\n---\n{content}\n---")
            else:
                print(f"Error Response Text: {response.text}")
        except Exception as e:
            print(f"An error occurred: {e}")

async def main():
    # 确保 local_llm_service.py 正在运行
    test_questions = [
        "张三在哪里工作？",
        "项目Alpha的文档编写任务分配给了谁？",
        "法国的首都是哪里？" # 测试 "无法生成"
    ]
    for q in test_questions:
        await call_llm_for_cypher(q)

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
    --- END OF FILE CONTENT ---

  File: workspace.yaml
    --- START OF FILE CONTENT ---
load_from:
  - python_module:
      module_name: zhz_rag_pipeline_dagster.zhz_rag_pipeline.definitions
      working_directory: /home/zhz/zhz_agent
    --- END OF FILE CONTENT ---


Directory: zhz_rag_pipeline_dagster/
  File (skipped, extension not included): 25-5-28进度说明书.jpg
  File (skipped, extension not included): pyproject.toml
  File: setup.py
    --- START OF FILE CONTENT ---
# /home/zhz/zhz_agent/zhz_rag_pipeline_dagster/setup.py
from setuptools import find_packages, setup

setup(
    name="zhz_rag_pipeline_dagster_project", # 给一个包名
    version="0.0.1",
    packages=find_packages(), # 会找到 zhz_rag_pipeline 这个包
    install_requires=[
        "dagster",
        "dagster-webserver",
        # 添加其他 zhz_rag_pipeline_dagster 项目直接依赖的库
        # 例如 kuzu, dagster-pydantic (如果之后还要用) 等
        # 但核心的 zhz_rag 包的依赖不在这里列出，它应该是独立安装的
    ],
)
    --- END OF FILE CONTENT ---


Directory: zhz_rag_pipeline_dagster/zhz_rag_pipeline/
  File: __init__.py
    --- START OF FILE CONTENT ---
# zhz_rag_pipeline/__init__.py
# This file makes Python treat the directory as a package.
# You can also define a __version__ or import key modules here if needed.
    --- END OF FILE CONTENT ---

  File: custom_io_managers.py
    --- START OF FILE CONTENT ---
# /home/zhz/zhz_agent/zhz_rag_pipeline_dagster/zhz_rag_pipeline/custom_io_managers.py
import json
import os
from typing import List, Type, Union, get_args, get_origin, Any, Optional 
from dagster import UPathIOManager, InputContext, OutputContext, DagsterInvariantViolationError
from pydantic import BaseModel as PydanticBaseModel
from upath import UPath

class PydanticListJsonIOManager(UPathIOManager):
    extension: str = ".jsonl"

    def __init__(self, base_dir: Optional[str] = None): # Changed base_path to base_dir for clarity
        resolved_base_dir: UPath
        if base_dir:
            resolved_base_dir = UPath(base_dir).resolve() # Resolve to absolute path
        else:
            # Default to <DAGSTER_HOME>/storage/pydantic_jsonl_io
            # DAGSTER_HOME defaults to ~/.dagster, but can be overridden by env var
            dagster_home_str = os.getenv("DAGSTER_HOME", os.path.join(os.path.expanduser("~"), ".dagster"))
            resolved_base_dir = UPath(dagster_home_str) / "storage" / "pydantic_jsonl_io"
        
        # Ensure the directory exists
        try:
            resolved_base_dir.mkdir(parents=True, exist_ok=True)
        except Exception as e:
            # Log this error appropriately, perhaps using a direct print if logger isn't set up yet
            # or re-raise as a Dagster-specific error.
            print(f"[PydanticListJsonIOManager __init__] ERROR: Could not create bafef __init__(self, base_dir: Optse directory {resolved_base_dir}: {e}")
            # Depending on Dagster's init sequence, context.log might not be available here.
            # It's safer to let UPathIOManager handle its own base_path or ensure dir exists before.
            # For now, we proceed, UPathIOManager might handle it or fail later.

        super().__init__(base_path=resolved_base_dir)
        # Log the final base path used by the UPathIOManager instance
        # self.log available after super().__init__() in ConfigurableIOManager context
        # For direct instantiation, we might need to pass a logger or use a global one.
        # print(f"[PydanticListJsonIOManager __init__] Initialized with resolved base_path: {self.base_path}")


    def dump_to_path(self, context: OutputContext, obj: List[PydanticBaseModel], path: UPath):
        context.log.info(f"[PydanticListJsonIOManager dump_to_path] Attempting to dump to resolved path: {path.resolve()}")
        
        if not isinstance(obj, list):
            msg = f"Expected a list of Pydantic models, got {type(obj)}"
            context.log.error(msg)
            raise TypeError(msg)
        
        # Optional: More robust type checking for list items if needed, using context.dagster_type
        # For now, assume obj is List[PydanticBaseModel] based on upstream asset's type hint.

        try:
            with path.open("w", encoding="utf-8") as f:
                for model_instance in obj:
                    if not isinstance(model_instance, PydanticBaseModel):
                        context.log.warning(f"Item in list is not a Pydantic model: {type(model_instance)}. Skipping.")
                        continue
                    json_str = model_instance.json() # Pydantic V1
                    f.write(json_str + "\n")
            context.log.info(f"[PydanticListJsonIOManager dump_to_path] Successfully dumped {len(obj)} items to {path.resolve()}")
        except Exception as e:
            context.log.error(f"[PydanticListJsonIOManager dump_to_path] Failed to dump object to {path.resolve()}: {e}", exc_info=True)
            raise

    def load_from_path(self, context: InputContext, path: UPath) -> List[PydanticBaseModel]:
        context.log.info(f"[PydanticListJsonIOManager load_from_path] Attempting to load from resolved path: {path.resolve()}")
        
        list_typing_type = context.dagster_type.typing_type
        origin = get_origin(list_typing_type)
        args = get_args(list_typing_type)

        if not (origin is list and args and issubclass(args[0], PydanticBaseModel)):
            msg = (
                f"PydanticListJsonIOManager can only handle inputs of type List[PydanticModel], "
                f"but got {list_typing_type} for input '{context.name}'."
            )
            context.log.error(msg)
            raise DagsterInvariantViolationError(msg) # Use Dagster specific error
        
        model_type: Type[PydanticBaseModel] = args[0]
        context.log.info(f"[PydanticListJsonIOManager load_from_path] Target model type for list items: {model_type.__name__}")

        loaded_models: List[PydanticBaseModel] = []
        if not path.exists():
            context.log.warning(f"[PydanticListJsonIOManager load_from_path] File not found at {path.resolve()}, returning empty list for input '{context.name}'.")
            return loaded_models

        try:
            with path.open("r", encoding="utf-8") as f:
                for line_number, line in enumerate(f, 1):
                    line_content = line.strip()
                    if not line_content:
                        continue
                    try:
                        model_instance = model_type.parse_raw(line_content) # Pydantic V1
                        loaded_models.append(model_instance)
                    except Exception as e_parse:
                        context.log.error(
                            f"[PydanticListJsonIOManager load_from_path] Failed to parse JSON line {line_number} "
                            f"into {model_type.__name__} from {path.resolve()}: {e_parse}. "
                            f"Line content (first 100 chars): '{line_content[:100]}...'",
                            exc_info=True
                        )
                        # Optionally re-raise or decide to skip problematic lines
                        # For now, we'll skip
            context.log.info(f"[PydanticListJsonIOManager load_from_path] Successfully loaded {len(loaded_models)} instances of {model_type.__name__} from {path.resolve()}")
        except Exception as e_read:
            context.log.error(f"[PydanticListJsonIOManager load_from_path] Failed to read or process file {path.resolve()}: {e_read}", exc_info=True)
            raise # Re-raise if file reading itself fails catastrophically
            
        return loaded_models
    --- END OF FILE CONTENT ---

  File: definitions.py
    --- START OF FILE CONTENT ---
# /home/zhz/zhz_agent/zhz_rag_pipeline_dagster/zhz_rag_pipeline/definitions.py
import dagster as dg
import os

# 导入 in_process_executor
from dagster import define_asset_job, in_process_executor

from zhz_rag_pipeline_dagster.zhz_rag_pipeline.ingestion_assets import all_ingestion_assets
from zhz_rag_pipeline_dagster.zhz_rag_pipeline.processing_assets import (
    all_processing_assets,
    # 单独导入 Kuzu 相关的资产，以便放入特定作业
    kuzu_schema_initialized_asset,
    kuzu_entity_nodes_asset,
    kuzu_entity_relations_asset,
    # 也需要 kg_extractions 作为上游
    kg_extraction_asset,
    # 以及 kg_extractions 的上游
    clean_chunk_text_asset# 假设 kg_extraction_asset 的上游是 text_chunks
)
from zhz_rag_pipeline_dagster.zhz_rag_pipeline.evaluation_assets import all_evaluation_assets
from zhz_rag_pipeline_dagster.zhz_rag_pipeline.resources import (
    SentenceTransformerResource, SentenceTransformerResourceConfig,
    ChromaDBResource, ChromaDBResourceConfig,
    SGLangAPIResource, SGLangAPIResourceConfig,
    KuzuDBReadWriteResource, 
    KuzuDBReadOnlyResource,
    GeminiAPIResource, GeminiAPIResourceConfig
)
from zhz_rag_pipeline_dagster.zhz_rag_pipeline.custom_io_managers import PydanticListJsonIOManager

# 将所有非 Kuzu 写操作的资产组合起来
# 注意：我们需要从 all_processing_assets 中移除 Kuzu 相关的写资产
# 或者更简单的方式是，明确列出哪些资产属于哪个作业或全局资产组
non_kuzu_write_processing_assets = [
    asset for asset in all_processing_assets 
    if asset.key not in [
        kuzu_schema_initialized_asset.key, 
        kuzu_entity_nodes_asset.key, 
        kuzu_entity_relations_asset.key
    ]
]
# kg_extraction_asset 虽然是 kg_building 组，但它不直接写 KuzuDB，而是产生供下游写入的数据
# text_chunks_asset 是 kg_extraction_asset 的上游，也需要包含

# 所有资产（用于默认加载，或者如果某些资产不属于特定作业）
# all_project_assets = all_ingestion_assets + non_kuzu_write_processing_assets + all_evaluation_assets
# 实际上，定义了作业后，我们主要通过作业来执行。
# 我们可以将所有资产都列在 Definitions 的 assets 中，然后作业通过 selection 选择。

all_defined_assets = all_ingestion_assets + all_processing_assets + all_evaluation_assets


# 定义 KuzuDB 写入作业
kuzu_kg_write_job = define_asset_job(
    name="kuzu_kg_write_job",
    selection=[ # 选择所有参与 KuzuDB 知识图谱构建的资产
        clean_chunk_text_asset, # kg_extraction_asset 的上游
        kg_extraction_asset,
        kuzu_schema_initialized_asset,
        kuzu_entity_nodes_asset,
        kuzu_entity_relations_asset
    ],
    executor_def=in_process_executor # <--- 使用单进程执行器
)

# IO Manager
pydantic_io_manager_instance = PydanticListJsonIOManager()

defs = dg.Definitions(
    assets=all_defined_assets, # 列出所有资产
    jobs=[kuzu_kg_write_job],  # <--- 添加作业
    resources={
        "embedder": SentenceTransformerResource(
            model_name_or_path=SentenceTransformerResourceConfig().model_name_or_path
        ),
        "chroma_db": ChromaDBResource(
            collection_name=ChromaDBResourceConfig().collection_name,
            persist_directory=ChromaDBResourceConfig().persist_directory
        ),
        "sglang_api": SGLangAPIResource(
            api_url=SGLangAPIResourceConfig().api_url,
            default_temperature=SGLangAPIResourceConfig().default_temperature,
            default_max_new_tokens=SGLangAPIResourceConfig().default_max_new_tokens
        ),
        "kuzu_readwrite_db": KuzuDBReadWriteResource(
            # 使用资源类中定义的默认值
            # clear_on_startup_for_testing=True # 测试时可以设为True，确保从干净状态开始
        ),
        "kuzu_readonly_db": KuzuDBReadOnlyResource(
            # 使用资源类中定义的默认值
        ),
        "gemini_api": GeminiAPIResource(
            model_name=GeminiAPIResourceConfig().model_name,
            proxy_url=GeminiAPIResourceConfig().proxy_url,
            default_temperature=GeminiAPIResourceConfig().default_temperature,
            default_max_tokens=GeminiAPIResourceConfig().default_max_tokens
        ),
        "pydantic_json_io_manager": pydantic_io_manager_instance,
        # 如果 KuzuDB 资源被其他非此作业的资产使用，确保它们使用 KuzuDBReadOnlyResource
    }
)
    --- END OF FILE CONTENT ---

  File: evaluation_assets.py
    --- START OF FILE CONTENT ---
import dagster as dg
import os
from typing import Dict, List, Any # Optional 可能之后会用到

# 从项目中导入我们重构的批量评估函数和相关工具/常量
from zhz_rag.evaluation.batch_eval_cypher import run_cypher_batch_evaluation
from zhz_rag.evaluation.batch_eval_answer import run_answer_batch_evaluation
from zhz_rag.evaluation.analyze_cypher import perform_cypher_evaluation_analysis
from zhz_rag.evaluation.analyze_answer import perform_answer_evaluation_analysis
from zhz_rag.utils.common_utils import (
    find_latest_rag_interaction_log,
    RAG_INTERACTION_LOGS_DIR,
    EVALUATION_RESULTS_LOGS_DIR,
    get_evaluation_result_log_filepath
)
# 导入 GeminiAPIResource 以声明资源依赖
from zhz_rag_pipeline_dagster.zhz_rag_pipeline.resources import GeminiAPIResource

# --- 资产定义 ---

@dg.asset(
    name="latest_rag_interaction_log_for_evaluation",
    description="Provides the filepath of the latest RAG interaction log to be used for evaluation.",
    group_name="evaluation_pipeline",
    compute_kind="python" # 可选，指明计算类型
)
def latest_rag_interaction_log_for_evaluation_asset(context: dg.AssetExecutionContext) -> str:
    """
    Finds and returns the path to the latest RAG interaction log file.
    """
    log_filepath = find_latest_rag_interaction_log(RAG_INTERACTION_LOGS_DIR)
    if not log_filepath or not os.path.exists(log_filepath):
        error_msg = f"No RAG interaction log file found in directory: {RAG_INTERACTION_LOGS_DIR}"
        context.log.error(error_msg)
        raise dg.Failure(description=error_msg)
    
    context.log.info(f"Using RAG interaction log for evaluation: {log_filepath}")
    context.add_output_metadata({"log_filepath": log_filepath, "filename": os.path.basename(log_filepath)})
    return log_filepath

@dg.asset(
    name="batch_cypher_evaluations_log", # 资产名称最好能反映它产出的是日志文件
    description="Runs batch evaluation of Cypher queries and produces an evaluation log file.",
    group_name="evaluation_pipeline",
    compute_kind="python",
    # deps=[latest_rag_interaction_log_for_evaluation_asset] # 通过函数参数自动推断依赖
)
async def batch_cypher_evaluation_log_asset(
    context: dg.AssetExecutionContext,
    gemini_api: GeminiAPIResource,
    latest_rag_interaction_log_for_evaluation: str # <--- 修改参数名
) -> dg.Output[str]:
    context.log.info(f"Starting batch Cypher evaluation using log file: {latest_rag_interaction_log_for_evaluation}") # <--- 使用新参数名
    
    # 从 Dagster 配置中获取参数，或使用默认/环境变量
    # 这里我们先用之前脚本中的方式，未来可以转为 Dagster run_config
    app_version = os.getenv("APP_VERSION_TAG", "dagster_cypher_eval_0.2")
    # 对于 use_simulated_api，在 Dagster 中通常会通过资源配置或 op_config 来控制，
    # 而不是直接依赖环境变量，这样更灵活。但为了保持与脚本一致，暂时保留。
    use_simulated = os.getenv("USE_SIMULATED_GEMINI_CYPHER_EVAL", "false").lower() == "true"
    api_delay = float(os.getenv("GEMINI_API_CALL_DELAY_SECONDS", "4.1"))

    if use_simulated:
        context.log.warning("Cypher evaluation asset is using SIMULATED Gemini API calls.")

    # 调用我们重构的、现在接受 gemini_resource 的批量评估函数
    eval_stats = await run_cypher_batch_evaluation(
        gemini_resource_for_evaluator=gemini_api, # 传递注入的 Dagster 资源
        rag_interaction_log_filepath=latest_rag_interaction_log_for_evaluation,
        app_version=app_version,
        use_simulated_api=use_simulated, # 这个参数现在由 run_cypher_batch_evaluation 内部处理
        api_call_delay=api_delay
    )
    context.log.info(f"Batch Cypher evaluation completed. Statistics: {eval_stats}")

    # 确定输出的评估结果日志文件名 (与 evaluator.py 中一致)
    output_log_filepath = get_evaluation_result_log_filepath(evaluation_name="cypher_gemini_flash")
    
    # 确保目录存在 (get_evaluation_result_log_filepath 内部的 log_interaction_data 会处理)
    # 但这里我们也可以提前确保，或者依赖 log_interaction_data
    os.makedirs(os.path.dirname(output_log_filepath), exist_ok=True)
            
    metadata = {"evaluation_stats": eval_stats, "output_filepath": output_log_filepath}
    if eval_stats.get("cypher_queries_evaluated", 0) == 0:
        metadata["warning"] = "No Cypher queries were evaluated. Output log might be empty."
        context.log.warning(metadata["warning"])

    return dg.Output(output_log_filepath, metadata=metadata)


@dg.asset(
    name="batch_answer_evaluations_log", # 资产名称
    description="Runs batch evaluation of generated answers from RAG logs using Gemini.",
    group_name="evaluation_pipeline",
    compute_kind="python",
    # deps=[latest_rag_interaction_log_for_evaluation_asset] # 通过函数参数自动推断依赖
)
async def batch_answer_evaluation_log_asset(
    context: dg.AssetExecutionContext,
    gemini_api: GeminiAPIResource,
    latest_rag_interaction_log_for_evaluation: str # <--- 修改参数名
) -> dg.Output[str]:
    context.log.info(f"Starting batch Answer evaluation using log file: {latest_rag_interaction_log_for_evaluation}") # <--- 使用新参数名
    app_version = os.getenv("APP_VERSION_TAG", "dagster_answer_eval_0.2")
    use_simulated = os.getenv("USE_SIMULATED_GEMINI_ANSWER_EVAL", "false").lower() == "true"
    api_delay = float(os.getenv("GEMINI_API_CALL_DELAY_SECONDS", "4.1"))

    if use_simulated:
        context.log.warning("Answer evaluation asset is using SIMULATED Gemini API calls.")

    eval_stats = await run_answer_batch_evaluation(
        gemini_resource_for_evaluator=gemini_api, # 传递注入的 Dagster 资源
        rag_interaction_log_filepath=latest_rag_interaction_log_for_evaluation,
        app_version=app_version,
        use_simulated_api=use_simulated, # 这个参数现在由 run_answer_batch_evaluation 内部处理
        api_call_delay=api_delay
    )
    context.log.info(f"Batch Answer evaluation completed. Statistics: {eval_stats}")

    output_log_filepath = get_evaluation_result_log_filepath(evaluation_name="answer_gemini_flash")
    os.makedirs(os.path.dirname(output_log_filepath), exist_ok=True)

    metadata = {"evaluation_stats": eval_stats, "output_filepath": output_log_filepath}
    if eval_stats.get("answers_evaluated", 0) == 0:
        metadata["warning"] = "No answers were evaluated. Output log might be empty."
        context.log.warning(metadata["warning"])
        
    return dg.Output(output_log_filepath, metadata=metadata)

@dg.asset(
    name="cypher_evaluation_analysis_report", # 资产名称
    description="Generates a CSV analysis report from Cypher evaluation results.",
    group_name="evaluation_pipeline",
    compute_kind="python",
    # deps=[batch_cypher_evaluation_log_asset] # 通过函数参数自动推断依赖
)
def cypher_analysis_report_asset(
    context: dg.AssetExecutionContext,
    batch_cypher_evaluations_log: str # 上游资产的输出 (即 cypher 评估日志文件的路径)
) -> dg.Output[str]: # 输出 CSV 报告文件的路径
    """
    Analyzes Cypher evaluation logs and produces a CSV report.
    """
    context.log.info(f"Starting Cypher evaluation analysis using log file: {batch_cypher_evaluations_log}")

    if not os.path.exists(batch_cypher_evaluations_log):
        error_msg = f"Input Cypher evaluation log file not found: {batch_cypher_evaluations_log}"
        context.log.error(error_msg)
        raise dg.Failure(description=error_msg)

    # 构建输出CSV文件的路径
    # 我们希望CSV文件也存储在 EVALUATION_RESULTS_LOGS_DIR 目录下
    # 文件名可以基于输入日志名或固定一个模式
    base_input_log_name = os.path.basename(batch_cypher_evaluations_log)
    # 从 "eval_results_cypher_gemini_flash_YYYYMMDD.jsonl" 生成 "analysis_cypher_gemini_flash_YYYYMMDD.csv"
    if base_input_log_name.startswith("eval_results_") and base_input_log_name.endswith(".jsonl"):
        analysis_file_name = "analysis_" + base_input_log_name[len("eval_results_"):-len(".jsonl")] + ".csv"
    else: # Fallback naming
        analysis_file_name = f"analysis_cypher_report_{context.run_id[:8]}.csv"
    
    output_csv_filepath = os.path.join(EVALUATION_RESULTS_LOGS_DIR, analysis_file_name)
    
    success = perform_cypher_evaluation_analysis(
        evaluation_log_filepath=batch_cypher_evaluations_log,
        output_csv_filepath=output_csv_filepath
    )

    if success:
        context.log.info(f"Cypher evaluation analysis report generated: {output_csv_filepath}")
        return dg.Output(output_csv_filepath, metadata={"output_csv_filepath": output_csv_filepath, "source_log": base_input_log_name})
    else:
        error_msg = f"Cypher evaluation analysis failed for log file: {batch_cypher_evaluations_log}"
        context.log.error(error_msg)
        raise dg.Failure(description=error_msg)


@dg.asset(
    name="answer_evaluation_analysis_report", # 资产名称
    description="Generates a CSV analysis report from Answer evaluation results.",
    group_name="evaluation_pipeline",
    compute_kind="python",
    # deps=[batch_answer_evaluations_log_asset] # 通过函数参数自动推断依赖
)
def answer_analysis_report_asset(
    context: dg.AssetExecutionContext,
    batch_answer_evaluations_log: str # 上游资产的输出 (即 answer 评估日志文件的路径)
) -> dg.Output[str]: # 输出 CSV 报告文件的路径
    """
    Analyzes Answer evaluation logs and produces a CSV report.
    """
    context.log.info(f"Starting Answer evaluation analysis using log file: {batch_answer_evaluations_log}")

    if not os.path.exists(batch_answer_evaluations_log):
        error_msg = f"Input Answer evaluation log file not found: {batch_answer_evaluations_log}"
        context.log.error(error_msg)
        raise dg.Failure(description=error_msg)

    base_input_log_name = os.path.basename(batch_answer_evaluations_log)
    if base_input_log_name.startswith("eval_results_") and base_input_log_name.endswith(".jsonl"):
        analysis_file_name = "analysis_" + base_input_log_name[len("eval_results_"):-len(".jsonl")] + ".csv"
    else: # Fallback naming
        analysis_file_name = f"analysis_answer_report_{context.run_id[:8]}.csv"
        
    output_csv_filepath = os.path.join(EVALUATION_RESULTS_LOGS_DIR, analysis_file_name)

    success = perform_answer_evaluation_analysis(
        evaluation_log_filepath=batch_answer_evaluations_log,
        output_csv_filepath=output_csv_filepath
    )

    if success:
        context.log.info(f"Answer evaluation analysis report generated: {output_csv_filepath}")
        return dg.Output(output_csv_filepath, metadata={"output_csv_filepath": output_csv_filepath, "source_log": base_input_log_name})
    else:
        error_msg = f"Answer evaluation analysis failed for log file: {batch_answer_evaluations_log}"
        context.log.error(error_msg)
        raise dg.Failure(description=error_msg)

# 将所有评估相关的资产收集到一个列表中，方便在 definitions.py 中引用
all_evaluation_assets = [
    latest_rag_interaction_log_for_evaluation_asset,
    batch_cypher_evaluation_log_asset,
    batch_answer_evaluation_log_asset,
    cypher_analysis_report_asset, # <--- 新增
    answer_analysis_report_asset, # <--- 新增
]
    --- END OF FILE CONTENT ---

  File: ingestion_assets.py
    --- START OF FILE CONTENT ---
# zhz_rag_pipeline/ingestion_assets.py
import dagster as dg
import os
from typing import List, Dict, Any, Union

# 从我们新建的pydantic模型文件中导入
from .pydantic_models_dagster import LoadedDocumentOutput, ParsedDocumentOutput

class LoadDocumentsConfig(dg.Config):
    documents_directory: str = "/home/zhz/zhz_agent/data/raw_documents/" # 更新后的原始文档目录
    allowed_extensions: List[str] = [".txt"]

@dg.asset(
    name="raw_documents",
    description="Loads raw documents from a specified directory.",
    group_name="ingestion" # 给资产分组
)
def load_documents_asset(
    context: dg.AssetExecutionContext, 
    config: LoadDocumentsConfig
) -> List[LoadedDocumentOutput]:
    
    loaded_docs: List[LoadedDocumentOutput] = []
    target_directory = config.documents_directory
    allowed_exts = tuple(config.allowed_extensions) 

    context.log.info(f"Scanning directory: {target_directory} for files with extensions: {allowed_exts}")

    if not os.path.isdir(target_directory):
        context.log.error(f"Directory not found: {target_directory}")
        return loaded_docs

    for filename in os.listdir(target_directory):
        file_path = os.path.join(target_directory, filename)
        if os.path.isfile(file_path):
            file_name_lower = filename.lower()
            file_extension = os.path.splitext(file_name_lower)[1]

            if file_extension in allowed_exts:
                context.log.info(f"Found matching file: {file_path}")
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    doc_output = LoadedDocumentOutput(
                        document_path=file_path,
                        file_type=file_extension,
                        raw_content=content,
                        metadata={
                            "filename": filename,
                            "source_directory": target_directory,
                            "size_bytes": os.path.getsize(file_path)
                        }
                    )
                    loaded_docs.append(doc_output)
                    context.log.info(f"Successfully loaded and created output for: {file_path}")
                except Exception as e:
                    context.log.error(f"Failed to read or process file {file_path}: {e}")
            else:
                context.log.debug(f"Skipping file with non-allowed extension: {file_path}")
        else:
            context.log.debug(f"Skipping non-file item: {file_path}")
            
    if not loaded_docs:
        context.log.warning(f"No matching documents found in {target_directory}")

    if loaded_docs:
        context.add_output_metadata(
            metadata={
                "num_documents_loaded": len(loaded_docs),
                "first_document_path": loaded_docs[0].document_path if loaded_docs else "N/A"
            }
        )
    return loaded_docs


@dg.asset(
    name="parsed_documents",
    description="Parses loaded documents into text and extracts basic structure.",
    group_name="ingestion"
    # deps=[load_documents_asset] # <--- 删除这一行，因为依赖已通过函数参数 raw_documents 声明
)
def parse_document_asset(
    context: dg.AssetExecutionContext, 
    raw_documents: List[LoadedDocumentOutput] 
) -> List[ParsedDocumentOutput]:
    
    parsed_docs: List[ParsedDocumentOutput] = []
    context.log.info(f"Received {len(raw_documents)} documents to parse.")

    for doc_input in raw_documents:
        context.log.info(f"Parsing document: {doc_input.document_path} (Type: {doc_input.file_type})")
        parsed_text_content = ""
        
        try:
            if doc_input.file_type == ".txt":
                if isinstance(doc_input.raw_content, bytes):
                    parsed_text_content = doc_input.raw_content.decode('utf-8')
                elif isinstance(doc_input.raw_content, str):
                    parsed_text_content = doc_input.raw_content
                else:
                    # 抛出更具体的错误或记录并跳过
                    context.log.error(f"Unexpected raw_content type for .txt file: {type(doc_input.raw_content)} in {doc_input.document_path}")
                    parsed_text_content = f"[Error: Unexpected content type {type(doc_input.raw_content)}]"

            # TODO: Add parsers for other file types like .pdf, .docx here
            # elif doc_input.file_type == ".pdf":
            #     parsed_text_content = "[PDF parsing not yet implemented]"
            #     context.log.warning(f"PDF parsing not yet implemented for {doc_input.document_path}")
            else:
                parsed_text_content = f"[Unsupported file type: {doc_input.file_type}]"
                context.log.warning(f"Unsupported file type '{doc_input.file_type}' for parsing: {doc_input.document_path}")

            parsed_output = ParsedDocumentOutput(
                parsed_text=parsed_text_content,
                # document_structure is None by default
                original_metadata=doc_input.metadata 
            )
            parsed_docs.append(parsed_output)
            context.log.info(f"Successfully (or with placeholder) parsed: {doc_input.document_path}")

        except Exception as e:
            context.log.error(f"Failed to parse document {doc_input.document_path}: {e}")
            parsed_output = ParsedDocumentOutput(
                parsed_text=f"[Error parsing document: {str(e)}]",
                original_metadata=doc_input.metadata
            )
            parsed_docs.append(parsed_output)

    if parsed_docs:
        context.add_output_metadata(
            metadata={
                "num_documents_parsed": len(parsed_docs),
                "first_parsed_doc_filename": parsed_docs[0].original_metadata.get("filename", "N/A") if parsed_docs else "N/A"
            }
        )
    return parsed_docs

all_ingestion_assets = [load_documents_asset, parse_document_asset]
    --- END OF FILE CONTENT ---

  File: processing_assets.py
    --- START OF FILE CONTENT ---
# /home/zhz/zhz_agent/zhz_rag_pipeline_dagster/zhz_rag_pipeline/processing_assets.py
import dagster as dg
from typing import List, Dict, Any, Optional
import uuid
from langchain_text_splitters import RecursiveCharacterTextSplitter
import hashlib
import pandas as pd 
from zhz_rag.utils.common_utils import normalize_text_for_id
from zhz_rag_pipeline_dagster.zhz_rag_pipeline.pydantic_models_dagster import (
    ChunkOutput,
    ParsedDocumentOutput,
    EmbeddingOutput,
    KGTripleSetOutput, 
    ExtractedEntity,
    ExtractedRelation
)
from zhz_rag_pipeline_dagster.zhz_rag_pipeline.resources import (
    SentenceTransformerResource,
    ChromaDBResource,
    SGLangAPIResource,
    KuzuDBReadWriteResource,
    KuzuDBReadOnlyResource
)
import jieba
import bm25s
import pickle
import numpy as np
import os

class TextChunkerConfig(dg.Config):
    chunk_size: int = 500
    chunk_overlap: int = 50
    # separators: Optional[List[str]] = None # 可选的自定义分隔符

@dg.asset(
    name="text_chunks",
    description="Cleans and chunks parsed documents into smaller text segments.",
    group_name="processing", # 属于处理组
    # deps=["parsed_documents"] # <--- 删除或注释掉这一行
)
def clean_chunk_text_asset(
    context: dg.AssetExecutionContext,
    config: TextChunkerConfig,
    parsed_documents: List[ParsedDocumentOutput] 
) -> List[ChunkOutput]: 
    
    all_chunks: List[ChunkOutput] = []
    context.log.info(f"Received {len(parsed_documents)} parsed documents to clean and chunk.")

    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=config.chunk_size,
        chunk_overlap=config.chunk_overlap,
        # length_function=len, # 默认
        # add_start_index=True, # 如果需要块的起始索引
        # separators=config.separators if config.separators else None # 使用配置的分隔符
    )

    for parsed_doc in parsed_documents:
        # 使用原始文件名作为文档ID，如果不存在则生成UUID
        doc_id_from_meta = parsed_doc.original_metadata.get("filename")
        if not doc_id_from_meta:
            doc_id_from_meta = parsed_doc.original_metadata.get("document_path", str(uuid.uuid4()))
            context.log.warning(f"Filename not found in metadata for a document, using path or UUID: {doc_id_from_meta}")
        
        source_dir = parsed_doc.original_metadata.get('source_directory', 'Unknown_Source_Dir')
        context.log.info(f"Processing document: {doc_id_from_meta} (from {source_dir})")

        cleaned_text = parsed_doc.parsed_text.strip()

        if not cleaned_text or cleaned_text.startswith("[Unsupported file type:") or cleaned_text.startswith("[Error parsing document:"):
            context.log.warning(f"Document {doc_id_from_meta} has no valid content or was unsupported/errored in parsing, skipping chunking.")
            continue
        
        try:
            chunks_text_list = text_splitter.split_text(cleaned_text)
            context.log.info(f"Document {doc_id_from_meta} split into {len(chunks_text_list)} chunks.")

            for i, chunk_text_content in enumerate(chunks_text_list):
                chunk_meta = parsed_doc.original_metadata.copy() 
                chunk_meta.update({
                    "chunk_number": i + 1,
                    "total_chunks_for_doc": len(chunks_text_list),
                    "chunk_char_length": len(chunk_text_content),
                })

                chunk_output = ChunkOutput( # chunk_id 会在 ChunkOutput 的 __init__ 中自动生成
                    chunk_text=chunk_text_content,
                    source_document_id=doc_id_from_meta, # 使用从元数据获取的文档ID
                    chunk_metadata=chunk_meta
                )
                all_chunks.append(chunk_output)
        
        except Exception as e:
            context.log.error(f"Failed to chunk document {doc_id_from_meta}: {e}")
            
    if all_chunks:
        context.add_output_metadata(
            metadata={
                "total_chunks_generated": len(all_chunks),
                "first_chunk_doc_id": all_chunks[0].source_document_id if all_chunks else "N/A"
            }
        )
    else:
        context.log.warning("No chunks were generated from the input documents.")
        
    return all_chunks

# --- 新增：EmbeddingGenerationAgent (实现为 Asset) ---
@dg.asset(
    name="text_embeddings",
    description="Generates vector embeddings for text chunks using a SentenceTransformer model.",
    group_name="processing",
    # deps=["text_chunks"] # <--- 删除或注释掉这一行
)
def generate_embeddings_asset(
    context: dg.AssetExecutionContext,
    text_chunks: List[ChunkOutput], # 输入是上游资产的输出列表
    embedder: SentenceTransformerResource # <--- 注入我们定义的Resource
) -> List[EmbeddingOutput]:
    
    all_embeddings: List[EmbeddingOutput] = []
    context.log.info(f"Received {len(text_chunks)} text chunks to generate embeddings for.")

    if not text_chunks:
        context.log.warning("No text chunks received, skipping embedding generation.")
        return all_embeddings

    # 提取所有块的文本内容进行批量编码
    chunk_texts_to_encode = [chunk.chunk_text for chunk in text_chunks]
    
    try:
        context.log.info(f"Starting batch embedding generation for {len(chunk_texts_to_encode)} texts...")
        # 使用Resource的encode方法
        vectors = embedder.encode(chunk_texts_to_encode) 
        context.log.info(f"Successfully generated {len(vectors)} embedding vectors.")

        if len(vectors) != len(text_chunks):
            # 这是一个预期外的情况，应该记录严重错误
            context.log.error(f"Mismatch in number of chunks ({len(text_chunks)}) and generated vectors ({len(vectors)}). Aborting.")
            # 可以在这里抛出异常来使资产失败
            raise ValueError("Embedding generation resulted in a mismatched number of vectors.")

        for i, chunk_input in enumerate(text_chunks):
            embedding_output = EmbeddingOutput(
                chunk_id=chunk_input.chunk_id,
                chunk_text=chunk_input.chunk_text,
                embedding_vector=vectors[i],
                embedding_model_name=embedder.model_name_or_path, # 从Resource获取模型名
                original_chunk_metadata=chunk_input.chunk_metadata
            )
            all_embeddings.append(embedding_output)
        
        context.log.info(f"All {len(all_embeddings)} embeddings prepared.")

    except Exception as e:
        context.log.error(f"Failed to generate embeddings: {e}")
        # 根据策略，可以选择让资产失败，或者返回空列表/部分结果
        # 这里我们选择抛出异常，让资产运行失败，以便调查
        raise

    if all_embeddings:
        context.add_output_metadata(
            metadata={
                "total_embeddings_generated": len(all_embeddings),
                "embedding_model_used": embedder.model_name_or_path,
                "first_chunk_id_embedded": all_embeddings[0].chunk_id if all_embeddings else "N/A"
            }
        )
    return all_embeddings

# --- 新增：VectorStorageAgent (实现为 Asset) ---
@dg.asset(
    name="vector_store_embeddings",
    description="Stores text embeddings into a ChromaDB vector store.",
    group_name="indexing", # 新的分组
    # deps=["text_embeddings"] # 依赖上一个资产的name
)
def vector_storage_asset(
    context: dg.AssetExecutionContext,
    text_embeddings: List[EmbeddingOutput], # 输入是上游资产的输出列表
    chroma_db: ChromaDBResource # <--- 注入ChromaDB Resource
) -> None: # 这个资产通常只执行操作，不产生新的可传递数据资产，所以返回None
    
    context.log.info(f"Received {len(text_embeddings)} embeddings to store in ChromaDB.")

    if not text_embeddings:
        context.log.warning("No embeddings received, nothing to store.")
        # 可以在这里添加一个 AssetMaterialization 来记录这个空操作
        context.add_output_metadata(metadata={"num_embeddings_stored": 0, "status": "No data to store"})
        return

    ids_to_store: List[str] = []
    embeddings_to_store: List[List[float]] = []
    metadatas_to_store: List[Dict[str, Any]] = []

    for emb_output in text_embeddings: # emb_output 是 EmbeddingOutput 类型
        ids_to_store.append(emb_output.chunk_id) 
        embeddings_to_store.append(emb_output.embedding_vector)
        
        simple_metadata = {}
        for key, value in emb_output.original_chunk_metadata.items(): # 从原始块元数据开始
            if isinstance(value, (str, int, float, bool)):
                simple_metadata[key] = value
            else:
                simple_metadata[key] = str(value) 
        
        simple_metadata["chunk_text"] = emb_output.chunk_text # <--- 直接从emb_output获取

        metadatas_to_store.append(simple_metadata)

    try:
        chroma_db.add_embeddings(
            ids=ids_to_store,
            embeddings=embeddings_to_store,
            metadatas=metadatas_to_store
        )
        context.log.info(f"Successfully stored/updated {len(ids_to_store)} embeddings in ChromaDB.")
        
        # 记录物化信息
        context.add_output_metadata(
            metadata={
                "num_embeddings_stored": len(ids_to_store),
                "collection_name": chroma_db.collection_name,
                "status": "Success"
            }
        )
    except Exception as e:
        context.log.error(f"Failed to store embeddings in ChromaDB: {e}")
        context.add_output_metadata(
            metadata={
                "num_embeddings_stored": 0,
                "collection_name": chroma_db.collection_name,
                "status": f"Failed: {str(e)}"
            }
        )
        raise # 让资产失败


# --- 新增：定义 KeywordIndexAgent 的配置 Pydantic 模型 ---
class BM25IndexConfig(dg.Config):
    index_file_path: str = "/home/zhz/zhz_agent/zhz_rag/stored_data/bm25_index/"

# --- 修改：KeywordIndexAgent (实现为 Asset) ---
@dg.asset(
    name="keyword_index",
    description="Builds and persists a BM25 keyword index from text chunks.",
    group_name="indexing",
    # deps=["text_chunks"] 
)
def keyword_index_asset(
    context: dg.AssetExecutionContext,
    config: BM25IndexConfig,
    text_chunks: List[ChunkOutput] 
) -> None:
    
    context.log.info(f"Received {len(text_chunks)} text chunks to build BM25 index.")

    if not text_chunks:
        # ... (无数据处理不变) ...
        context.log.warning("No text chunks received, skipping BM25 index building.")
        context.add_output_metadata(metadata={"num_documents_indexed": 0, "status": "No data"})
        return

    corpus_texts: List[str] = [chunk.chunk_text for chunk in text_chunks]
    document_ids: List[str] = [chunk.chunk_id for chunk in text_chunks] # 我们仍然需要保存这个映射

    context.log.info("Tokenizing corpus using jieba...")
    # 使用jieba分词，但bm25s有自己的tokenize函数，可以接受自定义分词器，或者直接处理分词后的列表
    # 为了与bm25s的tokenize函数配合，我们可以先用jieba分好，再传给bm25s的tokenizer
    # 或者，如果bm25s的默认分词或其Tokenizer类能满足中文需求，可以直接用。
    # 为了简单且利用jieba，我们先分词
    corpus_tokenized_jieba = [list(jieba.cut_for_search(text)) for text in corpus_texts]
    context.log.info(f"Jieba tokenization complete. Example: {corpus_tokenized_jieba[0][:10] if corpus_tokenized_jieba else 'N/A'}")

    context.log.info("Initializing BM25s model and indexing corpus...")
    try:
        # 根据bm25s文档，先创建BM25对象，然后调用index方法
        bm25_model = bm25s.BM25() # 可以传入k1, b等参数
        # .index() 方法接受已经分词的语料库 (list of list of str)
        bm25_model.index(corpus_tokenized_jieba)
        context.log.info("BM25s model indexed successfully.")
    except Exception as e:
        context.log.error(f"Failed to initialize or index with BM25s model: {e}")
        raise

    index_directory = config.index_file_path # 这应该是一个目录路径

    if not os.path.exists(index_directory):
        os.makedirs(index_directory, exist_ok=True)
        context.log.info(f"Created directory for BM25 index: {index_directory}")

    try:
        context.log.info(f"Saving BM25 model to directory: {index_directory}")
        # 使用bm25s的save方法，它会将多个文件保存到该目录下
        # 它会自动保存词汇表 (vocab.index.json) 和其他必要文件
        bm25_model.save(
            index_directory,
            # 文件名参数是可选的，bm25s有默认文件名，例如：
            # data_name="data.csc.index.npy",
            # indices_name="indices.csc.index.npy",
            # indptr_name="indptr.csc.index.npy",
            # vocab_name="vocab.index.json", 
            # params_name="params.index.json"
        )
        context.log.info(f"BM25 model saved successfully to {index_directory}")

        # 单独保存我们的 document_ids 列表，因为bm25s内部索引是基于0,1,2...
        # 而我们需要映射回原始的chunk_id
        doc_ids_path = os.path.join(index_directory, "doc_ids.pkl") # 保持这个文件名
        with open(doc_ids_path, 'wb') as f_out:
            pickle.dump(document_ids, f_out)
        context.log.info(f"Document IDs saved successfully to {doc_ids_path}")
        
        context.add_output_metadata(
            metadata={
                "num_documents_indexed": len(corpus_texts),
                "index_directory_path": index_directory, # <--- 修改：现在是目录路径
                "status": "Success"
            }
        )
    except Exception as e:
        # ... (错误处理不变) ...
        context.log.error(f"Failed to save BM25 model or document IDs: {e}")
        context.add_output_metadata(
            metadata={
                "num_documents_indexed": 0,
                "index_directory_path": index_directory,
                "status": f"Failed to save index: {str(e)}"
            }
        )
        raise

# 知识图谱
DEFAULT_KG_EXTRACTION_SCHEMA = { # <--- 覆盖这里的整个字典
    "type": "object",
    "properties": {
        "entities": {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "text": {"type": "string", "description": "提取到的实体原文"},
                    "label": {"type": "string", "description": "实体类型 (例如: PERSON, ORGANIZATION, TASK)"}
                },
                "required": ["text", "label"]
            },
            "description": "从文本中提取出的实体列表。"
        },
        "relations": { # <--- 新增/确保这部分存在且正确
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "head_entity_text": {"type": "string", "description": "头实体的文本"},
                    "head_entity_label": {"type": "string", "description": "头实体的类型 (例如: PERSON, TASK)"},
                    "relation_type": {"type": "string", "description": "关系类型 (例如: WORKS_AT, ASSIGNED_TO)"},
                    "tail_entity_text": {"type": "string", "description": "尾实体的文本"},
                    "tail_entity_label": {"type": "string", "description": "尾实体的类型 (例如: ORGANIZATION, PERSON)"}
                },
                "required": ["head_entity_text", "head_entity_label", "relation_type", "tail_entity_text", "tail_entity_label"]
            },
            "description": "从文本中提取出的关系三元组列表。"
        }
    },
    "required": ["entities", "relations"] # <--- 确保 "relations" 也在这里
}

class KGExtractionConfig(dg.Config):
    extraction_prompt_template: str = ( # <--- 覆盖这里的整个多行字符串
        "你是一个信息抽取助手。请从以下提供的文本中抽取出所有的人名(PERSON)、组织机构名(ORGANIZATION)和任务(TASK)实体。\n"
        "同时，请抽取出以下两种关系：\n"
        "1. WORKS_AT (当一个人在一个组织工作时，例如：PERSON WORKS_AT ORGANIZATION)\n"
        "2. ASSIGNED_TO (当一个任务分配给一个人时，例如：TASK ASSIGNED_TO PERSON)\n\n"
        "请严格按照以下JSON格式进行输出，不要包含任何额外的解释或Markdown标记：\n"
        "{{\n"
        "  \"entities\": [\n"
        "    {{\"text\": \"实体1原文\", \"label\": \"实体1类型\"}},\n"
        "    ...\n"
        "  ],\n"
        "  \"relations\": [\n"
        "    {{\"head_entity_text\": \"头实体文本\", \"head_entity_label\": \"头实体类型\", \"relation_type\": \"关系类型\", \"tail_entity_text\": \"尾实体文本\", \"tail_entity_label\": \"尾实体类型\"}},\n"
        "    ...\n"
        "  ]\n"
        "}}\n"
        "如果文本中没有可抽取的实体或关系，请返回一个空的对应列表 (例如 {{\"entities\": [], \"relations\": []}})。\n\n"
        "示例文本1：'项目Alpha的文档编写任务分配给了张三。张三在谷歌工作。'\n"
        "期望JSON输出1：\n"
        "{{\n"
        "  \"entities\": [\n"
        "    {{\"text\": \"项目Alpha的文档编写任务\", \"label\": \"TASK\"}},\n"
        "    {{\"text\": \"张三\", \"label\": \"PERSON\"}},\n"
        "    {{\"text\": \"谷歌\", \"label\": \"ORGANIZATION\"}}\n"
        "  ],\n"
        "  \"relations\": [\n"
        "    {{\"head_entity_text\": \"项目Alpha的文档编写任务\", \"head_entity_label\": \"TASK\", \"relation_type\": \"ASSIGNED_TO\", \"tail_entity_text\": \"张三\", \"tail_entity_label\": \"PERSON\"}},\n"
        "    {{\"head_entity_text\": \"张三\", \"head_entity_label\": \"PERSON\", \"relation_type\": \"WORKS_AT\", \"tail_entity_text\": \"谷歌\", \"tail_entity_label\": \"ORGANIZATION\"}}\n"
        "  ]\n"
        "}}\n\n"
        "文本：\n"
        "\"{text_to_extract}\"\n\n"
        "JSON输出："
    )
    sglang_model_name: str = "Qwen2.5-3B-Instruct_via_SGLang" # 保持不变

# --- 新增：KGExtractionAgent (实现为 Asset) ---
@dg.asset(
    name="kg_extractions",
    description="Extracts entities (and potentially relations) from text chunks for knowledge graph construction.",
    group_name="kg_building",
    io_manager_key="pydantic_json_io_manager" 
)
async def kg_extraction_asset(
    context: dg.AssetExecutionContext,
    text_chunks: List[ChunkOutput], 
    config: KGExtractionConfig,     
    sglang_api: SGLangAPIResource
) -> List[KGTripleSetOutput]: # 确保返回类型注解正确
    
    all_kg_outputs: List[KGTripleSetOutput] = []
    context.log.info(f"Received {len(text_chunks)} text chunks for KG extraction.")

    if not text_chunks:
        context.log.warning("No text chunks received, skipping KG extraction.")
        context.add_output_metadata(metadata={"num_chunks_processed": 0, "total_entities_extracted": 0, "total_relations_extracted": 0})
        return all_kg_outputs

    total_entities_count = 0
    total_relations_count = 0
    for i, chunk in enumerate(text_chunks):
        context.log.info(f"Extracting KG from chunk {i+1}/{len(text_chunks)} (ID: {chunk.chunk_id})")
        
        prompt = config.extraction_prompt_template.format(text_to_extract=chunk.chunk_text)
        
        try:
            structured_response = await sglang_api.generate_structured_output(
                prompt=prompt,
                json_schema=DEFAULT_KG_EXTRACTION_SCHEMA 
            )
            context.log.debug(f"SGLang structured response for chunk {chunk.chunk_id}: {structured_response}")

            entities_data = structured_response.get("entities", [])
            extracted_entities_list: List[ExtractedEntity] = []
            if isinstance(entities_data, list):
                for entity_dict in entities_data:
                    if isinstance(entity_dict, dict) and "text" in entity_dict and "label" in entity_dict:
                        # --- 规范化实体文本和标签 ---
                        normalized_entity_text = normalize_text_for_id(entity_dict["text"])
                        # 标签通常已经是大写或特定枚举值，但如果LLM可能返回不同大小写，也应规范化
                        normalized_entity_label = entity_dict["label"].upper() # 保持标签大写
                        extracted_entities_list.append(ExtractedEntity(
                            text=normalized_entity_text, # <--- 使用规范化后的文本
                            label=normalized_entity_label  # <--- 使用规范化/统一后的标签
                        ))
                    else:
                        context.log.warning(f"Skipping malformed entity data in chunk {chunk.chunk_id}: {entity_dict}")
            else:
                context.log.warning(f"'entities' field in SGLang response for chunk {chunk.chunk_id} is not a list: {entities_data}")
            
            total_entities_count += len(extracted_entities_list)

            relations_data = structured_response.get("relations", [])
            extracted_relations_list: List[ExtractedRelation] = []
            if isinstance(relations_data, list):
                for rel_dict in relations_data:
                    if (isinstance(rel_dict, dict) and
                        all(key in rel_dict for key in ["head_entity_text", "head_entity_label", 
                                                        "relation_type", "tail_entity_text", "tail_entity_label"])):
                        # --- 规范化关系中的实体文本和标签 ---
                        normalized_head_text = normalize_text_for_id(rel_dict["head_entity_text"])
                        normalized_head_label = rel_dict["head_entity_label"].upper()
                        normalized_tail_text = normalize_text_for_id(rel_dict["tail_entity_text"])
                        normalized_tail_label = rel_dict["tail_entity_label"].upper()
                        # 关系类型通常也应该是规范的
                        normalized_relation_type = rel_dict["relation_type"].upper()
                        extracted_relations_list.append(ExtractedRelation(
                            head_entity_text=normalized_head_text,
                            head_entity_label=normalized_head_label,
                            relation_type=normalized_relation_type,
                            tail_entity_text=normalized_tail_text,
                            tail_entity_label=normalized_tail_label
                        ))
                    else:
                        context.log.warning(f"Skipping malformed relation data in chunk {chunk.chunk_id}: {rel_dict}")
            else:
                context.log.warning(f"'relations' field in SGLang response for chunk {chunk.chunk_id} is not a list: {relations_data}")
            
            total_relations_count += len(extracted_relations_list)
            
            kg_output = KGTripleSetOutput(
                chunk_id=chunk.chunk_id,
                extracted_entities=extracted_entities_list,
                extracted_relations=extracted_relations_list,
                extraction_model_name=config.sglang_model_name,
                original_chunk_metadata=chunk.chunk_metadata
            )
            all_kg_outputs.append(kg_output)

        except Exception as e:
            context.log.error(f"Failed KG extraction for chunk {chunk.chunk_id}: {e}", exc_info=True) # 添加 exc_info=True
            all_kg_outputs.append(KGTripleSetOutput(
                chunk_id=chunk.chunk_id,
                extraction_model_name=config.sglang_model_name,
                original_chunk_metadata={"error": str(e), **chunk.chunk_metadata}
            ))
            
    context.add_output_metadata(
        metadata={
            "num_chunks_processed": len(text_chunks),
            "total_entities_extracted": total_entities_count,
            "total_relations_extracted": total_relations_count,
            "status": "Success" if len(all_kg_outputs) == len(text_chunks) else "Partial Success"
        }
    )
    return all_kg_outputs

# KuzuDB Concurrency Key (as suggested in the new strategy text file for write assets)
KUZU_WRITE_CONCURRENCY_KEY = "kuzu_write_access"

@dg.asset(
    name="kuzu_schema_initialized",
    description="Ensures KuzuDB is initialized and schema (tables) are ready, and performs DDL/Checkpoint.",
    group_name="kg_building",
    # deps=[], # 依赖通过参数自动推断，或者如果资源不作为参数传入，则不需要显式 deps
    tags={dg.MAX_RUNTIME_SECONDS_TAG: "300"} # KUZU_WRITE_CONCURRENCY_KEY 在 in_process 作业中意义不大
)
def kuzu_schema_initialized_asset(
    context: dg.AssetExecutionContext,
    kuzu_readwrite_db: KuzuDBReadWriteResource # 注入资源
) -> dg.Output[str]:
    db_path_used = kuzu_readwrite_db._resolved_db_path # 可以从资源获取路径信息
    context.log.info(f"Using KuzuDB at: {db_path_used}.")
    
    conn = kuzu_readwrite_db.get_connection() # <--- 从资源获取连接

    try:
        context.log.info("Executing DDL statements for schema creation...")
        schema_ddl_queries = [
            "CREATE NODE TABLE IF NOT EXISTS ExtractedEntity (id_prop STRING, text STRING, label STRING, PRIMARY KEY (id_prop))",
            "CREATE REL TABLE IF NOT EXISTS WorksAt (FROM ExtractedEntity TO ExtractedEntity)",
            "CREATE REL TABLE IF NOT EXISTS AssignedTo (FROM ExtractedEntity TO ExtractedEntity)"
        ]
        for ddl_query in schema_ddl_queries:
            context.log.debug(f"Executing DDL: {ddl_query}")
            conn.execute(ddl_query)
        context.log.info("DDL statements execution completed.")
        
        context.log.info("Executing manual CHECKPOINT.")
        conn.execute("CHECKPOINT;")
        context.log.info("Manual CHECKPOINT completed.")

        context.log.info("Verifying table existence after schema initialization...")
        node_table_names = conn._get_node_table_names()
        rel_tables_info = conn._get_rel_table_names()
        rel_table_names = [info['name'] for info in rel_tables_info]
        all_defined_tables = node_table_names + rel_table_names
        context.log.info(f"All defined tables in KuzuDB: {all_defined_tables}")
        
        required_tables = ["ExtractedEntity", "WorksAt", "AssignedTo"]
        all_found = True
        missing_tables = []
        for tbl in required_tables:
            if tbl not in all_defined_tables:
                all_found = False
                missing_tables.append(tbl)
        
        if all_found:
            context.log.info("Verification SUCCESS: All required tables found in KuzuDB.")
        else:
            raise dg.Failure(f"Schema verification failed. Missing tables: {', '.join(missing_tables)}")

    except Exception as e:
        context.log.error(f"Failed during KuzuDB schema DDL/CHECKPOINT/Verification: {e}", exc_info=True)
        raise dg.Failure(f"KuzuDB schema initialization/verification failed: {e}")
        
    return dg.Output("KuzuDB schema ensured, checkpointed, and verified.", metadata={"db_path": db_path_used, "defined_tables": all_defined_tables})

@dg.asset(
    name="kuzu_entity_nodes",
    description="Stores extracted entities as nodes in KuzuDB knowledge graph.",
    group_name="kg_building",
    # deps=[kuzu_schema_initialized_asset], # 通过参数推断
    tags={dg.MAX_RUNTIME_SECONDS_TAG: "600"}
)
def kuzu_entity_nodes_asset(
    context: dg.AssetExecutionContext,
    kg_extractions: List[KGTripleSetOutput],
    kuzu_schema_initialized: str, # 依赖上游资产的输出
    kuzu_readwrite_db: KuzuDBReadWriteResource # 注入资源
) -> None:
    context.log.info(f"Received {len(kg_extractions)} KG extraction sets to store entities in KuzuDB.")
    context.log.info(f"Upstream kuzu_schema_initialized_asset reported: {kuzu_schema_initialized}")

    if not kg_extractions:
        context.log.warning("No KG extractions received, nothing to store in KuzuDB.")
        context.add_output_metadata(metadata={"nodes_created_or_merged": 0, "status": "No data"})
        return
        
    dml_statements: List[tuple[str, Dict[str, Any]]] = []
    total_nodes_processed = 0

    for kg_output_set in kg_extractions:
        for entity in kg_output_set.extracted_entities:
            # 假设 entity.text 和 entity.label 已经是规范化过的
            text_for_id = entity.text 
            label_for_id = entity.label # 假设已经是大写
            id_prop_input_string = text_for_id + label_for_id # <--- 用于生成哈希的字符串
            entity_id_prop = hashlib.md5(id_prop_input_string.encode('utf-8')).hexdigest()  
            context.log.info(f"NODE CREATION: text='{entity.text}', label='{entity.label}', "
                             f"id_prop_input='{id_prop_input_string}', generated_id_prop='{entity_id_prop}'")
            query = """
                MERGE (e:ExtractedEntity {id_prop: $id_prop})
                ON CREATE SET e.text = $text, e.label = $label 
            """
            params = {
                "id_prop": entity_id_prop,
                "text": entity.text, 
                "label": entity.label
            }
            dml_statements.append((query, params))

    if not dml_statements:
        context.log.info("No valid entities found to store in KuzuDB after processing extractions.")
        context.add_output_metadata(metadata={"nodes_created_or_merged": 0, "status": "No entities to store"})
        return
    
    conn = kuzu_readwrite_db.get_connection() # <--- 从资源获取连接
    try:
        context.log.info(f"Executing {len(dml_statements)} MERGE operations for entities in KuzuDB...")
        executed_count = 0
        for query, params in dml_statements:
            context.log.debug(f"Executing DML: {query} with params: {params}")
            conn.execute(query, parameters=params)
            executed_count +=1
        context.log.info(f"Executed {executed_count} DML statements successfully for entities.")
        
        context.add_output_metadata(
            metadata={
                "nodes_created_or_merged": executed_count, # 使用实际执行数量
                "status": "Success"
            }
        )
    except Exception as e:
        context.log.error(f"Failed to store entities in KuzuDB: {e}", exc_info=True)
        raise dg.Failure(description=f"Failed to store entities in KuzuDB: {str(e)}")

@dg.asset(
    name="kuzu_entity_relations",
    description="Creates relationships in KuzuDB based on extracted KG data.",
    group_name="kg_building",
    deps=[kuzu_entity_nodes_asset.key], # 显式声明对 kuzu_entity_nodes_asset 的依赖
    tags={dg.MAX_RUNTIME_SECONDS_TAG: "600"}
)

def kuzu_entity_relations_asset(
    context: dg.AssetExecutionContext,
    kg_extractions: List[KGTripleSetOutput],
    kuzu_schema_initialized: str, # 依赖 kuzu_schema_initialized_asset 的输出
    kuzu_readwrite_db: KuzuDBReadWriteResource
) -> None:
    context.log.info(f"Received {len(kg_extractions)} KG extraction sets to create relations in KuzuDB.")
    context.log.info(f"Upstream kuzu_schema_initialized_asset reported: {kuzu_schema_initialized}")

    conn = kuzu_readwrite_db.get_connection()

    # --- Schema验证日志 ---
    try:
        context.log.info("Verifying table existence at the START of kuzu_entity_relations_asset...")
        node_tables_at_start = conn._get_node_table_names()
        rel_tables_info_at_start = conn._get_rel_table_names()
        rel_tables_at_start = [info['name'] for info in rel_tables_info_at_start]
        all_tables_at_start_actual_case = node_tables_at_start + rel_tables_at_start
        
        # 我们期望的表名（在DDL中定义的大小写）
        expected_relation_tables_in_schema = ["AssignedTo", "WorksAt"] 

        context.log.info(f"Node tables at start of relations asset: {node_tables_at_start}")
        context.log.info(f"Rel tables at start of relations asset (actual case): {rel_tables_at_start}")
        context.log.info(f"All tables at start of relations asset (actual case): {all_tables_at_start_actual_case}")

        for expected_table in expected_relation_tables_in_schema:
            # 检查时，我们将从数据库获取的表名与期望的表名进行比较
            # KuzuDB 返回的表名是区分大小写的，与 DDL 一致
            if expected_table not in all_tables_at_start_actual_case:
                context.log.error(f"CRITICAL: Expected table '{expected_table}' NOT FOUND at the very start of kuzu_entity_relations_asset on the shared connection!")
            else:
                context.log.info(f"Expected table '{expected_table}' IS PRESENT at the start of kuzu_entity_relations_asset.")
    except Exception as e_verify_start:
        context.log.error(f"Error verifying tables at start of kuzu_entity_relations_asset: {e_verify_start}")
    # --- Schema验证日志结束 ---

    if not kg_extractions:
        context.log.warning("No KG extractions received, nothing to store for relations.")
        context.add_output_metadata(metadata={"relations_created_or_merged": 0, "status": "No data"})
        return

    relations_to_create_params: List[Dict[str, Any]] = []
    relation_type_for_cypher_map: List[str] = [] # 用于存储 Cypher 查询中实际使用的关系表名

    for kg_output_set in kg_extractions:
        for rel_idx, rel in enumerate(kg_output_set.extracted_relations):
            context.log.info(f"Processing relation {rel_idx+1} from chunk {kg_output_set.chunk_id}: "
                             f"{rel.head_entity_text} -[{rel.relation_type}]-> {rel.tail_entity_text}")

            head_text_for_id = rel.head_entity_text
            head_label_for_id = rel.head_entity_label 
            tail_text_for_id = rel.tail_entity_text
            tail_label_for_id = rel.tail_entity_label

            head_id_prop_input_string = head_text_for_id + head_label_for_id
            head_entity_id_prop = hashlib.md5(head_id_prop_input_string.encode('utf-8')).hexdigest()
            
            tail_id_prop_input_string = tail_text_for_id + tail_label_for_id
            tail_entity_id_prop = hashlib.md5(tail_id_prop_input_string.encode('utf-8')).hexdigest()
            
            context.log.info(f"  Attempting to match Head: text='{rel.head_entity_text}', label='{rel.head_entity_label}', "
                             f"id_prop_input='{head_id_prop_input_string}', generated_head_id_prop='{head_entity_id_prop}'")
            context.log.info(f"  Attempting to match Tail: text='{rel.tail_entity_text}', label='{rel.tail_entity_label}', "
                             f"id_prop_input='{tail_id_prop_input_string}', generated_tail_id_prop='{tail_entity_id_prop}'")

            head_found = False
            tail_found = False
            try:
                head_check_result = conn.execute("MATCH (n:ExtractedEntity {id_prop: $id}) RETURN n.text, n.label", {"id": head_entity_id_prop})
                if head_check_result.has_next():
                    head_data = head_check_result.get_next()
                    context.log.info(f"    VERIFIED Head Node: id_prop='{head_entity_id_prop}', text='{head_data[0]}', label='{head_data[1]}'")
                    head_found = True
                else:
                    context.log.error(f"    VERIFICATION FAILED: Head Node with id_prop='{head_entity_id_prop}' (from text='{rel.head_entity_text}') NOT FOUND.")
                head_check_result.close()

                tail_check_result = conn.execute("MATCH (n:ExtractedEntity {id_prop: $id}) RETURN n.text, n.label", {"id": tail_entity_id_prop})
                if tail_check_result.has_next():
                    tail_data = tail_check_result.get_next()
                    context.log.info(f"    VERIFIED Tail Node: id_prop='{tail_entity_id_prop}', text='{tail_data[0]}', label='{tail_data[1]}'")
                    tail_found = True
                else:
                    context.log.error(f"    VERIFICATION FAILED: Tail Node with id_prop='{tail_entity_id_prop}' (from text='{rel.tail_entity_text}') NOT FOUND.")
                tail_check_result.close()
            except Exception as e_verify:
                context.log.error(f"    Error during node verification for relation: {e_verify}")

            if head_found and tail_found:
                # rel.relation_type 应该是从 kg_extraction_asset 传来的全大写形式，例如 "ASSIGNED_TO"
                relation_type_from_extraction = rel.relation_type 
                
                # 将其映射到 DDL 中定义的实际表名（首字母大写）
                actual_cypher_table_name = ""
                if relation_type_from_extraction == "ASSIGNED_TO":
                    actual_cypher_table_name = "AssignedTo"
                elif relation_type_from_extraction == "WORKS_AT":
                    actual_cypher_table_name = "WorksAt"
                
                if actual_cypher_table_name: # 如果是我们支持的关系类型
                    relations_to_create_params.append({
                        "head_id_prop": head_entity_id_prop,
                        "tail_id_prop": tail_entity_id_prop,
                    })
                    relation_type_for_cypher_map.append(actual_cypher_table_name)
                else:
                    context.log.warning(f"  Skipping relation due to unmapped original type: '{relation_type_from_extraction}'")
            else:
                context.log.warning(f"  Skipping relation creation for '{rel.head_entity_text} -[{rel.relation_type}]-> {rel.tail_entity_text}' because one or both nodes were not found with generated id_props.")
            
    if not relations_to_create_params:
        context.log.info("No valid relations to create after node verification and type mapping.")
        context.add_output_metadata(metadata={"relations_created_or_merged": 0, "status": "No valid relations after node/type check"})
        return
            
    executed_count = 0
    try:
        context.log.info(f"Attempting to execute {len(relations_to_create_params)} CREATE operations for relations in KuzuDB...")
        for i, params in enumerate(relations_to_create_params):
            rel_table_for_cypher = relation_type_for_cypher_map[i]
            query = f"""
                MATCH (h:ExtractedEntity {{id_prop: $head_id_prop}}), (t:ExtractedEntity {{id_prop: $tail_id_prop}})
                CREATE (h)-[r:{rel_table_for_cypher}]->(t)
            """
            context.log.debug(f"Executing DML for relation type '{rel_table_for_cypher}': {query} with params: {params}")
            conn.execute(query, parameters=params)
            executed_count += 1
        context.log.info(f"Successfully submitted {executed_count} DML statements for relations.")
        
        context.log.info("Final verification of relation counts after DML execution...")
        final_rel_counts = {}
        unique_relation_types_attempted = set(relation_type_for_cypher_map)
        for rel_type_to_check_in_cypher in unique_relation_types_attempted:
            try:
                count_query_result = conn.execute(f"MATCH ()-[r:{rel_type_to_check_in_cypher}]->() RETURN count(r) AS count")
                count_df = pd.DataFrame(count_query_result.get_as_df())
                actual_count_in_db_raw = count_df['count'].iloc[0] if not count_df.empty else 0
                actual_count_in_db = int(actual_count_in_db_raw) # <--- 修改这里：转换为Python int
                final_rel_counts[rel_type_to_check_in_cypher] = actual_count_in_db
                context.log.info(f"  Relation table '{rel_type_to_check_in_cypher}' final count in DB: {actual_count_in_db}")
            except Exception as e_count_final:
                context.log.error(f"  Error during final count for relation table '{rel_type_to_check_in_cypher}': {e_count_final}")
        context.add_output_metadata(
            metadata={
                "relations_attempted_creation": len(relations_to_create_params),
                "relations_dml_submitted_and_executed_by_kuzu": executed_count, # 更准确的描述
                "final_relation_counts_in_db": final_rel_counts,
                "status": "Success" if executed_count == len(relations_to_create_params) and executed_count > 0 else "Partial Success or Issues" if executed_count > 0 else "No relations created"
            }
        )
    except Exception as e:
        context.log.error(f"Failed during DML execution for relations: {e}", exc_info=True)
        raise dg.Failure(description=f"Failed to create relations in KuzuDB: {str(e)}")
    
# 确保 all_processing_assets 列表正确
all_processing_assets = [
    clean_chunk_text_asset,
    generate_embeddings_asset,
    vector_storage_asset,
    keyword_index_asset,
    kg_extraction_asset,
    kuzu_schema_initialized_asset,
    kuzu_entity_nodes_asset,
    kuzu_entity_relations_asset
]
    --- END OF FILE CONTENT ---

  File: pydantic_models_dagster.py
    --- START OF FILE CONTENT ---
# zhz_rag_pipeline/pydantic_models_dagster.py
from typing import List, Dict, Any, Union, Optional
from pydantic import BaseModel
import uuid
from typing import List # 确保 List 已导入


class LoadedDocumentOutput(BaseModel):
    document_path: str
    file_type: str
    raw_content: Union[str, bytes]
    metadata: Dict[str, Any]

class ParsedDocumentOutput(BaseModel):
    parsed_text: str
    document_structure: Optional[Dict[str, Any]] = None
    original_metadata: Dict[str, Any]

class ChunkOutput(BaseModel):
    chunk_id: str = "" 
    chunk_text: str
    source_document_id: str 
    chunk_metadata: Dict[str, Any]

    def __init__(self, **data: Any):
        if 'chunk_id' not in data or not data['chunk_id']:
            data['chunk_id'] = str(uuid.uuid4())
        super().__init__(**data)

class EmbeddingOutput(BaseModel):
    chunk_id: str 
    chunk_text: str 
    embedding_vector: List[float]
    embedding_model_name: str 
    original_chunk_metadata: Dict[str, Any]

class ExtractedEntity(BaseModel):
    text: str 
    label: str 

class ExtractedRelation(BaseModel):
    head_entity_text: str
    head_entity_label: str # 例如 "PERSON"
    relation_type: str    # 例如 "WORKS_AT"
    tail_entity_text: str
    tail_entity_label: str # 例如 "ORGANIZATION"

class KGTripleSetOutput(BaseModel):
    chunk_id: str 
    extracted_entities: List[ExtractedEntity] = []
    extracted_relations: List[ExtractedRelation] = [] 
    extraction_model_name: str 
    original_chunk_metadata: Dict[str, Any]

    --- END OF FILE CONTENT ---

  File: resources.py
    --- START OF FILE CONTENT ---
# /home/zhz/zhz_agent/zhz_rag_pipeline_dagster/zhz_rag_pipeline/resources.py
import dagster as dg
from sentence_transformers import SentenceTransformer
import chromadb
from chromadb.config import Settings
from typing import List, Dict, Any, Union, Optional, ContextManager, Iterator
import logging
import httpx
import asyncio
import json
# from neo4j import GraphDatabase, Driver, Result # Neo4j不再直接用于此资源
import litellm
import os
import kuzu # 确保导入 kuzu
import shutil
from pydantic import PrivateAttr, Field as PydanticField
from contextlib import contextmanager
import portalocker # <--- 重新导入 portalocker
import time # <--- 导入 time，可能用于短暂等待

# --- SentenceTransformerResource ---
class SentenceTransformerResourceConfig(dg.Config):
    model_name_or_path: str = "/home/zhz/models/bge-small-zh-v1.5"

class SentenceTransformerResource(dg.ConfigurableResource):
    model_name_or_path: str
    _model: SentenceTransformer = PrivateAttr(default=None)
    _logger: Optional[dg.DagsterLogManager] = PrivateAttr(default=None)

    def setup_for_execution(self, context: dg.InitResourceContext) -> None:
        self._logger = context.log
        self._logger.info(f"Initializing SentenceTransformer model from: {self.model_name_or_path}")
        try:
            self._model = SentenceTransformer(self.model_name_or_path)
            self._logger.info("SentenceTransformer model initialized successfully.")
        except Exception as e:
            self._logger.error(f"Failed to initialize SentenceTransformer model: {e}", exc_info=True)
            raise

    def encode(self, texts: List[str], batch_size: int = 32, normalize_embeddings: bool = True) -> List[List[float]]:
        if self._model is None:
            if self._logger:
                self._logger.error("SentenceTransformer model is not initialized in encode method.")
            raise RuntimeError("SentenceTransformer model is not initialized.")
        
        logger_instance = self._logger if self._logger else dg.get_dagster_logger()
        logger_instance.debug(f"Encoding {len(texts)} texts. Normalize embeddings: {normalize_embeddings}")
        
        embeddings_np = self._model.encode(
            texts, 
            batch_size=batch_size, 
            convert_to_tensor=False, 
            normalize_embeddings=normalize_embeddings
        )
        return [emb.tolist() for emb in embeddings_np]

# --- ChromaDBResource ---
class ChromaDBResourceConfig(dg.Config):
    collection_name: str = "rag_documents"
    persist_directory: str = "/home/zhz/zhz_agent/zhz_rag/stored_data/chromadb_index/"

class ChromaDBResource(dg.ConfigurableResource):
    collection_name: str
    persist_directory: str

    _client: chromadb.Client = PrivateAttr(default=None)
    _collection: chromadb.Collection = PrivateAttr(default=None)
    _logger: Optional[dg.DagsterLogManager] = PrivateAttr(default=None)

    def setup_for_execution(self, context: dg.InitResourceContext) -> None:
        self._logger = context.log
        self._logger.info(f"Initializing ChromaDB client and collection '{self.collection_name}'...")
        self._logger.info(f"ChromaDB data will be persisted to: {self.persist_directory}")
        try:
            os.makedirs(self.persist_directory, exist_ok=True)
            self._client = chromadb.PersistentClient(path=self.persist_directory)
            self._collection = self._client.get_or_create_collection(
                name=self.collection_name,
                metadata={"hnsw:space": "cosine"}
            )
            self._logger.info(f"ChromaDB collection '{self.collection_name}' initialized/loaded. Count: {self._collection.count()}")
        except Exception as e:
            self._logger.error(f"Failed to initialize ChromaDB: {e}", exc_info=True)
            raise

    def add_embeddings(self, ids: List[str], embeddings: List[List[float]], metadatas: List[Dict[str, Any]] = None):
        logger_instance = self._logger if self._logger else dg.get_dagster_logger()
        if self._collection is None:
            logger_instance.error("ChromaDB collection is not initialized. Cannot add embeddings.")
            raise RuntimeError("ChromaDB collection is not initialized.")
        
        if not (len(ids) == len(embeddings) and (metadatas is None or len(ids) == len(metadatas))):
            logger_instance.error("Length mismatch for ids, embeddings, or metadatas.")
            raise ValueError("Length of ids, embeddings, and metadatas (if provided) must be the same.")

        if not ids:
            logger_instance.info("No ids provided to add_embeddings, skipping.")
            return

        logger_instance.info(f"Adding/updating {len(ids)} embeddings to ChromaDB collection '{self.collection_name}'...")
        self._collection.add(ids=ids, embeddings=embeddings, metadatas=metadatas)
        logger_instance.info(f"Embeddings added/updated. Collection count now: {self._collection.count()}")

    def query_embeddings(self, query_embeddings: List[List[float]], n_results: int = 5) -> chromadb.QueryResult:
        logger_instance = self._logger if self._logger else dg.get_dagster_logger()
        if self._collection is None:
            logger_instance.error("ChromaDB collection is not initialized. Cannot query embeddings.")
            raise RuntimeError("ChromaDB collection is not initialized.")
        logger_instance.debug(f"Querying ChromaDB collection '{self.collection_name}' with {len(query_embeddings)} vectors, n_results={n_results}.")
        return self._collection.query(query_embeddings=query_embeddings, n_results=n_results)

# --- SGLangAPIResource ---
class SGLangAPIResourceConfig(dg.Config):
    api_url: str = "http://127.0.0.1:30000/generate"
    default_temperature: float = 0.1
    default_max_new_tokens: int = 512

class SGLangAPIResource(dg.ConfigurableResource):
    api_url: str
    default_temperature: float
    default_max_new_tokens: int
    _logger: Optional[dg.DagsterLogManager] = PrivateAttr(default=None)

    def setup_for_execution(self, context: dg.InitResourceContext) -> None:
        self._logger = context.log
        self._logger.info(f"SGLangAPIResource configured with API URL: {self.api_url}")

    async def generate_structured_output(
        self, prompt: str, json_schema: Dict[str, Any],
        temperature: Optional[float] = None, max_new_tokens: Optional[int] = None
    ) -> Dict[str, Any]:
        logger_instance = self._logger if self._logger else dg.get_dagster_logger()
        temp_to_use = temperature if temperature is not None else self.default_temperature
        tokens_to_use = max_new_tokens if max_new_tokens is not None else self.default_max_new_tokens
        payload = {
            "text": prompt,
            "sampling_params": {
                "temperature": temp_to_use,
                "max_new_tokens": tokens_to_use,
                "stop": ["<|im_end|>"],
                "json_schema": json.dumps(json_schema)
            }
        }
        logger_instance.debug(f"Sending request to SGLang. Prompt (start): {prompt[:100]}... Schema: {json.dumps(json_schema)}")
        try:
            async with httpx.AsyncClient(timeout=120.0) as client:
                response = await client.post(self.api_url, json=payload)
                response.raise_for_status()
                response_json = response.json()
                generated_text = response_json.get("text", "").strip()
                logger_instance.debug(f"SGLang raw response text: {generated_text}")
                try:
                    parsed_output = json.loads(generated_text)
                    return parsed_output
                except json.JSONDecodeError as e:
                    logger_instance.error(f"Failed to decode SGLang JSON output: {generated_text}. Error: {e}", exc_info=True)
                    raise ValueError(f"SGLang output was not valid JSON: {generated_text}") from e
        except httpx.HTTPStatusError as e:
            logger_instance.error(f"SGLang API HTTP error: {e.response.status_code} - {e.response.text}", exc_info=True)
            raise
        except httpx.RequestError as e:
            logger_instance.error(f"SGLang API request error: {e}", exc_info=True)
            raise
        except Exception as e:
            logger_instance.error(f"Unexpected error during SGLang call: {e}", exc_info=True)
            raise

# --- GeminiAPIResource ---
class GeminiAPIResourceConfig(dg.Config):
    model_name: str = PydanticField(default="gemini/gemini-1.5-flash-latest", description="Name of the Gemini model.")
    proxy_url: Optional[str] = PydanticField(default_factory=lambda: os.getenv("LITELLM_PROXY_URL"), description="Optional proxy URL for LiteLLM.")
    default_temperature: float = 0.1
    default_max_tokens: int = 2048
    
class GeminiAPIResource(dg.ConfigurableResource):
    model_name: str
    proxy_url: Optional[str]
    default_temperature: float
    default_max_tokens: int
    _api_key: Optional[str] = PrivateAttr(default=None)
    _logger: Optional[dg.DagsterLogManager] = PrivateAttr(default=None)

    def setup_for_execution(self, context: dg.InitResourceContext) -> None:
        self._logger = context.log
        self._api_key = os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")
        if self.model_name and not self.model_name.startswith("gemini/"):
            if "gemini" in self.model_name.lower():
                self._logger.info(f"Model name '{self.model_name}' auto-prefixed to 'gemini/'.")
                self.model_name = f"gemini/{self.model_name.split('/')[-1]}"
            else:
                self._logger.warning(f"Model name '{self.model_name}' does not start with 'gemini/'.")
        if not self._api_key:
            self._logger.warning("Gemini API key not found. API calls will likely fail.")
        else:
            self._logger.info(f"GeminiAPIResource initialized. Model: {self.model_name}, Proxy: {self.proxy_url or 'Not set'}")

    async def call_completion(
        self, messages: List[Dict[str, str]],
        temperature: Optional[float] = None, max_tokens: Optional[int] = None,
    ) -> Optional[str]:
        logger_instance = self._logger if self._logger else dg.get_dagster_logger()
        if not self._api_key:
            logger_instance.error("Gemini API key is not configured.")
            return None
        temp_to_use = temperature if temperature is not None else self.default_temperature
        tokens_to_use = max_tokens if max_tokens is not None else self.default_max_tokens
        litellm_params = {
            "model": self.model_name, "messages": messages, "api_key": self._api_key,
            "temperature": temp_to_use, "max_tokens": tokens_to_use,
        }
        if self.proxy_url:
            litellm_params["proxy"] = {"http": self.proxy_url, "https": self.proxy_url} # type: ignore
        logger_instance.debug(f"Calling LiteLLM (Gemini) with params (excluding messages): { {k:v for k,v in litellm_params.items() if k != 'messages'} }")
        raw_output_text: Optional[str] = None
        try:
            response = await litellm.acompletion(**litellm_params) # type: ignore
            if response and response.choices and response.choices[0].message and response.choices[0].message.content:
                raw_output_text = response.choices[0].message.content
                logger_instance.debug(f"LiteLLM (Gemini) raw response (first 300 chars): {raw_output_text[:300]}...")
            else:
                logger_instance.warning(f"LiteLLM (Gemini) returned empty/malformed response: {response}")
        except Exception as e_generic:
            logger_instance.error(f"Error calling Gemini via LiteLLM: {e_generic}", exc_info=True)
        return raw_output_text

# --- KuzuDB Resources (New Strategy Applied) ---
class KuzuDBReadWriteResource(dg.ConfigurableResource):
    db_path_str: str = PydanticField(
        default=os.path.join("zhz_rag", "stored_data", "kuzu_default_db"),
        description=(
            "Path to the KuzuDB database directory. "
            "Can be relative to the project root (if not starting with '/') or absolute."
        )
    )
    clear_on_startup_for_testing: bool = PydanticField(
        default=False, # 生产中通常为 False，测试时可设为 True
        description="If true, delete and re-initialize the DB when the resource is first set up. USE WITH CAUTION."
    )

    _logger: Optional[dg.DagsterLogManager] = PrivateAttr(default=None)
    _resolved_db_path: str = PrivateAttr()
    _db: Optional[kuzu.Database] = PrivateAttr(default=None) # <--- 持有 Database 实例
    _conn: Optional[kuzu.Connection] = PrivateAttr(default=None) # <--- 持有 Connection 实例

    def setup_for_execution(self, context: dg.InitResourceContext) -> None:
        self._logger = context.log
        if os.path.isabs(self.db_path_str):
            self._resolved_db_path = self.db_path_str
        else:
            self._resolved_db_path = os.path.abspath(self.db_path_str)
        
        self._logger.info(
            f"KuzuDBReadWriteResource setup: resolved_path='{self._resolved_db_path}', "
            f"clear_on_startup_for_testing={self.clear_on_startup_for_testing}"
        )

        if self.clear_on_startup_for_testing:
            if os.path.exists(self._resolved_db_path):
                self._logger.warning(f"Clearing KuzuDB directory: {self._resolved_db_path}")
                try:
                    shutil.rmtree(self._resolved_db_path)
                    self._logger.info(f"Successfully removed KuzuDB directory.")
                except OSError as e:
                    self._logger.error(f"Failed to remove KuzuDB directory {self._resolved_db_path}: {e}", exc_info=True)
                    raise
        
        try:
            os.makedirs(os.path.dirname(self._resolved_db_path), exist_ok=True)
            self._db = kuzu.Database(self._resolved_db_path, read_only=False)
            self._conn = kuzu.Connection(self._db)
            self._logger.info(f"KuzuDB Database and Connection initialized successfully at {self._resolved_db_path}.")
        except Exception as e:
            self._logger.error(f"Failed to initialize KuzuDB: {e}", exc_info=True)
            raise

    def teardown_for_execution(self, context: dg.InitResourceContext) -> None:
        self._logger.info(f"Tearing down KuzuDBReadWriteResource for {self._resolved_db_path}...")
        if self._conn is not None:
            # 可以在这里选择性地执行最后的 CHECKPOINT，但通常 KuzuDB 关闭时会处理
            # try:
            #     self._logger.info("Executing final CHECKPOINT on KuzuDB connection before teardown.")
            #     self._conn.execute("CHECKPOINT;")
            #     self._logger.info("Final CHECKPOINT successful.")
            # except Exception as e_chk:
            #     self._logger.error(f"Error during final CHECKPOINT: {e_chk}")
            del self._conn # Kuzu Connection 没有 close()
            self._conn = None
        if self._db is not None:
            del self._db # 依赖 KuzuDB Database 的 __del__ 方法进行清理和锁释放
            self._db = None
        self._logger.info("KuzuDBReadWriteResource teardown complete.")

    def get_connection(self) -> kuzu.Connection:
        """Returns the managed KuzuDB connection."""
        if self._conn is None:
            # 这种错误不应该在 in_process_executor 下发生，因为 setup_for_execution 会先运行
            self._logger.error("KuzuDB connection not available. Resource might not have been set up correctly.")
            raise Exception("KuzuDB connection not available. Resource might not have been set up correctly.")
        return self._conn
            
# KuzuDBReadOnlyResource 定义保持不变
class KuzuDBReadOnlyResource(dg.ConfigurableResource):
    db_path_str: str = PydanticField(
        default=os.path.join("zhz_rag", "stored_data", "kuzu_default_db"),
        description=(
            "Path to the KuzuDB database directory for read-only access. "
            "Can be relative to the project root (if not starting with '/') or absolute."
        )
    )
    _logger: Optional[dg.DagsterLogManager] = PrivateAttr(default=None)
    _resolved_db_path: str = PrivateAttr()

    def setup_for_execution(self, context: dg.InitResourceContext) -> None:
        self._logger = context.log
        if os.path.isabs(self.db_path_str):
            self._resolved_db_path = self.db_path_str
        else:
            self._resolved_db_path = os.path.abspath(self.db_path_str)

        self._logger.info(f"KuzuDBReadOnlyResource setup: resolved_path='{self._resolved_db_path}'")
        if not os.path.exists(self._resolved_db_path):
            self._logger.error(f"KuzuDB path {self._resolved_db_path} does not exist for ReadOnly access. Operations will likely fail.")

    def teardown_for_execution(self, context: dg.InitResourceContext) -> None:
        logger_instance = self._logger if self._logger else dg.get_dagster_logger()
        logger_instance.info("KuzuDBReadOnlyResource teardown complete.")

    @contextmanager
    def get_readonly_connection(self) -> Iterator[kuzu.Connection]:
        logger_instance = self._logger if self._logger else dg.get_dagster_logger()
        db_instance: Optional[kuzu.Database] = None
        logger_instance.info(f"Attempting to open KuzuDB(RO) at {self._resolved_db_path} for readonly session.")
        
        if not os.path.exists(self._resolved_db_path):
            logger_instance.error(f"KuzuDB directory {self._resolved_db_path} not found for read-only access.")
            raise FileNotFoundError(f"KuzuDB directory {self._resolved_db_path} not found for read-only access.")

        try:
            db_instance = kuzu.Database(self._resolved_db_path, read_only=True)
            logger_instance.info(f"KuzuDB(RO) session opened at {self._resolved_db_path}")
            conn = kuzu.Connection(db_instance)
            yield conn
        except Exception as e:
            logger_instance.error(f"Error during KuzuDB(RO) session: {e}", exc_info=True)
            raise
        finally:
            if db_instance:
                del db_instance
                logger_instance.info(f"KuzuDB(RO) Database object for session at {self._resolved_db_path} dereferenced (closed).")
    --- END OF FILE CONTENT ---

  File: 获取当前目录下的所有py格式文件.py
    --- START OF FILE CONTENT ---
import os
import sys
import fnmatch

# --- 配置 ---
# 1. 输出文件的名称
OUTPUT_FILENAME = '现阶段核心代码.txt' # <--- 输出文件名

# 2. 需要包含的文件扩展名 (小写) 或完整文件名
TARGET_ITEMS = (
    '.py',      # Python 脚本
)

# 3. 需要排除的目录名称 (主要用于递归扫描，此处作用较小，但保留以防万一)
EXCLUDE_DIRS = {
    '.git',
    '__pycache__',
    'venv', '.venv', # 虚拟环境
    'tests', 'test',
    '.vscode',
    'node_modules',
    'dist', 'build',
}

# 4. 需要排除的文件名或模式 (使用 fnmatch，不区分大小写)
EXCLUDE_FILES = {
    '.DS_Store',
    '*.log',
    # 脚本自身和输出文件会自动排除
}
# ---

script_dir = os.path.dirname(os.path.abspath(__file__))
# 项目路径现在就是脚本所在的目录
project_path = script_dir
output_file_path = os.path.join(script_dir, OUTPUT_FILENAME)

combined_content = []
processed_files_count = 0

print(f"正在读取 '{project_path}' 目录下的核心 Python 文件...")

# 自动排除脚本自身和输出文件
exclude_files_lower_patterns = {f.lower() for f in EXCLUDE_FILES}
exclude_files_lower_patterns.add(os.path.basename(__file__).lower())
exclude_files_lower_patterns.add(OUTPUT_FILENAME.lower())

exclude_dirs_lower = {d.lower() for d in EXCLUDE_DIRS} # 保留，但在此版本中作用不大

def should_exclude_dir(dir_name_full_path):
    # 此函数在此版本中基本不会被积极使用，因为我们不递归进入子目录
    dir_name = os.path.basename(dir_name_full_path)
    return dir_name.lower() in exclude_dirs_lower

def should_include_file(file_name_full_path):
    file_name = os.path.basename(file_name_full_path)
    file_name_lower = file_name.lower()

    # 检查是否在排除文件列表
    for pattern in exclude_files_lower_patterns:
        if fnmatch.fnmatchcase(file_name_lower, pattern):
            return False # 排除

    # 检查是否匹配目标扩展名或完整文件名
    for target in TARGET_ITEMS:
        if target.startswith('.'): # 是扩展名
            if file_name_lower.endswith(target):
                return True
        else: # 是完整文件名 (虽然我们现在只用扩展名)
            if file_name_lower == target.lower():
                return True
    return False # 不包含

def collect_files_in_current_dir(current_path_abs):
    global processed_files_count
    try:
        items = sorted(os.listdir(current_path_abs))
    except Exception as e:
        print(f"错误：无法读取目录 '{current_path_abs}' 的内容: {e}")
        return

    for item_name in items:
        item_path_abs = os.path.join(current_path_abs, item_name)
        # 对于当前目录的文件，其相对于 project_path (即 current_path_abs) 的路径就是文件名本身
        relative_path_to_project_root = item_name

        if os.path.isfile(item_path_abs): # 只处理文件
            if should_include_file(item_path_abs):
                print(f"  正在添加: {relative_path_to_project_root}")
                processed_files_count += 1
                combined_content.append(f"--- START OF FILE {relative_path_to_project_root.replace(os.sep, '/')} ---")
                try:
                    with open(item_path_abs, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                        combined_content.append(content)
                except Exception as e:
                    print(f"  *** 警告：读取文件 {relative_path_to_project_root} 时出错: {e} ***")
                    combined_content.append(f"*** ERROR READING FILE {relative_path_to_project_root}: {e} ***")
                combined_content.append(f"--- END OF FILE {relative_path_to_project_root.replace(os.sep, '/')} ---")
                combined_content.append("\n\n")
        # 我们不再递归进入子目录，所以移除了 os.path.isdir 的检查和递归调用

# 执行收集
collect_files_in_current_dir(project_path) # project_path 就是 script_dir

# --- 保存合并后的内容到文件 ---
final_output = "".join(combined_content)

if processed_files_count > 0:
    try:
        with open(output_file_path, 'w', encoding='utf-8') as outfile:
            outfile.write(final_output)
        print(f"\n成功！已将 {processed_files_count} 个 Python 文件的合并内容保存到文件: {output_file_path}")
    except Exception as e:
        print(f"\n错误：无法将内容写入文件 '{output_file_path}': {e}")
        sys.exit(1)
else:
    print(f"\n在当前目录 '{project_path}' 中未找到任何符合条件的 Python 文件。请检查 TARGET_ITEMS 设置。")
    --- END OF FILE CONTENT ---


Directory: zhz_rag_pipeline_dagster/zhz_rag_pipeline_dagster_project.egg-info/
  File (skipped, extension not included): PKG-INFO
  File: SOURCES.txt
    --- START OF FILE CONTENT ---
pyproject.toml
setup.py
zhz_rag_pipeline/__init__.py
zhz_rag_pipeline/custom_io_managers.py
zhz_rag_pipeline/definitions.py
zhz_rag_pipeline/evaluation_assets.py
zhz_rag_pipeline/ingestion_assets.py
zhz_rag_pipeline/processing_assets.py
zhz_rag_pipeline/pydantic_models_dagster.py
zhz_rag_pipeline/resources.py
zhz_rag_pipeline/获取当前目录下的所有py格式文件.py
zhz_rag_pipeline_dagster_project.egg-info/PKG-INFO
zhz_rag_pipeline_dagster_project.egg-info/SOURCES.txt
zhz_rag_pipeline_dagster_project.egg-info/dependency_links.txt
zhz_rag_pipeline_dagster_project.egg-info/requires.txt
zhz_rag_pipeline_dagster_project.egg-info/top_level.txt
    --- END OF FILE CONTENT ---

  File: dependency_links.txt
    --- START OF FILE CONTENT ---


    --- END OF FILE CONTENT ---

  File: requires.txt
    --- START OF FILE CONTENT ---
dagster
dagster-webserver

    --- END OF FILE CONTENT ---

  File: top_level.txt
    --- START OF FILE CONTENT ---
zhz_rag_pipeline

    --- END OF FILE CONTENT ---


Directory: zhz_rag/
  File: __init__.py
    --- File is empty ---

  File (skipped, extension not included): setup - 副本.py:Zone.Identifier
  File: setup.py
    --- START OF FILE CONTENT ---
# /home/zhz/zhz_agent/zhz_rag/setup.py
from setuptools import find_packages, setup

setup(
    name="zhz_rag_core",
    version="0.1.0",
    packages=find_packages(),
    install_requires=[
        # Pydantic 版本由主 requirements.txt 控制
        # LiteLLM 版本由主 requirements.txt 控制
        # ChromaDB 版本由主 requirements.txt 控制

        "protobuf>=4.25.0,<5.30.0", # 放宽 protobuf 上限，因为 pydantic 2.11.5 可能需要较新的
        "packaging>=23.2,<25.0",
        "rich>=13.7.0,<14.0.0",
        
        "fastapi>=0.110.0,<0.116.0", # 保持较新
        "starlette>=0.35.0,<0.47.0", # 保持较新

        "langchain-core>=0.1.50,<0.4.0", # 较新 langchain 可能更好兼容
        "langchain-text-splitters>=0.0.1,<0.3.0",

        "httpx>=0.27.0", # 使用较新 httpx
        "python-dotenv>=1.0.0",
        "neo4j>=5.0.0", # neo4j 驱动
        "sentence-transformers>=2.2.0", # sentence-transformers
        "transformers>=4.38.0,<4.39.0", # 固定您之前的版本或小幅更新
        "torch>=2.0.0",
        "numpy<2.0", # 保持 Numpy < 2.0
        "bm25s",
        "jieba",
        "uvicorn[standard]", # 添加 standard extras
        "pandas>=2.0.0",
        "sqlalchemy>=2.0.0",
        "databases[aiosqlite]>=0.9.0", # for async sqlite
        "apscheduler>=3.10.0",
        "pytz",
    ],
)
    --- END OF FILE CONTENT ---


Directory: zhz_rag/crewai_integration/
  File: __init__.py
    --- File is empty ---

  File: run_crew.py
    --- START OF FILE CONTENT ---
# /home/zhz/zhz_agent/run_agent.py

import os
import json
import datetime

from crewai import Agent, Task, Crew, Process

# --- 导入我们自己的项目模块 (使用绝对导入) ---
from zhz_rag.crewai_integration.tools import HybridRAGTool, BaseMCPTool
from zhz_rag.config.pydantic_models import QueryRequest # 用于 RAG 工具的输入
from zhz_rag.utils.common_utils import call_mcpo_tool
from zhz_rag.llm.custom_crewai_llms import CustomGeminiLLM

# --- 环境配置 ---
from dotenv import load_dotenv
load_dotenv()

# --- CrewAI 基类和事件系统 ---
from crewai.tools import BaseTool
from pydantic import BaseModel, Field
from typing import Any, Dict, List, Optional, Type
from crewai.llms.base_llm import BaseLLM as CrewAIBaseLLM
try:
    from crewai.utilities.events.base_event_listener import BaseEventListener as CrewAIBaseCallbackHandler
    from crewai.utilities.events import LLMCallStartedEvent, LLMCallCompletedEvent
    print("Successfully imported BaseEventListener and Event Types")
except ImportError:
    print("Failed to import BaseEventListener or Event Types, using dummy classes.")
    class CrewAIBaseCallbackHandler: pass
    class LLMCallStartedEvent: pass
    class LLMCallCompletedEvent: pass

# --- LiteLLM ---
import litellm

# --- 定义简单工具以供测试 ---
class SimpleToolInput(BaseModel):
    message: str = Field(description="A simple message string for the tool.")

class MySimpleTestTool(BaseTool):
    name: str = "MySimpleTestTool"
    description: str = "A very simple test tool that takes a message and returns it."
    args_schema: Type[BaseModel] = SimpleToolInput

    def _run(self, message: str) -> str:
        print(f"MySimpleTestTool received: {message}")
        return f"MySimpleTestTool processed: {message}"

# --- 配置 Agent 使用的 LLM 实例 ---
GEMINI_MODEL_NAME = "gemini/gemini-1.5-flash-latest"
GEMINI_API_KEY = os.getenv("GOOGLE_API_KEY") or os.getenv("GEMINI_API_KEY")

if not GEMINI_API_KEY:
    print("CRITICAL ERROR: GOOGLE_API_KEY or GEMINI_API_KEY not set.")
    exit(1)

# --- 定义详细的事件监听器 ---
class MyDetailedLogger(CrewAIBaseCallbackHandler):
    def __init__(self):
        super().__init__()
        print(f"[{datetime.datetime.now()}] MyDetailedLogger: 已初始化。")

    def setup_listeners(self, crewai_event_bus):
        print(f"[{datetime.datetime.now()}] MyDetailedLogger: 正在设置监听器...")

        @crewai_event_bus.on(LLMCallStartedEvent)
        def handle_llm_start(source, event: LLMCallStartedEvent):
            self.on_llm_start_logic(source, event)

        @crewai_event_bus.on(LLMCallCompletedEvent)
        def handle_llm_completed(source, event: LLMCallCompletedEvent):
            self.on_llm_end_logic(source, event)

        print(f"[{datetime.datetime.now()}] MyDetailedLogger: 监听器设置完成。")

    def on_llm_start_logic(self, source, event: LLMCallStartedEvent):
        print(f"\n>>>> LLM 调用开始 (Event Logic) <<<<")
        llm_inputs = getattr(event, 'llm_inputs', {})
        messages = llm_inputs.get('messages')
        tools = llm_inputs.get('tools')
        print(f"来源 (Source): {source}")
        if messages:
            print("消息 (来自 event.llm_inputs):")
            if isinstance(messages, list) and len(messages) > 0:
                first_message = messages[0]
                if isinstance(first_message, dict) and 'content' in first_message:
                    content_snippet = str(first_message.get('content', ''))[:300]
                    print(f"   Role: {first_message.get('role')}, Content Snippet: {content_snippet}...")
                else:
                     print(f"  First message (raw): {first_message}")
            else:
                 print(f"  Messages (raw): {messages}")
        else:
            print("消息 (来自 event.llm_inputs): 无")
        if tools:
            print("工具 (来自 event.llm_inputs):")
            try:
                print(f"  {json.dumps(tools, indent=2, ensure_ascii=False)}")
            except Exception as e:
                print(f"  无法序列化工具为 JSON: {e}. 工具: {tools}")
        else:
            print("工具 (来自 event.llm_inputs): 无")
        print("----------------------------------")

    def on_llm_end_logic(self, source, event: LLMCallCompletedEvent):
        print(f"\n>>>> LLM 调用结束 (Event Logic) <<<<")
        response = getattr(event, 'llm_output', None)
        print(f"来源 (Source): {source}")
        if response:
            if hasattr(response, 'choices') and response.choices:
                choice = response.choices[0]
                if hasattr(choice, 'message') and choice.message:
                    print(f"  消息内容: {choice.message.content}")
                    if hasattr(choice.message, 'tool_calls') and choice.message.tool_calls:
                        print(f"  工具调用: {choice.message.tool_calls}")
                    else:
                        print(f"  工具调用: 无")
            elif hasattr(response, 'content'):
                print(f"  响应内容: {response.content}")
            else:
                print(f"  LLM 响应 (来自 event.llm_output): {str(response)[:500]}...")
        else:
            print("  在 event.llm_output 中未找到响应对象。")
        print("----------------------------------")

# --- 实例化 CustomGeminiLLM ---
custom_llm_tool_config = {"function_calling_config": {"mode": "AUTO"}}
zhz_agent_tool = HybridRAGTool()
researcher_tools = [zhz_agent_tool]

llm_for_agent = CustomGeminiLLM(
    model=GEMINI_MODEL_NAME,
    api_key=GEMINI_API_KEY,
    temperature=0.1,
    max_tokens=2048,
    tool_config=custom_llm_tool_config,
    agent_tools=researcher_tools # 传递工具列表以供缓存
)
print(f"Custom Agent LLM configured: {GEMINI_MODEL_NAME} with custom tool_config")

# --- 设置 BaseMCPTool 的调用器 ---
BaseMCPTool.set_mcpo_caller(call_mcpo_tool)

# --- 定义 Agents ---
researcher_agent = Agent(
    role='信息检索专家',
    goal='准确地回答用户查询，并且只使用提供的工具。',
    backstory=(
        "你是一位高级AI助手，专注于信息检索。"
        "你的专长在于高效地利用工具来查找最相关和最精确的答案来回应用户的查询。"
    ),
    llm=llm_for_agent,
    tools=researcher_tools,
    verbose=True,
    allow_delegation=False,
)

writer_agent = Agent(
    role='报告撰写专家',
    goal='根据提供的信息，撰写清晰、结构良好且富有洞察力的报告。',
    backstory=(
        "您是一位资深的报告撰写专家，拥有出色的分析和写作能力。"
        "您擅长将复杂的信息提炼成易于理解的报告，并能根据不同的输出状态（答案、澄清、错误）"
        "灵活调整报告内容和格式。"
    ),
    llm=llm_for_agent,
    verbose=True,
    allow_delegation=False,
)

# --- 定义 Tasks (包含上下文传递修复) ---
research_task_description = """你收到了来自用户的以下查询：

'{query}'

你应该使用提供的 `HybridRAGQueryTool` 工具来处理这个查询。
如果这个工具需要 `top_k_vector`, `top_k_kg`, 或 `top_k_bm25` 这些参数，请使用以下建议值：
top_k_vector: 5, top_k_kg: 3, top_k_bm25: 5。
在使用完必要的工具后，你的最终输出应该是（使用中文）：'我的最终答案是：' 
后跟你使用的工具返回的精确、完整的JSON字符串输出内容。"""

research_task_expected_output = "短语 '我的最终答案是：' 后跟你使用的工具返回的精确、完整的JSON字符串输出内容。"

research_task = Task(
    description=research_task_description,
    expected_output=research_task_expected_output,
    agent=researcher_agent,
)

report_writing_task = Task(
    description="""根据【前一个任务】（信息检索专家）提供的RAG工具输出（它是一个JSON字符串），生成一份报告或响应。
请仔细分析这个JSON字符串输出，它应该包含一个 'status' 字段。
1. 如果 'status' 是 'success'，则提取 'final_answer' 字段的内容，并基于此答案撰写一份简洁的报告。
2. 如果 'status' 是 'clarification_needed'，则提取 'clarification_question' 字段的内容，并向用户明确指出需要澄清的问题，例如：'系统需要澄清：[澄清问题]'。
3. 如果 'status' 是 'error'，则提取 'error_message' (或 'error') 字段的内容，并向用户报告错误，例如：'RAG服务发生错误：[错误信息]'。
你的最终输出必须是清晰、专业且符合上述情况的报告或响应。""",
    expected_output="一份清晰的报告，或者一个明确的澄清请求，或者一个错误报告。",
    agent=writer_agent,
    context=[research_task],
)

# --- 实例化监听器 ---
my_event_logger = MyDetailedLogger()

# --- 定义 Crew (添加 event_listeners) ---
office_brain_crew = Crew(
    agents=[researcher_agent, writer_agent],
    tasks=[research_task, report_writing_task],
    process=Process.sequential,
    verbose=True,
    event_listeners=[my_event_logger] # <<< --- 激活事件监听器 ---
)

# --- 启动 Crew ---
if __name__ == "__main__":
    print("--- 启动智能助手终端大脑 Crew (使用 CustomGeminiLLM 和事件监听器) ---")
    user_query_input = "公司2024年第一季度在华东和华北的总销售额一共是多少？"
    # --- 修复：kickoff inputs 只包含 query ---
    inputs = {'query': user_query_input}
    result = office_brain_crew.kickoff(inputs=inputs)
    print("\n\n=== 最终报告 ===\n")
    if hasattr(result, 'raw'):
        print(result.raw)
    else:
        print(result)
    print("\n--- Crew 任务完成 ---")
    --- END OF FILE CONTENT ---

  File: tools.py
    --- START OF FILE CONTENT ---
# zhz_agent/custom_crewai_tools.py

import os
import json
import asyncio
import traceback
from typing import Type, List, Dict, Any, Optional, ClassVar
from pydantic import BaseModel, Field
from crewai.tools import BaseTool
import httpx

# 从 zhz_agent.pydantic_models 导入 QueryRequest
from zhz_rag.config.pydantic_models import QueryRequest # 用于 RAG 工具的输入

# MCPO 代理的基地址
MCPO_BASE_URL = os.getenv("MCPO_BASE_URL", "http://localhost:8006")

class BaseMCPTool(BaseTool):
    mcpo_base_url: str = MCPO_BASE_URL
    _call_mcpo_func: ClassVar[callable] = None

    @classmethod
    def set_mcpo_caller(cls, caller: callable):
        cls._call_mcpo_func = caller

    def __init__(self, **kwargs):
        super().__init__(**kwargs)

    async def _call_mcpo_endpoint(self, service_and_tool_path: str, payload: dict) -> dict | str:
        api_url = f"{self.mcpo_base_url}/{service_and_tool_path}"
        cleaned_payload = {k: v for k, v in payload.items() if v is not None}
        print(f"BaseMCPTool: Calling mcpo endpoint: POST {api_url} with payload: {json.dumps(cleaned_payload, ensure_ascii=False)}")
        
        # --- [修改] 移除 proxies=None 参数 ---
        async with httpx.AsyncClient(trust_env=False) as client:
            response = None
            try:
                headers = {"Content-Type": "application/json"}
                response = await client.post(api_url, json=cleaned_payload, headers=headers, timeout=300.0)
                print(f"BaseMCPTool: mcpo status code for {service_and_tool_path}: {response.status_code}")
                print(f"BaseMCPTool: mcpo response headers for {service_and_tool_path}: {response.headers}") # <--- 新增日志
                # 尝试分块读取响应或提前获取少量内容进行日志记录，以防响应过大卡住 .text 或 .json()
                try:
                    response_text_snippet = await response.aread(num_bytes=1024) # 读取前1KB
                    print(f"BaseMCPTool: mcpo response text snippet (first 1KB) for {service_and_tool_path}: {response_text_snippet.decode(errors='ignore')}")
                except Exception as e_read:
                    print(f"BaseMCPTool: Error reading response snippet: {e_read}")

                if response.status_code == 200:
                    try:
                        # print(f"BaseMCPTool: mcpo raw response text for {service_and_tool_path}: {response.text}") # 如果怀疑内容问题，可以取消注释，但小心大响应
                        return response.json()
                    except json.JSONDecodeError:
                        print(f"BaseMCPTool Warning: mcpo returned status 200 but response is not JSON for '{service_and_tool_path}'. Returning raw text.")
                        return response.text
                else:
                    error_text = f"mcpo call to '{service_and_tool_path}' failed with status {response.status_code}. Response: {response.text[:500]}..."
                    print(f"BaseMCPTool Error: {error_text}")
                    return {"error": error_text, "status_code": response.status_code}
            except httpx.RequestError as exc:
                error_msg = f"BaseMCPTool HTTP RequestError calling mcpo tool '{service_and_tool_path}': {type(exc).__name__} - {exc}"
                print(f"BaseMCPTool Error: {error_msg}"); traceback.print_exc()
                return {"error": error_msg, "exception_type": type(exc).__name__}
            except Exception as exc:
                error_msg = f"BaseMCPTool Unexpected error calling mcpo tool '{service_and_tool_path}': {type(exc).__name__} - {exc}"
                response_text_snippet = response.text[:500] if response and hasattr(response, 'text') else "Response object not available or no text."
                print(f"BaseMCPTool Error: {error_msg}. Response snippet: {response_text_snippet}"); traceback.print_exc()
                return {"error": error_msg, "exception_type": type(exc).__name__}

    def _handle_tool_result(self, result: dict | str, tool_name_for_log: str) -> str:
        print(f"BaseMCPTool DEBUG: {tool_name_for_log} result from mcpo: {str(result)[:500]}...")
        parsed_result = result
        if isinstance(result, str):
            try:
                parsed_result = json.loads(result)
            except json.JSONDecodeError:
                if "error" in result.lower() or "failed" in result.lower() or "traceback" in result.lower():
                    return f"调用 {tool_name_for_log} 失败，返回非JSON错误文本: {result}"
                print(f"BaseMCPTool Info: Result for {tool_name_for_log} is a non-JSON string, returning as is.")
                return result
        if isinstance(parsed_result, dict):
            if "error" in parsed_result and "status_code" in parsed_result:
                return f"调用 {tool_name_for_log} 时发生HTTP错误：{parsed_result.get('error')}"
            if parsed_result.get("status") == "error":
                error_msg = parsed_result.get("error_message", "未知错误")
                error_code = parsed_result.get("error_code", "NO_CODE")
                return f"工具 {tool_name_for_log} 执行失败 (错误码: {error_code})：{error_msg}"
            try:
                return json.dumps(parsed_result, ensure_ascii=False, indent=2)
            except Exception as e:
                print(f"BaseMCPTool Error formatting successful dict result for {tool_name_for_log}: {e}")
                return str(parsed_result)
        print(f"BaseMCPTool Warning: Unexpected result format from {tool_name_for_log} mcpo call: {type(result)}, content: {str(result)[:200]}")
        return f"从 {tool_name_for_log} 服务收到的结果格式不正确或无法处理: {str(result)[:500]}"

    def _run_default_sync_wrapper(self, **kwargs) -> str:
        tool_name = getattr(self, 'name', self.__class__.__name__)
        print(f"BaseMCPTool INFO: Synchronous _run called for {tool_name} with args: {kwargs}.")
        result_str = ""
        try:
            # --- 改进的 asyncio.run 处理 ---
            try:
                loop = asyncio.get_running_loop()
            except RuntimeError:
                loop = None

            async def async_runner():
                return await self._arun(**kwargs)

            if loop and loop.is_running():
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
                    future = executor.submit(asyncio.run, async_runner())
                    result = future.result(timeout=120)
            else:
                result = asyncio.run(async_runner())
            result_str = str(result)
        except asyncio.TimeoutError:
            error_message = f"Tool {tool_name} execution timed out after 120 seconds."
            print(f"BaseMCPTool ERROR_TRACE: {error_message}"); result_str = error_message
        except RuntimeError as e:
            if "cannot run event loop while another loop is running" in str(e).lower() or "event loop is already running" in str(e).lower():
                error_message = (f"BaseMCPTool Error in {tool_name} _run: Nested asyncio event loop conflict. Original error: {e}")
            else:
                error_message = f"BaseMCPTool RuntimeError in {tool_name} _run: {type(e).__name__} - {e}"
            print(f"BaseMCPTool ERROR_TRACE: {error_message}"); traceback.print_exc();
            result_str = error_message
        except Exception as e:
            error_message = f"BaseMCPTool General Exception in {tool_name} _run: {type(e).__name__} - {e}"
            print(f"BaseMCPTool ERROR_TRACE: {error_message}"); traceback.print_exc(); result_str = error_message
        return result_str

class HybridRAGTool(BaseMCPTool):
    name: str = "HybridRAGQueryTool"
    description: str = (
        "【核心RAG工具】用于通过执行混合检索增强生成 (RAG) 搜索来回答用户问题。 "
        "该工具整合了向量检索、知识图谱检索和关键词检索，并进行智能融合和重排序。 "
        "当用户需要从知识库中获取信息、回答复杂问题或生成报告时，应调用此工具。"
    )
    args_schema: Type[BaseModel] = QueryRequest
    target_mcp_service_path: str = "zhz_agent_rag_service/query_rag_v2"

    async def _arun(self, query: str, top_k_vector: int, top_k_kg: int, top_k_bm25: int, **kwargs: Any) -> str: # --- 确认有 **kwargs ---
        tool_name_for_log = getattr(self, 'name', "HybridRAGTool")
        print(f"CrewAI Tool DEBUG: {tool_name_for_log}._arun called with query='{query}', top_k_vector={top_k_vector}, top_k_kg={top_k_kg}, top_k_bm25={top_k_bm25}, additional_kwargs={kwargs}")

        security_context = kwargs.get('security_context')
        if security_context:
            print(f"CrewAI Tool INFO: Received security_context (in HybridRAGTool): {str(security_context)[:200]}...")

        payload = {
            "query": query,
            "top_k_vector": top_k_vector,
            "top_k_kg": top_k_kg,
            "top_k_bm25": top_k_bm25
        }
        result = await self._call_mcpo_endpoint(self.target_mcp_service_path, payload)
        return self._handle_tool_result(result, self.name)

    def _run(self, query: str, top_k_vector: int, top_k_kg: int, top_k_bm25: int, **kwargs: Any) -> str: # --- 确认有 **kwargs ---
        return self._run_default_sync_wrapper(query=query, top_k_vector=top_k_vector, top_k_kg=top_k_kg, top_k_bm25=top_k_bm25, **kwargs)
    --- END OF FILE CONTENT ---


Directory: zhz_rag/config/
  File: constants.py
    --- START OF FILE CONTENT ---
# zhz_agent/zhz_rag/config/constants.py

NEW_KG_SCHEMA_DESCRIPTION = """
# 知识图谱结构 (KuzuDB) 与 Cypher 查询生成规则

## 1. 节点定义:
- 节点标签: `:ExtractedEntity` (你必须且只能使用此节点标签)
- 节点属性:
    - `id_prop`: STRING (主键，实体的唯一标识)
    - `text`: STRING (实体的名称或文本内容)
    - `label`: STRING (实体类型。允许的值: "PERSON", "ORGANIZATION", "TASK")

## 2. 关系定义:
- 关系类型: `:WorksAt`
    - 结构: `(:ExtractedEntity {label:"PERSON"}) -[:WorksAt]-> (:ExtractedEntity {label:"ORGANIZATION"})`
    - 含义: 一个人 (PERSON) 在一个组织 (ORGANIZATION) 工作。
- 关系类型: `:AssignedTo`
    - 结构: `(:ExtractedEntity {label:"TASK"}) -[:AssignedTo]-> (:ExtractedEntity {label:"PERSON"})`
    - 含义: 一个任务 (TASK) 被分配给一个人 (PERSON)。

## 3. Cypher 查询生成 - 输出为 JSON 对象:

    你的【完整且唯一】的回答，必须是一个符合以下描述的 JSON 对象：
    {
      "status": "success" | "unable_to_generate",
      "query": "string"
    }

    规则:
    a. **节点匹配**: 使用 `MATCH (var:ExtractedEntity {label: 'TYPE'})`.
    b. **属性使用**: 只用 `id_prop`, `text`, `label`.
    c. **关系使用**: 只用 `:WorksAt`, `:AssignedTo` (注意方向和类型).
    d. **"AND" 逻辑**: 对同一实体多条件，用独立 MATCH 并通过公共变量连接.
       例如: `MATCH (entityA:ExtractedEntity {text:'A'})-[:R1]->(t1), (entityA)-[:R2]->(t2) RETURN entityA`.
       严禁错误地将不相关的关系链式连接.

    e. **JSON 输出逻辑**:
        i.  **若能生成有效 Cypher**:
            - `status` 字段必须为 `"success"`.
            - `query` 字段必须为【纯粹的 Cypher 查询字符串】。
            - **【【严禁在 `query` 字段中包含任何 Cypher 之外的文本、解释、思考过程或 Markdown。】】**
        ii. **若无法生成有效 Cypher** (因问题超出 Schema 范围等):
            - `status` 字段必须为 `"unable_to_generate"`.
            - `query` 字段必须为【固定的中文字符串】: `"无法生成Cypher查询."`
            - **【【严禁在 `query` 字段中包含任何此固定短语之外的文本。】】**

    f. **Cypher 返回别名**: 在 Cypher 的 `RETURN` 子句中用 `AS` 指定别名.

## 4. JSON 输出格式示例:

### 示例 1 (能够生成查询):
用户问题: "任务'FixBug123'分配给了谁？"
你的【完整且唯一】的 JSON 回答:
```json
{
  "status": "success",
  "query": "MATCH (t:ExtractedEntity {text: 'FixBug123', label: 'TASK'})-[:AssignedTo]->(p:ExtractedEntity {label: 'PERSON'}) RETURN p.text AS Assignee"
}
示例 2 (无法根据Schema回答):
用户问题: "法国的首都是哪里？"
你的【完整且唯一】的 JSON 回答:
{
  "status": "unable_to_generate",
  "query": "无法生成Cypher查询."
}
"""
    --- END OF FILE CONTENT ---

  File: mcp_servers.json
    --- START OF FILE CONTENT ---
{
  "mcpServers": {
    "zhz_rag_mcp_service": { 
      "command": "/home/zhz/zhz_agent/.venv/bin/python", 
      "args": [
        "-m", 
        "zhz_rag.api.rag_mcp_service" 
      ],
      "cwd": "/home/zhz/zhz_agent", 
      "env": {
        "PYTHONPATH": "/home/zhz/zhz_agent:/home/zhz/zhz_agent/zhz_rag",
        "SGLANG_API_URL": "http://localhost:8088/v1/chat/completions",
        "CHROMA_PERSIST_DIRECTORY": "/home/zhz/zhz_agent/zhz_rag/stored_data/chromadb_index",
        "BM25_INDEX_DIRECTORY": "/home/zhz/zhz_agent/zhz_rag/stored_data/bm25_index",
        "KUZU_DB_PATH": "/home/zhz/zhz_agent/zhz_rag/stored_data/kuzu_default_db"
      }
    }
  }
}
    --- END OF FILE CONTENT ---

  File: pydantic_models.py
    --- START OF FILE CONTENT ---
# /home/zhz/zhz_agent/zhz_rag/config/pydantic_models.py
from pydantic import BaseModel, Field, root_validator # 使用 root_validator 替代 model_validator
from typing import List, Dict, Any, Optional
from enum import Enum
from datetime import datetime
import uuid

# --- RAG Models ---
class QueryRequest(BaseModel):
    query: str = Field(description="用户提出的原始查询文本。", json_schema_extra=lambda schema: schema.pop('default', None) if schema.get('default') is None else None)
    top_k_vector: int = Field(description="期望检索的向量搜索结果数量。", json_schema_extra=lambda schema: schema.pop('default', None) if schema.get('default') is None else None)
    top_k_kg: int = Field(description="期望检索的知识图谱结果数量。", json_schema_extra=lambda schema: schema.pop('default', None) if schema.get('default') is None else None)
    top_k_bm25: int = Field(description="期望检索的 BM25 关键词搜索结果数量。", json_schema_extra=lambda schema: schema.pop('default', None) if schema.get('default') is None else None)

    @root_validator(pre=True)
    @classmethod
    def remove_internal_params(cls, values: Dict[str, Any]) -> Dict[str, Any]:
        if isinstance(values, dict):
            # print(f"Pydantic DEBUG (QueryRequest before validation): Received data for validation: {str(values)[:500]}") # 可以取消注释以进行调试
            removed_security_context = values.pop('security_context', None)
            if removed_security_context:
                # print(f"Pydantic INFO (QueryRequest before validation): Removed 'security_context': {str(removed_security_context)[:100]}")
                pass
            removed_agent_fingerprint = values.pop('agent_fingerprint', None)
            if removed_agent_fingerprint:
                # print(f"Pydantic INFO (QueryRequest before validation): Removed 'agent_fingerprint': {str(removed_agent_fingerprint)[:100]}")
                pass
        return values

    class Config:
        extra = 'forbid'

class RetrievedDocument(BaseModel):
    source_type: str
    content: str
    score: Optional[float] = Field(default=None, json_schema_extra=lambda schema: schema.pop('default', None) if schema.get('default') is None else None)
    metadata: Optional[Dict[str, Any]] = Field(default=None, json_schema_extra=lambda schema: schema.pop('default', None) if schema.get('default') is None else None)

class HybridRAGResponse(BaseModel):
    original_query: str
    answer: str
    retrieved_sources: List[RetrievedDocument]
    debug_info: Optional[Dict[str, Any]] = Field(default=None, json_schema_extra=lambda schema: schema.pop('default', None) if schema.get('default') is None else None)


# --- Task Management Models ---
class TaskStatus(str, Enum):
    PENDING = "pending"
    ACTIVE = "active"
    COMPLETED = "completed"
    CANCELLED = "cancelled"
    FAILED = "failed"
    REMINDING = "reminding"

class ReminderMethod(str, Enum):
    NOTIFICATION = "notification"

class TaskModel(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()), description="任务的唯一ID (自动生成)")
    title: str = Field(description="任务标题")
    description: Optional[str] = Field(None, description="任务的详细描述")
    status: TaskStatus = Field(default=TaskStatus.PENDING, description="任务当前状态")
    created_at: datetime = Field(default_factory=datetime.utcnow, description="任务创建时间 (UTC)")
    updated_at: datetime = Field(default_factory=datetime.utcnow, description="任务最后更新时间 (UTC)")
    due_date: Optional[datetime] = Field(None, description="任务截止日期或计划执行时间 (UTC)")
    reminder_time: Optional[datetime] = Field(None, description="任务提醒时间 (UTC)")
    reminder_offset_minutes: Optional[int] = Field(None, description="提醒时间相对于due_date的提前分钟数 (例如10分钟前)")
    reminder_methods: List[ReminderMethod] = Field(default=[ReminderMethod.NOTIFICATION], description="提醒方式列表")
    priority: int = Field(default=0, description="任务优先级 (例如 0:普通, 1:重要, 2:紧急)")
    tags: List[str] = Field(default_factory=list, description="任务标签")
    action_type: Optional[str] = Field(None, description="任务到期时需要执行的动作类型 (例如 'navigate', 'send_message', 'run_report')")
    action_payload: Dict[str, Any] = Field(default_factory=dict, description="执行动作时需要的参数 (例如导航的目的地)")
    execution_result: Optional[str] = Field(None, description="任务执行后的结果或错误信息")
    last_executed_at: Optional[datetime] = Field(None, description="上次执行时间 (UTC)")

    class Config:
        use_enum_values = True
        orm_mode = True # Pydantic V1 中使用 orm_mode = True 替代 from_attributes

class CreateTaskRequest(BaseModel):
    title: str
    description: Optional[str] = None
    due_date: Optional[datetime] = None
    reminder_offset_minutes: Optional[int] = None
    reminder_methods: Optional[List[ReminderMethod]] = [ReminderMethod.NOTIFICATION]
    priority: Optional[int] = 0
    tags: Optional[List[str]] = None
    action_type: Optional[str] = None
    action_payload: Optional[Dict[str, Any]] = None
    
    class Config:
        extra = 'forbid'

class UpdateTaskRequest(BaseModel):
    title: Optional[str] = None
    description: Optional[str] = None
    status: Optional[TaskStatus] = None
    due_date: Optional[datetime] = None
    reminder_offset_minutes: Optional[int] = None
    reminder_methods: Optional[List[ReminderMethod]] = None
    priority: Optional[int] = None
    tags: Optional[List[str]] = None
    action_type: Optional[str] = None
    action_payload: Optional[Dict[str, Any]] = None

    class Config:
        extra = 'forbid'
    --- END OF FILE CONTENT ---


Directory: zhz_rag/zhz_rag_core.egg-info/
  File (skipped, extension not included): PKG-INFO
  File: SOURCES.txt
    --- START OF FILE CONTENT ---
setup.py
api/__init__.py
api/main_api.py
api/rag_mcp_service.py
api/task_manager_api.py
core_rag/__init__.py
core_rag/fusion_engine.py
core_rag/kg_retriever.py
core_rag/retrievers/__init__.py
core_rag/retrievers/chromadb_retriever.py
core_rag/retrievers/file_bm25_retriever.py
crewai_integration/__init__.py
crewai_integration/run_crew.py
crewai_integration/tools.py
evaluation/__init__.py
evaluation/analyze_answer.py
evaluation/analyze_cypher.py
evaluation/batch_eval_answer.py
evaluation/batch_eval_cypher.py
evaluation/evaluator.py
finetuning/__init__.py
finetuning/refine_answer_data.py
finetuning/refine_cypher_data.py
llm/__init__.py
llm/custom_crewai_llms.py
llm/sglang_wrapper.py
stored_data/__init__.py
task_management/__init__.py
task_management/db_models.py
task_management/jobs.py
zhz_rag_core.egg-info/PKG-INFO
zhz_rag_core.egg-info/SOURCES.txt
zhz_rag_core.egg-info/dependency_links.txt
zhz_rag_core.egg-info/requires.txt
zhz_rag_core.egg-info/top_level.txt
    --- END OF FILE CONTENT ---

  File: dependency_links.txt
    --- START OF FILE CONTENT ---


    --- END OF FILE CONTENT ---

  File: requires.txt
    --- START OF FILE CONTENT ---
protobuf<5.30.0,>=4.25.0
packaging<25.0,>=23.2
rich<14.0.0,>=13.7.0
fastapi<0.116.0,>=0.110.0
starlette<0.47.0,>=0.35.0
langchain-core<0.4.0,>=0.1.50
langchain-text-splitters<0.3.0,>=0.0.1
httpx>=0.27.0
python-dotenv>=1.0.0
neo4j>=5.0.0
sentence-transformers>=2.2.0
transformers<4.39.0,>=4.38.0
torch>=2.0.0
numpy<2.0
bm25s
jieba
uvicorn[standard]
pandas>=2.0.0
sqlalchemy>=2.0.0
databases[aiosqlite]>=0.9.0
apscheduler>=3.10.0
pytz

    --- END OF FILE CONTENT ---

  File: top_level.txt
    --- START OF FILE CONTENT ---
api
core_rag
crewai_integration
evaluation
finetuning
llm
stored_data
task_management

    --- END OF FILE CONTENT ---


Directory: zhz_rag/utils/
  File (skipped, extension not included): ZHZ_AGENT_tasks.db
  File: common_utils.py
    --- START OF FILE CONTENT ---
# zhz_rag/utils/common_utils.py

import httpx
import json
import traceback
import os
import glob
from dotenv import load_dotenv
from datetime import datetime, timezone
import uuid
import logging
import asyncio #确保 asyncio 被导入
from typing import List, Dict, Any, Optional
import re
import unicodedata

load_dotenv()

# --- Logger Configuration ---
utils_logger = logging.getLogger("UtilsLogger")
utils_logger.setLevel(logging.INFO)
if not utils_logger.hasHandlers():
    _utils_console_handler = logging.StreamHandler()
    _utils_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s - %(filename)s:%(lineno)d - %(message)s')
    _utils_console_handler.setFormatter(_utils_formatter)
    utils_logger.addHandler(_utils_console_handler)
    utils_logger.propagate = False
utils_logger.info("--- UtilsLogger configured ---")

# --- MCP Configuration ---
MCPO_BASE_URL = os.getenv("MCPO_BASE_URL", "http://localhost:8006")

# --- Standard Project Directory Paths ---
# _COMMON_UTILS_FILE_PATH = os.path.abspath(__file__)
# _UTILS_DIR = os.path.dirname(_COMMON_UTILS_FILE_PATH) # zhz_rag/utils/
# _ZHZ_RAG_PACKAGE_DIR = os.path.dirname(_UTILS_DIR)     # zhz_rag/

# More robust way to get zhz_rag package directory if common_utils.py is in zhz_rag/utils/
_CURRENT_FILE_DIR = os.path.dirname(os.path.abspath(__file__))
# Assuming this file (common_utils.py) is in zhz_rag/utils/
# Then _ZHZ_RAG_PACKAGE_DIR should be the parent of _CURRENT_FILE_DIR
_ZHZ_RAG_PACKAGE_DIR = os.path.dirname(_CURRENT_FILE_DIR)


# Root directory for all data generated and used at runtime by the RAG system (logs, indexes etc.)
# This will be zhz_rag/stored_data/
STORED_DATA_ROOT_DIR = os.path.join(_ZHZ_RAG_PACKAGE_DIR, 'stored_data')

# Specific subdirectories within stored_data
RAG_INTERACTION_LOGS_DIR = os.path.join(STORED_DATA_ROOT_DIR, 'rag_interaction_logs')
EVALUATION_RESULTS_LOGS_DIR = os.path.join(STORED_DATA_ROOT_DIR, 'evaluation_results_logs')
# Example for other potential stored data:
# CHROMA_DB_DIR = os.path.join(STORED_DATA_ROOT_DIR, 'chromadb_index')
# BM25_INDEX_DIR = os.path.join(STORED_DATA_ROOT_DIR, 'bm25_index')


# Root directory for data generated by the finetuning preparation scripts
# This will be zhz_rag/finetuning/generated_data/
FINETUNING_GENERATED_DATA_DIR = os.path.join(_ZHZ_RAG_PACKAGE_DIR, 'finetuning', 'generated_data')

# Ensure these directories exist
_DIRECTORIES_TO_CREATE = [
    STORED_DATA_ROOT_DIR,
    RAG_INTERACTION_LOGS_DIR,
    EVALUATION_RESULTS_LOGS_DIR,
    FINETUNING_GENERATED_DATA_DIR
]
for dir_path in _DIRECTORIES_TO_CREATE:
    if not os.path.exists(dir_path):
        try:
            os.makedirs(dir_path, exist_ok=True)
            utils_logger.info(f"Successfully created directory: {dir_path}")
        except Exception as e:
            utils_logger.error(f"Error creating directory {dir_path}: {e}. Consider creating it manually.")

# --- Log File Path Getters ---

def get_interaction_log_filepath() -> str:
    """Gets the full path for the current RAG interaction log file (daily rotation)."""
    today_str = datetime.now(timezone.utc).strftime("%Y%m%d")
    return os.path.join(RAG_INTERACTION_LOGS_DIR, f"rag_interactions_{today_str}.jsonl")

def get_evaluation_result_log_filepath(evaluation_name: str) -> str:
    """Gets the full path for an evaluation result log file (daily rotation, by evaluation name)."""
    today_str = datetime.now(timezone.utc).strftime("%Y%m%d")
    return os.path.join(EVALUATION_RESULTS_LOGS_DIR, f"eval_results_{evaluation_name}_{today_str}.jsonl")

def find_latest_rag_interaction_log(log_dir: str = RAG_INTERACTION_LOGS_DIR) -> Optional[str]:
    """
    Finds the latest RAG interaction log file (rag_interactions_*.jsonl) in the specified directory.
    Defaults to RAG_INTERACTION_LOGS_DIR.
    """
    utils_logger.debug(f"Searching for RAG interaction logs in: {log_dir}")
    rag_log_pattern = os.path.join(log_dir, "rag_interactions_*.jsonl")
    candidate_rag_logs = glob.glob(rag_log_pattern)

    if candidate_rag_logs:
        candidate_rag_logs.sort(key=os.path.getmtime, reverse=True)
        utils_logger.info(f"Automatically selected RAG interaction log: {candidate_rag_logs[0]}")
        return candidate_rag_logs[0]
    else:
        utils_logger.warning(f"No RAG interaction log files found matching pattern: {rag_log_pattern} in directory {log_dir}")
        return None

# --- Logging Function ---

async def log_interaction_data(
    interaction_data: Dict[str, Any],
    is_evaluation_result: bool = False,
    evaluation_name_for_file: Optional[str] = None
):
    """
    Asynchronously appends a single interaction data or evaluation result to a JSONL file.
    """
    if is_evaluation_result:
        if not evaluation_name_for_file:
            evaluation_name_for_file = interaction_data.get("task_type", "general_eval_result") # More specific default
        filepath = get_evaluation_result_log_filepath(evaluation_name=evaluation_name_for_file)
    else:
        filepath = get_interaction_log_filepath()

    if "timestamp_utc" not in interaction_data:
        interaction_data["timestamp_utc"] = datetime.now(timezone.utc).isoformat()
    if "interaction_id" not in interaction_data and not is_evaluation_result: # Eval results use original_interaction_id_ref
        interaction_data["interaction_id"] = str(uuid.uuid4())
    elif "interaction_id" not in interaction_data and is_evaluation_result and "original_interaction_id_ref" in interaction_data:
        # For eval results, ensure there's an ID, can be a new one for the eval log entry itself
         interaction_data["interaction_id"] = str(uuid.uuid4())


    try:
        def _write_sync():
            # Ensure the directory for the specific log file exists
            log_file_dir = os.path.dirname(filepath)
            if not os.path.exists(log_file_dir):
                try:
                    os.makedirs(log_file_dir, exist_ok=True)
                    utils_logger.info(f"Created directory for log file: {log_file_dir}")
                except Exception as e_mkdir:
                    utils_logger.error(f"Error creating directory {log_file_dir} for log file: {e_mkdir}")
                    return # Prevent writing if directory creation fails

            with open(filepath, 'a', encoding='utf-8') as f:
                f.write(json.dumps(interaction_data, ensure_ascii=False) + "\n")
        
        await asyncio.to_thread(_write_sync)
        # utils_logger.debug(f"Successfully logged data (type: {interaction_data.get('task_type', 'N/A')}) to {filepath}")
    except Exception as e:
        utils_logger.error(f"Failed to log interaction data to {filepath}: {e}", exc_info=True)

# --- MCP Tool Calling Utility ---

async def call_mcpo_tool(tool_name_with_prefix: str, payload: Dict[str, Any]) -> Dict[str, Any]:
    """
    Asynchronously calls an MCP tool service and returns the JSON response or an error dictionary.
    """
    api_url = f"{MCPO_BASE_URL}/{tool_name_with_prefix}"
    # Ensure payload is a dictionary, even if it's empty
    cleaned_payload = {k: v for k, v in (payload or {}).items() if v is not None}


    utils_logger.info(f"Calling MCP endpoint: POST {api_url} with payload: {json.dumps(cleaned_payload, ensure_ascii=False)}")

    async with httpx.AsyncClient() as client:
        response = None
        try:
            headers = {"Content-Type": "application/json"}
            response = await client.post(api_url, json=cleaned_payload, headers=headers, timeout=120.0)
            utils_logger.info(f"MCP status code for {tool_name_with_prefix}: {response.status_code}")

            if response.status_code == 200:
                try:
                    result_data = response.json()
                    # MCP specific error handling (if MCP wraps tool errors)
                    if isinstance(result_data, dict) and result_data.get("isError"):
                        error_content_list = result_data.get("content", [{"type": "text", "text": "Unknown error from MCP tool"}])
                        error_text = "Unknown error from MCP tool"
                        for item in error_content_list:
                            if item.get("type") == "text":
                                error_text = item.get("text", error_text)
                                break
                        utils_logger.error(f"MCP Tool '{tool_name_with_prefix}' execution failed (isError=true): {error_text}")
                        try:
                            # Try to parse if the error_text itself is a JSON string with more details
                            parsed_mcp_error = json.loads(error_text)
                            if isinstance(parsed_mcp_error, dict) and "error" in parsed_mcp_error:
                                return {"error": f"Tool '{tool_name_with_prefix}' failed via MCP: {parsed_mcp_error['error']}"}
                        except json.JSONDecodeError:
                            pass 
                        return {"error": f"Tool '{tool_name_with_prefix}' failed via MCP: {error_text}"}
                    return result_data
                except json.JSONDecodeError:
                    utils_logger.warning(f"MCP call to '{tool_name_with_prefix}' returned status 200 but response is not JSON. Raw text: {response.text[:500]}...")
                    # Return a structured error if possible, or the raw text wrapped
                    return {"error": "Non-JSON response from MCP tool", "raw_response": response.text}
            else:
                error_text = f"MCP call to '{tool_name_with_prefix}' failed with status {response.status_code}. Response: {response.text[:500]}..."
                utils_logger.error(error_text)
                return {"error": error_text, "status_code": response.status_code}

        except httpx.RequestError as exc:
            error_msg = f"HTTP RequestError calling MCP tool '{tool_name_with_prefix}': {type(exc).__name__} - {exc}"
            utils_logger.error(error_msg, exc_info=True)
            return {"error": error_msg, "exception_type": type(exc).__name__}
        except Exception as exc:
            error_msg = f"Unexpected error calling MCP tool '{tool_name_with_prefix}': {type(exc).__name__} - {exc}"
            response_text_snippet = response.text[:500] if response and hasattr(response, 'text') else "Response object not available or no text."
            utils_logger.error(f"{error_msg}. Response snippet: {response_text_snippet}", exc_info=True)
            return {"error": error_msg, "exception_type": type(exc).__name__}
        
def load_jsonl_file(filepath: str, encoding: str = 'utf-8') -> List[Dict[str, Any]]:
    """
    从 JSONL 文件加载数据。

    Args:
        filepath (str): JSONL 文件的路径。
        encoding (str): 文件编码，默认为 'utf-8'。

    Returns:
        List[Dict[str, Any]]: 从文件中加载的字典列表。如果文件不存在或解析出错，
                              会记录错误并返回空列表。
    """
    data_list: List[Dict[str, Any]] = []
    if not os.path.exists(filepath):
        utils_logger.error(f"File not found: {filepath}") # 使用已有的 utils_logger
        return data_list

    try:
        with open(filepath, 'r', encoding=encoding) as f:
            for line_number, line in enumerate(f, 1):
                try:
                    if line.strip(): # 确保行不是空的
                        data_list.append(json.loads(line.strip()))
                except json.JSONDecodeError as e_json:
                    utils_logger.warning(f"Skipping malformed JSON line {line_number} in {filepath}: {e_json}")
                except Exception as e_line:
                    utils_logger.warning(f"Error processing line {line_number} in {filepath}: {e_line}")
    except FileNotFoundError: # 再次捕获以防万一，虽然上面已经检查了
        utils_logger.error(f"File not found during open: {filepath}")
    except Exception as e_file:
        utils_logger.error(f"Error reading or processing file {filepath}: {e_file}", exc_info=True)
        return [] # 如果文件读取层面发生严重错误，返回空列表

    utils_logger.info(f"Successfully loaded {len(data_list)} entries from {filepath}")
    return data_list

def normalize_text_for_id(text: str) -> str:
    if not isinstance(text, str):
        return str(text) 
    
    try:
        normalized_text = unicodedata.normalize('NFKD', text)
        normalized_text = normalized_text.lower()
        normalized_text = normalized_text.strip()
        normalized_text = re.sub(r'\s+', ' ', normalized_text)
        return normalized_text
    except Exception as e:
        return text
    --- END OF FILE CONTENT ---

  File: db_utils.py
    --- START OF FILE CONTENT ---
# ZHZ_AGENT/database.py
import os
from databases import Database
from sqlalchemy import create_engine
from sqlalchemy.orm import declarative_base
from typing import Optional

# --- APScheduler 相关导入 ---
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.jobstores.sqlalchemy import SQLAlchemyJobStore
# --- [修改] 明确导入并使用 pytz ---
import pytz #

# --- 数据库配置 ---
ZHZ_AGENT_DIR = os.path.dirname(os.path.abspath(__file__))
DB_NAME = "ZHZ_AGENT_tasks.db"
DATABASE_FILE_PATH = os.path.join(ZHZ_AGENT_DIR, DB_NAME)
DATABASE_URL = f"sqlite+aiosqlite:///{DATABASE_FILE_PATH}"

database = Database(DATABASE_URL)
sqlalchemy_engine = create_engine(DATABASE_URL.replace("+aiosqlite", ""))
Base = declarative_base() #

# --- 全局调度器实例定义 ---
scheduler: Optional[AsyncIOScheduler] = None

def get_scheduler() -> AsyncIOScheduler:
    """获取或创建调度器实例，并配置作业存储和 UTC 时区。"""
    global scheduler
    if scheduler is None:
        jobstore_url = f"sqlite:///{DATABASE_FILE_PATH}"
        jobstores = {
            'default': SQLAlchemyJobStore(url=jobstore_url, tablename='apscheduler_jobs_v2') #
        }
        # --- [修复] 明确使用 pytz.utc 设置时区 ---
        scheduler = AsyncIOScheduler(
            jobstores=jobstores,
            timezone=pytz.utc # <--- 强制使用 pytz.utc #
        )
        import logging
        logging.getLogger('apscheduler').setLevel(logging.DEBUG)
        print(f"APScheduler initialized with timezone: {pytz.utc}") # 确认使用 pytz.utc #
    return scheduler #
    --- END OF FILE CONTENT ---

  File: load_neo4j_data.py
    --- START OF FILE CONTENT ---
# zhz_agent/load_neo4j_data.py
import json
import os
from neo4j import GraphDatabase, basic_auth
from dotenv import load_dotenv
import traceback

load_dotenv() # 确保加载 .env 文件中的NEO4J凭证

NEO4J_URI = os.getenv("NEO4J_URI", "bolt://localhost:7687")
NEO4J_USER = os.getenv("NEO4J_USER", "neo4j")
NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD") # 您需要确保这个密码是正确的

DATA_PATH = os.path.join(os.path.dirname(__file__), "data")
SAMPLE_KG_PATH = os.path.join(DATA_PATH, "sample_kg.json")

def clear_database(driver):
    """清除数据库中的所有节点和关系"""
    with driver.session(database="neo4j") as session:
        session.run("MATCH (n) DETACH DELETE n")
        print("Cleared all nodes and relationships from the database.")

def create_constraints(driver):
    """创建一些基本约束，确保节点属性的唯一性（如果适用）"""
    with driver.session(database="neo4j") as session:
        try:
            session.run("CREATE CONSTRAINT IF NOT EXISTS FOR (p:Person) REQUIRE p.name IS UNIQUE")
            session.run("CREATE CONSTRAINT IF NOT EXISTS FOR (pr:Project) REQUIRE pr.name IS UNIQUE")
            session.run("CREATE CONSTRAINT IF NOT EXISTS FOR (r:Region) REQUIRE r.name IS UNIQUE")
            session.run("CREATE CONSTRAINT IF NOT EXISTS FOR (prod:Product) REQUIRE prod.name IS UNIQUE")
            session.run("CREATE CONSTRAINT IF NOT EXISTS FOR (d:Document) REQUIRE d.id IS UNIQUE")
            # SalesAmount 通常不需要唯一约束，因为它可能重复（例如不同区域同一时期的销售）
            print("Ensured constraints are created (or already exist).")
        except Exception as e:
            print(f"Error creating constraints: {e}")


def load_data(driver, kg_data):
    """根据kg_data中的facts加载数据到Neo4j"""
    facts = kg_data.get("facts", [])
    
    with driver.session(database="neo4j") as session:
        entities_to_create = set()
        node_types_from_schema = { # 定义了主要实体的标签和它们的主要标识属性
            "Person": "name", "Project": "name", "Region": "name", 
            "Product": "name", "Document": "id", "Idea": "name" # 新增Idea类型
        }

        for fact in facts:
            subject_name = fact.get("subject")
            object_name = fact.get("object")
            fact_type = fact.get("type", "")

            subject_label = None
            # 基于fact_type或其他逻辑推断subject_label
            if "person_" in fact_type: subject_label = "Person"
            elif "region_" in fact_type: subject_label = "Region"
            elif "product_" in fact_type: subject_label = "Product"
            # ... 其他类型的映射 ...
            
            if subject_label and subject_name:
                prop_name = node_types_from_schema.get(subject_label, "name")
                entities_to_create.add((subject_label, prop_name, subject_name))

            object_label = None
            if not fact_type.endswith("_amount"): # 不是直接的销售额事实
                if "_project" in fact_type: object_label = "Project"
                elif "_product" in fact_type: object_label = "Product"
                elif "_document" in fact_type: object_label = "Document"
                elif "_idea" in fact_type: object_label = "Idea" # 新增对Idea类型的处理
                # ... 其他类型的映射 ...

                if object_label and object_name:
                    prop_name = node_types_from_schema.get(object_label, "name") # Document会用id, Idea会用name
                    entities_to_create.add((object_label, prop_name, object_name))
        
        for label, prop, value in entities_to_create:
            if value is not None:
                query = f"MERGE (n:{label} {{{prop}: $value}})"
                session.run(query, value=value)
                print(f"Merged node: ({label} {{{prop}: '{value}'}})")

        for fact in facts:
            s_name = fact.get("subject")
            rel = fact.get("relation")
            o_name = fact.get("object")
            fact_type = fact.get("type", "")
            period = fact.get("period")

            if fact_type == "region_sales_amount" and period:
                session.run("MERGE (r:Region {name: $s_name})", s_name=s_name)
                try:
                    # ... (销售额解析逻辑不变) ...
                    if isinstance(o_name, str) and '万元' in o_name:
                        numeric_val_str = o_name.replace('万元', '').strip()
                        numeric_val = float(numeric_val_str)
                        unit_val = '万元'
                    # ... (其他单位解析) ...
                    else:
                        numeric_val = float(o_name) # 尝试直接转换
                        unit_val = None 
                    
                    query = """
                    MATCH (r:Region {name: $s_name})
                    CREATE (sa:SalesAmount {numeric_amount: $num_val, period: $period, unit: $unit_val})
                    CREATE (r)-[:HAS_SALES_AMOUNT]->(sa)
                    """
                    session.run(query, s_name=s_name, num_val=numeric_val, period=period, unit_val=unit_val)
                    print(f"Created SalesAmount for {s_name}, {period}: {numeric_val} {unit_val or ''}")
                except ValueError:
                    print(f"Could not parse sales amount: {o_name} for {s_name}, {period}. Skipping this SalesAmount fact.")
                
            elif s_name and rel and o_name: 
                s_label, o_label = None, None
                s_prop, o_prop = "name", "name" 

                # --- 更精确的标签和属性推断 ---
                if fact_type == "person_project" and rel == "WORKS_ON":
                    s_label, o_label = "Person", "Project"
                elif fact_type == "person_idea" and rel == "PROPOSED_IDEA": # 新增
                    s_label, o_label = "Person", "Idea"
                elif fact_type == "region_product" and rel == "HAS_SALES_PRODUCT": # 假设type是 region_product
                    s_label, o_label = "Region", "Product"
                elif fact_type == "product_document" and rel == "RELATED_TO":
                    s_label, o_label = "Product", "Document"
                    o_prop = "id" # Document用id匹配
                # 您可以根据您的fact_type添加更多精确的映射规则

                if s_label and o_label:
                    query = f"""
                    MATCH (s:{s_label} {{{s_prop}: $s_name}})
                    MATCH (o:{o_label} {{{o_prop}: $o_name}})
                    MERGE (s)-[:{rel}]->(o)
                    """
                    session.run(query, s_name=s_name, o_name=o_name)
                    print(f"Merged relationship: ({s_label} {{{s_prop}:'{s_name}'}})-[:{rel}]->({o_label} {{{o_prop}:'{o_name}'}})")
                else:
                    print(f"Could not determine labels for fact: {fact} (s_label: {s_label}, o_label: {o_label}). Relationship not created.")
            else:
                print(f"Skipping incomplete fact: {fact}")


if __name__ == "__main__":
    driver = None
    try:
        driver = GraphDatabase.driver(NEO4J_URI, auth=basic_auth(NEO4J_USER, NEO4J_PASSWORD))
        driver.verify_connectivity()
        print("Successfully connected to Neo4j.")
        
        clear_database(driver) # 清空数据库
        create_constraints(driver) # 创建约束

        with open(SAMPLE_KG_PATH, 'r', encoding='utf-8') as f:
            kg_data_to_load = json.load(f)
        
        load_data(driver, kg_data_to_load)
        
        print("\nData loading process completed.")
        print("You can now verify the data in Neo4j Browser (http://localhost:7474).")
        print("Example query to check SalesAmount:")
        print("MATCH (r:Region)-[:HAS_SALES_AMOUNT]->(sa:SalesAmount) RETURN r.name, sa.numeric_amount, sa.unit, sa.period")
        print("Example query to check Person-Project:")
        print("MATCH (p:Person)-[:WORKS_ON]->(proj:Project) RETURN p.name, proj.name")

    except Exception as e:
        print(f"An error occurred: {e}")
        traceback.print_exc()
    finally:
        if driver:
            driver.close()
            print("Neo4j connection closed.")
    --- END OF FILE CONTENT ---


Directory: zhz_rag/core_rag/
  File: __init__.py
    --- START OF FILE CONTENT ---
# zhz_agent/core_rag/__init__.py
from .kg_retriever import KGRetriever
from .fusion_engine import FusionEngine
# 如果上面 retrievers/__init__.py 也做了导出，这里也可以考虑是否进一步导出
    --- END OF FILE CONTENT ---

  File: fusion_engine.py
    --- START OF FILE CONTENT ---
# zhz_agent/fusion.py
import hashlib
import jieba
import torch
import asyncio
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from typing import List, Dict, Any, Optional
import logging 
import os

# 从项目内部导入pydantic_models
from zhz_rag.config.pydantic_models import RetrievedDocument

class FusionEngine:
    _current_script_path = os.path.abspath(__file__)
    _script_directory = os.path.dirname(_current_script_path)

    # 确保您的模型路径指向正确的位置，如果不在 local_models/bge-reranker-base
    LOCAL_RERANKER_MODEL_PATH = os.getenv(
        "RERANKER_MODEL_PATH", 
        "/home/zhz/models/bge-reranker-base" # <--- 直接指定新的、统一管理后的模型路径
    )

    def __init__(self, logger: Optional[logging.Logger] = None):
        if logger:
            self.logger = logger
        else:
            self.logger = logging.getLogger("FusionEngineLogger")
            if not self.logger.hasHandlers():
                self.logger.setLevel(logging.INFO)
                self.logger.info("FusionEngine initialized with its own basic logger (no handlers configured by default).")
            else:
                self.logger.info("FusionEngine initialized, re-using existing logger configuration for FusionEngineLogger.")

        self.reranker_tokenizer: Optional[AutoTokenizer] = None
        self.reranker_model: Optional[AutoModelForSequenceClassification] = None
        self.reranker_device = "cuda" if torch.cuda.is_available() else "cpu"
        self._load_reranker_model()

    def _load_reranker_model(self):
        self.logger.info(f"FusionEngine: Loading reranker model from: {self.LOCAL_RERANKER_MODEL_PATH} to {self.reranker_device}...")
        
        if not os.path.isdir(self.LOCAL_RERANKER_MODEL_PATH): # 检查是否是目录
            _error_msg_model_path = f"Error: Reranker model local path does not exist or is not a directory: {self.LOCAL_RERANKER_MODEL_PATH}."
            self.logger.error(_error_msg_model_path)
            # 在实际应用中，这里可能应该抛出异常，或者让服务无法启动
            # 为了测试，我们先允许模型为空，后续调用会检查
            self.reranker_model = None
            self.reranker_tokenizer = None
            return # 提前返回

        try:
            self.reranker_tokenizer = AutoTokenizer.from_pretrained(self.LOCAL_RERANKER_MODEL_PATH)
            self.reranker_model = AutoModelForSequenceClassification.from_pretrained(self.LOCAL_RERANKER_MODEL_PATH)
            self.reranker_model.to(self.reranker_device)

            if self.reranker_device == 'cuda' and hasattr(self.reranker_model, 'half'): # 检查是否有half方法
                self.reranker_model.half()
                self.logger.info("FusionEngine: Reranker model loaded to GPU and using FP16.")
            else:
                self.logger.info(f"FusionEngine: Reranker model loaded to {self.reranker_device}.")
            
            self.reranker_model.eval()
            self.logger.info("FusionEngine: Reranker model loading successful!")
        except Exception as e:
            self.logger.error(f"Error: Reranker model loading failed: {e}", exc_info=True)
            self.reranker_tokenizer = None
            self.reranker_model = None

    def _rerank_documents_sync(self, query: str, documents: List[RetrievedDocument]) -> List[RetrievedDocument]:
        if not self.reranker_model or not self.reranker_tokenizer:
            self.logger.warning("FusionEngine: Reranker model not loaded. Cannot perform fine-grained reranking. Returning documents as is (or after basic sort if any).")
            # 可以选择返回原始顺序，或者按原始分数（如果可比）排序
            return sorted(documents, key=lambda doc: doc.score if doc.score is not None else -float('inf'), reverse=True)


        if not documents:
            self.logger.info("FusionEngine: No documents to rerank.")
            return []

        # 确保文档内容是字符串
        pairs = []
        valid_documents_for_reranking = []
        for doc in documents:
            if isinstance(doc.content, str):
                pairs.append([query, doc.content])
                valid_documents_for_reranking.append(doc)
            else:
                self.logger.warning(f"FusionEngine: Document with non-string content skipped for reranking. ID: {doc.metadata.get('chunk_id', 'N/A')}, Type: {type(doc.content)}")
        
        if not pairs:
            self.logger.info("FusionEngine: No valid document pairs for reranking after content check.")
            return []

        self.logger.info(f"FusionEngine: Reranking {len(valid_documents_for_reranking)} documents with CrossEncoder...")
        
        try:
            with torch.no_grad():
                inputs = self.reranker_tokenizer(
                    pairs, 
                    padding=True, 
                    truncation=True, 
                    return_tensors='pt', 
                    max_length=512 # BGE Reranker通常是512
                ).to(self.reranker_device)
                
                logits = self.reranker_model(**inputs).logits
                # CrossEncoder通常直接输出一个分数，而不是需要sigmoid/softmax
                # BGE-Reranker输出的是logit，可以直接用作分数，或者通过sigmoid转为概率（但不必要）
                scores = logits.view(-1).float().cpu().numpy()

            for i, doc in enumerate(valid_documents_for_reranking):
                doc.score = float(scores[i]) # 更新文档的score为reranker的打分

            reranked_docs = sorted(valid_documents_for_reranking, key=lambda doc: doc.score, reverse=True)
            self.logger.info(f"FusionEngine: Reranking complete. {len(reranked_docs)} documents sorted.")
            return reranked_docs
        except Exception as e_rerank_detail:
            self.logger.error(f"FusionEngine: Detailed error during reranking with CrossEncoder: {e_rerank_detail}", exc_info=True)
            # 如果重排序失败，返回按原始分数（如果可比）排序的文档，或者简单返回valid_documents_for_reranking
            return sorted(valid_documents_for_reranking, key=lambda d: d.score if d.score is not None else -float('inf'), reverse=True)


    def _tokenize_text(self, text: str) -> set[str]:
        if not isinstance(text, str): # 添加类型检查
            self.logger.warning(f"FusionEngine: _tokenize_text received non-string input: {type(text)}. Returning empty set.")
            return set()
        return set(jieba.cut(text))

    def _calculate_jaccard_similarity(self, query_tokens: set[str], doc_tokens: set[str]) -> float:
        if not query_tokens or not doc_tokens: # 处理空集合的情况
            return 0.0
        intersection = len(query_tokens.intersection(doc_tokens))
        union = len(query_tokens.union(doc_tokens))
        return intersection / union if union > 0 else 0.0
        
    async def fuse_results(
        self,
        all_raw_retrievals: List[RetrievedDocument],
        user_query: str,
        top_n_final: int = 3
    ) -> List[RetrievedDocument]:

        self.logger.info(f"FusionEngine: Fusing {len(all_raw_retrievals)} raw retrieved documents for query: '{user_query}'. Target top_n_final: {top_n_final}")

        if not all_raw_retrievals:
            self.logger.info("FusionEngine: No documents to fuse.")
            return []

        # 1. 去重 (基于内容的哈希值)
        unique_docs_map: Dict[str, RetrievedDocument] = {}
        for doc in all_raw_retrievals:
            if not isinstance(doc.content, str) or not doc.content.strip():
                self.logger.debug(f"FusionEngine: Skipping doc with invalid content for hashing: {doc.metadata.get('chunk_id', 'N/A') if doc.metadata else 'N/A'}")
                continue
            content_hash = hashlib.md5(doc.content.encode('utf-8')).hexdigest()
            if content_hash not in unique_docs_map:
                unique_docs_map[content_hash] = doc
            else:
                # 如果内容重复，可以保留分数较高的一个（如果分数可比且来自不同召回源）
                # 这里简化处理，保留第一个遇到的，或者可以根据source_type和score进行更复杂的选择
                if doc.score is not None and unique_docs_map[content_hash].score is not None:
                    if doc.score > unique_docs_map[content_hash].score: # type: ignore
                        unique_docs_map[content_hash] = doc # 保留分数更高的
                elif doc.score is not None: # 当前文档有分数，已存的没有
                     unique_docs_map[content_hash] = doc
                self.logger.debug(f"FusionEngine: Duplicate content hash found. Doc with score {doc.score} vs existing {unique_docs_map[content_hash].score}. Content: {doc.content[:50]}...")
        
        unique_docs = list(unique_docs_map.values())
        self.logger.info(f"FusionEngine: After deduplication (content hash): {len(unique_docs)} documents.")

        if not unique_docs:
            return []

        # 2. 初步筛选 (基于长度和Jaccard相似度)
        # 定义阈值
        JACCARD_THRESHOLD = 0.05  # Jaccard相似度阈值，低于此则可能被过滤
        MIN_DOC_LENGTH_CHARS_KG = 10    # 知识图谱结果的最小字符长度
        MIN_DOC_LENGTH_CHARS_OTHER = 10 # 其他来源（向量、BM25）的最小字符长度
        # Reranker (如BGE-Reranker) 通常处理的token上限是512。
        # 一个中文字符大致对应1-3个token，英文单词大致对应1个token。
        # 为安全起见，可以设置一个字符上限，例如 1000-1500 字符，避免超长输入给Reranker。
        # 如果Reranker的tokenizer有max_length参数，它会自动截断，但预先过滤可以减少不必要的处理。
        MAX_DOC_LENGTH_CHARS = 1500 # 文档的最大字符长度，防止过长输入给reranker

        query_tokens_set = self._tokenize_text(user_query)
        screened_results: List[RetrievedDocument] = []
        
        self.logger.info(f"FusionEngine: Starting light screening for {len(unique_docs)} unique documents.")
        for doc_idx, doc in enumerate(unique_docs):
            doc_content_str = str(doc.content) # 确保是字符串
            doc_length = len(doc_content_str)
            
            # 长度筛选
            min_len_chars = MIN_DOC_LENGTH_CHARS_KG if doc.source_type == "knowledge_graph" else MIN_DOC_LENGTH_CHARS_OTHER
            if not (min_len_chars <= doc_length <= MAX_DOC_LENGTH_CHARS):
                self.logger.debug(f"  Screening: Doc {doc_idx} (ID: {doc.metadata.get('chunk_id', 'N/A') if doc.metadata else 'N/A'}) failed length check. Length: {doc_length}, Expected: [{min_len_chars}-{MAX_DOC_LENGTH_CHARS}], Type: {doc.source_type}. Content: '{doc_content_str[:50]}...'")
                continue

            # Jaccard相似度筛选 (可选，如果query_tokens_set为空则跳过)
            if query_tokens_set: # 只有当查询分词结果非空时才进行Jaccard计算
                doc_tokens_set = self._tokenize_text(doc_content_str)
                if not doc_tokens_set: # 如果文档分词结果为空，Jaccard为0
                    jaccard_sim = 0.0
                else:
                    jaccard_sim = self._calculate_jaccard_similarity(query_tokens_set, doc_tokens_set)
                
                if jaccard_sim < JACCARD_THRESHOLD:
                    self.logger.debug(f"  Screening: Doc {doc_idx} (ID: {doc.metadata.get('chunk_id', 'N/A') if doc.metadata else 'N/A'}) failed Jaccard check. Similarity: {jaccard_sim:.4f} < {JACCARD_THRESHOLD}. Content: '{doc_content_str[:50]}...'")
                    continue
            else:
                self.logger.debug(f"  Screening: Doc {doc_idx} (ID: {doc.metadata.get('chunk_id', 'N/A') if doc.metadata else 'N/A'}) - Query tokens empty, skipping Jaccard check.")


            screened_results.append(doc)
            self.logger.debug(f"  Screening: Doc {doc_idx} (ID: {doc.metadata.get('chunk_id', 'N/A') if doc.metadata else 'N/A'}) passed light screening.")
        
        self.logger.info(f"FusionEngine: After light screening: {len(screened_results)} documents remain.")
        
        if not screened_results:
            self.logger.info("FusionEngine: No documents remain after light screening. Returning empty list.")
            return []
        
        # 如果初筛后文档数量仍然很多，可以考虑再根据原始分数进行一次粗排和截断
        # 例如，如果 screened_results 数量 > top_n_final * 10，则取分数最高的前 top_n_final * 10 个
        # 这需要确保原始分数具有一定的可比性，或者对不同来源的分数进行大致的归一化
        # 当前我们先不加这一步，假设上游召回和初步筛选已将数量控制在合理范围
        docs_for_reranking = screened_results

        # 3. 使用Cross-Encoder进行精细重排序
        # _rerank_documents_sync 是同步函数，在异步函数中调用需要用 asyncio.to_thread
        final_fused_and_reranked_results = await asyncio.to_thread(
            self._rerank_documents_sync,
            query=user_query,
            documents=docs_for_reranking # 使用筛选后的文档
        )

        self.logger.info(f"FusionEngine: After reranking: {len(final_fused_and_reranked_results)} documents.")
        for i_doc, doc_reranked in enumerate(final_fused_and_reranked_results[:top_n_final+5]): # 日志多打几条看看分数
            self.logger.debug(f"  Reranked Doc {i_doc}: type={doc_reranked.source_type}, new_score={doc_reranked.score:.4f}, content='{str(doc_reranked.content)[:100]}...'")

        # 4. 根据 top_n_final 截取最终结果
        final_output_documents = final_fused_and_reranked_results[:top_n_final]

        self.logger.info(f"FusionEngine: Returning final top {len(final_output_documents)} documents.")
        return final_output_documents
    --- END OF FILE CONTENT ---

  File: kg_retriever.py
    --- START OF FILE CONTENT ---
# zhz_rag/core_rag/kg_retriever.py
import os
import json
import kuzu
import pandas as pd
from typing import List, Dict, Any, Optional, Callable, Iterator # 确保 Iterator 已导入
import logging
from contextlib import contextmanager

# 导入您的Cypher生成函数和Schema描述
from zhz_rag.llm.sglang_wrapper import generate_cypher_query # 确保路径正确
from zhz_rag.config.constants import NEW_KG_SCHEMA_DESCRIPTION # 确保路径正确

# 日志配置
kg_logger = logging.getLogger(__name__) 
# 确保 kg_logger 的级别和处理器已在 zhz_rag_mcp_service 或其他主入口配置，
# 或者在这里为它单独配置 handler 和 formatter，例如：
if not kg_logger.hasHandlers():
    kg_logger.setLevel(logging.DEBUG) # 开发时可以设为 DEBUG
    ch = logging.StreamHandler()
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s')
    ch.setFormatter(formatter)
    kg_logger.addHandler(ch)
    kg_logger.propagate = False # 避免重复日志（如果根logger也配置了handler）
kg_logger.info("KGRetriever (KuzuDB) logger initialized/reconfirmed.")


class KGRetriever:
    KUZU_DB_PATH_ENV = os.getenv("KUZU_DB_PATH", "/home/zhz/zhz_agent/zhz_rag/stored_data/kuzu_default_db")

    def __init__(self, db_path: Optional[str] = None, llm_cypher_generator_func: Callable = generate_cypher_query):
        self.db_path = db_path if db_path else self.KUZU_DB_PATH_ENV
        self.llm_cypher_generator_func = llm_cypher_generator_func
        self._db: Optional[kuzu.Database] = None
        kg_logger.info(f"KGRetriever (KuzuDB) __init__ called. Attempting to connect to DB path: {self.db_path}")
        self._connect_to_kuzu()
        # 这条日志现在移到 _connect_to_kuzu 成功之后打印

    def _connect_to_kuzu(self):
        kg_logger.info(f"Attempting to load KuzuDB from path: {self.db_path}")
        try:
            if not os.path.exists(self.db_path):
                kg_logger.error(f"KuzuDB path does not exist: {self.db_path}. KGRetriever cannot connect.")
                self._db = None
                return # 明确返回
            
            # 对于检索，通常只读即可，除非有特殊写需求
            # 如果 mcpo 服务可能并发访问，需要考虑 KuzuDB 的并发处理能力和锁机制
            self._db = kuzu.Database(self.db_path, read_only=True) 
            kg_logger.info(f"Successfully loaded KuzuDB from {self.db_path}. KGRetriever (KuzuDB) initialized and connected.")
        except Exception as e:
            kg_logger.error(f"Failed to connect to KuzuDB at {self.db_path}: {e}", exc_info=True)
            self._db = None

    @contextmanager
    def _get_connection(self) -> Iterator[kuzu.Connection]:
        if not self._db:
            kg_logger.warning("KuzuDB database object is None in _get_connection. Attempting to reconnect...")
            self._connect_to_kuzu() # 尝试重新连接
            if not self._db: # 再次检查
                kg_logger.error("KuzuDB reconnection failed. Cannot get a connection.")
                raise ConnectionError("KuzuDB is not connected or failed to reconnect. Cannot get a connection.")
        
        conn = None # 初始化 conn
        try:
            conn = kuzu.Connection(self._db)
            kg_logger.debug("KuzuDB connection obtained.")
            yield conn
        except Exception as e_conn: # 捕获 kuzu.Connection() 可能的异常
            kg_logger.error(f"Failed to create KuzuDB connection object: {e_conn}", exc_info=True)
            raise ConnectionError(f"Failed to create KuzuDB connection: {e_conn}")
        finally:
            # Kuzu Connection 对象没有显式的 close() 方法。
            # 它通常在其关联的 Database 对象被销毁时或垃圾回收时关闭。
            kg_logger.debug("KuzuDB connection context manager exiting.")
            pass 

    def close(self):
        kg_logger.info(f"Closing KuzuDB for retriever using path: {self.db_path}")
        if self._db:
            # KuzuDB Database 对象在其 __del__ 方法中处理关闭和资源释放。
            # 显式删除引用有助于触发垃圾回收，但不保证立即关闭。
            # KuzuDB 没有显式的 db.close() 方法。
            del self._db
            self._db = None
            kg_logger.info("KuzuDB Database object dereferenced (closed).")

    def execute_cypher_query_sync(self, query: str, parameters: Optional[Dict[str, Any]] = None) -> List[Dict[str, Any]]:
        if not self._db:
            kg_logger.error("KuzuDB not initialized in execute_cypher_query_sync. Cannot execute query.")
            return []
        
        kg_logger.info(f"--- Executing KuzuDB Cypher ---")
        kg_logger.info(f"Query: {query}")
        kg_logger.info(f"Params: {parameters if parameters else 'No parameters'}")
        
        results_list: List[Dict[str, Any]] = []
        try:
            with self._get_connection() as conn: # 使用上下文管理器获取连接
                prepared_statement = conn.prepare(query)
                # 注意：KuzuDB 的 execute 方法对参数的处理方式。
                # 如果 parameters 为 None 或空字典，应传递 None 或 {}。
                # 如果查询本身不包含参数占位符，传递参数字典可能会导致错误。
                # 我们需要确保Cypher查询中的参数占位符（如 $param）与parameters字典中的键匹配。
                
                actual_params = parameters if parameters else {} # 确保是字典
                query_result = conn.execute(prepared_statement, **actual_params) # 使用 ** 解包参数
                
                df = query_result.get_as_df()
                results_list = df.to_dict(orient='records')
                
                kg_logger.info(f"KuzuDB Cypher executed. Records count: {len(results_list)}")
                if results_list:
                    kg_logger.debug(f"First KuzuDB record (sample): {json.dumps(results_list[0], ensure_ascii=False, indent=2, default=str)}")
                else:
                    kg_logger.debug("KuzuDB query returned no records.")
        except RuntimeError as kuzu_runtime_error: # KuzuDB Python API 通常抛出 RuntimeError
             kg_logger.error(f"KuzuDB RuntimeError during Cypher execution: '{query}' with params: {parameters}. Error: {kuzu_runtime_error}", exc_info=True)
             # 可以考虑将 KuzuDB 的错误信息包装后向上抛出或返回
             # return [{"error": f"KuzuDB execution error: {kuzu_runtime_error}"}] 
        except ConnectionError as conn_err: # 如果 _get_connection 内部抛出
             kg_logger.error(f"KuzuDB ConnectionError during Cypher execution: {conn_err}", exc_info=True)
        except Exception as e:
            kg_logger.error(f"Unexpected error executing KuzuDB Cypher query: '{query}' with params: {parameters}. Error: {e}", exc_info=True)
        return results_list

    # ... ( _format_kuzu_record_for_retrieval 和 retrieve_with_llm_cypher 保持不变，
    # 但 retrieve_with_llm_cypher 内部对 execute_cypher_query_sync 的调用现在会经过新的错误处理) ...
    def _format_kuzu_record_for_retrieval(self, record_data: Dict[str, Any]) -> str:
        # ... (保持不变)
        parts = []
        for key, value in record_data.items():
            if isinstance(value, dict): 
                if 'label' in value and 'text' in value: 
                    parts.append(f"{key}({value['text']}:{value['label']})")
                elif '_label' in value and '_src' in value and '_dst' in value: 
                     parts.append(f"{key}(TYPE={value['_label']})")
                else:
                    value_str = json.dumps(value, ensure_ascii=False, default=str) 
                    if len(value_str) > 100: value_str = value_str[:100] + "..."
                    parts.append(f"{key}: {value_str}")
            elif value is not None:
                parts.append(f"{key}: {str(value)}")
        return " | ".join(parts) if parts else "No specific details found in this KuzuDB record."

    async def retrieve_with_llm_cypher(self, query: str, top_k: int = 3) -> List[Dict[str, Any]]:
        kg_logger.info(f"Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '{query}', top_k: {top_k}")
        
        kg_logger.info(f"Calling LLM to generate Cypher query for KuzuDB...")
        cypher_query = await self.llm_cypher_generator_func(
            user_question=query,
            kg_schema_description=NEW_KG_SCHEMA_DESCRIPTION 
        )
        kg_logger.info(f"LLM generated Cypher query for KuzuDB:\n---\n{cypher_query}\n---")

        if not cypher_query or cypher_query == "无法生成Cypher查询。":
            kg_logger.warning("LLM could not generate a valid Cypher query for KuzuDB.")
            return []

        if "LIMIT" not in cypher_query.upper():
            cypher_query_with_limit = f"{cypher_query} LIMIT {top_k}"
        else: 
            cypher_query_with_limit = cypher_query
            kg_logger.info(f"Query already contains LIMIT, using as is: {cypher_query_with_limit}")

        results_from_kuzu = self.execute_cypher_query_sync(cypher_query_with_limit)
        
        retrieved_docs_for_rag: List[Dict[str, Any]] = []
        for record_dict in results_from_kuzu:
            content_str = self._format_kuzu_record_for_retrieval(record_dict)
            doc_data = {
                "source_type": "knowledge_graph_kuzu",
                "content": content_str,
                "score": 1.0, 
                "metadata": {"cypher_query": cypher_query, "original_query": query, "raw_kuzu_record": record_dict}
            }
            retrieved_docs_for_rag.append(doc_data)

        kg_logger.info(f"Retrieved {len(retrieved_docs_for_rag)} documents from KuzuDB using LLM-generated Cypher.")
        return retrieved_docs_for_rag
    --- END OF FILE CONTENT ---

  File: kg_retriever_kuzu.log.txt
    --- START OF FILE CONTENT ---
2025-06-03 09:06:18,553 - INFO - kg_retriever.py:35 - zhz_rag.core_rag.kg_retriever - --- KG logging (KuzuDB) reconfigured to write to kg_retriever_kuzu.log ---
2025-06-03 09:06:21,417 - INFO - kg_retriever.py:61 - zhz_rag.core_rag.kg_retriever - Successfully loaded KuzuDB from /home/zhz/zhz_agent/zhz_rag/stored_data/kuzu_default_db
2025-06-03 09:06:21,417 - INFO - kg_retriever.py:52 - zhz_rag.core_rag.kg_retriever - KGRetriever (KuzuDB) initialized. DB path: /home/zhz/zhz_agent/zhz_rag/stored_data/kuzu_default_db, Connected: True
2025-06-03 09:06:47,704 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '张三在哪里工作？', top_k: 2
2025-06-03 09:06:47,704 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:06:47,758 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:06:47,758 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:06:47,775 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '张三当前的工作地点具体是哪个城市或地区？', top_k: 2
2025-06-03 09:06:47,775 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:06:47,826 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:06:47,826 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:06:47,841 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '张三过去的工作经历中，是否有过不同地区的任职情况？', top_k: 2
2025-06-03 09:06:47,841 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:06:47,891 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:06:47,891 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:06:47,906 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '张三所在的公司所属行业及业务范围是什么？', top_k: 2
2025-06-03 09:06:47,906 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:06:47,957 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:06:47,957 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:06:47,972 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '张三在哪里工作？', top_k: 2
2025-06-03 09:06:47,972 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:06:48,026 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:06:48,026 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:07:30,193 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '项目Alpha的文档编写任务分配给了谁？', top_k: 2
2025-06-03 09:07:30,193 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:07:30,244 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:07:30,244 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:07:30,262 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '项目Alpha的文档编写任务由谁具体负责？', top_k: 2
2025-06-03 09:07:30,262 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:07:30,313 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:07:30,313 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:07:30,326 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '文档编写任务的详细内容和范围有哪些？', top_k: 2
2025-06-03 09:07:30,326 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:07:30,377 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:07:30,377 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:07:30,395 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '任务分配是否考虑了团队成员的技能匹配度？', top_k: 2
2025-06-03 09:07:30,396 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:07:30,452 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:07:30,452 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:07:30,475 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '项目Alpha的文档编写任务分配给了谁？', top_k: 2
2025-06-03 09:07:30,475 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:07:30,527 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:07:30,527 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:08:09,710 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '李四负责哪些任务？', top_k: 2
2025-06-03 09:08:09,710 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:08:09,761 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:08:09,761 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:08:09,774 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '李四所属的部门或团队是哪个？', top_k: 2
2025-06-03 09:08:09,774 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:08:09,829 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:08:09,829 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:08:09,843 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '李四的主要工作职责是什么？', top_k: 2
2025-06-03 09:08:09,843 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:08:09,898 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:08:09,898 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:08:09,915 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '李四的职责是否包括跨部门协作？', top_k: 2
2025-06-03 09:08:09,915 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:08:09,965 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:08:09,965 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:08:09,993 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '李四负责哪些任务？', top_k: 2
2025-06-03 09:08:09,993 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:08:10,044 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:08:10,044 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:08:35,552 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '市场部有哪些员工？', top_k: 2
2025-06-03 09:08:35,552 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:08:35,606 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:08:35,606 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:08:35,626 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '市场部的员工主要由哪些职位或角色组成？', top_k: 2
2025-06-03 09:08:35,626 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:08:35,677 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:08:35,677 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:08:35,690 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '市场部员工总数是多少？', top_k: 2
2025-06-03 09:08:35,690 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:08:35,739 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:08:35,740 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:08:35,758 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '市场部的员工在哪些地区或部门分布？', top_k: 2
2025-06-03 09:08:35,758 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:08:35,809 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:08:35,809 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:08:35,823 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '市场部有哪些员工？', top_k: 2
2025-06-03 09:08:35,823 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:08:35,874 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:08:35,874 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:09:04,073 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '列出所有类型为TASK的实体。', top_k: 2
2025-06-03 09:09:04,073 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:09:04,130 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:09:04,130 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:09:04,147 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: 'TASK实体的定义和分类标准是什么？', top_k: 2
2025-06-03 09:09:04,147 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:09:04,199 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:09:04,199 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:09:04,217 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: 'TASK实体的结构或属性有哪些关键特征？', top_k: 2
2025-06-03 09:09:04,217 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:09:04,267 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:09:04,267 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:09:04,287 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: 'TASK实体在不同数据源或时间点的分布情况如何？', top_k: 2
2025-06-03 09:09:04,287 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:09:04,337 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:09:04,337 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:09:04,370 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '列出所有类型为TASK的实体。', top_k: 2
2025-06-03 09:09:04,370 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:09:04,421 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:09:04,421 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:09:43,028 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '查询所有在创新科技公司工作的员工。', top_k: 2
2025-06-03 09:09:43,028 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:09:43,080 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:09:43,080 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:09:43,126 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '创新科技公司当前的员工总数是多少？', top_k: 2
2025-06-03 09:09:43,126 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:09:43,177 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:09:43,178 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:09:43,191 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '公司员工的职位分布有哪些主要类别？', top_k: 2
2025-06-03 09:09:43,191 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:09:43,246 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:09:43,246 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:09:43,261 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '创新科技公司员工所属的行业领域有哪些？', top_k: 2
2025-06-03 09:09:43,261 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:09:43,313 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:09:43,313 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:09:43,328 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '查询所有在创新科技公司工作的员工。', top_k: 2
2025-06-03 09:09:43,328 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:09:43,380 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:09:43,380 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:10:21,156 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '查找所有人员的名称。', top_k: 2
2025-06-03 09:10:21,156 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:10:21,208 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:10:21,208 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:10:21,223 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '人员的分类标准是什么？（如部门、职位等）', top_k: 2
2025-06-03 09:10:21,223 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:10:21,280 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:10:21,280 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:10:21,305 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '所有人员的详细信息包括哪些字段？（如姓名、职位、部门等）', top_k: 2
2025-06-03 09:10:21,305 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:10:21,356 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:10:21,356 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:10:21,371 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '人员的状态有哪些类型？（如在职、离职、休假等）', top_k: 2
2025-06-03 09:10:21,371 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:10:21,421 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:10:21,421 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:10:21,438 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '查找所有人员的名称。', top_k: 2
2025-06-03 09:10:21,438 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:10:21,489 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:10:21,489 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:11:05,141 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '有多少个组织类型的实体？', top_k: 2
2025-06-03 09:11:05,141 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:11:05,193 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:11:05,193 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:11:05,206 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '有哪些常见的组织类型及其定义？', top_k: 2
2025-06-03 09:11:05,206 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:11:05,256 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:11:05,256 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:11:05,275 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '不同行业或规模的组织类型有何差异？', top_k: 2
2025-06-03 09:11:05,275 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:11:05,325 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:11:05,325 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:11:05,342 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '各数据库或系统中组织类型的统计数量是否一致？', top_k: 2
2025-06-03 09:11:05,342 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:11:05,396 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:11:05,396 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:11:05,420 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '有多少个组织类型的实体？', top_k: 2
2025-06-03 09:11:05,420 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:11:05,470 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:11:05,470 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:11:29,860 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '王五既在A公司工作，又负责了项目B吗？', top_k: 2
2025-06-03 09:11:29,860 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:11:29,912 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:11:29,912 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:11:29,926 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '王五当前是否在A公司担任正式职务？', top_k: 2
2025-06-03 09:11:29,926 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:11:29,976 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:11:29,976 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:11:29,991 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '项目B的负责人是否为王五？是否有相关职责说明？', top_k: 2
2025-06-03 09:11:29,991 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:11:30,040 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:11:30,040 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:11:30,054 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '王五在A公司的工作经历与项目B的关联性如何？', top_k: 2
2025-06-03 09:11:30,054 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:11:30,108 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:11:30,108 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:11:30,125 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '王五既在A公司工作，又负责了项目B吗？', top_k: 2
2025-06-03 09:11:30,125 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:11:30,175 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:11:30,175 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:12:12,541 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '列出所有被分配了任务的员工。', top_k: 2
2025-06-03 09:12:12,541 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:12:12,591 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:12:12,591 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:12:12,607 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '如何获取当前系统中所有被分配任务的员工列表？', top_k: 2
2025-06-03 09:12:12,607 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:12:12,660 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:12:12,660 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:12:12,674 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '哪些员工已明确分配了具体任务，哪些尚未分配？', top_k: 2
2025-06-03 09:12:12,675 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:12:12,725 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:12:12,725 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:12:12,742 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '被分配任务的员工其所在部门或职位有哪些差异？', top_k: 2
2025-06-03 09:12:12,742 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:12:12,792 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:12:12,792 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:12:12,806 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '列出所有被分配了任务的员工。', top_k: 2
2025-06-03 09:12:12,806 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:12:12,856 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:12:12,856 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:12:51,662 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '名为“市场调研报告”的任务分配给了哪个PERSON？', top_k: 2
2025-06-03 09:12:51,662 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:12:51,714 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:12:51,714 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:12:51,731 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '市场调研报告的完成者是谁？', top_k: 2
2025-06-03 09:12:51,731 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:12:51,781 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:12:51,781 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:12:51,800 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '该任务分配的依据是什么？', top_k: 2
2025-06-03 09:12:51,800 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:12:51,853 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:12:51,853 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:12:51,868 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '是否有其他人员参与了市场调研报告的编制？', top_k: 2
2025-06-03 09:12:51,868 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:12:51,918 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:12:51,918 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:12:51,936 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '名为“市场调研报告”的任务分配给了哪个PERSON？', top_k: 2
2025-06-03 09:12:51,936 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:12:51,986 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:12:51,986 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:13:31,436 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '名为“战略规划部”的ORGANIZATION有哪些PERSON在里面工作？', top_k: 2
2025-06-03 09:13:31,436 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:13:31,491 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:13:31,491 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:13:31,504 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '战略规划部的ORGANIZATION中有哪些主要的职位或角色？', top_k: 2
2025-06-03 09:13:31,504 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:13:31,555 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:13:31,555 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:13:31,568 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '部门内不同人员的职责分工有哪些具体差异？', top_k: 2
2025-06-03 09:13:31,568 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:13:31,623 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:13:31,623 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:13:31,638 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '战略规划部的员工是否包含高级管理人员或专业领域专家？', top_k: 2
2025-06-03 09:13:31,638 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:13:31,689 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:13:31,689 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:13:31,704 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '名为“战略规划部”的ORGANIZATION有哪些PERSON在里面工作？', top_k: 2
2025-06-03 09:13:31,704 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:13:31,756 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:13:31,756 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:14:09,591 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '告诉我关于张三和他的工作单位的信息。', top_k: 2
2025-06-03 09:14:09,591 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:14:09,645 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:14:09,645 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:14:09,665 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '张三目前在哪家公司担任什么职位？', top_k: 2
2025-06-03 09:14:09,665 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:14:09,715 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:14:09,715 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:14:09,736 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '张三所在的部门主要负责哪些业务领域？', top_k: 2
2025-06-03 09:14:09,736 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:14:09,787 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:14:09,787 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:14:09,800 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '张三的职业发展路径以及公司对他的评价如何？', top_k: 2
2025-06-03 09:14:09,800 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:14:09,852 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:14:09,852 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:14:09,866 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '告诉我关于张三和他的工作单位的信息。', top_k: 2
2025-06-03 09:14:09,866 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:14:09,918 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:14:09,919 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:14:55,991 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '谁在谷歌工作，并且也负责了项目Alpha的文档编写任务？', top_k: 2
2025-06-03 09:14:55,991 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:14:56,042 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:14:56,042 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:14:56,057 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '谷歌的哪些部门有员工负责项目Alpha的文档编写？', top_k: 2
2025-06-03 09:14:56,057 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:14:56,107 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:14:56,107 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:14:56,122 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '负责项目Alpha文档编写的主要职位是什么？', top_k: 2
2025-06-03 09:14:56,122 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:14:56,172 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:14:56,172 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:14:56,189 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '这些员工在谷歌的工作年限或之前的工作经历有哪些？', top_k: 2
2025-06-03 09:14:56,189 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:14:56,243 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:14:56,243 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:14:56,264 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '谁在谷歌工作，并且也负责了项目Alpha的文档编写任务？', top_k: 2
2025-06-03 09:14:56,264 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:14:56,316 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:14:56,316 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:15:30,458 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '张三的年龄是多少？', top_k: 2
2025-06-03 09:15:30,458 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:15:30,508 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:15:30,508 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:15:30,521 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '张三的年龄信息来自何处？', top_k: 2
2025-06-03 09:15:30,521 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:15:30,575 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:15:30,575 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:15:30,590 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '是否有最新更新的张三年龄数据？', top_k: 2
2025-06-03 09:15:30,590 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:15:30,641 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:15:30,641 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:15:30,656 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '张三的年龄是否有公开的变动记录？', top_k: 2
2025-06-03 09:15:30,656 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:15:30,707 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:15:30,707 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:15:30,719 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '张三的年龄是多少？', top_k: 2
2025-06-03 09:15:30,719 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:15:30,771 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:15:30,772 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:16:07,538 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '项目Alpha的预算有多少？', top_k: 2
2025-06-03 09:16:07,538 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:16:07,590 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:16:07,590 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:16:07,635 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '项目Alpha的总预算金额是多少？', top_k: 2
2025-06-03 09:16:07,635 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:16:07,685 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:16:07,685 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:16:07,741 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '项目Alpha的预算分配是否包含研发、市场和运营等不同部门？', top_k: 2
2025-06-03 09:16:07,741 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:16:07,794 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:16:07,794 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:16:07,800 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '项目Alpha的预算执行计划是否包含风险应对措施？', top_k: 2
2025-06-03 09:16:07,800 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:16:07,851 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:16:07,851 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:16:07,858 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '项目Alpha的预算有多少？', top_k: 2
2025-06-03 09:16:07,858 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:16:07,909 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:16:07,909 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:22:08,360 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '李四和王五是同事吗？', top_k: 2
2025-06-03 09:22:08,360 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:24:08,497 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:24:08,497 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:24:08,525 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '李四和王五是同事吗？', top_k: 2
2025-06-03 09:24:08,525 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:26:08,565 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:26:08,565 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:30:08,839 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '谷歌公司是什么时候成立的？', top_k: 2
2025-06-03 09:30:08,840 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:32:08,975 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:32:08,975 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:32:08,998 - INFO - kg_retriever.py:152 - zhz_rag.core_rag.kg_retriever - Starting KG retrieval (KuzuDB) with LLM-generated Cypher for query: '谷歌公司是什么时候成立的？', top_k: 2
2025-06-03 09:32:08,998 - INFO - kg_retriever.py:158 - zhz_rag.core_rag.kg_retriever - Calling LLM to generate Cypher query for KuzuDB...
2025-06-03 09:34:09,102 - INFO - kg_retriever.py:163 - zhz_rag.core_rag.kg_retriever - LLM generated Cypher query for KuzuDB:
---
无法生成Cypher查询。
---
2025-06-03 09:34:09,102 - WARNING - kg_retriever.py:166 - zhz_rag.core_rag.kg_retriever - LLM could not generate a valid Cypher query for KuzuDB.
2025-06-03 09:36:09,208 - INFO - kg_retriever.py:88 - zhz_rag.core_rag.kg_retriever - KuzuDB Database object dereferenced (intended to trigger close).

    --- END OF FILE CONTENT ---


Directory: zhz_rag/core_rag/retrievers/
  File: __init__.py
    --- START OF FILE CONTENT ---
# zhz_agent/core_rag/retrievers/__init__.py
from .chromadb_retriever import ChromaDBRetriever
from .file_bm25_retriever import FileBM25Retriever
    --- END OF FILE CONTENT ---

  File: chromadb_retriever.py
    --- START OF FILE CONTENT ---
from typing import List, Dict, Any, Optional
from sentence_transformers import SentenceTransformer
import chromadb
import logging


# 配置ChromaDBRetriever的日志记录器
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

class ChromaDBRetriever:
    def __init__(
        self,
        collection_name: str = "rag_documents",
        persist_directory: str = "/home/zhz/dagster_home/chroma_data",
        embedding_model_name_or_path: str = "/home/zhz/models/bge-small-zh-v1.5",
    ):
        """
        初始化ChromaDBRetriever。

        Args:
            collection_name (str): 要查询的ChromaDB集合名称。
            persist_directory (str): ChromaDB数据持久化的目录。
            embedding_model_name_or_path (str): 用于查询向量化的SentenceTransformer模型名称或路径。
            device (str): 模型运行的设备 (例如 "cpu", "cuda")。
        """
        self.collection_name = collection_name
        self.persist_directory = persist_directory
        self.embedding_model_name_or_path = embedding_model_name_or_path
        self._client: Optional[chromadb.Client] = None
        self._collection: Optional[chromadb.Collection] = None
        self._embedding_model: Optional[SentenceTransformer] = None

        self._initialize_retriever()

    def _initialize_retriever(self):
        """
        初始化ChromaDB客户端、集合和嵌入模型。
        """
        try:
            logger.info(f"Initializing ChromaDB client from path: {self.persist_directory}")
            self._client = chromadb.PersistentClient(path=self.persist_directory)
            logger.info(f"Getting ChromaDB collection: {self.collection_name}")
            self._collection = self._client.get_collection(name=self.collection_name)
            if self._collection.count() == 0:
                logger.warning(f"ChromaDB collection '{self.collection_name}' is empty!")
            else:
                logger.info(f"ChromaDB collection '{self.collection_name}' loaded. Item count: {self._collection.count()}")
        except Exception as e:
            logger.error(f"Failed to initialize ChromaDB client or collection: {e}")
            raise

        try:
            logger.info(f"Loading SentenceTransformer model: {self.embedding_model_name_or_path}")
            self._embedding_model = SentenceTransformer(self.embedding_model_name_or_path)
            logger.info("SentenceTransformer model loaded successfully.")
        except Exception as e:
            logger.error(f"Failed to load SentenceTransformer model: {e}")
            raise
            
    def retrieve(self, query_text: str, n_results: int = 5, include_fields: Optional[List[str]] = None) -> List[Dict[str, Any]]:
        """
        根据查询文本从ChromaDB检索相似的文档块。

        Args:
            query_text (str): 用户查询的文本。
            n_results (int): 希望返回的最大结果数量。
            include_fields (Optional[List[str]]): 希望从ChromaDB返回的字段列表，
                                               例如 ["metadatas", "documents", "distances"]。
                                               如果为None，则ChromaDB通常会返回默认字段。
                                               我们存储时，chunk_text在metadatas里。

        Returns:
            List[Dict[str, Any]]: 检索到的文档块列表。每个字典通常包含：
                                   'id' (chunk_id), 
                                   'text' (chunk_text from metadata), 
                                   'metadata' (原始元数据),
                                   'distance' (相似度距离，越小越相似)
                                   具体结构取决于ChromaDB的返回和我们的处理。
        """
        if self._collection is None or self._embedding_model is None:
            logger.error("Retriever is not properly initialized.")
            # 尝试重新初始化，或者直接返回错误/空列表
            try:
                self._initialize_retriever()
                if self._collection is None or self._embedding_model is None: # 再次检查
                    return []
            except Exception as e:
                logger.error(f"Failed to re-initialize retriever during retrieve call: {e}")
                return []

        logger.info(f"Retrieving documents for query: '{query_text[:100]}...' with n_results={n_results}")
        
        try:
            # 1. 将查询文本向量化并归一化
            query_embedding_np = self._embedding_model.encode(
                query_text, 
                convert_to_tensor=False, 
                normalize_embeddings=True # <--- 关键：归一化查询嵌入
            )
            query_embedding = query_embedding_np.tolist()
            
            # 2. 在ChromaDB中查询 (include_fields_query 的逻辑不变)
            if include_fields is None:
                include_fields_query = ["metadatas", "distances"] 
            else:
                include_fields_query = include_fields
            results = self._collection.query(
                query_embeddings=[query_embedding], 
                n_results=n_results,
                include=include_fields_query 
            )
            # 3. 处理并格式化结果
            retrieved_docs = []
            if results and results.get("ids") and results.get("ids")[0]:
                ids_list = results["ids"][0]
                metadatas_list = results.get("metadatas", [[]])[0] 
                distances_list = results.get("distances", [[]])[0] 

                for i in range(len(ids_list)):
                    # ... (提取 chunk_id, metadata, distance 的代码不变) ...
                    chunk_id = ids_list[i]
                    metadata = metadatas_list[i] if metadatas_list and i < len(metadatas_list) else {}
                    distance = distances_list[i] if distances_list and i < len(distances_list) else float('inf')
                    chunk_text_content = metadata.get("chunk_text", "[Chunk text not found in metadata]")

                    # 计算相似度分数
                    # 如果ChromaDB使用cosine距离 (范围0-2, 0表示最相似)
                    # 相似度 = 1 - (distance / 2)  => 范围 0-1, 1表示最相似
                    # 或者直接用 cosine_similarity = 1 - distance (如果distance是 1-cos_sim)
                    # ChromaDB的cosine距离是 sqrt(2-2*cos_sim) 的平方，即 2-2*cos_sim (如果向量已归一化)
                    # 所以 cos_sim = 1 - distance / 2
                    # 我们希望分数越大越好
                    score = (1 - distance / 2.0) if distance != float('inf') and distance <=2.0 else 0.0 
                    # 确保分数在合理范围，如果distance意外地大于2，则score为0

                    retrieved_docs.append({
                        "id": chunk_id,
                        "text": chunk_text_content,
                        "score": score, # <--- 更新了分数计算
                        "distance": distance, 
                        "metadata": metadata 
                    })
                
                logger.info(f"Retrieved {len(retrieved_docs)} documents from ChromaDB.")
            else:
                logger.info("No documents retrieved from ChromaDB for the query.")

            return retrieved_docs

        except Exception as e:
            logger.error(f"Error during ChromaDB retrieval: {e}")
            return []

if __name__ == '__main__':
    # 简单的测试代码
    logger.info("--- ChromaDBRetriever Test ---")
    
    # 确保您的ChromaDB数据库中已经有通过Dagster流水线存入的数据
    # 并且模型路径正确
    try:
        retriever = ChromaDBRetriever()
        
        # 测试查询
        test_query = "人工智能的应用有哪些？" 
        # 根据您doc1.txt "这是第一个测试文档，关于人工智能和机器学习。" 应该能召回一些
        
        retrieved_results = retriever.retrieve(test_query, n_results=3)
        
        if retrieved_results:
            print(f"\n--- Retrieved Results for query: '{test_query}' ---")
            for i, doc in enumerate(retrieved_results):
                print(f"Result {i+1}:")
                print(f"  ID: {doc['id']}")
                print(f"  Text (first 100 chars): {doc['text'][:100]}...")
                print(f"  Score: {doc['score']:.4f} (Distance: {doc['distance']:.4f})")
                print(f"  Metadata: {doc['metadata']}")
                print("-" * 20)
        else:
            print(f"\nNo results retrieved for query: '{test_query}'")
            
        # 测试一个可能没有结果的查询
        # test_query_no_results = "恐龙为什么会灭绝？"
        # retrieved_no_results = retriever.retrieve(test_query_no_results, n_results=3)
        # if not retrieved_no_results:
        #     print(f"\nCorrectly retrieved no results for query: '{test_query_no_results}'")

    except Exception as e:
        print(f"An error occurred during the test: {e}")

    --- END OF FILE CONTENT ---

  File: file_bm25_retriever.py
    --- START OF FILE CONTENT ---
from typing import List, Dict, Any, Optional, Tuple
import jieba
import bm25s # 我们确认使用 bm25s
import pickle
import os
import logging
import numpy as np

# 配置日志记录器
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

class FileBM25Retriever:
    def __init__(
        self,
        index_directory_path: str = "/home/zhz/dagster_home/bm25_index_data/", # 与Dagster中配置一致
        # user_dict_path: Optional[str] = None 
    ):
        self.index_directory_path = index_directory_path
        # self.user_dict_path = user_dict_path

        self._bm25_model: Optional[bm25s.BM25] = None
        self._doc_ids: Optional[List[str]] = None 
        # self._tokenizer: Optional[bm25s.Tokenizer] = None # bm25s.tokenize 是一个函数，或者可以用Tokenizer类

        self._initialize_retriever()

    def _initialize_retriever(self):
        # if self.user_dict_path and os.path.exists(self.user_dict_path):
        #     # ... (加载jieba用户词典的逻辑不变) ...
        
        if not os.path.isdir(self.index_directory_path): # <--- 修改：检查目录是否存在
            logger.error(f"BM25 index directory not found at: {self.index_directory_path}")
            raise FileNotFoundError(f"BM25 index directory not found: {self.index_directory_path}")

        try:
            logger.info(f"Loading BM25 model from directory: {self.index_directory_path}")
            # 使用bm25s的load类方法
            # load_corpus=False 因为我们不期望在模型文件中包含原始语料库文本
            # mmap=False (默认) 先不使用内存映射，除非索引非常大
            self._bm25_model = bm25s.BM25.load(
                self.index_directory_path,
                load_corpus=False, # 通常我们不需要在这里加载原始语料库
                # mmap=False 
            )
            
            if self._bm25_model is None: # load 失败通常会抛异常，但以防万一
                logger.error("Failed to load BM25 model (returned None).")
                raise ValueError("Failed to load BM25 model.")
            logger.info("BM25 model loaded successfully.")

            # 单独加载 document_ids 列表
            doc_ids_path = os.path.join(self.index_directory_path, "doc_ids.pkl")
            if not os.path.exists(doc_ids_path):
                logger.error(f"doc_ids.pkl not found in {self.index_directory_path}")
                raise FileNotFoundError(f"doc_ids.pkl not found in {self.index_directory_path}")
            
            with open(doc_ids_path, 'rb') as f_in:
                self._doc_ids = pickle.load(f_in)
            
            if self._doc_ids is None: # pickle 加载空文件可能返回None
                 logger.warning(f"doc_ids.pkl loaded, but it was empty or invalid.")
                 self._doc_ids = [] # 设为空列表以避免后续错误
            logger.info(f"Document IDs loaded successfully. Number of indexed documents: {len(self._doc_ids)}")

        except Exception as e:
            logger.error(f"Failed to load BM25 index or document IDs: {e}")
            raise
            
    def retrieve(self, query_text: str, n_results: int = 5) -> List[Dict[str, Any]]:
        # ... (初始化检查和空索引检查不变) ...
        if self._bm25_model is None or self._doc_ids is None:
            logger.error("BM25 Retriever is not properly initialized.")
            # ... (尝试重新初始化或返回空的逻辑不变) ...
            return []
        
        if not self._doc_ids: 
            logger.info("BM25 index is empty, no results to retrieve.")
            return []

        logger.info(f"Retrieving documents with BM25 for query: '{query_text[:100]}...' with n_results={n_results}")

        try:
            # 1. 将查询文本分词
            # bm25s 有自己的 tokenize 函数，它会处理停用词、词干提取（如果配置了）并返回模型期望的格式
            # 我们需要确保查询时的分词方式与索引时一致。
            # 如果索引时用了jieba，查询时也应该用jieba。
            # bm25s.BM25 对象在加载后，其内部应该已经有了词汇表 (vocab_dict)，
            # 它的 get_scores 方法期望的是与词汇表ID对应的输入，或者它能自己处理分词后的文本列表。
            
            query_tokenized_jieba = list(jieba.cut_for_search(query_text))
            logger.debug(f"Tokenized query (jieba): {query_tokenized_jieba}")

            # 2. 使用BM25模型进行查询
            # bm25s 的 retrieve 方法可以直接返回文档索引和分数
            # 它接受分词后的查询 (list of str)
            # results 是文档索引 (numpy array), scores 是对应的分数 (numpy array)
            # 它们都是 (n_queries, k) 的形状，我们只有一个查询，所以是 (1, k)
            
            # 确保 k 不超过实际文档数
            actual_k = min(n_results, len(self._doc_ids))
            if actual_k == 0: # 如果索引中没有文档
                return []

            results_indices, results_scores = self._bm25_model.get_top_n(
                query_tokenized_jieba, 
                corpus=None, # 我们不需要在这里提供原始语料库，它返回的是索引
                n=actual_k
            )
            # get_top_n 返回的是一个列表（每个查询一个结果列表），我们只有一个查询
            # 每个结果列表中的元素是 (doc_index, score) 吗？还是直接是doc_index?
            # 查阅 bm25s 文档：get_top_n(query_tokens, documents, n=5)
            #   - query_tokens: list of tokens for the query.
            #   - documents: list of documents (list of tokens).
            #   - n: number of top documents to retrieve.
            # Returns: list of top n documents.
            # 这看起来是返回文档本身，不是我们想要的。

            # 让我们回到使用 get_scores 然后自己排序的方式，这更可控
            all_scores = self._bm25_model.get_scores(query_tokenized_jieba)
            
            top_n_indices = np.argsort(all_scores)[-actual_k:][::-1] # 降序取前N

            retrieved_docs = []
            for doc_corpus_index in top_n_indices:
                doc_id = self._doc_ids[doc_corpus_index] # 从0-based索引映射到我们的chunk_id
                score = float(all_scores[doc_corpus_index]) 
                retrieved_docs.append({
                    "id": doc_id,
                    "score": score
                })
            
            logger.info(f"Retrieved {len(retrieved_docs)} documents using BM25.")
            return retrieved_docs

        except Exception as e:
            logger.error(f"Error during BM25 retrieval: {e}")
            return []
            
    def retrieve(self, query_text: str, n_results: int = 5) -> List[Dict[str, Any]]:
        """
        根据查询文本使用BM25检索相关的文档块ID和分数。

        Args:
            query_text (str): 用户查询的文本。
            n_results (int): 希望返回的最大结果数量。

        Returns:
            List[Dict[str, Any]]: 检索到的文档块列表。每个字典包含：
                                   'id' (chunk_id), 
                                   'score' (BM25分数)
        """
        if self._bm25_model is None or self._doc_ids is None:
            logger.error("BM25 Retriever is not properly initialized.")
            try:
                self._initialize_retriever()
                if self._bm25_model is None or self._doc_ids is None:
                    return []
            except Exception as e:
                logger.error(f"Failed to re-initialize BM25 retriever during retrieve call: {e}")
                return []
        
        if not self._doc_ids: # 如果索引为空
            logger.info("BM25 index is empty, no results to retrieve.")
            return []

        logger.info(f"Retrieving documents with BM25 for query: '{query_text[:100]}...' with n_results={n_results}")

        try:
            # 1. 将查询文本分词
            query_tokenized = list(jieba.cut_for_search(query_text))
            logger.debug(f"Tokenized query: {query_tokenized}")

            # 2. 使用BM25模型进行查询
            # bm25s 的 get_scores 方法返回所有文档的分数
            # bm25s 的 get_batch_results (或类似名称) 可能更适合获取top-N
            # 我们需要查阅 bm25s 的API来获取top-N的文档索引和分数
            # 假设它有一个类似 get_top_n 的方法，或者我们需要自己处理 get_scores 的结果

            # 查阅 bm25s 文档，它通常使用 `bm25_model.get_scores(query_tokenized)` 得到所有分数
            # 然后我们需要自己排序并取top N
            # 或者，bm25s.BM25 可能有更直接的方法，例如 `search` 或 `query`
            # 经过快速查阅，bm25s 似乎没有直接的 top_n 方法，但其设计是为了快速计算所有分数。
            # `bm25_model.get_scores(query_tokenized)` 返回一个numpy数组，包含每个文档的分数。

            all_scores = self._bm25_model.get_scores(query_tokenized)
            
            # 获取分数最高的n_results个文档的索引
            # 注意：如果实际文档数少于n_results，则取实际数量
            actual_n_results = min(n_results, len(self._doc_ids))
            
            # 使用numpy的argsort来获取排序后的索引，然后取最后N个（因为argsort默认升序）
            # 或者取负数再取前N个
            top_n_indices = np.argsort(all_scores)[-actual_n_results:][::-1] # 降序取前N

            retrieved_docs = []
            for index in top_n_indices:
                doc_id = self._doc_ids[index]
                score = float(all_scores[index]) # 转换为Python float
                # 我们只返回ID和分数，文本内容由上层逻辑获取
                retrieved_docs.append({
                    "id": doc_id,
                    "score": score
                })
            
            logger.info(f"Retrieved {len(retrieved_docs)} documents using BM25.")
            return retrieved_docs

        except Exception as e:
            logger.error(f"Error during BM25 retrieval: {e}")
            return []

if __name__ == '__main__':
    logger.info("--- FileBM25Retriever Test ---")
    
    # 确保您的BM25索引文件已通过Dagster流水线创建
    # (例如 /home/zhz/dagster_home/bm25_index/rag_bm25_index.pkl)
    try:
        retriever = FileBM25Retriever()
        
        # 测试查询 (与ChromaDBRetriever使用相同的查询，以便后续比较和融合)
        test_query = "人工智能的应用有哪些？" 
        
        retrieved_results = retriever.retrieve(test_query, n_results=3)
        
        if retrieved_results:
            print(f"\n--- BM25 Retrieved Results for query: '{test_query}' ---")
            for i, doc in enumerate(retrieved_results):
                print(f"Result {i+1}:")
                print(f"  ID: {doc['id']}")
                print(f"  Score: {doc['score']:.4f}")
                # 我们这里不获取文本，由rag_service负责
                print("-" * 20)
        else:
            print(f"\nNo results retrieved with BM25 for query: '{test_query}'")

    except Exception as e:
        print(f"An error occurred during the BM25 test: {e}")
    --- END OF FILE CONTENT ---


Directory: zhz_rag/llm/
  File: __init__.py
    --- START OF FILE CONTENT ---
# zhz_agent/llm/__init__.py
from .sglang_wrapper import (
    call_sglang_llm,
    generate_answer_from_context,
    generate_cypher_query,
    generate_expanded_queries,
    generate_intent_classification,
    generate_clarification_question,
    generate_clarification_options,
    NO_ANSWER_PHRASE_ANSWER_CLEAN,
    NO_ANSWER_PHRASE_KG_CLEAN
)
from .custom_crewai_llms import CustomGeminiLLM, CustomSGLangLLM
    --- END OF FILE CONTENT ---

  File: custom_crewai_llms.py
    --- START OF FILE CONTENT ---
#/home/zhz/zhz_agent/custom_llm.py
import os
import json
import httpx
import asyncio
import traceback
from typing import List, Dict, Any, Optional, Union, Sequence, Type 
# --- CrewAI & LiteLLM Imports ---
from crewai.tools import BaseTool
from crewai.llms.base_llm import BaseLLM as CrewAIBaseLLM
import litellm

# --- [修改] Local Imports -> 改为绝对导入 ---
from zhz_rag.llm.sglang_wrapper import call_sglang_llm # For SGLang LLM
from dotenv import load_dotenv

load_dotenv()

# --- SGLang Config ---
SGLANG_API_URL_FOR_LLM = os.getenv("SGLANG_API_URL", "http://localhost:30000/generate")

# --- CustomGeminiLLM (from ceshi/run_agent.py with fixes) ---
class CustomGeminiLLM(CrewAIBaseLLM):
    model_name: str
    api_key: str
    max_tokens: Optional[int] = 2048
    tool_config: Optional[Dict[str, Any]] = None
    stop: Optional[List[str]] = None
    _gemini_tools_cache: Optional[List[Dict[str, Any]]] = None

    def __init__(self, model: str, api_key: str, temperature: float = 0.1, max_tokens: Optional[int] = 2048, tool_config: Optional[Dict[str, Any]] = None, stop: Optional[List[str]] = None, agent_tools: Optional[List[BaseTool]] = None, **kwargs):
        super().__init__(model=model, temperature=temperature)
        self.model_name = model
        self.api_key = api_key
        self.max_tokens = max_tokens
        self.tool_config = tool_config or {"function_calling_config": {"mode": "AUTO"}}
        self.stop = stop
        if agent_tools:
            self._gemini_tools_cache = self._convert_crewai_tools_to_gemini_format(agent_tools)
            print(f"CustomGeminiLLM __init__: Cached {len(self._gemini_tools_cache)} tools.")
        else:
            print("CustomGeminiLLM __init__: No agent_tools provided for caching.")

    def _remove_unwanted_fields(self, schema: Dict[str, Any]) -> Dict[str, Any]:
        if not isinstance(schema, dict):
            return schema

        schema.pop('title', None)

        if "properties" in schema:
            if "type" not in schema:
                schema["type"] = "object"
            for prop_name, prop_def in list(schema["properties"].items()):
                if isinstance(prop_def, dict):
                    prop_def.pop('default', None)
                    prop_def.pop('title', None)
                    self._remove_unwanted_fields(prop_def)
        elif schema.get("type") == "object" and "properties" not in schema:
            schema["properties"] = {}

        keys_to_delete = [k for k, v in schema.items() if k == 'default']
        for k in keys_to_delete:
            del schema[k]

        for k, v in schema.items():
            if isinstance(v, dict):
                self._remove_unwanted_fields(v)
            elif isinstance(v, list):
                for i, item in enumerate(v):
                    if isinstance(item, dict):
                        v[i] = self._remove_unwanted_fields(item)
        return schema

    def _convert_crewai_tools_to_gemini_format(self, tools: Optional[List[BaseTool]]) -> Optional[List[Dict[str, Any]]]:
        if not tools:
            return None
        gemini_tool_declarations = []
        for tool_instance in tools:
            tool_name = tool_instance.name
            tool_description = tool_instance.description
            if not hasattr(tool_instance, 'args_schema') or not tool_instance.args_schema:
                parameters_schema = {"type": "object", "properties": {}}
            else:
                try:
                    if hasattr(tool_instance.args_schema, 'model_json_schema'):
                        pydantic_schema = tool_instance.args_schema.model_json_schema()
                    else:
                        pydantic_schema = tool_instance.args_schema.schema()
                    cleaned_schema = self._remove_unwanted_fields(pydantic_schema.copy())
                    parameters_schema = cleaned_schema
                except Exception as e:
                    print(f"Error processing schema for tool {tool_name}: {e}")
                    parameters_schema = {"type": "object", "properties": {}}
            gemini_tool_declarations.append({
                "name": tool_name,
                "description": tool_description,
                "parameters": parameters_schema
            })
        final_tools_for_litellm = []
        for declaration in gemini_tool_declarations:
            final_tools_for_litellm.append({
                "type": "function",
                "function": declaration
            })
        return final_tools_for_litellm

    def call(self, messages: Union[str, List[Dict[str, str]]], tools: Optional[List[dict]] = None, callbacks: Optional[List[Any]] = None, **kwargs: Any) -> Union[str, Any]:
        print(f"CustomGeminiLLM CALL method invoked.")
        print(f"  CALL - Tools received by CustomLLM.call: {'Yes' if tools else 'No'}")
        print(f"  CALL - Callbacks received by CustomLLM.call: {'Yes' if callbacks else 'No'}")

        if isinstance(messages, str):
            processed_messages = [{"role": "user", "content": messages}]
        else:
            processed_messages = messages

        litellm_params = {
            "model": self.model_name,
            "messages": processed_messages,
            "api_key": self.api_key,
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,
            "stop": self.stop
        }

        # --- Proxy Addition ---
        proxy_url = os.getenv("LITELLM_PROXY_URL")
        if proxy_url:
            litellm_params["proxy"] = {
                "http": proxy_url,
                "https": proxy_url,
            }
            print(f"CustomGeminiLLM.call - Using proxy: {proxy_url}")
        else:
            print("CustomGeminiLLM.call - No proxy configured (LITELLM_PROXY_URL not set).")

        # --- Tool Handling (tools: null fix) ---
        final_tools_for_litellm = None
        received_tools_to_process = tools
        if not received_tools_to_process and self._gemini_tools_cache:
            print("  CALL - INFO: Tools argument was None, using cached tools.")
            received_tools_to_process = self._gemini_tools_cache

        if received_tools_to_process:
            cleaned_tools_for_litellm = []
            for tool_dict in received_tools_to_process:
                current_tool_def = tool_dict.copy()
                if current_tool_def.get("type") == "function" and "function" in current_tool_def:
                    func_def = current_tool_def["function"].copy()
                    if "parameters" in func_def:
                        func_def["parameters"] = self._remove_unwanted_fields(func_def["parameters"].copy())
                    current_tool_def["function"] = func_def
                    cleaned_tools_for_litellm.append(current_tool_def)
                else:
                    cleaned_tools_for_litellm.append(tool_dict)
            final_tools_for_litellm = cleaned_tools_for_litellm

        if final_tools_for_litellm:
            litellm_params["tools"] = final_tools_for_litellm
            fc_config = self.tool_config.get("function_calling_config", {})
            mode = fc_config.get("mode", "AUTO").upper()
            allowed_names = fc_config.get("allowed_function_names")

            if mode == "ANY" and allowed_names:
                litellm_params["tool_choice"] = {
                    "type": "function",
                    "function": {"name": allowed_names[0]}
                }
            elif mode in ["AUTO", "ANY", "NONE"]:
                litellm_params["tool_choice"] = mode.lower()
            else:
                litellm_params["tool_choice"] = "auto"
            print(f"CustomGeminiLLM DEBUG: Setting tool_choice to: {litellm_params['tool_choice']}")

        if callbacks:
            litellm_params["callbacks"] = callbacks

        try:
            print(f"CustomGeminiLLM.call - LiteLLM PARAMS (Preview): model={litellm_params['model']}, msgs_count={len(litellm_params['messages'])}, tools={'Yes' if 'tools' in litellm_params else 'No'}, tool_choice={litellm_params.get('tool_choice')}, proxy={'Yes' if 'proxy' in litellm_params else 'No'}")
            response = litellm.completion(**litellm_params)
        except Exception as e:
            print(f"CRITICAL ERROR: LiteLLM completion call failed: {e}")
            if callbacks:
                for handler in callbacks:
                    if hasattr(handler, 'on_llm_error'):
                        try:
                            handler.on_llm_error(error=e, llm=self, **kwargs)
                        except Exception as cb_err:
                            print(f"Error in callback on_llm_error: {cb_err}")
            raise

        llm_message_response = response.choices[0].message
        if hasattr(llm_message_response, 'tool_calls') and llm_message_response.tool_calls:
            print(f"CustomGeminiLLM.call - Detected tool_calls: {llm_message_response.tool_calls}")
            # --- ReAct Format Workaround (AttributeError fix) ---
            tool_call = llm_message_response.tool_calls[0]
            action = tool_call.function.name
            action_input = tool_call.function.arguments
            react_string = f"Action: {action}\nAction Input: {action_input}"
            print(f"CustomGeminiLLM.call - Returning ReAct string: {react_string}")
            return react_string
        else:
            print(f"CustomGeminiLLM.call - Returning text content.")
            return llm_message_response.content or ""

    def get_token_counter_instance(self):
        class GeminiTokenCounter:
            def __init__(self, model_name):
                self.model_name = model_name

            def count_tokens(self, text: Union[str, List[Dict[str,str]]]) -> int:
                try:
                    if isinstance(text, list):
                        return litellm.token_counter(model=self.model_name, messages=text)
                    return litellm.token_counter(model=self.model_name, text=str(text))
                except Exception as e:
                    print(f"Warning: Token counting failed ({e}), falling back to rough estimate.")
                    if isinstance(text, list):
                        return sum(len(str(m.get("content","")).split()) for m in text)
                    return len(str(text).split())
        return GeminiTokenCounter(model_name=self.model_name)


# --- CustomSGLangLLM (from hybrid_rag/custom_llm.py) ---
class CustomSGLangLLM(CrewAIBaseLLM):
    endpoint_url: str = SGLANG_API_URL_FOR_LLM
    model_name: str = "qwen2-3b-instruct"
    temperature: float = 0.1
    max_new_tokens_val: int = 1024

    def __init__(self, endpoint: Optional[str] = None, model: Optional[str] = None, temperature: Optional[float] = None, max_new_tokens: Optional[int] = None, **kwargs: Any):
        super().__init__(**kwargs)
        if endpoint: self.endpoint_url = endpoint
        if model: self.model_name = model
        if temperature is not None: self.temperature = temperature
        if max_new_tokens is not None: self.max_new_tokens_val = max_new_tokens
        print(f"CustomSGLangLLM initialized. Endpoint: {self.endpoint_url}, Model: {self.model_name}, Temp: {self.temperature}, MaxTokens: {self.max_new_tokens_val}")

    def _prepare_sglang_prompt(self, messages: Sequence[Dict[str, str]]) -> str:
        prompt_str = ""
        for message in messages:
            role = message.get("role")
            content = message.get("content")
            if role and content:
                prompt_str += f"<|im_start|>{role}\n{content}<|im_end|>\n"
        prompt_str += "<|im_start|>assistant\n"
        return prompt_str

    def call(self, messages: Sequence[Dict[str, str]], **kwargs: Any) -> str:
        print(f"CustomSGLangLLM.call received messages: {messages}")
        sglang_prompt = self._prepare_sglang_prompt(messages)
        print(f"CustomSGLangLLM.call prepared sglang_prompt (first 200 chars): {sglang_prompt[:200]}...")
        stop_sequences_for_sglang = kwargs.get("stop", ["<|im_end|>", "<|endoftext|>"])

        try:
            try:
                loop = asyncio.get_running_loop()
            except RuntimeError:
                loop = None

            async def async_runner():
                return await call_sglang_llm(
                    prompt=sglang_prompt,
                    temperature=self.temperature,
                    max_new_tokens=self.max_new_tokens_val,
                    stop_sequences=stop_sequences_for_sglang
                )

            if loop and loop.is_running():
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
                    future = executor.submit(asyncio.run, async_runner())
                    response_text = future.result(timeout=120)
            else:
                response_text = asyncio.run(async_runner())

        except Exception as e:
            print(f"CustomSGLangLLM.call: Error during SGLang call: {type(e).__name__} - {e}")
            traceback.print_exc()
            return f"LLM_CALL_ERROR: 调用SGLang服务失败 - {str(e)}"

        if response_text is None:
            print("CustomSGLangLLM.call: SGLang returned None.")
            return "LLM_CALL_ERROR: SGLang服务未返回任何文本。"

        print(f"CustomSGLangLLM.call: SGLang returned text (first 200 chars): {response_text[:200]}...")
        return response_text

    def get_token_ids(self, text: str) -> List[int]:
        print("CustomSGLangLLM.get_token_ids: Not implemented, returning empty list.")
        return []

    @property
    def support_function_calling(self) -> bool:
        return False

    @property
    def support_stop_words(self) -> bool:
        return True

    @property
    def available_models(self) -> List[str]:
        return [self.model_name]

    @property
    def context_window(self) -> int:
        return 32768

    @property
    def identifying_params(self) -> Dict[str, Any]:
        return {
            "model": self.model_name,
            "endpoint_url": self.endpoint_url,
            "temperature": self.temperature,
            "max_new_tokens": self.max_new_tokens_val,
        }
    --- END OF FILE CONTENT ---

  File: sglang_wrapper.py
    --- START OF FILE CONTENT ---
# zhz_agent/llm.py (renamed to sglang_wrapper.py as per typical module naming)
# or more accurately, this is the content for sglang_wrapper.py based on the inputs

import os
import httpx  # 用于异步HTTP请求
import json  # 用于处理JSON数据
import asyncio  # 用于 asyncio.to_thread
from typing import List, Dict, Any, Optional, Union # Added Union
from dotenv import load_dotenv
import traceback  # Ensure traceback is imported
from zhz_rag.utils.common_utils import log_interaction_data # 导入通用日志函数
import logging
import re
import uuid  # 用于生成 interaction_id
from datetime import datetime, timezone  # 用于生成时间戳

load_dotenv()  # 确保加载.env文件

_LLM_DIR = os.path.dirname(os.path.abspath(__file__))
RAG_INTERACTION_LOGS_DIR = os.path.join(_LLM_DIR, '..', '..', 'stored_data', 'rag_interaction_logs')

if not os.path.exists(RAG_INTERACTION_LOGS_DIR):
    try:
        os.makedirs(RAG_INTERACTION_LOGS_DIR)
    except Exception:
        pass

def get_llm_log_filepath() -> str:
    """获取当前LLM交互日志文件的完整路径，按天分割。"""
    today_str = datetime.now(timezone.utc).strftime("%Y%m%d")
    return os.path.join(RAG_INTERACTION_LOGS_DIR, f"rag_interactions_{today_str}.jsonl")

async def log_llm_interaction_to_jsonl(interaction_data: Dict[str, Any]):
    """
    将单条LLM交互数据异步追加到JSONL文件中。
    (This function might be part of what log_interaction_data uses, or an alternative logger. Keeping for completeness from original llm.py)
    """
    filepath = get_llm_log_filepath()
    try:
        def _write_sync():
            with open(filepath, 'a', encoding='utf-8') as f:
                f.write(json.dumps(interaction_data, ensure_ascii=False) + "\n")
        await asyncio.to_thread(_write_sync)
        llm_py_logger.debug(f"Successfully logged LLM interaction to {filepath}")
    except Exception as e:
        llm_py_logger.error(f"Failed to log LLM interaction to {filepath}: {e}", exc_info=True)

llm_py_logger = logging.getLogger("LLMUtilsLogger")
llm_py_logger.setLevel(os.getenv("LLM_LOG_LEVEL", "INFO").upper())

if not llm_py_logger.hasHandlers():
    _llm_console_handler = logging.StreamHandler()
    _llm_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s - %(filename)s:%(lineno)d - %(message)s')
    _llm_console_handler.setFormatter(_llm_formatter)
    llm_py_logger.addHandler(_llm_console_handler)
    llm_py_logger.propagate = False

llm_py_logger.info("--- LLMUtilsLogger configured ---")

NO_ANSWER_PHRASE_ANSWER_CLEAN = "根据目前提供的资料，我无法找到关于您问题的明确信息。"
NO_ANSWER_PHRASE_KG_CLEAN = "从知识图谱中未找到直接相关信息。"
UNIQUE_STOP_TOKEN = "<|im_endofunable|>"
NO_ANSWER_PHRASE_ANSWER_WITH_STOP_TOKEN = f"{NO_ANSWER_PHRASE_ANSWER_CLEAN}{UNIQUE_STOP_TOKEN}"
NO_ANSWER_PHRASE_KG_WITH_STOP_TOKEN = f"{NO_ANSWER_PHRASE_KG_CLEAN}{UNIQUE_STOP_TOKEN}"

# Placeholder for the schema description. Replace with actual schema.
NEW_KG_SCHEMA_DESCRIPTION = """
{
  "node_labels": ["Person", "Project", "Task", "Document", "Region", "SalesAmount", "Product"],
  "relationship_types": ["WORKS_ON", "ASSIGNED_TO", "HAS_DOCUMENT", "HAS_SALES_AMOUNT", "RELATED_TO"],
  "node_properties": {
    "Person": [{"property": "name", "type": "STRING"}, {"property": "role", "type": "STRING"}],
    "Project": [{"property": "name", "type": "STRING"}, {"property": "status", "type": "STRING"}],
    "Task": [{"property": "name", "type": "STRING"}, {"property": "status", "type": "STRING"}, {"property": "priority", "type": "STRING"}],
    "Document": [{"property": "id", "type": "STRING"}, {"property": "title", "type": "STRING"}, {"property": "type", "type": "STRING"}],
    "Region": [{"property": "name", "type": "STRING"}],
    "SalesAmount": [{"property": "period", "type": "STRING"}, {"property": "numeric_amount", "type": "FLOAT"}, {"property": "unit", "type": "STRING"}],
    "Product": [{"property": "name", "type": "STRING"}, {"property": "category", "type": "STRING"}]
  },
  "relationship_properties": {},
  "output_format_guidance": {
    "description": "Your response MUST be a JSON object with two fields: 'status' and 'query'.",
    "status_field": {
      "description": "The 'status' field can be one of two values: 'success' or 'unable_to_generate'.",
      "success": "If you can generate a Cypher query, status should be 'success'.",
      "unable_to_generate": "If you cannot generate a Cypher query based on the question and schema, status should be 'unable_to_generate'."
    },
    "query_field": {
      "description": "The 'query' field contains the Cypher query as a string if status is 'success'.",
      "success_example": "MATCH (n) RETURN n LIMIT 1",
      "unable_to_generate_example": "无法生成Cypher查询."
    }
  },
  "examples": [
    {
      "User Question": "Who is task 'FixBug123' assigned to?",
      "Your EXACT Response": {
        "status": "success",
        "query": "MATCH (t:Task {name: 'FixBug123'})<-[:ASSIGNED_TO]-(p:Person) RETURN p.name AS assignedTo"
      }
    },
    {
      "User Question": "What is the color of the sky?",
      "Your EXACT Response": {
        "status": "unable_to_generate",
        "query": "无法生成Cypher查询."
      }
    }
  ]
}
"""

LLM_API_URL = os.getenv("SGLANG_API_URL", "http://localhost:8088/v1/chat/completions")

async def call_llm_via_openai_api(
    prompt: Union[str, List[Dict[str, str]]],
    temperature: float = 0.2,
    max_new_tokens: Optional[int] = 1024,
    stop_sequences: Optional[List[str]] = None,
    task_type: str = "unknown_llm_call",
    user_query_for_log: Optional[str] = None,
    model_name_for_log: str = "qwen3_gguf_via_openai_api", # Updated default model name
    application_version_for_log: str = "0.1.0"
) -> Optional[str]:

    llm_py_logger.info(f"Attempting to call LLM. Task: {task_type}, Target API: {LLM_API_URL}")

    current_messages: List[Dict[str, str]]
    original_prompt_for_log: str # For logging the original SGLang-style prompt if applicable

    if isinstance(prompt, str):
        original_prompt_for_log = prompt
        llm_py_logger.warning(f"call_llm_via_openai_api received a string prompt for task '{task_type}'. Attempting basic conversion to OpenAI messages. This is deprecated and may not be optimal.")
        current_messages = []
        if "<|im_start|>system" in original_prompt_for_log:
            parts = original_prompt_for_log.split("<|im_start|>")
            for part_content in parts:
                if not part_content.strip():
                    continue
                # Strip <|im_end|> and then content
                role_content_pair = part_content.split("<|im_end|>")[0].strip()
                if "\n" in role_content_pair: # Expects "role\ncontent"
                    role, message_content = role_content_pair.split("\n", 1)
                    current_messages.append({"role": role.strip().lower(), "content": message_content.strip()})
                else: # Fallback if no explicit role, assume user, or handle simple SGLang role prefix
                    # This part needs careful mapping from SGLang role prefixes if used without newline
                    # For now, a simple split for "system content" or "user content" without newline might be too naive.
                    # The provided split logic was `role, message_content = role_content_pair.split("\n", 1)`
                    # If it's just "system: message" or "system message" this is harder.
                    # The logic from the txt:
                    #   role_content_pair = part_content.split("<|im_end|>")[0].strip()
                    #   if "\n" in role_content_pair:
                    #       role, message_content = role_content_pair.split("\n", 1)
                    #       current_messages.append({"role": role.strip().lower(), "content": message_content.strip()})
                    #   else: # 可能是只有内容的user message
                    #       current_messages.append({"role": "user", "content": role_content_pair.strip()})
                    # This seems reasonable. Let's ensure role extraction.
                    # A more robust way for SGLang prompts:
                    # Check for "system\n", "user\n", "assistant\n" explicitly.
                    temp_role_content = role_content_pair.strip()
                    role_found = False
                    for r in ["system", "user", "assistant"]:
                        if temp_role_content.lower().startswith(r): # covers "system\ncontent" or "system content"
                            # check if role is followed by newline or space
                            if len(temp_role_content) > len(r) and (temp_role_content[len(r)] == '\n' or temp_role_content[len(r)] == ' ' or temp_role_content[len(r)] == ':'):
                                message_content = temp_role_content[len(r):].lstrip(' \n:')
                                current_messages.append({"role": r, "content": message_content.strip()})
                                role_found = True
                                break
                    if not role_found: # Default to user if no role prefix detected or if it's just content
                         current_messages.append({"role": "user", "content": temp_role_content})


            if not current_messages or (current_messages and current_messages[-1]["role"] == "assistant"):
                 current_messages.append({"role": "user", "content": "Continue."}) # Ensure last message is user if needed
        else: # If not SGLang format with <|im_start|>system, treat the whole string as a user message
            current_messages = [{"role": "user", "content": original_prompt_for_log}]
        llm_py_logger.debug(f"  Converted string prompt to messages: {json.dumps(current_messages, ensure_ascii=False, indent=2)}")
    elif isinstance(prompt, list):
        current_messages = prompt
        original_prompt_for_log = "Messages list provided directly."
        llm_py_logger.debug(f"  Received messages list directly: {json.dumps(current_messages, ensure_ascii=False, indent=2)}")
    else:
        llm_py_logger.error(f"Invalid 'prompt' argument type for call_llm_via_openai_api: {type(prompt)}")
        return None

    payload = {
        "model": model_name_for_log,
        "messages": current_messages,
        "temperature": temperature,
        "max_tokens": max_new_tokens,
    }
    if stop_sequences:
        payload["stop"] = stop_sequences

    headers = {"Content-Type": "application/json"}
    
    llm_parameters_for_log = {
        "model": model_name_for_log,
        "temperature": temperature,
        "max_tokens": max_new_tokens,
        "stop_sequences": stop_sequences
    }
    raw_llm_output_text = None

    try:
        llm_py_logger.info(f"Sending request to LLM API: {LLM_API_URL}")
        llm_py_logger.debug(f"Payload: {json.dumps(payload, ensure_ascii=False, indent=2)}")
        async with httpx.AsyncClient(timeout=120.0) as client:
            response = await client.post(LLM_API_URL, json=payload, headers=headers)
            response.raise_for_status()
            response_json = response.json()
            
            if response_json.get("choices") and \
               isinstance(response_json["choices"], list) and \
               len(response_json["choices"]) > 0 and \
               response_json["choices"][0].get("message"):
                raw_llm_output_text = response_json["choices"][0]["message"].get("content")
                if raw_llm_output_text is None: # content might be null
                    raw_llm_output_text = "" 
            else:
                raw_llm_output_text = "[[LLM_RESPONSE_MALFORMED_CHOICES_OR_MESSAGE]]"
            
            llm_py_logger.info(f"LLM Raw Output (from API): {str(raw_llm_output_text)[:500]}...")

            interaction_log_data = {
                "interaction_id": str(uuid.uuid4()),
                "timestamp_utc": datetime.now(timezone.utc).isoformat(),
                "task_type": task_type,
                "user_query_for_task": user_query_for_log,
                "llm_input_messages": current_messages,
                "llm_input_original_prompt_if_string": original_prompt_for_log if isinstance(prompt, str) else None,
                "llm_parameters": llm_parameters_for_log,
                "raw_llm_output": raw_llm_output_text,
                "application_version": application_version_for_log
            }
            await log_interaction_data(interaction_log_data)
            return raw_llm_output_text

    except httpx.HTTPStatusError as e:
        llm_py_logger.error(f"HTTPStatusError calling LLM API: {e}. Response: {e.response.text[:500]}", exc_info=True)
        error_info = f"HTTPStatusError: {e.response.status_code} - {e.response.text[:200]}"
    except httpx.RequestError as e:
        llm_py_logger.error(f"RequestError calling LLM API: {e}", exc_info=True)
        error_info = f"RequestError: {str(e)}"
    except json.JSONDecodeError as e:
        response_text_for_debug = "N/A"
        if 'response' in locals() and hasattr(response, 'text'):
            response_text_for_debug = response.text[:500]
        llm_py_logger.error(f"JSONDecodeError from LLM API: {e}. Raw response: {response_text_for_debug}", exc_info=True)
        error_info = f"JSONDecodeError: {str(e)}"
    except Exception as e:
        llm_py_logger.error(f"Unknown error in call_llm_via_openai_api: {type(e).__name__} - {e}", exc_info=True)
        error_info = f"Unknown error: {type(e).__name__} - {str(e)}"

    error_log_data = {
        "interaction_id": str(uuid.uuid4()),
        "timestamp_utc": datetime.now(timezone.utc).isoformat(),
        "task_type": task_type + "_error",
        "user_query_for_task": user_query_for_log,
        "llm_input_messages": current_messages if 'current_messages' in locals() else [{"role":"system", "content": "Error: messages not formed"}],
        "llm_input_original_prompt_if_string": original_prompt_for_log if 'original_prompt_for_log' in locals() and isinstance(prompt, str) else None,
        "llm_parameters": llm_parameters_for_log,
        "raw_llm_output": f"Error: {error_info}. Partial raw output: {str(raw_llm_output_text)[:200] if raw_llm_output_text else 'N/A'}",
        "error_details": traceback.format_exc(),
        "application_version": application_version_for_log
    }
    await log_interaction_data(error_log_data)
    return None

async def generate_cypher_query(user_question: str, kg_schema_description: str = NEW_KG_SCHEMA_DESCRIPTION) -> Optional[str]:
    llm_py_logger.info(f"Attempting to generate Cypher query for: '{user_question}' using JSON output mode via OpenAI API.")
    
    system_prompt_for_json_cypher = kg_schema_description 
    
    messages_for_llm = [
        {"role": "system", "content": system_prompt_for_json_cypher},
        {"role": "user", "content": f"用户问题: {user_question}"} 
    ]

    llm_json_response_str = await call_llm_via_openai_api( 
        prompt=messages_for_llm, # Pass messages list to 'prompt' parameter
        temperature=0.0, 
        max_new_tokens=1024, 
        stop_sequences=None, # For JSON mode, model should end JSON object
        task_type="cypher_generation_json_schema",
        user_query_for_log=user_question,
        model_name_for_log="qwen3_gguf_cypher_json" 
    )

    if not llm_json_response_str:
        llm_py_logger.warning(f"LLM call for Cypher JSON returned None or empty. User question: '{user_question}'")
        log_data_on_none = {
            "interaction_id": str(uuid.uuid4()),
            "timestamp_utc": datetime.now(timezone.utc).isoformat(),
            "task_type": "cypher_generation_json_schema_llm_returned_none",
            "user_query_for_task": user_question,
            "llm_input_messages": messages_for_llm,
            "raw_llm_output": None,
            "processed_llm_output": "无法生成Cypher查询."
        }
        await log_interaction_data(log_data_on_none)
        return "无法生成Cypher查询." 

    try:
        llm_py_logger.debug(f"Attempting to parse LLM JSON response for Cypher: {llm_json_response_str}")
        # Assuming local_llm_service.py or the model itself handles <think> tags for JSON mode.
        parsed_response = json.loads(llm_json_response_str)
        status = parsed_response.get("status")
        query_content = parsed_response.get("query")

        log_data_after_parse = {
            "interaction_id": str(uuid.uuid4()),
            "timestamp_utc": datetime.now(timezone.utc).isoformat(),
            "task_type": "cypher_json_parsing_attempt",
            "user_query_for_task": user_question,
            "raw_json_from_llm": llm_json_response_str,
            "parsed_status": status,
            "parsed_query_content": query_content
        }
        await log_interaction_data(log_data_after_parse)

        if status == "success" and isinstance(query_content, str) and query_content.strip():
            final_cypher = query_content.strip()
            # Clean markdown, though ideally JSON mode shouldn't produce it.
            if final_cypher.startswith("```cypher"):
                final_cypher = final_cypher[len("```cypher"):].strip()
            if final_cypher.startswith("```"):
                final_cypher = final_cypher[len("```"):].strip()
            if final_cypher.endswith("```"):
                final_cypher = final_cypher[:-len("```")].strip()
            
            llm_py_logger.info(f"Successfully extracted Cypher from JSON: {final_cypher}")
            return final_cypher
        elif status == "unable_to_generate" and query_content == "无法生成Cypher查询.":
            llm_py_logger.info(f"LLM indicated unable to generate Cypher via JSON for: '{user_question}'")
            return "无法生成Cypher查询."
        else:
            llm_py_logger.warning(f"LLM JSON response format unexpected or content missing. Status: {status}, Query: {query_content}. Raw JSON: {llm_json_response_str}")
            return "无法生成Cypher查询."
    except json.JSONDecodeError:
        llm_py_logger.error(f"Failed to parse JSON response from LLM for Cypher generation: {llm_json_response_str}", exc_info=True)
        if llm_json_response_str.strip() == "无法生成Cypher查询.":
             llm_py_logger.info("LLM output was the 'unable to generate' phrase directly, not JSON, but JSON Schema should have been applied.")
        return "无法生成Cypher查询." 
    except Exception as e:
        llm_py_logger.error(f"Error processing LLM JSON response for Cypher: {e}", exc_info=True)
        return "无法生成Cypher查询."

async def generate_answer_from_context(user_query: str, context_str: str) -> Optional[str]: # context 参数名改为 context_str
    llm_py_logger.info(f"Generating answer for query: '{user_query[:100]}...' using provided context.")
    
    system_prompt_for_answer = f"""
你是一个AI问答助手。你的任务是根据【上下文信息】回答【用户问题】。

**核心指令：**

1.  **尝试直接回答：** 请首先仔细阅读【上下文信息】，如果其中包含能直接回答【用户问题】的内容，请用上下文中的信息直接、简洁地回答。
2.  **忠实原文：** 你的回答必须严格基于【上下文信息】，禁止加入任何外部知识或个人观点。
3.  **如果无法回答：** 如果你分析了【上下文信息】后，确认其中确实没有能回答【用户问题】的明确信息，那么请只回答以下这句话：
 "{NO_ANSWER_PHRASE_ANSWER_CLEAN}"
 不要添加任何其他解释、建议或反问。

请直接给出答案，或者只给出上述那句固定的“无法找到信息”的回复。
"""
    # 构造 messages 列表
    messages_for_llm = [
        {"role": "system", "content": system_prompt_for_answer},
        {"role": "user", "content": f"用户问题: {user_query}\n\n上下文信息:\n{context_str}"}
    ]

    raw_answer = await call_llm_via_openai_api(
        prompt=messages_for_llm, # <--- 传递 messages 列表
        temperature=0.05,
        max_new_tokens=1024, 
        stop_sequences=['<|im_end|>', UNIQUE_STOP_TOKEN], # 可以保留，以防万一
        task_type="answer_generation_from_context",
        user_query_for_log=user_query,
        model_name_for_log="qwen3_gguf_answer_gen"
    )
    
    if raw_answer and raw_answer.strip() and \
       raw_answer.strip() != "[[LLM_RESPONSE_MALFORMED_CHOICES_OR_MESSAGE]]" and \
       raw_answer.strip() != "[[CONTENT_NOT_FOUND]]":
        
        # local_llm_service.py 中的 post_process_llm_output 应该已经处理了 <think>
        # 但如果模型仍然可能输出 "根据目前提供的资料..." 之外的内容，
        # 而我们期望严格匹配，这里可以再加一层检查。
        # 对于答案生成，通常不需要像Cypher那样严格的后处理。
        final_answer = raw_answer.strip()
        if final_answer == NO_ANSWER_PHRASE_ANSWER_CLEAN:
            llm_py_logger.info("LLM indicated unable to answer from context.")
        return final_answer
    else:
        llm_py_logger.warning(f"Answer generation returned None, empty, or placeholder. Query: {user_query}")
        return NO_ANSWER_PHRASE_ANSWER_CLEAN # Fallback

async def generate_simulated_kg_query_response(user_query: str, kg_schema_description: str, kg_data_summary_for_prompt: str) -> Optional[str]:
    prompt_str = f"""<|im_start|>system
你是一个知识图谱查询助手。你的任务是根据用户提出的问题、知识图谱Schema描述和图谱中的数据摘要，直接抽取出与问题最相关的1-2个事实片段作为答案。
只输出事实片段，不要解释，不要生成Cypher语句，不要包含任何额外对话或标记。
如果找不到直接相关的事实，请**直接且完整地**回答：“{NO_ANSWER_PHRASE_KG_WITH_STOP_TOKEN}”<|im_end|>
<|im_start|>user
知识图谱Schema描述:
{kg_schema_description}

知识图谱数据摘要: 
{kg_data_summary_for_prompt}

用户问题: {user_query}<|im_end|>
<|im_start|>assistant
"""
    stop_sequences = ["<|im_end|>", UNIQUE_STOP_TOKEN]
    return await call_llm_via_openai_api(
        prompt=prompt_str,
        temperature=0.5,
        max_new_tokens=256,
        stop_sequences=stop_sequences,
        task_type="simulated_kg_query_response",
        user_query_for_log=user_query
    )

async def generate_expanded_queries(original_query: str) -> List[str]:
    prompt_str = f"""<|im_start|>system
你是一个专家查询分析师。根据用户提供的查询，生成3个不同但相关的子问题，以探索原始查询的不同方面。这些子问题将用于检索更全面的信息。
你的回答必须是一个JSON数组（列表），其中每个元素是一个字符串（子问题）。
只输出JSON数组，不要包含任何其他解释、对话标记或代码块。

示例:
用户查询: "公司年度财务报告和未来一年的预算规划"
助手:
[
  "公司最近的年度财务报告总结是什么？",
  "未来一年的详细预算规划有哪些主要构成？",
  "对比往年，公司财务状况有何显著变化？"
]<|im_end|>
<|im_start|>user
原始查询: {original_query}<|im_end|>
<|im_start|>assistant
"""
    stop_sequences = ["<|im_end|>"]
    
    llm_py_logger.info(f"调用LLM API进行查询扩展 (Prompt长度: {len(prompt_str)} 字符)...")
    llm_output = await call_llm_via_openai_api(
        prompt=prompt_str,
        temperature=0.7,
        max_new_tokens=512,
        stop_sequences=stop_sequences,
        task_type="query_expansion",
        user_query_for_log=original_query
    )
    expanded_queries = []
    if llm_output:
        try:
            json_str = llm_output.strip()
            if json_str.startswith("```json"):
                json_str = json_str[len("```json"):].strip()
            if json_str.endswith("```"):
                json_str = json_str[:-len("```")].strip()
            
            parsed_queries = json.loads(json_str)
            if isinstance(parsed_queries, list) and all(isinstance(q, str) for q in parsed_queries):
                expanded_queries = parsed_queries
                llm_py_logger.info(f"LLM成功生成 {len(expanded_queries)} 个扩展查询。")
            else:
                llm_py_logger.warning(f"LLM生成的扩展查询JSON格式不符合预期 (不是字符串列表): {llm_output[:200]}...")
        except json.JSONDecodeError as e:
            llm_py_logger.error(f"解析LLM扩展查询JSON失败: {e}. 原始输出: {llm_output[:200]}...", exc_info=True)
        except Exception as e:
            llm_py_logger.error(f"处理LLM扩展查询时发生未知错误: {e}. 原始输出: {llm_output[:200]}...", exc_info=True)
    else:
        llm_py_logger.warning("LLM未能生成扩展查询。")

    # Always include the original query
    if original_query not in expanded_queries:
        expanded_queries.append(original_query)
    return expanded_queries


async def generate_clarification_question(original_query: str, uncertainty_reason: str) -> Optional[str]:
    prompt_str = f"""<|im_start|>system
你是一个智能助手，擅长在理解用户查询时识别歧义并请求澄清。
你的任务是根据用户原始查询和系统检测到的不确定性原因，生成一个简洁、明确的澄清问题。
澄清问题应该帮助用户选择正确的意图，或者提供更多必要的信息。
只输出澄清问题，不要包含任何额外解释、对话标记或代码块。<|im_end|>
<|im_start|>user
用户原始查询: {original_query}
不确定性原因: {uncertainty_reason}

请生成一个澄清问题:<|im_end|>
<|im_start|>assistant
"""
    stop_sequences = ["<|im_end|>"]
    llm_py_logger.info(f"调用LLM API生成澄清问题 (Prompt长度: {len(prompt_str)} 字符)...")
    clarification_question = await call_llm_via_openai_api(
        prompt=prompt_str,
        temperature=0.5,
        max_new_tokens=128,
        stop_sequences=stop_sequences,
        task_type="clarification_question_generation",
        user_query_for_log=original_query
    )
    if not clarification_question or clarification_question.strip() == "":
        llm_py_logger.warning("LLM未能生成澄清问题，返回默认提示。")
        return "抱歉，我不太理解您的意思，请您再具体说明一下。"
    llm_py_logger.info(f"LLM成功生成澄清问题: {clarification_question.strip()}")
    return clarification_question.strip()

async def generate_clarification_options(original_query: str, uncertainty_reason: str) -> List[str]:
    prompt_str = f"""<|im_start|>system
你是一个智能助手，擅长根据用户查询的模糊性提供具体的澄清选项。
你的任务是根据用户原始查询和系统检测到的不确定性原因，生成3-5个具体的、可供用户选择的澄清选项。
每个选项都应该是一个简洁的短语或问题，帮助用户明确其意图。
你的回答必须是一个JSON数组（列表），其中每个元素是一个字符串（澄清选项）。
只输出JSON数组，不要包含任何其他解释、对话标记或代码块。

示例:
用户查询: "帮我预定机票。"
不确定性原因: "缺少出发城市、目的地、日期等信息。"
助手:
[
  "请问您想从哪个城市出发？",
  "请问您的目的地是哪里？",
  "请问您希望在哪一天出行？",
  "您有偏好的航空公司或舱位等级吗？"
]<|im_end|>
<|im_start|>user
用户原始查询: {original_query}
不确定性原因: {uncertainty_reason}

请生成澄清选项:<|im_end|>
<|im_start|>assistant
"""
    stop_sequences = ["<|im_end|>"]
    llm_py_logger.info(f"调用LLM API生成澄清选项 (Prompt长度: {len(prompt_str)} 字符)...")
    llm_output = await call_llm_via_openai_api(
        prompt=prompt_str,
        temperature=0.7,
        max_new_tokens=256,
        stop_sequences=stop_sequences,
        task_type="clarification_options_generation",
        user_query_for_log=original_query
    )

    options = []
    if llm_output:
        try:
            json_str = llm_output.strip()
            if json_str.startswith("```json"):
                json_str = json_str[len("```json"):].strip()
            if json_str.endswith("```"):
                json_str = json_str[:-len("```")].strip()
            
            parsed_options = json.loads(json_str)
            if isinstance(parsed_options, list) and all(isinstance(o, str) for o in parsed_options):
                options = parsed_options
                llm_py_logger.info(f"LLM成功生成 {len(options)} 个澄清选项。")
            else:
                llm_py_logger.warning(f"LLM生成的澄清选项JSON格式不符合预期 (不是字符串列表): {llm_output[:200]}...")
        except json.JSONDecodeError as e:
            llm_py_logger.error(f"解析LLM澄清选项JSON失败: {e}. 原始输出: {llm_output[:200]}...", exc_info=True)
        except Exception as e:
            llm_py_logger.error(f"处理LLM澄清选项时发生未知错误: {e}. 原始输出: {llm_output[:200]}...", exc_info=True)
    else:
        llm_py_logger.warning("LLM未能生成澄清选项。")
    
    if not options:
        options.append("请提供更多详细信息。")
    
    return options


INTENT_CLASSIFICATION_JSON_SCHEMA = {
    "type": "object",
    "properties": {
        "clarification_needed": {"type": "boolean"},
        "reason": {"type": "string"}
    },
    "required": ["clarification_needed", "reason"]
}

async def generate_intent_classification(user_query: str) -> Dict[str, Any]:
    llm_py_logger.info(f"Generating intent classification for query: '{user_query[:100]}...'")
    prompt_str = f"""<|im_start|>system
你是一个智能意图分类器。你的任务是分析用户查询，判断该查询是否清晰明确，或者是否存在歧义、信息不足导致需要进一步澄清。
如果查询包含具体的命名实体（如人名“张三”、项目名“项目X”、产品名“新产品A”等），并且问题是关于这些实体的特定信息（例如“张三的职位是什么？”、“项目X的截止日期是哪天？”、“新产品A的功能有哪些？”），则通常认为查询是清晰的，不需要澄清。
只有当查询缺少定位关键信息所必需的核心实体，或者询问的范围过于宽泛无法直接操作时，才需要澄清。

如果查询需要澄清，请说明原因。
你的回答必须是一个JSON对象，包含两个字段：
1. "clarification_needed": 布尔值，如果需要澄清则为 true，否则为 false。
2. "reason": 字符串，如果需要澄清，请简要说明原因；如果不需要，则为空字符串。

示例1 (需要澄清 - 信息不足):
用户查询: "帮我预定明天去上海的机票。"
助手:
{{
  "clarification_needed": true,
  "reason": "缺少出发城市、具体时间（上午/下午/晚上）、舱位等级等信息。"
}}

示例2 (不需要澄清 - 清晰):
用户查询: "公司最新的销售额报告在哪里可以找到？"
助手:
{{
  "clarification_needed": false,
  "reason": ""
}}

示例3 (需要澄清 - 实体不明确):
用户查询: "关于项目进展的文档。"
助手:
{{
  "clarification_needed": true,
  "reason": "项目名称不明确，文档类型（报告、计划、会议纪要等）不明确。"
}}

示例4 (不需要澄清 - 包含具体实体和明确问题):
用户查询: "张三参与了哪个项目？"
助手:
{{
  "clarification_needed": false,
  "reason": ""
}}

示例5 (不需要澄清 - 包含具体实体和明确问题):
用户查询: "华东区域2024年第一季度的销售额是多少？"
助手:
{{
  "clarification_needed": false,
  "reason": ""
}}

示例6 (需要澄清 - “公司”指默认上下文，但其余部分仍模糊):
用户查询: "公司的政策"
助手:
{{
  "clarification_needed": true,
  "reason": "未能明确指出是关于哪方面的公司政策（例如：人力资源、IT安全、财务等）。"
}}<|im_end|>
<|im_start|>user
用户查询: {user_query}<|im_end|>
<|im_start|>assistant
"""
    stop_sequences = ["<|im_end|>"]
    llm_py_logger.info(f"调用LLM API进行意图分类 (Prompt长度: {len(prompt_str)} 字符)...")

    llm_output = await call_llm_via_openai_api(
        prompt=prompt_str,
        temperature=0.01,
        max_new_tokens=256,
        stop_sequences=stop_sequences,
        task_type="intent_classification",
        user_query_for_log=user_query
    )

    if llm_output:
        try:
            json_str = llm_output.strip()
            if json_str.startswith("```json"):
                json_str = json_str[len("```json"):].strip()
            if json_str.endswith("```"):
                json_str = json_str[:-len("```")].strip()

            parsed_result = json.loads(json_str)
            if isinstance(parsed_result, dict) and \
               "clarification_needed" in parsed_result and \
               "reason" in parsed_result:
                llm_py_logger.info(f"LLM成功进行意图分类: {parsed_result}")
                return parsed_result
            else:
                llm_py_logger.warning(f"LLM生成的意图分类JSON格式不符合预期: {llm_output[:200]}...")
        except json.JSONDecodeError as e:
            llm_py_logger.error(f"解析LLM意图分类JSON失败: {e}. 原始输出: {llm_output[:200]}...", exc_info=True)
        except Exception as e:
            llm_py_logger.error(f"处理LLM意图分类时发生未知错误: {e}. 原始输出: {llm_output[:200]}...", exc_info=True)

    llm_py_logger.warning("LLM未能生成有效的意图分类结果，默认不需澄清。")
    return {"clarification_needed": False, "reason": "LLM分类失败或无结果。"}
    --- END OF FILE CONTENT ---


Directory: zhz_rag/llm/rag_eval_data/

Directory: zhz_rag/task_management/
  File: __init__.py
    --- File is empty ---

  File: db_models.py
    --- START OF FILE CONTENT ---
# zhz_agent/database_models.py
from sqlalchemy import Column, String, DateTime, Integer, Text, Enum as SQLAlchemyEnum, ForeignKey, Boolean, JSON
from sqlalchemy.sql import func
import uuid

# --- [修改] 从 pydantic_models 导入枚举 -> 改为绝对导入 ---
from zhz_rag.config.pydantic_models import TaskStatus, ReminderMethod

# --- [修改] 从新的 database.py 导入 Base -> 改为绝对导入 ---
from zhz_rag.utils.db_utils import Base # <--- 确保只从这里导入 Base #

class TaskDB(Base): # 命名为 TaskDB 以区分 Pydantic 的 TaskModel
    __tablename__ = "tasks"

    id = Column(String, primary_key=True, index=True, default=lambda: str(uuid.uuid4()))
    title = Column(String, index=True, nullable=False)
    description = Column(Text, nullable=True) #
    status = Column(SQLAlchemyEnum(TaskStatus), default=TaskStatus.PENDING, nullable=False) #
    created_at = Column(DateTime(timezone=True), server_default=func.now(), nullable=False) #
    updated_at = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now(), nullable=False) #
    due_date = Column(DateTime(timezone=True), nullable=True) #
    reminder_time = Column(DateTime(timezone=True), nullable=True) #
    reminder_offset_minutes = Column(Integer, nullable=True) #
    reminder_methods = Column(JSON, default=[ReminderMethod.NOTIFICATION.value], nullable=False) #
    priority = Column(Integer, default=0, nullable=False) #
    tags = Column(JSON, default=[], nullable=False) #
    action_type = Column(String, nullable=True) #
    action_payload = Column(JSON, default={}, nullable=True) #
    execution_result = Column(Text, nullable=True) #
    last_executed_at = Column(DateTime(timezone=True), nullable=True) #

    def __repr__(self):
        return f"<TaskDB(id={self.id}, title='{self.title}', status='{self.status.value}')>"
    --- END OF FILE CONTENT ---

  File: jobs.py
    --- START OF FILE CONTENT ---
# zhz_agent/task_jobs.py
from datetime import datetime
from typing import Dict, Any
import os
import traceback
import httpx # <--- 确保 httpx 已导入
import json # <--- 确保 json 已导入

# 从 .database 导入 database 对象以便查询任务详情
# 从 .pydantic_models 导入 TaskModel 以便类型转换
# 从 .main 导入 scheduler 以便在需要时重新调度（虽然通常作业函数不直接操作调度器）
# 更好的做法是通过参数传递必要的信息，而不是依赖全局导入
WINDOWS_HOST_IP = os.getenv("WINDOWS_HOST_IP_FOR_WSL", "192.168.3.11") # <--- 请务必替换为您真实的Windows IP
LOCAL_AGENT_PORT = os.getenv("LOCAL_AGENT_PORT", "8003") # 与 local_agent_app.py 中的端口一致

# 如果 WINDOWS_HOST_IP 仍然是占位符，给出提示
if WINDOWS_HOST_IP == "在此处填写您上一步找到的Windows主机IP":
    print("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!")
    print("REMINDER_JOB WARNING: WINDOWS_HOST_IP 未正确设置在 task_jobs.py 中!")
    print("请编辑 task_jobs.py 文件，将 '在此处填写您上一步找到的Windows主机IP' 替换为实际IP地址。")
    print("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!")

LOCAL_AGENT_NOTIFY_URL = f"http://{WINDOWS_HOST_IP}:{LOCAL_AGENT_PORT}/notify"

async def send_task_reminder(task_id: str, task_title: str, reminder_methods: list):
    """
    实际发送任务提醒的函数。
    """
    print(f"REMINDER_JOB: [{datetime.utcnow()}] 正在为任务 '{task_id}' - '{task_title}' 发送提醒。")
    for method in reminder_methods:
        if method == "notification": # 假设 ReminderMethod.NOTIFICATION.value 是 "notification"
            print(f"  REMINDER_JOB: 尝试通过 Local Agent 发送桌面通知: '{task_title}'")
            try:
                async with httpx.AsyncClient(timeout=10.0) as client:
                    response = await client.post(
                        LOCAL_AGENT_NOTIFY_URL,
                        json={"title": f"任务提醒: {task_title}", "message": f"任务 '{task_title}' 即将到期或需要关注。"}
                    )
                    response.raise_for_status() # Raise an exception for bad status codes
                    print(f"  REMINDER_JOB: 本地代理通知请求发送成功. 状态: {response.status_code}")
            except httpx.RequestError as e:
                print(f"  REMINDER_JOB: 通过本地代理发送通知失败 (RequestError): {e}")
                traceback.print_exc()
            except Exception as e:
                print(f"  REMINDER_JOB: 通过本地代理发送通知失败 (General Error): {e}")
                traceback.print_exc()
        # elif method == "email": #
        #     print(f"  REMINDER_JOB: 模拟发送邮件提醒...")

async def execute_task_action(task_id: str, action_type: str, action_payload: Dict[str, Any]):
    """
    实际执行任务动作的函数。
    """
    print(f"EXECUTION_JOB: [{datetime.utcnow()}] 正在为任务 '{task_id}' 执行动作 '{action_type}'。")
    print(f"  EXECUTION_JOB: 动作参数: {action_payload}")

    final_result = f"动作 '{action_type}' 已模拟执行。"
    success = True

    if action_type == "navigate":
        destination = action_payload.get("destination")
        if destination:
            print(f"  EXECUTION_JOB: 模拟导航到 '{destination}'...")
            final_result = f"已模拟为导航到 '{destination}' 准备好路线。"
        else:
            final_result = "导航动作失败：缺少目的地。"
            success = False
    elif action_type == "log_event":
        event_details = action_payload.get("event_details", "无详情")
        print(f"  EXECUTION_JOB: 记录事件: '{event_details}'")
        final_result = f"事件 '{event_details}' 已记录。"
    else:
        final_result = f"未知的动作类型: {action_type}"
        success = False

    # 更新数据库中的任务状态和结果 (需要访问数据库)
    # 这部分逻辑最好通过API调用或服务层来完成，以避免循环导入和分散DB操作
    # 这里我们只打印信息，实际应用中需要实现DB更新
    print(f"  EXECUTION_JOB: 任务 '{task_id}' 执行完毕。结果: {final_result}, 状态: {'COMPLETED' if success else 'FAILED'}")

    --- END OF FILE CONTENT ---


Directory: zhz_rag/finetuning/
  File: __init__.py
    --- File is empty ---

  File: refine_answer_data.py
    --- START OF FILE CONTENT ---
# zhz_agent/refine_answer_finetune_data.py
import json
import os
import pandas as pd
from typing import List, Dict, Any, Optional
import glob
from datetime import datetime

# 假设 utils.py 和 constants.py 在同一个 zhz_agent 包内
try:
    from zhz_rag.utils.common_utils import (
    RAG_INTERACTION_LOGS_DIR,
    EVALUATION_RESULTS_LOGS_DIR,
    FINETUNING_GENERATED_DATA_DIR,
    find_latest_rag_interaction_log # 确保这个也被导入
)
    from zhz_rag.config.pydantic_models import RetrievedDocument
    # NO_ANSWER_PHRASE_ANSWER_CLEAN 将从 llm.py 导入，或者在constants.py中定义
    # 我们需要与 llm.py -> generate_answer_from_context 一致的 "无法回答" 短语
    from zhz_rag.llm.sglang_wrapper import NO_ANSWER_PHRASE_ANSWER_CLEAN 
except ImportError as e:
    print(f"ERROR: Could not import necessary modules for refine_answer_finetune_data: {e}")
    exit(1)

import logging

# 配置此脚本的logger
refine_answer_logger = logging.getLogger("RefineAnswerFinetuneDataLogger")
refine_answer_logger.setLevel(logging.INFO)
if not refine_answer_logger.hasHandlers():
    _console_handler = logging.StreamHandler()
    _formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s - %(filename)s:%(lineno)d - %(message)s')
    _console_handler.setFormatter(_formatter)
    refine_answer_logger.addHandler(_console_handler)
    refine_answer_logger.info("--- RefineAnswerFinetuneDataLogger configured ---")

# --- 配置 ---
RAG_LOG_DIR = "zhz_rag/stored_data/evaluation_results_logs/"
EVAL_LOG_DIR = "zhz_rag/stored_data/evaluation_results_logs/"
FINETUNE_DATA_DIR = "zhz_rag/finetuning/generated_data/"
os.makedirs(FINETUNE_DATA_DIR, exist_ok=True)

# --- 与 run_batch_answer_evaluation.py 中类似的上下文格式化函数 ---
def format_contexts_for_prompt(context_docs_raw: List[Dict[str, Any]]) -> str:
    """
    将从日志中解析出的上下文文档列表格式化为单一字符串，用于构建LLM的输入Prompt。
    这个格式应该与 llm.py -> generate_answer_from_context 中构建上下文的方式一致。
    """
    context_strings_for_llm = []
    if not context_docs_raw:
        return "No context provided."
        
    for i, doc_data in enumerate(context_docs_raw):
        try:
            # 尝试使用RetrievedDocument模型解析，如果原始日志中已经是这个结构
            # 但通常日志中可能是字典列表
            doc_content = doc_data.get("content", "[Content not available]")
            doc_source = doc_data.get("source_type", "unknown_source")
            doc_score = doc_data.get("score")
            
            # 与 rag_service.py 中准备上下文给LLM的格式保持一致
            # 在 rag_service.py 中是:
            # f"Source Type: {doc.source_type}, Score: {doc.score:.4f}\nContent: {doc.content}"
            # 我们这里也尽量模拟，但日志中的score可能不存在或格式不同
            header = f"Source Type: {doc_source}"
            if doc_score is not None:
                try:
                    header += f", Score: {float(doc_score):.4f}"
                except ValueError:
                    header += f", Score: {doc_score}" # 如果分数不是数字，直接用原始值
            
            context_strings_for_llm.append(f"{header}\nContent: {doc_content}")

        except Exception as e:
            refine_answer_logger.warning(f"Could not parse a context document fully for prompt: {doc_data}. Error: {e}")
            content = doc_data.get("content", "[Content not available]")
            context_strings_for_llm.append(f"Content: {content}") # 简化版

    return "\n\n---\n\n".join(context_strings_for_llm) if context_strings_for_llm else "No context provided."


def construct_qwen_answer_input_prompt(user_question: str, formatted_context: str) -> str:
    """
    根据用户问题和格式化的上下文构建Qwen生成答案时的完整输入Prompt。
    这个函数必须与 llm.py 中 generate_answer_from_context 内部构建Prompt的逻辑完全一致。
    """
    # --- 从 llm.py 的 generate_answer_from_context 函数复制并粘贴完整的 prompt 模板 ---
    # 注意：这里需要确保模板与 llm.py 中的完全一致
    prompt = f"""
<|im_start|>system
你是一个AI问答助手。你的任务是根据【上下文信息】回答【用户问题】。

**核心指令：**

1.  **尝试直接回答：** 请首先仔细阅读【上下文信息】，如果其中包含能直接回答【用户问题】的内容，请用上下文中的信息直接、简洁地回答。
2.  **忠实原文：** 你的回答必须严格基于【上下文信息】，禁止加入任何外部知识或个人观点。
3.  **如果无法回答：** 如果你分析了【上下文信息】后，确认其中确实没有能回答【用户问题】的明确信息，那么请只回答以下这句话：
    "根据目前提供的资料，我无法找到关于您问题的明确信息。"
    **不要添加任何其他解释、建议或反问。**

**请直接给出答案，或者只给出上述那句固定的“无法找到信息”的回复。**
<|im_start|>user
用户问题: {user_question}

上下文信息:
{formatted_context}
<|im_end|>
<|im_start|>assistant
"""
    return prompt

def load_logs_to_dict(filepath: str, key_field: str = "interaction_id") -> Dict[str, Dict[str, Any]]:
    """将JSONL文件加载到一个以指定字段为键的字典中。"""
    data_dict = {}
    if not os.path.exists(filepath):
        refine_answer_logger.error(f"Log file not found: {filepath}")
        return data_dict
    with open(filepath, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                log_entry = json.loads(line.strip())
                if key_field in log_entry and log_entry[key_field]: # 确保key_field的值不是None或空
                    data_dict[log_entry[key_field]] = log_entry
                elif key_field == "original_interaction_id_ref" and log_entry.get("original_interaction_id_ref"):
                    data_dict[log_entry["original_interaction_id_ref"]] = log_entry
            except json.JSONDecodeError:
                refine_answer_logger.warning(f"Skipping malformed JSON line in {filepath}")
    return data_dict

def generate_finetune_samples_for_answer(
    rag_interaction_logs: Dict[str, Dict[str, Any]],
    answer_evaluation_logs: Dict[str, Dict[str, Any]]
) -> List[Dict[str, str]]:
    finetune_samples = []
    processed_ids = set()

    refine_answer_logger.info(f"Processing {len(rag_interaction_logs)} RAG interaction logs and {len(answer_evaluation_logs)} Answer evaluation logs.")

    for interaction_id, rag_log in rag_interaction_logs.items():
        if rag_log.get("task_type") != "rag_query_processing_success":
            continue

        if interaction_id in processed_ids:
            continue
        processed_ids.add(interaction_id)

        user_question = rag_log.get("user_query")
        qwen_generated_answer_raw = rag_log.get("processed_llm_output") # Qwen的原始答案
        # retrieved_context_docs 在 rag_log 中可能是 "retrieved_context_docs" 或 "retrieved_documents_summary"
        # 我们需要原始的、完整的上下文文档
        retrieved_context_docs_raw = rag_log.get("retrieved_context_docs") 
        
        if not retrieved_context_docs_raw and rag_log.get("debug_info"): # 尝试从debug_info获取
             retrieved_context_docs_raw = rag_log.get("debug_info",{}).get("retrieved_context_docs")


        if qwen_generated_answer_raw is None or not qwen_generated_answer_raw.strip():
            qwen_generated_answer = NO_ANSWER_PHRASE_ANSWER_CLEAN # 空答案视为无法回答
        else:
            qwen_generated_answer = qwen_generated_answer_raw.strip()

        if not user_question or not retrieved_context_docs_raw:
            refine_answer_logger.warning(f"Skipping RAG log {interaction_id} due to missing user_question or retrieved_context_docs.")
            continue
        
        # 构建Prompt
        formatted_contexts_for_prompt = format_contexts_for_prompt(retrieved_context_docs_raw)
        qwen_answer_input_prompt = construct_qwen_answer_input_prompt(user_question, formatted_contexts_for_prompt)

        ideal_answer_output = None
        source_of_ideal = "unknown"
        gemini_scores_for_log = {}

        eval_log = answer_evaluation_logs.get(interaction_id)

        if eval_log and eval_log.get("eval_llm_processed_output_json"):
            eval_json = eval_log["eval_llm_processed_output_json"]
            summary_eval = eval_json.get("evaluation_summary", {})
            dimensions_eval = eval_json.get("dimensions", {})
            
            overall_score_str = summary_eval.get("overall_answer_quality_score")
            faithfulness_score_str = dimensions_eval.get("faithfulness", {}).get("score")
            relevance_score_str = dimensions_eval.get("relevance", {}).get("score")
            completeness_score_str = dimensions_eval.get("completeness", {}).get("score")
            context_sufficiency = dimensions_eval.get("completeness", {}).get("context_sufficiency_assessment", "Unknown")
            gemini_suggestion_answer = eval_json.get("suggestion_for_answer_improvement", "").strip()

            try:
                overall_score = int(overall_score_str) if overall_score_str is not None else 0
                faithfulness_score = int(faithfulness_score_str) if faithfulness_score_str is not None else 0
                relevance_score = int(relevance_score_str) if relevance_score_str is not None else 0
                completeness_score = int(completeness_score_str) if completeness_score_str is not None else 0
                gemini_scores_for_log = {
                    "overall": overall_score,
                    "faithfulness": faithfulness_score,
                    "relevance": relevance_score,
                    "completeness": completeness_score,
                    "context_sufficiency": context_sufficiency
                }
            except (ValueError, TypeError) as e:
                refine_answer_logger.warning(f"Could not parse one or more scores for {interaction_id}: {e}")
                overall_score = faithfulness_score = relevance_score = completeness_score = 0
                gemini_scores_for_log = { # 记录解析失败
                    "overall": "parse_error", "faithfulness": "parse_error", 
                    "relevance": "parse_error", "completeness": "parse_error",
                    "context_sufficiency": context_sufficiency
                }
                
            # --- Completion选择逻辑 (改进版) ---
            ideal_answer_output = None # 重新初始化
            source_of_ideal = "unknown" # 重新初始化

            # 规则 0: Qwen的原始答案就是标准的“无法回答”短语
            is_qwen_standard_no_answer = (qwen_generated_answer == NO_ANSWER_PHRASE_ANSWER_CLEAN)

            # 规则 1: 上下文不足，且Qwen正确地给出了标准的“无法回答”
            if is_qwen_standard_no_answer and \
               context_sufficiency == "Insufficient" and \
               overall_score >= 4: # Gemini认为Qwen的这个“无法回答”是高质量的
                ideal_answer_output = NO_ANSWER_PHRASE_ANSWER_CLEAN
                source_of_ideal = "qwen_standard_no_answer_confirmed_by_gemini_context_insufficient"
            
            # 规则 2: 上下文不足，Qwen可能没有给出标准“无法回答”，但Gemini建议应指出信息不足
            elif not is_qwen_standard_no_answer and \
                 context_sufficiency == "Insufficient" and \
                 completeness_score <=2 and \
                 ("information is not available" in gemini_suggestion_answer.lower() or \
                  "context does not contain" in gemini_suggestion_answer.lower() or \
                  "cannot be answered from the context" in gemini_suggestion_answer.lower() or \
                  "should state that the information is not found" in gemini_suggestion_answer.lower()):
                ideal_answer_output = NO_ANSWER_PHRASE_ANSWER_CLEAN
                source_of_ideal = "gemini_suggests_no_answer_due_to_insufficient_context"

            # 规则 3: Gemini 整体评分很高 (例如 overall, faithfulness, relevance 都 >= 4)
            # 并且 Qwen 的答案不是标准的“无法回答”（如果已经是，则由规则1处理）
            elif not is_qwen_standard_no_answer and \
                 overall_score >= 4 and faithfulness_score >= 4 and relevance_score >= 4:
                ideal_answer_output = qwen_generated_answer
                source_of_ideal = "qwen_high_score_by_gemini"
                # 如果此时 Gemini 仍有改进建议，可以额外标记
                if gemini_suggestion_answer and \
                   gemini_suggestion_answer != "No improvement needed." and \
                   "suggestion" not in source_of_ideal: # 避免重复标记
                    source_of_ideal += "_with_minor_gemini_suggestion"


            # 规则 4: Qwen的答案评分不高，但Gemini给出了具体的改进建议
            # 我们将这类样本标记出来，completion暂时使用Qwen的答案，供人工审核和优化
            elif overall_score < 4 and \
                 gemini_suggestion_answer and \
                 gemini_suggestion_answer != "No improvement needed." and \
                 len(gemini_suggestion_answer) > 10: # 假设太短的建议可能不具体
                ideal_answer_output = qwen_generated_answer # 保留Qwen答案作为基础
                source_of_ideal = "qwen_low_score_with_gemini_suggestion_for_review"
                refine_answer_logger.info(f"Answer log {interaction_id} (Qwen: '{qwen_generated_answer[:100]}...') marked for review due to low score but has Gemini suggestion: '{gemini_suggestion_answer[:100]}...'")
            
            # 规则 5: 如果Qwen的答案是标准“无法回答”，但上下文其实是充分的，或者Gemini认为可以回答
            # 这通常意味着Qwen可能错误地判断无法回答，或者Gemini的评估与Qwen的判断不一致
            elif is_qwen_standard_no_answer and \
                 (context_sufficiency == "Sufficient" or (context_sufficiency == "Partially Sufficient" and completeness_score >=3)) and \
                 overall_score < 4 : # Gemini不认可这个“无法回答”
                ideal_answer_output = qwen_generated_answer # 保留Qwen的“无法回答”
                source_of_ideal = "qwen_no_answer_but_gemini_disagrees_or_context_sufficient_for_review"
                refine_answer_logger.info(f"Answer log {interaction_id}: Qwen said 'no answer', but Gemini scores/context sufficiency suggest it might be answerable. Marked for review. Gemini scores: {gemini_scores_for_log}, Suggestion: '{gemini_suggestion_answer[:100]}...'")

            # 规则 6: 其他所有情况，暂时跳过，等待更明确的规则或人工审核
            else:
                refine_answer_logger.info(f"Answer log {interaction_id} (Qwen: '{qwen_generated_answer[:100]}...') did not meet current finetune criteria. Needs manual review or rule adjustment. Gemini scores: {gemini_scores_for_log}, Suggestion: '{gemini_suggestion_answer[:100]}...'")
                continue

        else: # 没有有效的Gemini评估日志
            refine_answer_logger.warning(f"No valid Gemini evaluation found for Answer log {interaction_id}. Qwen's output: '{qwen_generated_answer[:100]}...'. Skipping for finetune data.")
            continue
            
        if ideal_answer_output is not None:
            finetune_samples.append({
                "prompt": qwen_answer_input_prompt,
                "completion": ideal_answer_output.strip(),
                "original_qwen_answer": qwen_generated_answer_raw.strip() if qwen_generated_answer_raw else NO_ANSWER_PHRASE_ANSWER_CLEAN, # 记录Qwen最原始的输出
                "gemini_scores": gemini_scores_for_log,
                "gemini_suggestion": gemini_suggestion_answer if eval_log and eval_log.get("eval_llm_processed_output_json") else None,
                "source_of_ideal": source_of_ideal,
                "interaction_id": interaction_id
            })

    refine_answer_logger.info(f"Generated {len(finetune_samples)} Answer finetuning samples.")
    return finetune_samples


if __name__ == "__main__":
    rag_log_file = find_latest_rag_interaction_log(RAG_INTERACTION_LOGS_DIR)
    
    eval_log_file = None
    if rag_log_file:
        rag_log_basename = os.path.basename(rag_log_file)
        date_str_match = "".join(filter(str.isdigit, rag_log_basename))
        if len(date_str_match) >= 8:
            date_str = date_str_match[:8]
            evaluation_name = "answer_gemini_flash" # 与 evaluation.py 中一致
            eval_file_name = f"eval_results_{evaluation_name}_{date_str}.jsonl"
            eval_log_file = os.path.join(EVAL_LOG_DIR, eval_file_name)
            refine_answer_logger.info(f"Attempting to load Answer evaluation results from: {eval_log_file}")
        else:
            refine_answer_logger.error(f"Could not reliably extract date from RAG log filename: {rag_log_basename}")

    if not rag_log_file or not eval_log_file or not os.path.exists(eval_log_file):
        refine_answer_logger.error("Required log files for answer finetune data generation not found. Exiting.")
    else:
        rag_interactions = load_logs_to_dict(rag_log_file, key_field="interaction_id")
        answer_evaluations = load_logs_to_dict(eval_log_file, key_field="original_interaction_id_ref")

        if rag_interactions and answer_evaluations:
            finetune_data = generate_finetune_samples_for_answer(rag_interactions, answer_evaluations)
            
            if finetune_data:
                today_for_filename = datetime.now().strftime("%Y%m%d")
                output_filepath = os.path.join(FINETUNING_GENERATED_DATA_DIR, f"answer_finetune_samples_{today_for_filename}.jsonl")
                
                with open(output_filepath, 'w', encoding='utf-8') as f_out:
                    for sample in finetune_data:
                        f_out.write(json.dumps(sample, ensure_ascii=False) + "\n")
                refine_answer_logger.info(f"Successfully saved {len(finetune_data)} Answer finetuning samples to: {output_filepath}")
                
                try:
                    df = pd.DataFrame(finetune_data)
                    csv_output_filepath = os.path.join(FINETUNING_GENERATED_DATA_DIR, f"answer_finetune_samples_review_{today_for_filename}.csv")
                    df.to_csv(csv_output_filepath, index=False, encoding='utf-8-sig')
                    refine_answer_logger.info(f"Reviewable CSV for answers saved to: {csv_output_filepath}")
                except Exception as e_csv:
                    refine_answer_logger.error(f"Failed to save answer review CSV: {e_csv}")
            else:
                refine_answer_logger.info("No answer finetuning samples were generated.")
        else:
            refine_answer_logger.error("Failed to load data from log files for answer finetuning.")
    --- END OF FILE CONTENT ---

  File: refine_cypher_data.py
    --- START OF FILE CONTENT ---
# zhz_agent/refine_cypher_finetune_data.py
import json
import os
import pandas as pd
from typing import List, Dict, Any, Optional, Tuple
import glob
from datetime import datetime

# 假设 utils.py 和 constants.py 在同一个 zhz_agent 包内
try:
    from zhz_rag.utils.common_utils import get_interaction_log_filepath, get_evaluation_result_log_filepath, find_latest_rag_interaction_log # <--- 修改这里
    from zhz_rag.config.constants import NEW_KG_SCHEMA_DESCRIPTION
except ImportError as e:
    print(f"ERROR: Could not import necessary modules: {e}")
    # ... (错误处理)
    exit(1)

import logging

# 配置此脚本的logger
refine_logger = logging.getLogger("RefineFinetuneDataLogger")
refine_logger.setLevel(logging.INFO)
if not refine_logger.hasHandlers():
    _console_handler = logging.StreamHandler()
    _formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s - %(filename)s:%(lineno)d - %(message)s')
    _console_handler.setFormatter(_formatter)
    refine_logger.addHandler(_console_handler)
    refine_logger.info("--- RefineFinetuneDataLogger configured ---")

# --- 配置 ---
# 原始RAG交互日志的目录 (包含cypher_generation类型)
RAG_LOG_DIR = "zhz_rag/stored_data/rag_interaction_logs/"
# Gemini评估结果日志的目录
EVAL_LOG_DIR = "zhz_rag/stored_data/evaluation_results_logs/"
# 输出微调数据文件的目录
FINETUNE_DATA_DIR = "zhz_rag/finetuning/generated_data/"
os.makedirs(FINETUNE_DATA_DIR, exist_ok=True)


def load_logs_to_dict(filepath: str, key_field: str = "interaction_id") -> Dict[str, Dict[str, Any]]:
    """将JSONL文件加载到一个以指定字段为键的字典中。"""
    data_dict = {}
    if not os.path.exists(filepath):
        refine_logger.error(f"Log file not found: {filepath}")
        return data_dict
    with open(filepath, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                log_entry = json.loads(line.strip())
                if key_field in log_entry:
                    data_dict[log_entry[key_field]] = log_entry
                # 对于评估日志，我们可能需要用 original_interaction_id_ref 作为键
                elif key_field == "original_interaction_id_ref" and log_entry.get("original_interaction_id_ref"):
                    data_dict[log_entry["original_interaction_id_ref"]] = log_entry
            except json.JSONDecodeError:
                refine_logger.warning(f"Skipping malformed JSON line in {filepath}")
    return data_dict

def construct_qwen_input_prompt(user_question: str, schema_description: str) -> str:
    """
    根据用户问题和Schema描述构建Qwen生成Cypher时的完整输入Prompt。
    这个函数应该与 llm.py 中 generate_cypher_query 内部构建Prompt的逻辑一致。
    """
    # 这是我们在 llm.py -> generate_cypher_query 中使用的Prompt模板
    # 我们需要确保这里的模板与Qwen实际接收到的一致
    # 注意：这里使用了最新的V7版本（或您当前使用的版本）的Schema描述作为基础
    # 如果您的 generate_cypher_query 中的模板不同，请相应调整
    prompt = f"""<|im_start|>system
你是顶级Neo4j Cypher查询生成专家。你的任务是根据用户问题和严格提供的【知识图谱Schema】，生成一个【语法正确】、【逻辑合理】且【高效】的Cypher查询。

**【核心指令与约束 - 必须严格遵守！】**

1.  **【Schema绝对绑定 - 最高优先级】**:
    *   你生成的Cypher查询中所有用到的【节点标签】、【关系类型】、【属性名称】及其对应的【数据类型】，都**必须严格存在于**下面提供的 "知识图谱Schema描述" 中。
    *   在构建查询的每一步，都要反复与Schema核对。**严禁臆断、猜测或使用任何Schema中未明确定义的元素。**
    *   **属性名称的大小写和确切拼写必须与Schema完全一致。**
    *   **关系类型的名称和方向必须与Schema完全一致。** 例如，如果Schema定义为 `(Person)-[:WORKS_ON]->(Project)`，则查询中不能是 `(Project)-[:WORKS_ON]->(Person)`，除非Schema中也定义了反向关系。

2.  **【纯净输出格式 - 严格要求】**:
    *   如果能生成有效查询，你的回答**必须只包含纯粹的Cypher查询语句本身**。
    *   如果根据问题和Schema无法生成有效的Cypher查询（例如，问题超出了Schema表达能力，或问题本身逻辑不通），则**必须只输出固定的短语：“无法生成Cypher查询。”**
    *   **绝对禁止**在有效的Cypher语句前后添加任何前缀（如“Cypher查询: ”）、后缀、解释、注释、markdown标记（如 ```cypher ```）或任何其他多余的文本。

3.  **【属性与值的使用】**:
    *   当在`WHERE`子句中对属性进行匹配时，确保值的类型与Schema中定义的属性类型一致。例如，如果`name`是字符串，则匹配 `name: '张三'`；如果`year`是数字，则匹配 `year: 2023`。
    *   对于数值计算（如`SUM`, `AVG`），**必须**使用Schema中明确指定的数字类型属性（例如，`SalesAmount`节点的 `numeric_amount`）。

4.  **【查询构建逻辑指引】**:
    *   **实体识别**: 准确识别用户问题中的核心实体及其在Schema中对应的节点标签和属性。
    *   **关系路径**: 基于问题和Schema构建清晰的`MATCH`路径。
    *   **条件过滤**: 使用`WHERE`子句添加必要的过滤条件。
    *   **结果返回**: 使用`RETURN`子句指定需要返回的信息，并用`AS`为返回的列指定清晰、合法的别名（字母或下划线开头）。
    *   **多步查询**: 对于需要关联多个信息点的问题，合理使用`WITH`传递中间结果。
    *   **聚合**: 如需统计或汇总，正确使用`COUNT()`, `SUM()`, `COLLECT()`等聚合函数。

**【知识图谱Schema描述】**:
{schema_description}

**【查询示例 - 严格基于上述Schema】**:

*   用户问题: "张三参与了哪个项目？"
    Cypher查询: MATCH (p:Person {{name: '张三'}})-[:WORKS_ON]->(proj:Project) RETURN proj.name AS projectName

*   用户问题: "华东区域2024年第一季度的销售额是多少？"
    Cypher查询: MATCH (r:Region {{name: '华东'}})-[:HAS_SALES_AMOUNT]->(sa:SalesAmount {{period: '2024年第一季度'}}) RETURN sa.numeric_amount AS salesAmount, sa.unit AS salesUnit

*   用户问题: "查询所有产品的名称。"
    Cypher查询: MATCH (prod:Product) RETURN prod.name AS productName

*   用户问题: "项目X有哪些人参与？"
    Cypher查询: MATCH (p:Person)-[:WORKS_ON]->(proj:Project {{name: '项目X'}}) RETURN p.name AS participantName

*   用户问题: "2024年第一季度所有区域的总销售额是多少？"
    Cypher查询: MATCH (r:Region)-[:HAS_SALES_AMOUNT]->(sa:SalesAmount {{period: '2024年第一季度'}}) RETURN sum(sa.numeric_amount) AS totalSales, sa.unit AS commonUnit LIMIT 1 
    (此查询假设所有相关销售额的单位是相同的，并取第一个出现的单位作为代表)

*   用户问题: "与新产品A相关的文档ID是什么？"
    Cypher查询: MATCH (p:Product {{name: '新产品A'}})-[:RELATED_TO]->(d:Document) RETURN d.id AS documentId

*   用户问题: "公司CEO是谁？" (假设Schema中没有CEO信息)
    Cypher查询: 无法生成Cypher查询。

现在，请根据以下用户问题和上述Schema及规则生成Cypher查询。
<|im_end|>
<|im_start|>user
用户问题: {user_question}
<|im_end|>
<|im_start|>assistant
"""
    return prompt

def generate_finetune_samples_for_cypher(
    rag_interaction_logs: Dict[str, Dict[str, Any]],
    cypher_evaluation_logs: Dict[str, Dict[str, Any]]
) -> List[Dict[str, str]]:
    """
    根据原始交互日志和Gemini评估日志，生成用于Cypher微调的样本。
    返回一个列表，每个元素是 {"prompt": "...", "completion": "..."}
    """
    finetune_samples = []
    processed_ids = set()

    refine_logger.info(f"Processing {len(rag_interaction_logs)} RAG interaction logs and {len(cypher_evaluation_logs)} Cypher evaluation logs.")

    for interaction_id, rag_log in rag_interaction_logs.items():
        if rag_log.get("task_type") != "cypher_generation":
            continue

        if interaction_id in processed_ids:
            continue
        processed_ids.add(interaction_id)

        user_question = rag_log.get("user_query")
        qwen_generated_cypher_raw = rag_log.get("processed_llm_output") # 这是Qwen原始输出

        # --- 改进点: 处理Qwen输出为空或仅包含空白的情况 ---
        if qwen_generated_cypher_raw is None or not qwen_generated_cypher_raw.strip():
            qwen_generated_cypher = "无法生成Cypher查询." # 将空输出也视为无法生成
            refine_logger.info(f"Interaction {interaction_id}: Qwen output was empty/None, treating as '无法生成Cypher查询.'.")
        else:
            qwen_generated_cypher = qwen_generated_cypher_raw.strip()


        qwen_input_prompt = rag_log.get("llm_input_prompt")
        if not qwen_input_prompt:
            if user_question:
                qwen_input_prompt = construct_qwen_input_prompt(user_question, NEW_KG_SCHEMA_DESCRIPTION)
            else:
                refine_logger.warning(f"Skipping Cypher log {interaction_id} due to missing user_question for prompt reconstruction.")
                continue
        
        if not user_question: # qwen_generated_cypher 已确保非None
            refine_logger.warning(f"Skipping Cypher log {interaction_id} due to missing user_question.")
            continue

        ideal_cypher_output = None
        source_of_ideal = "unknown"
        gemini_score_for_log = None # 用于记录

        eval_log = cypher_evaluation_logs.get(interaction_id)

        if eval_log and eval_log.get("eval_llm_processed_output_json"):
            eval_json = eval_log["eval_llm_processed_output_json"]
            overall_score_str = eval_json.get("evaluation_summary", {}).get("overall_quality_score_cypher")
            gemini_suggestion_raw = eval_json.get("suggestion_for_improvement_cypher", "").strip()
            
            try:
                overall_score = int(overall_score_str)
                gemini_score_for_log = overall_score
            except (ValueError, TypeError):
                refine_logger.warning(f"Could not parse overall_quality_score_cypher for {interaction_id}: {overall_score_str}")
                overall_score = 0 # 默认给个低分
                gemini_score_for_log = 0

            # --- 规则1: Qwen自己就说无法生成 ---
            if qwen_generated_cypher == "无法生成Cypher查询.":
                # 如果Gemini也认为无法生成或评分低，那么采纳
                if "无法生成Cypher查询" in gemini_suggestion_raw or overall_score <= 2:
                    ideal_cypher_output = "无法生成Cypher查询."
                    source_of_ideal = "qwen_and_gemini_cannot_generate"
                # 如果Qwen说无法生成，但Gemini给出了高分建议，这很奇怪，需要人工看
                elif overall_score >=4 and "MATCH" in gemini_suggestion_raw.upper():
                     refine_logger.info(f"Cypher log {interaction_id}: Qwen said '无法生成', but Gemini suggested a high-score query '{gemini_suggestion_raw}'. Needs manual review.")
                     continue
                else: # Qwen说无法生成，Gemini建议不明确或中低分，也采纳Qwen的
                    ideal_cypher_output = "无法生成Cypher查询."
                    source_of_ideal = "qwen_cannot_generate_gemini_unclear"


            # --- 规则2: Qwen生成了查询，看Gemini评估 ---
            elif overall_score >= 4: # Gemini认为Qwen的输出质量高
                ideal_cypher_output = qwen_generated_cypher
                source_of_ideal = "qwen_high_score_by_gemini"

            
            # --- 规则3: Qwen的查询质量不高，但Gemini给出了具体的、看起来像Cypher的建议 ---
            elif gemini_suggestion_raw and \
                "无法生成Cypher查询" not in gemini_suggestion_raw and \
                "cannot be improved" not in gemini_suggestion_raw.lower() and \
                "needs to be extended" not in gemini_suggestion_raw.lower() and \
                ("MATCH " in gemini_suggestion_raw.upper() or \
                    "RETURN " in gemini_suggestion_raw.upper() or \
                    "CREATE " in gemini_suggestion_raw.upper() or \
                    "MERGE " in gemini_suggestion_raw.upper() or \
                    "WITH " in gemini_suggestion_raw.upper() or \
                    "OPTIONAL MATCH " in gemini_suggestion_raw.upper()
                ):

                # 简化处理：直接将 Gemini 的原始建议作为 completion 的候选
                # 清洗工作主要交给人工审核阶段
                # 我们仍然可以做非常基础的清理，比如首尾空格和常见的 markdown
                
                temp_completion = gemini_suggestion_raw.strip()
                if temp_completion.startswith("```") and temp_completion.endswith("```"):
                    temp_completion = temp_completion[3:-3].strip()
                    if temp_completion.lower().startswith("cypher"):
                        temp_completion = temp_completion[len("cypher"):].strip()
                elif temp_completion.startswith("`") and temp_completion.endswith("`"):
                    temp_completion = temp_completion[1:-1].strip()

                # 只要建议中包含核心Cypher关键字，我们就认为它有价值被审核
                core_cypher_keywords_check = ["MATCH", "RETURN", "CREATE", "MERGE", "WITH", "OPTIONAL MATCH"]
                suggestion_contains_cypher_keyword = False
                if temp_completion:
                    for core_keyword in core_cypher_keywords_check:
                        if core_keyword in temp_completion.upper():
                            suggestion_contains_cypher_keyword = True
                            break
                
                if suggestion_contains_cypher_keyword:
                    ideal_cypher_output = temp_completion # 使用初步清理后的建议
                    source_of_ideal = "gemini_suggestion_for_review" # 明确标记为需要审核
                    refine_logger.info(f"Interaction {interaction_id}: Gemini suggestion adopted for review. Raw: '{gemini_suggestion_raw[:150]}...', Processed for completion: '{ideal_cypher_output[:150]}...'")
                else:
                    refine_logger.warning(f"Interaction {interaction_id}: Gemini suggestion '{gemini_suggestion_raw[:150]}...' did not appear to contain core Cypher keywords after basic cleaning. Skipping.")
                    continue

            
            # --- 规则4: Gemini明确建议“无法生成” 或 Qwen的查询质量低且有严重问题 ---
            elif "无法生成Cypher查询" in gemini_suggestion_raw or \
                 (overall_score <= 2 and ("hallucinated" in eval_log.get("eval_llm_raw_output", "").lower() or \
                                         "schema violation" in eval_log.get("eval_llm_raw_output", "").lower() or \
                                         "syntax error" in eval_log.get("eval_llm_raw_output", "").lower())):
                ideal_cypher_output = "无法生成Cypher查询."
                source_of_ideal = "gemini_explicitly_cannot_generate_or_qwen_low_quality"
            
            # --- 规则5: 其他情况，需要人工审核 ---
            else:
                refine_logger.info(f"Cypher log {interaction_id} (Qwen: '{qwen_generated_cypher[:100]}...') needs manual review. Gemini score: {overall_score}, Suggestion: '{gemini_suggestion_raw[:100]}...'")
                continue 
        
        # --- 如果没有Gemini评估日志 ---
        else:
            refine_logger.warning(f"No valid Gemini evaluation found for Cypher log {interaction_id}. Qwen's output: '{qwen_generated_cypher[:100]}...'. Skipping for finetune data.")
            continue
            
        if ideal_cypher_output is not None:
            finetune_samples.append({
                "prompt": qwen_input_prompt,
                "completion": ideal_cypher_output.strip(), # 确保completion也strip
                "original_qwen_cypher": qwen_generated_cypher,
                "gemini_score": gemini_score_for_log,
                "source_of_ideal": source_of_ideal,
                "interaction_id": interaction_id
            })

    refine_logger.info(f"Generated {len(finetune_samples)} Cypher finetuning samples.")
    return finetune_samples


if __name__ == "__main__":
    # 1. 确定要处理的原始RAG交互日志文件 (包含cypher_generation)
    #    和对应的Gemini评估结果日志文件 (包含cypher_evaluation_result)
    
    # 自动查找最新的原始RAG交互日志
    rag_log_file = find_latest_rag_interaction_log(RAG_LOG_DIR) # utils.py中的函数
    
    # 构造对应的Gemini Cypher评估结果文件名
    # 假设评估文件名与原始日志文件名日期部分相同，且评估类型固定
    eval_log_file = None
    if rag_log_file:
        rag_log_basename = os.path.basename(rag_log_file)
        date_str_match = "".join(filter(str.isdigit, rag_log_basename)) # 提取文件名中的日期部分
        if len(date_str_match) >= 8: # 确保提取到至少YYYYMMDD
            date_str = date_str_match[:8]

            # 根据 evaluation.py 中 log_interaction_data 的 evaluation_name_for_file 参数构造
            evaluation_name = "cypher_gemini_flash" 
            eval_file_name = f"eval_results_{evaluation_name}_{date_str}.jsonl"
            
            eval_log_file = os.path.join(EVAL_LOG_DIR, eval_file_name)
            refine_logger.info(f"Attempting to load Cypher evaluation results from: {eval_log_file}")
        else:
            refine_logger.error(f"Could not reliably extract date from RAG log filename: {rag_log_basename}")
    
    if not rag_log_file or not eval_log_file or not os.path.exists(eval_log_file):
        refine_logger.error("Required log files not found. Exiting.")
        if not rag_log_file: refine_logger.error(f"RAG interaction log missing (expected pattern rag_interactions_*.jsonl in {RAG_LOG_DIR})")
        if rag_log_file and (not eval_log_file or not os.path.exists(eval_log_file)): refine_logger.error(f"Cypher evaluation result log missing (expected: {eval_log_file})")
    else:
        rag_interactions = load_logs_to_dict(rag_log_file, key_field="interaction_id")
        cypher_evaluations = load_logs_to_dict(eval_log_file, key_field="original_interaction_id_ref")

        if rag_interactions and cypher_evaluations:
            finetune_data = generate_finetune_samples_for_cypher(rag_interactions, cypher_evaluations)
            
            if finetune_data:
                # 获取当前日期用于文件名
                today_for_filename = datetime.now().strftime("%Y%m%d")
                output_filepath = os.path.join(FINETUNE_DATA_DIR, f"cypher_finetune_samples_{today_for_filename}.jsonl")
                
                with open(output_filepath, 'w', encoding='utf-8') as f_out:
                    for sample in finetune_data:
                        f_out.write(json.dumps(sample, ensure_ascii=False) + "\n")
                refine_logger.info(f"Successfully saved {len(finetune_data)} Cypher finetuning samples to: {output_filepath}")
                
                # 也可以同时保存一个CSV版本供人工审查
                try:
                    df = pd.DataFrame(finetune_data)
                    csv_output_filepath = os.path.join(FINETUNE_DATA_DIR, f"cypher_finetune_samples_review_{today_for_filename}.csv")
                    df.to_csv(csv_output_filepath, index=False, encoding='utf-8-sig')
                    refine_logger.info(f"Reviewable CSV saved to: {csv_output_filepath}")
                except Exception as e_csv:
                    refine_logger.error(f"Failed to save review CSV: {e_csv}")
            else:
                refine_logger.info("No finetuning samples were generated.")
        else:
            refine_logger.error("Failed to load data from log files.")
    --- END OF FILE CONTENT ---


Directory: zhz_rag/finetuning/generated_data/
  File (skipped, extension not included): answer_finetune_samples_20250531.jsonl
  File: answer_finetune_samples_review_20250531.csv
    --- START OF FILE CONTENT ---
﻿prompt,completion,original_qwen_answer,gemini_scores,gemini_suggestion,source_of_ideal,interaction_id
"
<|im_start|>system
你是一个AI问答助手。你的任务是根据【上下文信息】回答【用户问题】。

**核心指令：**

1.  **尝试直接回答：** 请首先仔细阅读【上下文信息】，如果其中包含能直接回答【用户问题】的内容，请用上下文中的信息直接、简洁地回答。
2.  **忠实原文：** 你的回答必须严格基于【上下文信息】，禁止加入任何外部知识或个人观点。
3.  **如果无法回答：** 如果你分析了【上下文信息】后，确认其中确实没有能回答【用户问题】的明确信息，那么请只回答以下这句话：
    ""根据目前提供的资料，我无法找到关于您问题的明确信息。""
    **不要添加任何其他解释、建议或反问。**

**请直接给出答案，或者只给出上述那句固定的“无法找到信息”的回复。**
<|im_start|>user
用户问题: 总结一下关于AI在医疗领域应用的主要内容。

上下文信息:
Source Type: vector_chroma, Score: 0.9200
Content: AI技术在医疗影像分析方面取得了显著进展，能够帮助医生更早发现癌症等疾病。例如，深度学习模型可以分析X光片、CT扫描结果，其准确率有时甚至超过人类专家。

---

Source Type: vector_chroma, Score: 0.8800
Content: 个性化医疗是未来的趋势，AI通过分析大量的患者数据，包括基因序列、生活方式、病史等，为每位患者量身定制治疗方案和用药指导，从而提高疗效并减少副作用。

---

Source Type: keyword_bm25s, Score: 15.5000
Content: 药物研发周期长、成本高是长期存在的问题。AI可以通过模拟筛选化合物、预测药物相互作用，极大地缩短新药从研发到上市的时间。
<|im_end|>
<|im_start|>assistant
",AI在医疗领域的主要应用包括辅助诊断（如通过图像识别分析医疗影像，识别病变），个性化治疗方案的制定（基于患者基因和生活习惯数据），以及新药研发加速（通过预测分子结构和药物反应）。,AI在医疗领域的主要应用包括辅助诊断（如通过图像识别分析医疗影像，识别病变），个性化治疗方案的制定（基于患者基因和生活习惯数据），以及新药研发加速（通过预测分子结构和药物反应）。,"{'overall': 5, 'faithfulness': 5, 'relevance': 5, 'completeness': 5, 'context_sufficiency': 'Sufficient'}",No improvement needed.,qwen_high_score_by_gemini,a1-rag-001
"
<|im_start|>system
你是一个AI问答助手。你的任务是根据【上下文信息】回答【用户问题】。

**核心指令：**

1.  **尝试直接回答：** 请首先仔细阅读【上下文信息】，如果其中包含能直接回答【用户问题】的内容，请用上下文中的信息直接、简洁地回答。
2.  **忠实原文：** 你的回答必须严格基于【上下文信息】，禁止加入任何外部知识或个人观点。
3.  **如果无法回答：** 如果你分析了【上下文信息】后，确认其中确实没有能回答【用户问题】的明确信息，那么请只回答以下这句话：
    ""根据目前提供的资料，我无法找到关于您问题的明确信息。""
    **不要添加任何其他解释、建议或反问。**

**请直接给出答案，或者只给出上述那句固定的“无法找到信息”的回复。**
<|im_start|>user
用户问题: 我们公司上季度的营销活动预算是多少？

上下文信息:
Source Type: vector_chroma, Score: 0.9500
Content: 会议纪要：Q3营销计划讨论...市场部张经理提出，本季度营销活动预算初步定为50万元，主要用于线上推广和内容制作...

---

Source Type: knowledge_graph, Score: 1.0000
Content: 事实: 营销活动Q3 -> 预算: 50万元
<|im_end|>
<|im_start|>assistant
",根据提供的信息，我们公司上季度的营销活动预算是50万元。,根据提供的信息，我们公司上季度的营销活动预算是50万元。,"{'overall': 4, 'faithfulness': 5, 'relevance': 5, 'completeness': 4, 'context_sufficiency': 'Sufficient'}",可以考虑在答案中提及信息来源，例如：'根据会议纪要和知识图谱信息，公司上季度营销活动预算为50万元。',qwen_high_score_by_gemini_with_minor_gemini_suggestion,a2-rag-002
"
<|im_start|>system
你是一个AI问答助手。你的任务是根据【上下文信息】回答【用户问题】。

**核心指令：**

1.  **尝试直接回答：** 请首先仔细阅读【上下文信息】，如果其中包含能直接回答【用户问题】的内容，请用上下文中的信息直接、简洁地回答。
2.  **忠实原文：** 你的回答必须严格基于【上下文信息】，禁止加入任何外部知识或个人观点。
3.  **如果无法回答：** 如果你分析了【上下文信息】后，确认其中确实没有能回答【用户问题】的明确信息，那么请只回答以下这句话：
    ""根据目前提供的资料，我无法找到关于您问题的明确信息。""
    **不要添加任何其他解释、建议或反问。**

**请直接给出答案，或者只给出上述那句固定的“无法找到信息”的回复。**
<|im_start|>user
用户问题: 请告诉我关于月球的三个有趣事实。

上下文信息:
Source Type: vector_chroma, Score: 0.8500
Content: 月球是地球的唯一天然卫星，其直径约为地球的四分之一。

---

Source Type: vector_chroma, Score: 0.9000
Content: 由于月球的自转周期和公转周期相等（潮汐锁定），我们从地球上始终只能看到月球的同一面。
<|im_end|>
<|im_start|>assistant
",月球是地球唯一的天然卫星，它的自转周期与公转周期相同，因此总是以同一面朝向地球。此外，月球的引力导致了地球上的潮汐现象，并且月球上没有大气层。,月球是地球唯一的天然卫星，它的自转周期与公转周期相同，因此总是以同一面朝向地球。此外，月球的引力导致了地球上的潮汐现象，并且月球上没有大气层。,"{'overall': 2, 'faithfulness': 2, 'relevance': 4, 'completeness': 2, 'context_sufficiency': 'Partially Sufficient'}",答案应严格基于提供的上下文。如果上下文不足以提供三个事实，应诚实说明，例如：'根据提供的信息，月球是地球唯一的天然卫星，并且总是以同一面朝向地球。目前信息不足以提供第三个事实。',qwen_low_score_with_gemini_suggestion_for_review,a3-rag-003
"
<|im_start|>system
你是一个AI问答助手。你的任务是根据【上下文信息】回答【用户问题】。

**核心指令：**

1.  **尝试直接回答：** 请首先仔细阅读【上下文信息】，如果其中包含能直接回答【用户问题】的内容，请用上下文中的信息直接、简洁地回答。
2.  **忠实原文：** 你的回答必须严格基于【上下文信息】，禁止加入任何外部知识或个人观点。
3.  **如果无法回答：** 如果你分析了【上下文信息】后，确认其中确实没有能回答【用户问题】的明确信息，那么请只回答以下这句话：
    ""根据目前提供的资料，我无法找到关于您问题的明确信息。""
    **不要添加任何其他解释、建议或反问。**

**请直接给出答案，或者只给出上述那句固定的“无法找到信息”的回复。**
<|im_start|>user
用户问题: Alpha项目的负责人是谁？

上下文信息:
Source Type: vector_chroma, Score: 0.7000
Content: 项目Beta的负责人是李明，项目Gamma的负责人是王芳。

---

Source Type: keyword_bm25s, Score: 10.1000
Content: 所有项目列表：项目Beta, 项目Gamma, 项目Delta。
<|im_end|>
<|im_start|>assistant
",根据目前提供的资料，我无法找到关于您问题的明确信息。,根据目前提供的资料，我无法找到关于您问题的明确信息。,"{'overall': 5, 'faithfulness': 5, 'relevance': 5, 'completeness': 5, 'context_sufficiency': 'Insufficient'}",No improvement needed.,qwen_standard_no_answer_confirmed_by_gemini_context_insufficient,a4-rag-004
"
<|im_start|>system
你是一个AI问答助手。你的任务是根据【上下文信息】回答【用户问题】。

**核心指令：**

1.  **尝试直接回答：** 请首先仔细阅读【上下文信息】，如果其中包含能直接回答【用户问题】的内容，请用上下文中的信息直接、简洁地回答。
2.  **忠实原文：** 你的回答必须严格基于【上下文信息】，禁止加入任何外部知识或个人观点。
3.  **如果无法回答：** 如果你分析了【上下文信息】后，确认其中确实没有能回答【用户问题】的明确信息，那么请只回答以下这句话：
    ""根据目前提供的资料，我无法找到关于您问题的明确信息。""
    **不要添加任何其他解释、建议或反问。**

**请直接给出答案，或者只给出上述那句固定的“无法找到信息”的回复。**
<|im_start|>user
用户问题: 解释一下什么是量子纠缠？

上下文信息:
Source Type: vector_chroma, Score: 0.9300
Content: 根据量子力学，当两个或多个粒子共同组成一个量子态时，即使它们在空间上分离，对其中一个粒子的测量也会瞬间影响到其他粒子的状态，这种现象被称为量子纠缠。

---

Source Type: vector_chroma, Score: 0.7800
Content: 爱因斯坦称量子纠缠为“鬼魅般的超距作用”。
<|im_end|>
<|im_start|>assistant
",量子纠缠是指当几个粒子在彼此相互作用后，由于各个粒子所拥有的特性已综合成为整体性质，无法单独描述各个粒子的性质，只能描述整体系统的性质的现象。,量子纠缠是指当几个粒子在彼此相互作用后，由于各个粒子所拥有的特性已综合成为整体性质，无法单独描述各个粒子的性质，只能描述整体系统的性质的现象。,"{'overall': 3, 'faithfulness': 3, 'relevance': 4, 'completeness': 2, 'context_sufficiency': 'Sufficient'}",答案应该更好地利用上下文信息，特别是上下文片段1中关于'即使它们在空间上分离，对其中一个粒子的测量也会瞬间影响到其他粒子的状态'的描述，这比当前答案更易于理解。可以考虑直接改写或总结上下文片段1的核心内容。,qwen_low_score_with_gemini_suggestion_for_review,a5-rag-005

    --- END OF FILE CONTENT ---

  File (skipped, extension not included): cypher_finetune_samples_20250531.jsonl
  File: cypher_finetune_samples_review_20250531.csv
    --- START OF FILE CONTENT ---
﻿prompt,completion,original_qwen_cypher,gemini_score,source_of_ideal,interaction_id
"<|im_start|>system
你是顶级Neo4j Cypher查询生成专家... (省略完整Schema和指令) ...【知识图谱Schema描述】
:ExtractedEntity {text: STRING, label: STRING (PERSON, ORGANIZATION, TASK)}
(:ExtractedEntity {label:""PERSON""})-[:WORKS_AT]->(:ExtractedEntity {label:""ORGANIZATION""})
(:ExtractedEntity {label:""TASK""})-[:ASSIGNED_TO]->(:ExtractedEntity {label:""PERSON""})
... (省略示例) ...现在，请根据以下用户问题和上述Schema及规则生成Cypher查询。
<|im_end|>
<|im_start|>user
用户问题: 张三在哪里工作？
<|im_end|>
<|im_start|>assistant
","MATCH (p:ExtractedEntity {text: '张三', label: 'PERSON'})-[:WORKS_AT]->(org:ExtractedEntity {label: 'ORGANIZATION'}) RETURN org.text AS organizationName","MATCH (p:ExtractedEntity {text: '张三', label: 'PERSON'})-[:WORKS_AT]->(org:ExtractedEntity {label: 'ORGANIZATION'}) RETURN org.text AS organizationName",5,qwen_high_score_by_gemini,c1-rag-001
"<|im_start|>system
你是顶级Neo4j Cypher查询生成专家... (同上) ...
<|im_end|>
<|im_start|>user
用户问题: 李四负责了哪些任务，并且这些任务的负责人是谁？
<|im_end|>
<|im_start|>assistant
","为了更准确地回答，查询应该确保只返回李四作为负责人的任务。可以考虑修改为：MATCH (task:ExtractedEntity {label: 'TASK'})-[:ASSIGNED_TO]->(p:ExtractedEntity {text: '李四', label: 'PERSON'}) RETURN task.text AS taskName, p.text AS assigneeName","MATCH (task:ExtractedEntity {label: 'TASK'})-[:ASSIGNED_TO]->(p:ExtractedEntity {text: '李四', label: 'PERSON'}), (task)-[:ASSIGNED_TO]->(assignee:ExtractedEntity {label: 'PERSON'}) RETURN task.text AS taskName, assignee.text AS assigneeName",3,gemini_suggestion_for_review,c2-rag-002
"<|im_start|>system
你是顶级Neo4j Cypher查询生成专家... (同上) ...
<|im_end|>
<|im_start|>user
用户问题: 项目Alpha的状态是什么？
<|im_end|>
<|im_start|>assistant
",无法生成Cypher查询.,MATCH (t:Task {name: '项目Alpha'}) RETURN t.status,1,gemini_explicitly_cannot_generate_or_qwen_low_quality,c3-rag-003
"<|im_start|>system
你是顶级Neo4j Cypher查询生成专家... (同上) ...
<|im_end|>
<|im_start|>user
用户问题: 王五的直属上级是谁？
<|im_end|>
<|im_start|>assistant
",无法生成Cypher查询.,无法生成Cypher查询.,5,qwen_and_gemini_cannot_generate,c4-rag-004
"<|im_start|>system
你是顶级Neo4j Cypher查询生成专家... (同上) ...
<|im_end|>
<|im_start|>user
用户问题: 数据库中有多少人？
<|im_end|>
<|im_start|>assistant
",无法生成Cypher查询.,无法生成Cypher查询.,1,qwen_and_gemini_cannot_generate,c6-rag-006

    --- END OF FILE CONTENT ---


Directory: zhz_rag/stored_data/
  File: __init__.py
    --- File is empty ---

  File (skipped, extension not included): eval_results_answer_gemini_flash_20250531.jsonl
  File (skipped, extension not included): eval_results_cypher_gemini_flash_20250531.jsonl
  File (skipped, extension not included): kuzu_default_db.lockfile
  File (skipped, extension not included): rag_interactions_20250531.jsonl

Directory: zhz_rag/stored_data/rag_interaction_logs/
  File (skipped, extension not included): rag_interactions_20250530.jsonl
  File (skipped, extension not included): rag_interactions_20250603.jsonl

Directory: zhz_rag/stored_data/evaluation_results_logs/
  File: analysis_answer_gemini_flash_20250530.csv
    --- START OF FILE CONTENT ---
﻿interaction_id_ref,user_question,generated_answer,overall_answer_quality_score,main_strengths_answer,main_weaknesses_answer,faithfulness_score,faithfulness_reasoning,faithfulness_problematic_segments,relevance_score,relevance_reasoning,completeness_context_sufficiency,completeness_context_reasoning,completeness_score,completeness_reasoning,coherence_score,coherence_reasoning,actionability_score,actionability_reasoning,gemini_suggestion_answer
a1-rag-001,总结一下关于AI在医疗领域应用的主要内容。,AI在医疗领域的主要应用包括辅助诊断（如通过图像识别分析医疗影像，识别病变），个性化治疗方案的制定（基于患者基因和生活习惯数据），以及新药研发加速（通过预测分子结构和药物反应）。,5,答案准确、全面，很好地总结了上下文信息。,无明显弱点。,5,所有信息点均来自上下文。,,5,完美回答了用户问题。,Sufficient,上下文提供了足够的信息点。,5,全面利用了上下文。,5,表达流畅清晰。,4,信息总结性强，但非直接行动指南。,No improvement needed.
a2-rag-002,我们公司上季度的营销活动预算是多少？,根据提供的信息，我们公司上季度的营销活动预算是50万元。,4,答案准确，但可以更明确指出信息来源。,可以补充说明信息来自会议纪要或知识图谱。,5,答案与上下文一致。,,5,直接回答了问题。,Sufficient,上下文明确给出了预算数字。,4,答案是完整的，但可以提供更多细节如信息来源。,5,流畅。,5,信息明确可用。,可以考虑在答案中提及信息来源，例如：'根据会议纪要和知识图谱信息，公司上季度营销活动预算为50万元。'
a3-rag-003,请告诉我关于月球的三个有趣事实。,月球是地球唯一的天然卫星，它的自转周期与公转周期相同，因此总是以同一面朝向地球。此外，月球的引力导致了地球上的潮汐现象，并且月球上没有大气层。,2,部分信息（天然卫星，同一面朝向地球）来自上下文。,答案中关于'引力导致潮汐'和'没有大气层'的信息在提供的上下文中找不到依据，属于幻觉。,2,'引力导致潮汐'和'没有大气层'是幻觉。,月球的引力导致了地球上的潮汐现象; 月球上没有大气层,4,尝试回答问题，但包含不准确信息。,Partially Sufficient,上下文只提供了两个明确的事实，不足以支持三个。,2,未能完全基于上下文，且编造了信息以满足数量要求。,4,语言通顺。,2,包含错误信息，降低了可用性。,答案应严格基于提供的上下文。如果上下文不足以提供三个事实，应诚实说明，例如：'根据提供的信息，月球是地球唯一的天然卫星，并且总是以同一面朝向地球。目前信息不足以提供第三个事实。'
a4-rag-004,Alpha项目的负责人是谁？,根据目前提供的资料，我无法找到关于您问题的明确信息。,5,正确判断上下文不足并给出了标准的无法回答的回复。,无。,5,答案本身没有事实性声明，与上下文不冲突。,,5,对于无法回答的情况，这是最相关的回复。,Insufficient,上下文中没有Alpha项目负责人的信息。,5,完美处理了上下文不足的情况。,5,标准回复，流畅。,3,虽然无法直接行动，但明确了信息缺失。,No improvement needed.
a5-rag-005,解释一下什么是量子纠缠？,量子纠缠是指当几个粒子在彼此相互作用后，由于各个粒子所拥有的特性已综合成为整体性质，无法单独描述各个粒子的性质，只能描述整体系统的性质的现象。,3,尝试解释了量子纠缠。,答案的表述比较晦涩，不如上下文片段1清晰易懂，且没有很好地融合上下文信息。,3,答案的核心概念与上下文大致相符，但表述方式不同，没有直接引用上下文的关键描述。,,4,回答了问题。,Sufficient,上下文提供了对量子纠缠的清晰解释。,2,未能很好地利用上下文中最清晰的解释（上下文片段1），答案自身的解释不够好。也没有提及爱因斯坦的评论。,3,表述有些拗口，不如上下文流畅。,3,对于非专业人士可能不够易懂。,答案应该更好地利用上下文信息，特别是上下文片段1中关于'即使它们在空间上分离，对其中一个粒子的测量也会瞬间影响到其他粒子的状态'的描述，这比当前答案更易于理解。可以考虑直接改写或总结上下文片段1的核心内容。

    --- END OF FILE CONTENT ---

  File: analysis_answer_gemini_flash_20250531.csv
    --- START OF FILE CONTENT ---
﻿interaction_id_ref,user_question,generated_answer,overall_answer_quality_score,main_strengths_answer,main_weaknesses_answer,faithfulness_score,faithfulness_reasoning,faithfulness_problematic_segments,relevance_score,relevance_reasoning,completeness_context_sufficiency,completeness_context_reasoning,completeness_score,completeness_reasoning,coherence_score,coherence_reasoning,actionability_score,actionability_reasoning,gemini_suggestion_answer
a1-rag-001,总结一下关于AI在医疗领域应用的主要内容。,AI在医疗领域的主要应用包括辅助诊断（如通过图像识别分析医疗影像，识别病变），个性化治疗方案的制定（基于患者基因和生活习惯数据），以及新药研发加速（通过预测分子结构和药物反应）。,4,"The answer is concise, well-structured, and accurately reflects the main points presented in the provided context.","The answer is slightly incomplete as it doesn't explicitly mention the improved accuracy sometimes exceeding human experts, a key detail from the context.",4,"All claims are directly supported by the context.  The answer paraphrases the information effectively, avoiding direct copying.  The only minor point is the omission of the detail about AI's accuracy sometimes surpassing human experts in medical imaging analysis.",,5,The answer directly and completely addresses the user's request to summarize the main applications of AI in the medical field.,Sufficient,"The provided context offers three distinct and relevant applications of AI in healthcare, sufficient for a concise summary.",4,"The answer covers the three main applications mentioned in the context. However, it could be slightly more complete by including the detail about AI's accuracy sometimes exceeding that of human experts in medical imaging, as this is a significant finding mentioned in the context.",5,"The answer is grammatically correct, well-structured, and easy to understand.  The language is clear and professional.",4,"The summary provides a clear and concise overview of AI applications in healthcare, useful for an office worker needing a quick understanding of the topic.  While not directly actionable in a task-oriented sense, it provides valuable background information.","To enhance completeness, the answer could be slightly expanded to include the detail from Context Snippet 1 regarding the accuracy of AI in medical imaging sometimes exceeding that of human experts.  For example:  'AI in healthcare is primarily used for assisted diagnosis (e.g., using image recognition to analyze medical images and identify lesions), personalized treatment plan development (based on patient genetic and lifestyle data), and accelerating new drug development (by predicting molecular structures and drug interactions).  In medical imaging analysis, AI's accuracy sometimes even surpasses that of human experts.'"
a2-rag-002,我们公司上季度的营销活动预算是多少？,根据提供的信息，我们公司上季度的营销活动预算是50万元。,5,"The answer is concise, accurate, and directly addresses the user's question using the provided context.",No significant weaknesses.,5,"The answer accurately reflects the information provided in both context snippets.  The 500,000 yuan budget is explicitly stated in both.",,5,The answer perfectly addresses the user's question about the marketing budget for the last quarter.,Sufficient,The provided context clearly and directly states the marketing budget for Q3.,5,The answer is complete given the sufficient context. It extracts and presents the key information needed to answer the user's question.,5,"The answer is grammatically correct, concise, and easy to understand.  The language is clear and professional.",5,The answer provides a clear and directly usable piece of information for an office worker.  The information is presented in a simple and easily understandable format.,No improvement needed.
a3-rag-003,请告诉我关于月球的三个有趣事实。,月球是地球唯一的天然卫星，它的自转周期与公转周期相同，因此总是以同一面朝向地球。此外，月球的引力导致了地球上的潮汐现象，并且月球上没有大气层。,3,"The answer is fluent and mostly coherent, correctly incorporating information from the provided context.","The answer is incomplete, failing to provide three facts as requested, and hallucinates a fact about the moon's lack of atmosphere.",3,"The first two sentences accurately reflect the provided context. However, the statement '并且月球上没有大气层' is a hallucination; this information was not present in the context.",并且月球上没有大气层,4,"The answer is relevant to the user's question about interesting facts about the moon, but it does not fulfill the request for *three* facts.",Insufficient,"The context only provides two facts about the moon.  To answer the question fully, more information is needed.",2,"The answer only provides two facts from the context and adds a hallucinated third fact.  Given the insufficient context, it fails to acknowledge the limitation and provide a complete answer to the user's request for three facts.",4,"The answer is well-written, grammatically correct, and easy to understand. The flow of information is logical.",3,"The answer provides some interesting facts about the moon, but the incompleteness and hallucination reduce its usability.  An office worker would likely need to seek additional information elsewhere.","The AI should explicitly state that it can only provide two facts based on the given context and then provide those two facts.  It should avoid hallucinating additional information.  If the system is capable of accessing external knowledge, it should be instructed to do so to fulfill the user's request for three facts."
a4-rag-004,Alpha项目的负责人是谁？,根据目前提供的资料，我无法找到关于您问题的明确信息。,4,The answer is honest and accurate in reflecting the limitations of the provided context.,"While truthful, the answer doesn't offer any suggestions or alternative approaches to find the information, which would be helpful for an office worker assistant.",5,"The answer is completely faithful to the provided context.  The context does not contain information about the Alpha project's leader, and the answer accurately reflects this.",,5,"The answer directly addresses the user's question about the Alpha project leader.  Although it doesn't provide an answer, it correctly states that the information is unavailable.",Insufficient,"The context only provides information about projects Beta and Gamma, and a list of projects that includes Delta, but not Alpha.",4,"Given the insufficient context, the answer is complete in acknowledging the lack of information.  However, a more helpful response might suggest alternative ways to find the information (e.g., checking a project database, contacting relevant personnel).",5,"The answer is grammatically correct, well-written, and easy to understand.  It's concise and polite.",3,"The answer is not directly actionable in the sense that it doesn't provide the requested information. However, it's usable in that it clearly indicates the information's absence.  A higher score would require suggestions for alternative actions.","While the answer is accurate, it could be improved by adding a suggestion on how to find the information. For example:  ""根据目前提供的资料，我无法找到关于Alpha项目负责人的明确信息。您可以尝试查询公司内部项目数据库或联系相关项目团队成员获取更多信息。"""
a5-rag-005,解释一下什么是量子纠缠？,量子纠缠是指当几个粒子在彼此相互作用后，由于各个粒子所拥有的特性已综合成为整体性质，无法单独描述各个粒子的性质，只能描述整体系统的性质的现象。,3,The answer is grammatically correct and attempts to define quantum entanglement.,"The answer is a significant simplification and misses key aspects highlighted in the context, particularly the instantaneous influence across distances.",3,"The answer is partially faithful. While it doesn't directly contradict the context, it omits the crucial element of instantaneous influence across distances, which is the core characteristic of quantum entanglement as described in Context Snippet 1.  The mention of particles interacting and forming an inseparable whole is a consequence of entanglement, but not its defining characteristic.",量子纠缠是指当几个粒子在彼此相互作用后，由于各个粒子所拥有的特性已综合成为整体性质，无法单独描述各个粒子的性质，只能描述整体系统的性质的现象。,4,"The answer is relevant to the user's question as it attempts to define quantum entanglement. However, its incompleteness reduces its overall relevance.",Partially Sufficient,"The context provides a definition of quantum entanglement but lacks a comprehensive explanation.  It highlights the key feature of instantaneous influence across distances, which is missing from the AI's response.",2,"The answer is incomplete because it fails to capture the essence of quantum entanglement as presented in the context.  It focuses on the resulting inseparable nature of the particles but ignores the instantaneous correlation across space, which is the most important and distinguishing feature.",4,"The answer is grammatically correct and coherent. The language is clear and easy to understand, although the explanation is oversimplified.",2,"The answer provides a definition, but it's too simplistic to be truly useful for an office worker.  It doesn't offer any practical application or deeper understanding of the concept.","The answer should incorporate the key information from Context Snippet 1, emphasizing the instantaneous correlation between entangled particles regardless of distance.  For example, the answer could be improved by adding:  '...This means that even when separated by large distances, measuring the state of one particle instantaneously affects the state of the other.'  Additionally, Context Snippet 2 could be incorporated to add context and interest."
a6-rag-006,公司下一季度的主要目标是什么？,公司下一季度的主要目标是提升市场份额和用户满意度。,3,The answer is relevant to the user's question and uses appropriate language.,"The answer is partially faithful and incomplete, hallucinating the addition of 'user satisfaction' as a key objective.",3,"The answer correctly identifies the increase in market share as a key objective, directly supported by the context. However, it adds 'user satisfaction,' which is not mentioned in the provided context. This constitutes a hallucination.",用户满意度,4,"The answer directly addresses the user's question about the company's main objectives for the next quarter.  While partially inaccurate, it remains relevant to the core query.",Partially Sufficient,"The context only provides one key objective.  While sufficient to answer part of the question, it lacks a complete picture of all objectives for the next quarter.",3,"The answer is incomplete because it only partially uses the available context and adds an unsupported objective.  Given the limited context, it should have acknowledged the lack of complete information or focused solely on the provided objective.",4,"The answer is well-written, grammatically correct, and easy to understand.  The phrasing is natural and professional.",3,"The answer provides some useful information, but the hallucinated addition of 'user satisfaction' reduces its usability.  An office worker would need to verify the accuracy of the information.","The AI should be more cautious about adding information not explicitly present in the context.  If the context is insufficient to fully answer the question, the answer should explicitly state this limitation.  For example, the answer could be: ""Based on the available information, a key objective for the next quarter is to increase market share by at least 5%.  Further information is needed to identify all objectives."""
a1-rag-001,总结一下关于AI在医疗领域应用的主要内容。,AI在医疗领域的主要应用包括辅助诊断（如通过图像识别分析医疗影像，识别病变），个性化治疗方案的制定（基于患者基因和生活习惯数据），以及新药研发加速（通过预测分子结构和药物反应）。,4,"The answer is concise, well-structured, and accurately reflects the main points presented in the provided context.","The answer is slightly incomplete as it doesn't explicitly mention the improved accuracy sometimes exceeding human experts, a key detail from the context.",4,"All information presented is directly supported by the context.  The answer is a good summary, but omits some details for brevity.  For example, the superior accuracy of AI in medical imaging analysis compared to human experts is mentioned in the context but not in the answer.",,5,The answer directly and completely addresses the user's request to summarize the main applications of AI in the medical field.,Sufficient,The provided context offers sufficient information to create a comprehensive summary of AI applications in medicine.,4,"The answer covers the main points from each context snippet. While it doesn't include every detail, the omission doesn't significantly detract from the overall summary.  The superior accuracy aspect could be added for better completeness.",5,"The answer is well-written, grammatically correct, and logically structured.  It's easy to understand and flows naturally.",4,"The summary provides useful information for an office worker, perhaps researching AI in healthcare.  While it doesn't offer actionable steps, it provides a clear and concise overview of the topic.","To improve completeness, the answer could include a brief mention of the higher accuracy sometimes achieved by AI in medical image analysis compared to human experts, as stated in Context Snippet 1.  For example,  '...in medical image analysis, sometimes exceeding the accuracy of human experts'."
a2-rag-002,我们公司上季度的营销活动预算是多少？,根据提供的信息，我们公司上季度的营销活动预算是50万元。,5,"The answer is concise, accurate, and directly addresses the user's question using the provided context.",No significant weaknesses.,5,"The answer accurately reflects the information provided in both context snippets.  The 500,000 yuan budget is explicitly stated in both.",,5,The answer directly and completely answers the user's question about the marketing budget for the last quarter.,Sufficient,The provided context clearly and unambiguously states the marketing budget for Q3.,5,The answer is complete given the sufficient context. It extracts and presents the relevant information effectively.,5,"The answer is grammatically correct, well-structured, and easy to understand.  The language is clear and professional.",5,"The answer provides a clear and concise answer to the user's question, making it highly actionable and usable for an office worker. The information is presented in a readily understandable format.",No improvement needed.
a3-rag-003,请告诉我关于月球的三个有趣事实。,月球是地球唯一的天然卫星，它的自转周期与公转周期相同，因此总是以同一面朝向地球。此外，月球的引力导致了地球上的潮汐现象，并且月球上没有大气层。,3,"The answer is fluent and mostly coherent, incorporating information directly from the provided context.","The answer is incomplete, failing to provide three facts as requested, and includes a hallucinated fact ('月球上没有大气层').",3,"The first two sentences accurately reflect the provided context. However, the statement '并且月球上没有大气层' is a hallucination; this information was not present in the context.",并且月球上没有大气层,4,"The answer is relevant to the user's question about interesting facts about the moon.  It addresses the core request, although incompletely.",Insufficient,"The context only provides two facts about the moon.  To fully answer the question, more information is needed.",2,"The answer only provides two facts from the context and adds a hallucinated third fact.  Given the insufficient context, it doesn't explicitly acknowledge the limitation, but it also doesn't attempt to fill the gap with fabricated information beyond the hallucination.",4,"The answer is well-written, grammatically correct, and logically structured.  The flow is natural and easy to understand.",3,"The answer provides some interesting facts about the moon, but its incompleteness and inclusion of a hallucination reduce its usability.  While the factual parts are useful, the overall quality is diminished.","The AI should explicitly state that it can only provide two facts based on the available context.  It should avoid hallucinating information.  To improve the answer, the system needs access to a broader knowledge base to provide three facts."
a4-rag-004,Alpha项目的负责人是谁？,根据目前提供的资料，我无法找到关于您问题的明确信息。,4,The answer is honest and accurate in reflecting the limitations of the provided context.,"While truthful, the answer doesn't offer any suggestions or alternative approaches to find the information, which would be helpful for an office worker assistant.",5,"The answer is completely faithful to the provided context.  The context does not contain information about the Alpha project's leader, and the answer accurately reflects this.",,5,"The answer directly addresses the user's question about the Alpha project leader.  Although it doesn't provide an answer, it correctly indicates the lack of information.",Insufficient,"The context only provides information about projects Beta and Gamma, and a list excluding Alpha.  Therefore, it's insufficient to answer the question.",4,"Given the insufficient context, the answer is complete in acknowledging the lack of information.  However, it could be improved by suggesting alternative ways to find the information.",5,"The answer is grammatically correct, well-written, and easy to understand.  It's concise and polite.",3,"The answer is not directly actionable in the sense that it doesn't provide the requested information. However, it's usable in that it honestly states the lack of information.  Adding suggestions for finding the information would improve actionability.","The answer could be improved by adding a suggestion, such as:  ""根据目前提供的资料，我无法找到关于Alpha项目负责人的明确信息。您可以尝试搜索公司内部项目数据库或联系相关项目团队成员获取更多信息。"""
a5-rag-005,解释一下什么是量子纠缠？,量子纠缠是指当几个粒子在彼此相互作用后，由于各个粒子所拥有的特性已综合成为整体性质，无法单独描述各个粒子的性质，只能描述整体系统的性质的现象。,3,The answer is grammatically correct and attempts to define quantum entanglement.,The answer is not faithful to the provided context and offers an incomplete and potentially misleading explanation of quantum entanglement.,2,"The answer's definition of quantum entanglement is not directly supported by the provided context. While the context mentions the instantaneous influence on other particles upon measurement of one entangled particle, the answer focuses on the inability to describe individual particle properties after interaction, which is a simplification and not a complete or accurate representation of the phenomenon as described in the context.",量子纠缠是指当几个粒子在彼此相互作用后，由于各个粒子所拥有的特性已综合成为整体性质，无法单独描述各个粒子的性质，只能描述整体系统的性质的现象。,4,"The answer is relevant to the user's question as it attempts to define quantum entanglement. However, the inaccuracy of the definition lowers the relevance score.",Partially Sufficient,The context provides a basic definition of quantum entanglement but lacks a comprehensive explanation.  It highlights the key aspect of instantaneous influence across distance but doesn't delve into the underlying quantum mechanics.,2,"The answer is incomplete because it doesn't capture the essence of quantum entanglement as presented in the context.  It omits the crucial element of instantaneous influence across spatial separation.  While the context is partially sufficient, the answer fails to utilize the available information effectively.",4,The answer is grammatically correct and coherent. The language is clear and easy to understand.,2,"The answer provides a definition, but the inaccurate definition makes it unusable for an office worker seeking a proper understanding of quantum entanglement.  It doesn't offer any practical application or further information.","The answer should directly reflect the information provided in the context.  It should mention the instantaneous influence on other particles when one entangled particle is measured, and explicitly state that this effect occurs even when the particles are spatially separated.  Adding a phrase like 'regardless of the distance separating them' would improve the accuracy and completeness of the answer.  The answer should avoid introducing concepts not supported by the provided context."
a6-rag-006,公司下一季度的主要目标是什么？,公司下一季度的主要目标是提升市场份额和用户满意度。,3,The answer is relevant to the user's question and uses appropriate language.,"The answer is partially faithful and incomplete, hallucinating the addition of 'user satisfaction' as a key objective.",3,"The answer correctly identifies the increase in market share as a key objective, directly supported by the context. However, it adds 'user satisfaction,' which is not mentioned in the provided context. This constitutes a hallucination.",用户满意度,4,"The answer directly addresses the user's question about the company's main objectives for the next quarter.  While partially inaccurate, it stays on topic.",Partially Sufficient,"The context only provides one key objective.  While sufficient to answer part of the question, it lacks a complete picture of all objectives for the next quarter.",3,"The answer only partially uses the available context. It correctly mentions the market share increase but adds an unsupported objective.  Given the limited context, it doesn't explicitly state the limitations of its knowledge.",5,"The answer is well-written, grammatically correct, and easy to understand.",3,"The answer provides some relevant information, but the hallucinated addition of 'user satisfaction' reduces its usability. An office worker would need to verify the accuracy of the information.","The answer should be revised to only include information directly supported by the context.  It should state that, based on the available information, the primary objective for the next quarter is to increase market share by at least 5%, and that other objectives may exist but are not currently known based on the provided data."
a1-rag-001,总结一下关于AI在医疗领域应用的主要内容。,AI在医疗领域的主要应用包括辅助诊断（如通过图像识别分析医疗影像，识别病变），个性化治疗方案的制定（基于患者基因和生活习惯数据），以及新药研发加速（通过预测分子结构和药物反应）。,4,"The answer is concise, well-structured, and accurately reflects the main points presented in the provided context.","The answer is slightly incomplete as it doesn't explicitly mention the improved accuracy sometimes exceeding human experts, a key detail from the context.",4,"All information presented is directly supported by the context.  The answer is a good summary, but omits some detail (e.g., the higher accuracy of AI in medical imaging compared to human experts).",,5,The answer directly and completely addresses the user's request to summarize the main applications of AI in medicine.,Sufficient,The provided context offers sufficient information to answer the user's question about the main applications of AI in healthcare.,4,"The answer covers the main points but could be more complete by including the detail about AI's superior accuracy in some medical imaging tasks, as mentioned in the first context snippet.",5,"The answer is well-written, grammatically correct, and logically structured.  It's easy to understand.",4,"The answer provides a clear and concise summary, useful for an office worker needing a quick overview of AI applications in healthcare.  While not actionable in a direct, task-oriented sense, it provides valuable background information.","To enhance completeness, the answer could add a phrase like:  ""...in medical imaging, sometimes exceeding the accuracy of human experts."" This would incorporate a key detail from the provided context."
a2-rag-002,我们公司上季度的营销活动预算是多少？,根据提供的信息，我们公司上季度的营销活动预算是50万元。,5,"The answer is concise, accurate, and directly addresses the user's question using the provided context.",No significant weaknesses.,5,"The answer accurately reflects the information provided in both context snippets.  The 500,000 yuan budget is explicitly stated in both.",,5,The answer directly and completely answers the user's question about the marketing budget for the last quarter.,Sufficient,The provided context clearly and directly states the marketing budget for Q3.  No additional information is needed to answer the question.,5,The answer is complete given the sufficient context. It extracts and presents the relevant information effectively.,5,"The answer is grammatically correct, well-structured, and easy to understand.  The language is clear and professional.",5,"The answer provides a clear and concise answer to the user's question, making it immediately actionable for an office worker who needs this budget information.",No improvement needed.
a3-rag-003,请告诉我关于月球的三个有趣事实。,月球是地球唯一的天然卫星，它的自转周期与公转周期相同，因此总是以同一面朝向地球。此外，月球的引力导致了地球上的潮汐现象，并且月球上没有大气层。,3,"The answer is fluent and mostly coherent, incorporating information directly from the provided context.","The answer is incomplete, failing to provide three facts as requested, and includes a hallucinated fact ('月球上没有大气层').",3,"The first two sentences accurately reflect the provided context. However, the statement '并且月球上没有大气层' is a hallucination; this information was not present in the context.",并且月球上没有大气层,4,"The answer addresses the user's request for facts about the moon, but it does not fulfill the quantity requested (three facts).",Insufficient,"The context only provides two facts about the moon.  To answer the question fully, more information is needed.",2,"The answer only provides two facts from the context and adds a hallucinated fact.  Given the insufficient context, it should have acknowledged the limitation and only presented the two available facts.",4,The answer is well-written and grammatically correct. The flow of information is logical and easy to understand.,3,"The answer provides some factual information about the moon, but its incompleteness and inclusion of a hallucination reduce its usability.  An office worker would likely need to seek additional information elsewhere.","The AI should explicitly state that it can only provide two facts based on the available context.  It should avoid hallucinating information.  To improve, the system needs access to a broader knowledge base to provide a complete answer to the user's request for three facts."
a4-rag-004,Alpha项目的负责人是谁？,根据目前提供的资料，我无法找到关于您问题的明确信息。,4,The answer is honest and accurately reflects the limitations of the provided context.,"While truthful, the answer doesn't offer any suggestions or alternative approaches to find the information, which would be helpful for an office worker assistant.",5,"The answer is completely faithful to the provided context.  The context does not contain information about the Alpha project's leader, and the answer correctly states this.",,5,"The answer directly addresses the user's question about the Alpha project leader.  Although it doesn't provide an answer, it accurately reflects the lack of information in the context.",Insufficient,"The context only provides information about projects Beta and Gamma, and a list of projects that includes Delta, but not Alpha.",4,"Given the insufficient context, the answer is complete in acknowledging the lack of information.  However, a more helpful response might suggest alternative ways to find the information (e.g., 'The provided documents do not list the Alpha project leader.  To find this information, you could check [suggestion 1], [suggestion 2], or contact [contact person].')",5,"The answer is grammatically correct, concise, and easy to understand.",3,"The answer is truthful but not very actionable.  While it correctly states that the information is unavailable, it doesn't offer any guidance on how to obtain the missing information.  A more usable response would provide suggestions for finding the information.",The answer could be improved by adding suggestions on how to find the information about the Alpha project leader. For example:  '根据目前提供的资料，我无法找到关于Alpha项目负责人的明确信息。您可以尝试查看项目管理系统，或者联系项目相关人员获取信息。'
a5-rag-005,解释一下什么是量子纠缠？,量子纠缠是指当几个粒子在彼此相互作用后，由于各个粒子所拥有的特性已综合成为整体性质，无法单独描述各个粒子的性质，只能描述整体系统的性质的现象。,3,The answer is grammatically correct and attempts to define quantum entanglement.,The answer is a significant simplification and doesn't accurately reflect the nuanced explanation provided in the context.  It omits the crucial aspect of instantaneous influence across distances.,3,"The answer is partially faithful. While it doesn't directly contradict the context, it significantly simplifies the concept. The context emphasizes the instantaneous influence on separated particles, which is missing from the generated answer. The generated answer focuses on the integrated nature of properties after interaction, which is a less complete and accurate description.",量子纠缠是指当几个粒子在彼此相互作用后，由于各个粒子所拥有的特性已综合成为整体性质，无法单独描述各个粒子的性质，只能描述整体系统的性质的现象。,4,"The answer is relevant to the user's question as it attempts to define quantum entanglement. However, due to its incompleteness, it doesn't fully address the core concept.",Sufficient,"The provided context gives a concise but accurate definition of quantum entanglement, including the key element of instantaneous influence across distances.",2,The answer is incomplete because it fails to capture the most important aspect of quantum entanglement highlighted in the context: the instantaneous correlation between spatially separated particles.  The context provides sufficient information for a more complete and accurate answer.,4,The answer is grammatically correct and coherent.  The language is clear and understandable.,3,"The answer provides a definition, but it's an oversimplified and incomplete one.  For an office worker, this definition would be insufficient for understanding the concept.  It lacks the crucial detail of instantaneous correlation.","The answer should incorporate the key information from the context, specifically the instantaneous influence on separated particles.  A better answer would be:  'Quantum entanglement, according to quantum mechanics, is a phenomenon where two or more particles become linked in such a way that measuring the state of one instantly affects the state of the others, even when they are spatially separated.  Einstein famously called this “spooky action at a distance”.'"
a6-rag-006,公司下一季度的主要目标是什么？,公司下一季度的主要目标是提升市场份额和用户满意度。,3,The answer is relevant to the user's question and uses appropriate language.,"The answer is partially faithful and incomplete, hallucinating the addition of 'user satisfaction' as a key objective.",3,"The answer correctly identifies the increase in market share as a key objective, directly supported by the context. However, it adds 'user satisfaction,' which is not mentioned in the provided context. This constitutes a hallucination.",用户满意度,4,"The answer directly addresses the user's question about the company's next quarter's main objectives.  While incomplete, the core element of market share increase is relevant.",Partially Sufficient,"The context only provides one objective.  While sufficient to answer part of the question, it lacks a complete picture of the company's objectives for the next quarter.",3,"The answer only partially uses the available context. It correctly states the market share increase but adds an unsupported objective.  Given the limited context, it could have acknowledged the lack of further information.",4,"The answer is well-written, grammatically correct, and easy to understand. The phrasing is natural and professional.",3,"The answer provides some useful information, but its incompleteness and hallucination reduce its actionability. An office worker would only get a partial understanding of the company's objectives.","The answer should explicitly state that the provided information only reflects one of the company's objectives for the next quarter, as stated by the CEO.  It should avoid adding information not present in the context.  A better response would be: 'Based on the CEO's statement, a key objective for the next quarter is to increase market share by at least 5%.  Further information on other objectives is not available in the provided context.'"
a1-rag-001,总结一下关于AI在医疗领域应用的主要内容。,AI在医疗领域的主要应用包括辅助诊断（如通过图像识别分析医疗影像，识别病变），个性化治疗方案的制定（基于患者基因和生活习惯数据），以及新药研发加速（通过预测分子结构和药物反应）。,4,"The answer is concise, well-structured, and accurately reflects the main points presented in the provided context.","The answer is slightly incomplete as it doesn't explicitly mention the improved accuracy sometimes exceeding human experts in medical image analysis, a key point from the context.",4,"All claims are directly supported by the context.  The answer is a good summary of the provided information. While it doesn't explicitly state the higher accuracy of AI in medical image analysis compared to human experts, this is a reasonable omission given the focus on summarizing the main applications.",,5,The answer directly and completely addresses the user's request to summarize the main applications of AI in the medical field.,Sufficient,"The context provides three key applications of AI in medicine: image analysis, personalized treatment, and drug development.  This is enough information to answer the question.",4,"The answer covers the three main applications mentioned in the context. However, it could be slightly more complete by including the detail about AI's potential to surpass human accuracy in image analysis, as mentioned in Context Snippet 1.",5,"The answer is grammatically correct, well-structured, and easy to understand.  The language is clear and professional.",4,"The summary provides useful information for an office worker, perhaps researching AI applications in healthcare.  While it doesn't offer actionable steps, it provides a clear and concise overview of the topic.","To enhance completeness, the answer could be slightly expanded to include the detail from Context Snippet 1 regarding the potential for AI to exceed human expert accuracy in medical image analysis.  For example,  '...including improved accuracy in medical image analysis, sometimes exceeding that of human experts...' could be added."
a2-rag-002,我们公司上季度的营销活动预算是多少？,根据提供的信息，我们公司上季度的营销活动预算是50万元。,5,"The answer is concise, accurate, and directly addresses the user's question using the provided context.",No significant weaknesses.,5,"The answer accurately reflects the information provided in both context snippets.  The 500,000 yuan budget is explicitly stated in both.",,5,The answer directly and completely answers the user's question about the marketing budget for the last quarter.,Sufficient,The provided context clearly and directly states the marketing budget for Q3.  No additional information is needed to answer the question.,5,The answer is complete given the sufficient context. It extracts and presents the relevant information effectively.,5,"The answer is grammatically correct, concise, and easy to understand.  The language is clear and professional.",5,"The answer provides a clear and concise answer to the user's question, directly providing the information needed for an office worker to proceed with their task.  The format is simple and easy to understand.",No improvement needed.
a3-rag-003,请告诉我关于月球的三个有趣事实。,月球是地球唯一的天然卫星，它的自转周期与公转周期相同，因此总是以同一面朝向地球。此外，月球的引力导致了地球上的潮汐现象，并且月球上没有大气层。,3,"The answer is fluent and mostly coherent, incorporating information directly from the provided context.","The answer is incomplete, failing to provide three facts as requested, and includes a hallucinated fact ('月球上没有大气层').",3,"The first two sentences accurately reflect the provided context. However, the statement '并且月球上没有大气层' is a hallucination; this information was not present in the context.",并且月球上没有大气层,4,"The answer is relevant to the user's question about interesting facts about the moon.  It addresses the core request, although incompletely.",Insufficient,"The context only provides two facts about the moon.  To fully answer the question, more information is needed.",2,"The answer only provides two facts from the context and adds a hallucinated third fact.  Given the insufficient context, it doesn't explicitly state the limitation, but it fails to meet the user's request for three facts.",4,"The answer is well-written, grammatically correct, and easy to understand. The flow of information is logical.",3,"The answer provides some interesting facts about the moon, but the incompleteness and hallucination reduce its usability.  While the information is factual (except for the hallucination), it's not sufficient to fully satisfy the user's request.",The AI should explicitly state that it can only provide two facts based on the given context and should avoid hallucinating additional information.  It could also suggest searching for additional information to fulfill the user's request for three facts.
a4-rag-004,Alpha项目的负责人是谁？,根据目前提供的资料，我无法找到关于您问题的明确信息。,4,The answer is honest and accurately reflects the limitations of the provided context.,"While truthful, the answer doesn't offer any suggestions or alternative approaches to find the information, which would be helpful for an office worker assistant.",5,"The answer is completely faithful to the provided context.  The context does not contain information about the Alpha project's leader, and the answer correctly states this.",,5,"The answer directly addresses the user's question about the Alpha project leader.  Although it doesn't provide a name, it accurately reflects the lack of information in the context.",Insufficient,"The context only provides information about projects Beta, Gamma, and Delta.  Information about Project Alpha is missing.",4,"Given the insufficient context, the answer is complete. It correctly identifies the lack of relevant information.  However, a more helpful response might suggest alternative ways to find the information (e.g., 'The provided documents do not list the Alpha project leader.  Could you provide additional documents or search the company directory?') ",5,"The answer is grammatically correct, clearly written, and easy to understand.",3,"The answer is truthful but not very actionable. While it correctly states that the information is unavailable, it doesn't offer any suggestions on how the user might find the information.  A more helpful response would suggest alternative search methods or resources.",The answer could be improved by adding a suggestion for alternative ways to find the information. For example:  '根据目前提供的资料，我无法找到关于Alpha项目负责人的明确信息。您可以尝试搜索公司内部数据库或联系相关项目团队以获取更多信息。'
a5-rag-005,解释一下什么是量子纠缠？,量子纠缠是指当几个粒子在彼此相互作用后，由于各个粒子所拥有的特性已综合成为整体性质，无法单独描述各个粒子的性质，只能描述整体系统的性质的现象。,3,The answer is grammatically correct and attempts to define quantum entanglement.,The answer is not faithful to the provided context and misses key aspects of quantum entanglement as described in the context.  It introduces concepts not supported by the provided text.,2,"The answer's definition of quantum entanglement is not directly supported by the provided context. While the context mentions the instantaneous influence on other particles upon measurement of one entangled particle, the answer focuses on the inability to describe individual particle properties after interaction, which is a different, albeit related, concept.  The context does not explicitly state this as the defining characteristic of entanglement.",量子纠缠是指当几个粒子在彼此相互作用后，由于各个粒子所拥有的特性已综合成为整体性质，无法单独描述各个粒子的性质，只能描述整体系统的性质的现象。,4,"The answer is relevant to the user's question as it attempts to define quantum entanglement. However, its inaccuracy reduces its overall relevance.",Partially Sufficient,The context provides a basic definition of quantum entanglement but lacks a complete explanation.  It highlights the instantaneous effect across distances but doesn't fully explain the underlying principles.,2,The answer is incomplete because it doesn't capture the essence of quantum entanglement as presented in the context (instantaneous influence across distances). It offers a related but ultimately inaccurate and incomplete description.,4,The answer is grammatically correct and coherent. The language is clear and easy to understand.,2,"The answer provides a definition, but the inaccurate definition makes it not very useful for an office worker.  It doesn't offer any practical application or further information.","The answer should directly reflect the information provided in the context.  It should emphasize the instantaneous correlation between the states of entangled particles, even when separated by distance.  A better answer would be:  'Quantum entanglement is a phenomenon where two or more particles become linked in such a way that measuring the state of one instantly affects the state of the others, regardless of the distance separating them.  This is described by Einstein as “spooky action at a distance”.'"
a6-rag-006,公司下一季度的主要目标是什么？,公司下一季度的主要目标是提升市场份额和用户满意度。,3,The answer is relevant to the user's question and uses appropriate language.,"The answer is partially faithful and incomplete, hallucinating the addition of 'user satisfaction' as a key objective.",3,"The answer correctly identifies the increase in market share as a key objective, directly supported by the context. However, it adds 'user satisfaction,' which is not mentioned in the provided context. This constitutes a hallucination.",用户满意度,4,"The answer directly addresses the user's question about the company's main objectives for the next quarter.  While partially inaccurate, it stays on topic.",Partially Sufficient,"The context only provides one key objective.  While sufficient to answer part of the question, it lacks a complete picture of the company's goals for the next quarter.",3,"The answer is incomplete because it only partially uses the available context and adds an unsupported objective.  Given the limited context, it could have acknowledged the lack of further information.",4,"The answer is well-written, grammatically correct, and easy to understand.  The phrasing is natural and professional.",3,"The answer provides some useful information, but its incompleteness and hallucination reduce its practical value. An office worker would need to seek additional information to get a full picture of the company's objectives.","The answer should be revised to only include information directly supported by the context.  It could state: 'The primary objective for the next quarter is to increase market share by at least 5%, as emphasized by the CEO.'  If the model lacks further information, it should explicitly state this limitation."

    --- END OF FILE CONTENT ---

  File: analysis_cypher_gemini_flash_20250530.csv
    --- START OF FILE CONTENT ---
﻿interaction_id_ref,user_question,generated_cypher,overall_quality_score,main_strength,main_weakness,syntax_score,syntax_reasoning,schema_overall_score,schema_node_label_correct,schema_entity_type_correct,schema_rel_type_correct,schema_prop_name_correct,schema_hallucinated_present,schema_hallucinated_elements,schema_reasoning,intent_score,intent_explanation_cypher,intent_alignment_notes,intent_key_elements_notes,intent_reasoning,qwen_error_patterns,gemini_suggestion
c1-rag-001,张三在哪里工作？,"MATCH (p:ExtractedEntity {text: '张三', label: 'PERSON'})-[:WORKS_AT]->(org:ExtractedEntity {label: 'ORGANIZATION'}) RETURN org.text AS organizationName",5,完全符合Schema，准确表达了用户意图。,无明显弱点。,5,语法正确。,5,True,True,True,True,False,,完美遵循Schema。,5,查询张三工作的组织名称。,完全对齐。,覆盖所有关键元素。,准确。,,No improvement needed.
c2-rag-002,李四负责了哪些任务，并且这些任务的负责人是谁？,"MATCH (task:ExtractedEntity {label: 'TASK'})-[:ASSIGNED_TO]->(p:ExtractedEntity {text: '李四', label: 'PERSON'}), (task)-[:ASSIGNED_TO]->(assignee:ExtractedEntity {label: 'PERSON'}) RETURN task.text AS taskName, assignee.text AS assigneeName",3,基本Schema遵循正确。,查询逻辑未能完全表达用户意图，它会返回所有分配给李四的任务，以及这些任务的所有负责人，而不是仅李四负责的任务的负责人。,5,语法正确。,4,True,True,True,True,False,,Schema遵循良好。,2,查询所有分配给李四的任务，并列出这些任务的所有负责人。,部分对齐，但未能准确表达'李四负责的任务的负责人'这一约束，而是返回了李四参与的任务以及这些任务的所有负责人。,未能将'李四'作为任务的唯一负责人进行限定。,意图理解有偏差。,Over-simplification of complex conditions,"为了更准确地回答，查询应该确保只返回李四作为负责人的任务。可以考虑修改为：MATCH (task:ExtractedEntity {label: 'TASK'})-[:ASSIGNED_TO]->(p:ExtractedEntity {text: '李四', label: 'PERSON'}) RETURN task.text AS taskName, p.text AS assigneeName"
c3-rag-003,项目Alpha的状态是什么？,MATCH (t:Task {name: '项目Alpha'}) RETURN t.status,1,无。,严重违反Schema，使用了禁用标签:Task和未定义属性status。,3,语法上可能勉强通过，但逻辑基于错误Schema。,1,False,False,True,False,True,":Task, name, status",严重Schema违规。,2,尝试查询名为项目Alpha的Task节点的状态属性。,如果Schema支持，意图是对的，但当前Schema不支持。,关键元素是状态，但Schema不支持。,基于错误Schema，无法准确评估意图。,Incorrect handling of the ':ExtractedEntity' and 'label' property convention,无法生成Cypher查询。问题询问的'状态'属性在当前Schema中未定义。
c4-rag-004,王五的直属上级是谁？,无法生成Cypher查询.,5,正确判断无法基于Schema生成查询。,无。,5,非查询，不适用语法评分，但输出符合要求。,5,True,True,True,True,False,,正确判断无法生成。,5,明确指出无法生成查询。,完全对齐，因为Schema不支持'直属上级'关系。,正确识别到Schema限制。,准确判断。,,无法生成Cypher查询。
c6-rag-006,数据库中有多少人？, ,1,无。,Qwen输出为空，未能生成有效查询或'无法生成'的判断。,1,空字符串不是有效Cypher。,1,False,False,False,False,False,,空输出，无法评估Schema遵循。,1,空字符串，不执行任何操作。,完全未对齐。,未处理问题。,无效输出。,Other,MATCH (p:ExtractedEntity {label: 'PERSON'}) RETURN count(p) AS numberOfPeople

    --- END OF FILE CONTENT ---

  File: analysis_cypher_gemini_flash_20250531.csv
    --- START OF FILE CONTENT ---
﻿interaction_id_ref,user_question,generated_cypher,overall_quality_score,main_strength,main_weakness,syntax_score,syntax_reasoning,schema_overall_score,schema_node_label_correct,schema_entity_type_correct,schema_rel_type_correct,schema_prop_name_correct,schema_hallucinated_present,schema_hallucinated_elements,schema_reasoning,intent_score,intent_explanation_cypher,intent_alignment_notes,intent_key_elements_notes,intent_reasoning,qwen_error_patterns,gemini_suggestion
c1-rag-001,张三在哪里工作？,"MATCH (p:ExtractedEntity {text: '张三', label: 'PERSON'})-[:WORKS_AT]->(org:ExtractedEntity {label: 'ORGANIZATION'}) RETURN org.text AS organizationName",5,The query perfectly adheres to the schema and accurately answers the user's question.,None. The query is excellent.,5,The Cypher query is syntactically perfect and will parse without errors in Neo4j.,5,True,True,True,True,False,,"The query perfectly adheres to all aspects of the provided schema.  No undefined labels, properties, or relationships are used.  All relationships have the correct direction and connect nodes of the correct types.",5,"This Cypher query finds all 'ORGANIZATION' nodes connected to a 'PERSON' node with the text '张三' via a ':WORKS_AT' relationship.  It then returns the 'text' property of the found 'ORGANIZATION' node, representing the name of the organization where 张三 works.",The retrieved information perfectly aligns with the user's question: '张三在哪里工作？' (Where does Zhang San work?).,"All key elements – the person ('张三'), the relationship (:WORKS_AT), and the organization – are accurately represented in the query.",The query completely and accurately captures the user's intent.  It correctly identifies the relevant entities and relationships to answer the question.,,No improvements needed. This is a perfect query given the schema.
c2-rag-002,李四负责了哪些任务，并且这些任务的负责人是谁？,"MATCH (task:ExtractedEntity {label: 'TASK'})-[:ASSIGNED_TO]->(p:ExtractedEntity {text: '李四', label: 'PERSON'}), (task)-[:ASSIGNED_TO]->(assignee:ExtractedEntity {label: 'PERSON'}) RETURN task.text AS taskName, assignee.text AS assigneeName",2,The query uses the correct node label and properties.,"The query incorrectly interprets the 'and' condition in the user's question, leading to a semantically incorrect result. It also returns the assignee of each task, which is redundant since the question already specifies that the assignee is Li Si.",5,The Cypher query is syntactically correct and will parse without errors.,4,True,True,True,True,False,,"The query adheres to the schema in terms of node labels, properties, and relationship types. However, the logic of connecting two ':ASSIGNED_TO' relationships is flawed, leading to a semantic error.",2,"The query returns a list of tasks assigned to '李四', along with the name of the person each task is assigned to.  Since the question already states that Li Si is the assignee, the second part of the return is redundant and incorrect.","The query partially aligns with the user's question by identifying tasks assigned to '李四'. However, it misinterprets the 'and' condition and provides redundant information about the assignee.",The query covers '李四' and 'tasks' but misinterprets the 'and' clause. It doesn't correctly understand that the second part of the question ('and these tasks'负责人是谁') is implied by the first part.,The query fails to accurately capture the user's intent due to the incorrect handling of the 'and' condition. The redundant information further reduces the accuracy.,"Incorrect handling of the ':ExtractedEntity' and 'label' property convention, Ignoring multiple constraints from the user question","The correct query should only match tasks assigned to '李四'.  The second part of the question is redundant given the first.  A correct query would be: `MATCH (task:ExtractedEntity {label: 'TASK'})-[:ASSIGNED_TO]->(p:ExtractedEntity {text: '李四', label: 'PERSON'}) RETURN task.text AS taskName`"
c3-rag-003,项目Alpha的状态是什么？,MATCH (t:Task {name: '项目Alpha'}) RETURN t.status,1,The query is syntactically simple.,The query severely violates the schema rules by using incorrect node labels and properties.  It attempts to access a property ('status') that is not defined in the schema.,3,"The query is syntactically correct in the sense that Neo4j would likely parse it without throwing an error. However, it's semantically meaningless given the schema.",1,False,False,False,False,True,":Task, name, status","The query violates multiple schema rules, including the most crucial one: using the correct node label.  The use of undefined properties ('name', 'status') is also a major violation.  Therefore, a score of 1 is appropriate.",1,"This query attempts to retrieve the 'status' property of a node labeled ':Task' with the 'name' property equal to '项目Alpha'.  However, since ':Task' and 'status' are not part of the schema, it would not retrieve any meaningful information.",The query does not align with the user's question because it relies on schema elements that do not exist.,"The query misses the key requirement of adhering to the defined schema. It attempts to retrieve 'status', which is not a defined property.  The key entity '项目Alpha' is present but incorrectly handled.",The query completely fails to capture the user's intent due to its severe schema violations.  It attempts to access information that is not present in the knowledge graph according to the provided schema.,"Incorrect handling of the ':ExtractedEntity' and 'label' property convention, Hallucination of schema elements (node labels and properties)",The query cannot be improved within the constraints of the provided schema.  The user's question requires information ('status') that is not available in the defined knowledge graph.  The response should be '无法生成Cypher查询。'
c5-rag-005,查询所有组织机构。,MATCH (o:ExtractedEntity {label: 'ORGANIZATION'}) RETURN o.text,3,The query is syntactically correct and attempts to retrieve the requested information.,It violates the schema rules by using a node label other than ':ExtractedEntity'.,5,The Cypher query is syntactically valid and will parse without errors in Neo4j.,1,False,False,True,True,True,ORGANIZATION,"The query severely violates the schema by using an incorrect node label.  This is a critical flaw, resulting in a low score.  The use of the label property is also incorrect in its implementation.",3,"If the schema were to allow the node label 'ORGANIZATION', this query would return the 'text' property of all nodes with that label.  This would represent the names or descriptions of all organizations in the database.","The query partially aligns with the user's intent. It aims to retrieve organizations, but the method is incorrect according to the schema.","The query covers the key entity 'organization', but it fails to use the schema-defined way to represent it.","The intent is partially captured, but the severe schema violation significantly impacts the accuracy.  The query would only work if the schema were different.",Incorrect handling of the ':ExtractedEntity' and 'label' property convention,MATCH (o:ExtractedEntity {label: 'ORGANIZATION'}) RETURN o.text
c1-rag-001,张三在哪里工作？,"MATCH (p:ExtractedEntity {text: '张三', label: 'PERSON'})-[:WORKS_AT]->(org:ExtractedEntity {label: 'ORGANIZATION'}) RETURN org.text AS organizationName",5,The query perfectly adheres to the schema and accurately answers the user's question.,None. The query is excellent.,5,The Cypher query is syntactically perfect and will parse without errors in Neo4j.,5,True,True,True,True,False,,"The query perfectly adheres to all aspects of the schema.  No undefined labels, properties, or relationships are used.  The relationship direction is correct.",5,"This query finds the organization where the person with the text '张三' works.  It returns the 'text' property of the organization node, representing the organization's name.",The retrieved information perfectly aligns with the user's question. The query directly answers 'where 张三 works'.,"All key elements ('张三', 'PERSON', 'WORKS_AT', 'ORGANIZATION') are correctly represented in the query.","The query accurately captures the user's intent. It correctly identifies the person, the relationship, and the organization, returning the expected information.",,No improvements needed.  The query is already optimal.
c2-rag-002,李四负责了哪些任务，并且这些任务的负责人是谁？,"MATCH (task:ExtractedEntity {label: 'TASK'})-[:ASSIGNED_TO]->(p:ExtractedEntity {text: '李四', label: 'PERSON'}), (task)-[:ASSIGNED_TO]->(assignee:ExtractedEntity {label: 'PERSON'}) RETURN task.text AS taskName, assignee.text AS assigneeName",2,The query uses the correct node label and properties.,"The query incorrectly interprets the 'and' condition in the user's question, leading to a semantically incorrect result.  It also returns the assignee even if it's the same as Li Si.",5,The Cypher query is syntactically correct and will parse without errors.,4,True,True,True,True,False,,"The query adheres to the schema in terms of labels, properties, and relationships. However, the logic of connecting two :ASSIGNED_TO relationships to the same task node is flawed and doesn't accurately reflect the user's intent.",2,"This query finds all tasks assigned to '李四' and then, for each of those tasks, it finds the person assigned to that task.  This means it will return a row for each person assigned to each task assigned to Li Si, even if Li Si is the assignee.","The query does not accurately reflect the user's intent. The user wants to know which tasks Li Si is responsible for, and who is responsible for those tasks. The query returns the assignee for each task, even if that assignee is Li Si himself.",The query misses the crucial 'and' condition. It treats the two parts of the question as independent clauses instead of a conjunctive statement.  It doesn't correctly identify that the 'assignee' should only be returned if it is different from Li Si.,"The query has a significant flaw in its interpretation of the user's intent.  It fails to capture the 'and' condition correctly, leading to an inaccurate result. The score is low because of this semantic error.","Incorrect handling of the ':ExtractedEntity' and 'label' property convention, Ignoring multiple constraints from the user question","MATCH (task:ExtractedEntity {label: 'TASK'})-[:ASSIGNED_TO]->(p:ExtractedEntity {text: '李四', label: 'PERSON'}) WITH task OPTIONAL MATCH (task)-[:ASSIGNED_TO]->(assignee:ExtractedEntity {label: 'PERSON'}) WHERE assignee.text <> '李四' RETURN task.text AS taskName, assignee.text AS assigneeName"
c3-rag-003,项目Alpha的状态是什么？,MATCH (t:Task {name: '项目Alpha'}) RETURN t.status,1,The query is syntactically correct (assuming a `Task` node label exists).,The query severely violates the schema by using an incorrect node label and property name.  It attempts to access a property ('status') that is not defined in the schema.,3,"The query is syntactically correct if a node with label `Task` and property `name` exists. However, this is not allowed by the schema.",1,False,False,True,False,True,":Task, name, status","The query has multiple gross violations of the schema, including using an incorrect node label and undefined properties.  Therefore, a score of 1 is appropriate.",1,"If the graph contained nodes with the label `Task` and a property `name`, this query would return the value of the `status` property for the node with `name` equal to '项目Alpha'. However, this is not possible given the schema.",The query does not align with the user's question because it uses schema elements that are not defined.,The query misses the key requirement of adhering to the specified schema. It fails to use the correct node label and properties.,The query completely misses the user's intent due to its severe schema violations.  It attempts to retrieve information that is not present in the graph according to the schema.,"Incorrect handling of the ':ExtractedEntity' and 'label' property convention, Hallucinated schema elements",The query cannot be improved within the constraints of the provided schema.  The question itself cannot be answered using the current schema because it requires information (task status) that is not modeled.
c5-rag-005,查询所有组织机构。,MATCH (o:ExtractedEntity {label: 'ORGANIZATION'}) RETURN o.text,3,The query is syntactically correct and attempts to retrieve the requested information.,It violates the schema rules by using a node label other than ':ExtractedEntity'.,5,The Cypher query is syntactically valid and will parse without errors in Neo4j.,1,False,False,True,True,True,ORGANIZATION,"The query severely violates the schema by using an incorrect node label.  This is a critical flaw, resulting in a low score.  The use of the label property is also incorrect in its implementation.",3,"If the schema were to allow the label 'ORGANIZATION', this query would return the 'text' property of all nodes with the label 'ORGANIZATION'.  However, this is not allowed by the schema.","The query partially aligns with the user's intent, but only if the schema were different.  The intent is to retrieve all organizations, but the method is incorrect according to the provided schema.","The query attempts to address the key entity 'organization', but fails to do so correctly due to schema violations.","The intent is partially addressed, but the schema violations significantly impact the accuracy.  A score of 3 reflects this partial success, heavily penalized by the schema violations.",Incorrect handling of the ':ExtractedEntity' and 'label' property convention,MATCH (o:ExtractedEntity {label: 'ORGANIZATION'}) RETURN o.text
c1-rag-001,张三在哪里工作？,"MATCH (p:ExtractedEntity {text: '张三', label: 'PERSON'})-[:WORKS_AT]->(org:ExtractedEntity {label: 'ORGANIZATION'}) RETURN org.text AS organizationName",5,The query perfectly adheres to the schema and accurately answers the user's question.,None. The query is excellent.,5,The Cypher query is syntactically perfect and will parse without errors in Neo4j.,5,True,True,True,True,False,,"The query perfectly adheres to all aspects of the provided schema.  No undefined labels, properties, or relationships are used.  The relationship direction is correct.",5,This Cypher query finds the organization where a person named '张三' works.  It returns the name of that organization.,The retrieved information perfectly aligns with the user's question. The query directly answers 'where 张三 works'.,"All key elements are covered: the person ('张三'), the relationship ':WORKS_AT', and the organization.  There are no missing or misinterpreted parts.","The query accurately captures the user's intent. It correctly identifies the person, the relationship, and the desired information (the organization's name).",,No improvements needed. The query is already optimal.
c2-rag-002,李四负责了哪些任务，并且这些任务的负责人是谁？,"MATCH (task:ExtractedEntity {label: 'TASK'})-[:ASSIGNED_TO]->(p:ExtractedEntity {text: '李四', label: 'PERSON'}), (task)-[:ASSIGNED_TO]->(assignee:ExtractedEntity {label: 'PERSON'}) RETURN task.text AS taskName, assignee.text AS assigneeName",2,The query uses the correct node label and properties.,"The query incorrectly interprets the 'and' condition in the user's question, leading to an inaccurate result.  It also returns the assignee even if it's the same as Li Si.",5,The Cypher query is syntactically correct and will parse without errors.,3,True,True,True,True,False,,"While the query uses only schema-defined elements, its interpretation of the 'and' condition is flawed, resulting in a lower score.  It doesn't correctly represent the user's intent to find distinct assignees for each task.",2,"This query returns a list of tasks assigned to '李四', along with the person assigned to each task.  However, it will list Li Si as the assignee for each of his tasks, even if he is the only assignee.","The query partially aligns with the user's question. It finds tasks assigned to Li Si, but it doesn't correctly handle the 'and' condition to find distinct assignees for each task. The query also doesn't distinguish between Li Si and other assignees.",The query misses the crucial aspect of finding *different* assignees for each task.  The 'and' condition is not correctly interpreted as two separate match patterns linked by a common task node. It treats the two `:ASSIGNED_TO` relationships as if they could exist on the same node simultaneously.,"The low score reflects the misinterpretation of the 'and' condition, leading to an inaccurate and incomplete answer to the user's question. The query doesn't distinguish between Li Si and other assignees for the tasks.","Incorrect handling of the ':ExtractedEntity' and 'label' property convention, Ignoring multiple constraints from the user question","The query needs to be rewritten to correctly handle the 'and' condition.  It should use two separate MATCH clauses connected by a common task node.  For example:

```cypher
MATCH (task:ExtractedEntity {label: 'TASK'})-[:ASSIGNED_TO]->(p:ExtractedEntity {text: '李四', label: 'PERSON'})
MATCH (task)-[:ASSIGNED_TO]->(assignee:ExtractedEntity {label: 'PERSON'}) 
WHERE p.text <> assignee.text
RETURN task.text AS taskName, collect(assignee.text) AS assigneeNames
```
This revised query uses two separate MATCH clauses connected by the `task` node, correctly representing the 'and' condition. The `WHERE` clause ensures that Li Si is not included in the list of assignees.  The `collect` function aggregates multiple assignees for a single task."
c3-rag-003,项目Alpha的状态是什么？,MATCH (t:Task {name: '项目Alpha'}) RETURN t.status,1,The query is syntactically simple.,The query severely violates the schema rules by using incorrect node labels and properties.  It attempts to access a property ('status') that does not exist in the defined schema.,3,"The Cypher query is syntactically valid, but it would likely produce an error because the `status` property doesn't exist on the nodes in the specified graph.",1,False,False,False,False,True,":Task, name, status","The query grossly violates the schema by using an undefined node label, undefined properties, and no relationships.  It fundamentally misinterprets the schema's structure.",1,"The query attempts to retrieve the 'status' property of a node labeled ':Task' with the 'name' property equal to '项目Alpha'.  Since ':Task' and 'status' are not part of the schema, it would return nothing.","The query does not align with the user's question because it uses schema elements that are not defined. The user's intent is to find the status of '项目Alpha', but the query cannot express this within the constraints of the provided schema.",The query misses the key element of using ':ExtractedEntity' and the 'label' property to represent the entity type. It also hallucinates the 'status' property and the ':Task' label.,The intent accuracy is extremely low because the query fundamentally misinterprets the schema and cannot retrieve the information the user is requesting.  It hallucinates schema elements that are not defined.,"Incorrect handling of the ':ExtractedEntity' and 'label' property convention, Hallucination of schema elements (node labels and properties)",The query cannot be improved within the constraints of the provided schema because the question requires information (project status) that is not represented in the schema.  The response should be '无法生成Cypher查询。'
c5-rag-005,查询所有组织机构。,MATCH (o:ExtractedEntity {label: 'ORGANIZATION'}) RETURN o.text,3,The query is syntactically correct and attempts to retrieve the requested information.,It violates the schema by using a node label other than ':ExtractedEntity'.,5,The Cypher query is syntactically valid and will parse without errors in Neo4j.,1,False,True,True,True,False,,"The overall schema adherence score is 1 because the query violates the most crucial rule: it implicitly uses a node label other than ':ExtractedEntity'.  While the use of `label` property is correct, the implicit use of a different label is a critical failure.",3,"If the graph contained nodes with the label ':ORGANIZATION', this query would return the `text` property of each of those nodes.  However, the schema mandates the use of ':ExtractedEntity' with a 'label' property.","The query partially aligns with the user's intent. It aims to retrieve organizations, but it does so using an incorrect node label.","The query covers the key entity 'organization' but uses an incorrect label, making it fail to adhere to the schema.","The intent accuracy score is 3 because, while the intent is clear, the query's execution would be incorrect given the strict schema constraints.  It partially addresses the intent but fails critically in schema adherence.",Incorrect handling of the ':ExtractedEntity' and 'label' property convention,MATCH (o:ExtractedEntity {label: 'ORGANIZATION'}) RETURN o.text
c1-rag-001,张三在哪里工作？,"MATCH (p:ExtractedEntity {text: '张三', label: 'PERSON'})-[:WORKS_AT]->(org:ExtractedEntity {label: 'ORGANIZATION'}) RETURN org.text AS organizationName",5,The query perfectly adheres to the schema and accurately answers the user's question.,None. The query is excellent.,5,The Cypher query is syntactically perfect and will parse without errors in Neo4j.,5,True,True,True,True,False,,"The query perfectly adheres to all aspects of the provided schema.  No undefined labels, properties, or relationships are used.  The relationship direction is correct.",5,"This Cypher query finds all 'ExtractedEntity' nodes representing 'PERSON' with the text '张三'.  For each such node, it then follows the ':WORKS_AT' relationship to find connected 'ExtractedEntity' nodes representing 'ORGANIZATION'.  The query returns the 'text' property of the found organization nodes, effectively providing the name of the organization where '张三' works.",The retrieved information perfectly aligns with the user's question. The query directly answers 'where 张三 works'.,"All key elements ('张三', 'PERSON', 'WORKS_AT', 'ORGANIZATION') are correctly represented in the query.",The query accurately captures the user's intent by retrieving the organization where '张三' works.  There are no gaps or inaccuracies.,,No improvements needed. The query is already optimal.
c2-rag-002,李四负责了哪些任务，并且这些任务的负责人是谁？,"MATCH (task:ExtractedEntity {label: 'TASK'})-[:ASSIGNED_TO]->(p:ExtractedEntity {text: '李四', label: 'PERSON'}), (task)-[:ASSIGNED_TO]->(assignee:ExtractedEntity {label: 'PERSON'}) RETURN task.text AS taskName, assignee.text AS assigneeName",2,The query uses the correct node label and properties.,"The query incorrectly interprets the 'and' condition in the user's question, leading to a semantically incorrect result. It also returns the assignee of each task, which is redundant since the question already specifies that the assignee is Li Si.",5,The Cypher query is syntactically correct and will parse without errors.,4,True,True,True,True,False,,"The query adheres to the schema in terms of node labels, properties, and relationship types. However, the logical connection between the two parts of the query is flawed, which is a significant semantic issue, but not a schema violation.",2,"This query returns a list of tasks assigned to '李四', along with the name of the person assigned to each of those tasks.  Since the question already states that Li Si is the assignee, the second part of the result is redundant and misleading.","The query partially aligns with the user's question by identifying tasks assigned to '李四'. However, it fails to correctly interpret the 'and' clause, resulting in an incorrect and redundant second part of the result.","The query covers '李四' and 'tasks assigned to 李四'. However, it misinterprets the 'and' clause connecting the two parts of the question.  The second part of the query ('... (task)-[:ASSIGNED_TO]->(assignee:ExtractedEntity {label: 'PERSON'})') is semantically incorrect in the context of the question.",The query's low intent accuracy score is due to its misinterpretation of the 'and' condition.  It returns redundant information and doesn't accurately answer the user's question.,"Incorrect handling of the ':ExtractedEntity' and 'label' property convention (although the syntax is correct, the semantic interpretation of the 'and' condition is flawed), Ignoring multiple constraints from the user question (the 'and' clause is not correctly handled)","The correct query should use two separate MATCH clauses connected by a common node representing '李四'.  The second part of the query is unnecessary.  A better query would be:

`MATCH (p:ExtractedEntity {text: '李四', label: 'PERSON'})<-[:ASSIGNED_TO]-(task:ExtractedEntity {label: 'TASK'}) RETURN task.text AS taskName`"
c3-rag-003,项目Alpha的状态是什么？,MATCH (t:Task {name: '项目Alpha'}) RETURN t.status,1,The query is syntactically correct (assuming a `status` property exists).,The query severely violates the schema by using an incorrect node label and an undefined property.,3,"The query is syntactically correct, but only if a `Task` node with a `status` property exists.  This is not defined in the schema.",1,False,False,True,False,True,":Task, name, status",The query uses a node label and property that are not defined in the provided schema.  This is a gross violation of the schema rules.,1,"If the graph contained nodes with the label ':Task' and a property 'name', this query would return the 'status' property of the node with 'name' equal to '项目Alpha'.",The query does not align with the user's question because it uses schema elements not defined in the provided KG_SCHEMA_DESCRIPTION.,"The query misses the key requirement of adhering to the specified schema.  It attempts to retrieve the status, but the way it does so is completely invalid according to the schema.","The query's intent is partially correct in that it tries to find the status of '项目Alpha'. However, its complete disregard for the schema makes it completely inaccurate and unusable.","Incorrect handling of the ':ExtractedEntity' and 'label' property convention, Hallucinated schema elements",Unable to generate a valid Cypher query based on the provided schema. The question requires information (status) not present in the schema.
c5-rag-005,查询所有组织机构。,MATCH (o:ExtractedEntity {label: 'ORGANIZATION'}) RETURN o.text,3,The query is syntactically correct and attempts to retrieve the requested information.,It violates the schema rules by using a node label other than ':ExtractedEntity'.,5,The Cypher query is syntactically valid and will parse without errors in Neo4j.,1,False,False,True,True,True,ORGANIZATION,The query receives a low score due to the critical violation of the node label rule.  The use of 'ORGANIZATION' as a node label is a major schema violation.  The entity type is not correctly queried using the 'label' property within the ':ExtractedEntity' node.,3,"If the schema were to allow the node label 'ORGANIZATION', this query would return the 'text' property of all nodes with the label 'ORGANIZATION'.  However, this is not allowed by the provided schema.","The query partially aligns with the user's intent, but only if the schema were different.  The user wants all organizations, and the query attempts to do that, but fails due to schema violations.","The query covers the key entity 'organization', but misinterprets how to access it within the given schema.","The intent accuracy is moderate because the query's goal is correct, but its execution is flawed due to the schema violations.  It would only work if the schema allowed the direct use of 'ORGANIZATION' as a node label, which is explicitly forbidden.",Incorrect handling of the ':ExtractedEntity' and 'label' property convention,MATCH (o:ExtractedEntity {label: 'ORGANIZATION'}) RETURN o.text

    --- END OF FILE CONTENT ---

  File (skipped, extension not included): eval_results_answer_gemini_flash_20250530.jsonl
  File (skipped, extension not included): eval_results_answer_gemini_flash_20250531.jsonl
  File (skipped, extension not included): eval_results_cypher_gemini_flash_20250530.jsonl
  File (skipped, extension not included): eval_results_cypher_gemini_flash_20250531.jsonl

Directory: zhz_rag/stored_data/kuzu_default_db/
  File (skipped, extension not included): .lock
  File (skipped, extension not included): .shadow
  File (skipped, extension not included): .wal
  File (skipped, extension not included): catalog.kz
  File (skipped, extension not included): data.kz
  File (skipped, extension not included): metadata.kz
  File (skipped, extension not included): n-0.hindex
  File (skipped, extension not included): n-0.hindex.ovf

Directory: zhz_rag/stored_data/chromadb_index/
  File (skipped, extension not included): chroma.sqlite3

Directory: zhz_rag/stored_data/chromadb_index/fc39f817-3d12-4574-a52b-5bdfe2d8f24b/
  File (skipped, extension not included): data_level0.bin
  File (skipped, extension not included): header.bin
  File (skipped, extension not included): length.bin
  File (skipped, extension not included): link_lists.bin

Directory: zhz_rag/stored_data/kuzu_test_visibility_db/
  File (skipped, extension not included): .lock
  File (skipped, extension not included): .shadow
  File (skipped, extension not included): .wal
  File (skipped, extension not included): catalog.kz
  File (skipped, extension not included): data.kz
  File (skipped, extension not included): metadata.kz
  File (skipped, extension not included): n-0.hindex
  File (skipped, extension not included): n-0.hindex.ovf

Directory: zhz_rag/stored_data/bm25_index/
  File (skipped, extension not included): data.csc.index.npy
  File (skipped, extension not included): doc_ids.pkl
  File (skipped, extension not included): indices.csc.index.npy
  File (skipped, extension not included): indptr.csc.index.npy
  File: params.index.json
    --- START OF FILE CONTENT ---
{
    "k1": 1.5,
    "b": 0.75,
    "delta": 0.5,
    "method": "lucene",
    "idf_method": "lucene",
    "dtype": "float32",
    "int_dtype": "int32",
    "num_docs": 2,
    "version": "0.2.13",
    "backend": "numpy"
}
    --- END OF FILE CONTENT ---

  File: vocab.index.json
    --- START OF FILE CONTENT ---
{"分配":0,"处理":1,"项目":2,"。":3,"自然":4,"语言":5,"第二":6,"自然语言":7,"任务分配":8,"工作":9,"技术":10,"第二个":11,"给":12,"Alpha":13,"文档":14,"张三在":15,"张":16,"的":17,"编写":18,"三":19,"了":20,"讨论":21,"任务":22,"二个":23,"谷歌":24,"":25}
    --- END OF FILE CONTENT ---


Directory: zhz_rag/evaluation/
  File: __init__.py
    --- File is empty ---

  File: analyze_answer.py
    --- START OF FILE CONTENT ---
# zhz_rag/evaluation/analyze_answer.py
import json
import os
import pandas as pd
from typing import List, Dict, Any, Optional
from collections import Counter

# --- 从项目中导入必要的模块 ---
try:
    from zhz_rag.utils.common_utils import (
        load_jsonl_file, # <--- 使用新的通用函数
        EVALUATION_RESULTS_LOGS_DIR # 导入评估日志目录常量
    )
except ImportError as e:
    print(f"ERROR: Could not import necessary modules in analyze_answer.py: {e}")
    print("Make sure this script is run in an environment where 'zhz_rag' package is accessible.")
    exit(1)

import logging

# --- 配置此脚本的logger ---
analyze_answer_logger = logging.getLogger("AnalyzeAnswerLogger")
analyze_answer_logger.setLevel(logging.INFO)
if not analyze_answer_logger.hasHandlers():
    _console_handler = logging.StreamHandler()
    _formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s - %(filename)s:%(lineno)d - %(message)s')
    _console_handler.setFormatter(_formatter)
    analyze_answer_logger.addHandler(_console_handler)
    analyze_answer_logger.propagate = False
analyze_answer_logger.info("--- AnalyzeAnswerLogger configured ---")

# --- 核心功能函数 ---

def extract_answer_evaluation_details(log_entry: Dict[str, Any]) -> Optional[Dict[str, Any]]:
    """
    从单条已解析的答案评估日志条目中提取关键信息。
    这个函数与您之前在 analyze_answer.py 中的版本基本一致，稍作调整。
    """
    details = {}
    eval_data = log_entry.get("eval_llm_processed_output_json")

    if not eval_data or not isinstance(eval_data, dict):
        analyze_answer_logger.warning(f"Skipping log entry due to missing or invalid 'eval_llm_processed_output_json'. Interaction ID ref: {log_entry.get('original_interaction_id_ref')}")
        return None

    details["interaction_id_ref"] = log_entry.get("original_interaction_id_ref")
    details["user_question"] = log_entry.get("user_question_for_eval")
    details["generated_answer"] = log_entry.get("generated_answer_for_eval")
    
    summary = eval_data.get("evaluation_summary", {})
    dimensions = eval_data.get("dimensions", {})
    
    details["overall_answer_quality_score"] = summary.get("overall_answer_quality_score")
    details["main_strengths_answer"] = summary.get("main_strengths_answer")
    details["main_weaknesses_answer"] = summary.get("main_weaknesses_answer")
    
    faithfulness = dimensions.get("faithfulness", {})
    details["faithfulness_score"] = faithfulness.get("score")
    details["faithfulness_reasoning"] = faithfulness.get("reasoning")
    # 确保 problematic_answer_segments_faithfulness 是列表，然后 join
    problematic_segments = faithfulness.get("problematic_answer_segments_faithfulness", [])
    if isinstance(problematic_segments, list):
        details["faithfulness_problematic_segments"] = "; ".join(problematic_segments)
    else:
        details["faithfulness_problematic_segments"] = str(problematic_segments) # 以防万一不是列表

    relevance = dimensions.get("relevance", {})
    details["relevance_score"] = relevance.get("score")
    details["relevance_reasoning"] = relevance.get("reasoning")
    
    completeness = dimensions.get("completeness", {})
    details["completeness_context_sufficiency"] = completeness.get("context_sufficiency_assessment")
    details["completeness_context_reasoning"] = completeness.get("context_sufficiency_reasoning")
    details["completeness_score"] = completeness.get("score")
    details["completeness_reasoning"] = completeness.get("reasoning")
    
    coherence = dimensions.get("coherence_fluency", {}) # 键名可能与prompt中的一致
    details["coherence_score"] = coherence.get("score")
    details["coherence_reasoning"] = coherence.get("reasoning")

    actionability = dimensions.get("actionability_usability", {}) # 键名可能与prompt中的一致
    details["actionability_score"] = actionability.get("score")
    details["actionability_reasoning"] = actionability.get("reasoning")
    
    details["gemini_suggestion_answer"] = eval_data.get("suggestion_for_answer_improvement")

    return details

def perform_answer_evaluation_analysis(
    evaluation_log_filepath: str,
    output_csv_filepath: str
) -> bool:
    """
    加载答案评估日志，进行分析，并保存结果到CSV。

    Args:
        evaluation_log_filepath (str): 答案评估结果日志文件的路径。
        output_csv_filepath (str): 分析结果CSV文件的保存路径。

    Returns:
        bool: 如果分析和保存成功则返回True，否则返回False。
    """
    analyze_answer_logger.info(f"Starting Answer evaluation analysis for log file: {evaluation_log_filepath}")
    analyze_answer_logger.info(f"Analysis results will be saved to: {output_csv_filepath}")

    evaluation_logs = load_jsonl_file(evaluation_log_filepath)

    if not evaluation_logs:
        analyze_answer_logger.warning(f"No evaluation logs found or loaded from {evaluation_log_filepath}. Analysis aborted.")
        return False

    extracted_details_list = []
    for log_entry in evaluation_logs:
        if log_entry.get("task_type") == "answer_evaluation_result": # 确保是答案评估日志
            details = extract_answer_evaluation_details(log_entry)
            if details:
                extracted_details_list.append(details)
        else:
            analyze_answer_logger.debug(f"Skipping log entry with task_type '{log_entry.get('task_type')}' as it's not 'answer_evaluation_result'.")


    if not extracted_details_list:
        analyze_answer_logger.info("No valid Answer evaluation details extracted from the logs. No CSV will be generated.")
        return False

    df = pd.DataFrame(extracted_details_list)
    
    score_columns = [
        "overall_answer_quality_score", "faithfulness_score", "relevance_score",
        "completeness_score", "coherence_score", "actionability_score"
    ]
    for col in score_columns:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')

    analyze_answer_logger.info(f"\n--- Preliminary Answer Evaluation Analysis (from {len(extracted_details_list)} entries) ---")
    analyze_answer_logger.info(f"Total evaluation entries processed: {len(df)}")

    for col_name in score_columns:
        if col_name in df.columns and not df[col_name].isnull().all():
            analyze_answer_logger.info(f"\nDimension: {col_name}")
            analyze_answer_logger.info(f"{df[col_name].describe()}")
            analyze_answer_logger.info("Score Distribution:")
            analyze_answer_logger.info(f"{df[col_name].value_counts(dropna=False).sort_index()}")
        else:
            analyze_answer_logger.info(f"\nDimension: {col_name} - No data or all NaN.")
            
    if "completeness_context_sufficiency" in df.columns and not df["completeness_context_sufficiency"].isnull().all():
        analyze_answer_logger.info("\nContext Sufficiency Assessment Distribution:")
        analyze_answer_logger.info(f"{df['completeness_context_sufficiency'].value_counts(dropna=False)}")
    else:
        analyze_answer_logger.info("\nContext Sufficiency Assessment Distribution: No data.")

    try:
        os.makedirs(os.path.dirname(output_csv_filepath), exist_ok=True)
        df.to_csv(output_csv_filepath, index=False, encoding='utf-8-sig')
        analyze_answer_logger.info(f"\nAnalysis results saved to: {output_csv_filepath}")
        return True
    except Exception as e:
        analyze_answer_logger.error(f"\nFailed to save CSV file: {e}", exc_info=True)
        return False

if __name__ == "__main__":
    EVALUATION_NAME_FOR_ANSWER = "answer_gemini_flash" # Must match the name used in batch_eval_answer.py / evaluator.py
    
    # Similar to analyze_cypher.py, we'll try to use the date from the previous successful run.
    target_date_str = "20250530" # From your previous successful run log for Cypher, assuming Answer evals are on same day.
                                 # Adjust if your answer eval logs have different dates.

    log_file_name_answer = f"eval_results_{EVALUATION_NAME_FOR_ANSWER}_{target_date_str}.jsonl"
    log_file_path_answer = os.path.join(EVALUATION_RESULTS_LOGS_DIR, log_file_name_answer)

    output_csv_name_answer = f"analysis_{EVALUATION_NAME_FOR_ANSWER}_{target_date_str}.csv"
    output_csv_path_answer = os.path.join(EVALUATION_RESULTS_LOGS_DIR, output_csv_name_answer)

    if not os.path.exists(log_file_path_answer):
        analyze_answer_logger.error(f"Answer evaluation log file for analysis not found: {log_file_path_answer}")
        analyze_answer_logger.info("Please ensure the filename and date match an existing evaluation log.")
        # Fallback logic similar to analyze_cypher.py could be added here if needed.
    
    if log_file_path_answer and os.path.exists(log_file_path_answer):
        perform_answer_evaluation_analysis(
            evaluation_log_filepath=log_file_path_answer,
            output_csv_filepath=output_csv_path_answer
        )
    else:
        analyze_answer_logger.info("Answer evaluation analysis will not run as no suitable log file was identified.")
    --- END OF FILE CONTENT ---

  File: analyze_cypher.py
    --- START OF FILE CONTENT ---
# zhz_rag/evaluation/analyze_cypher.py
import json
import os
import pandas as pd
from typing import List, Dict, Any, Optional
from collections import Counter

# --- 从项目中导入必要的模块 ---
try:
    from zhz_rag.utils.common_utils import (
        load_jsonl_file, # <--- 使用新的通用函数
        EVALUATION_RESULTS_LOGS_DIR # 导入评估日志目录常量
    )
except ImportError as e:
    print(f"ERROR: Could not import necessary modules in analyze_cypher.py: {e}")
    print("Make sure this script is run in an environment where 'zhz_rag' package is accessible.")
    exit(1)

import logging

# --- 配置此脚本的logger ---
analyze_cypher_logger = logging.getLogger("AnalyzeCypherLogger")
analyze_cypher_logger.setLevel(logging.INFO)
if not analyze_cypher_logger.hasHandlers():
    _console_handler = logging.StreamHandler()
    _formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s - %(filename)s:%(lineno)d - %(message)s')
    _console_handler.setFormatter(_formatter)
    analyze_cypher_logger.addHandler(_console_handler)
    analyze_cypher_logger.propagate = False
analyze_cypher_logger.info("--- AnalyzeCypherLogger configured ---")

# --- 核心功能函数 ---

def extract_cypher_evaluation_details(log_entry: Dict[str, Any]) -> Optional[Dict[str, Any]]:
    """
    从单条已解析的Cypher评估日志条目中提取关键信息。
    这个函数与您之前在 analyze_cypher.py 中的版本基本一致，稍作调整以适应通用加载。
    """
    details = {}
    # eval_llm_processed_output_json 字段包含了Gemini评估的JSON输出
    eval_data = log_entry.get("eval_llm_processed_output_json")

    if not eval_data or not isinstance(eval_data, dict):
        analyze_cypher_logger.warning(f"Skipping log entry due to missing or invalid 'eval_llm_processed_output_json'. Interaction ID ref: {log_entry.get('original_interaction_id_ref')}")
        return None # 如果核心评估数据缺失，则跳过此条目

    details["interaction_id_ref"] = log_entry.get("original_interaction_id_ref")
    details["user_question"] = log_entry.get("user_question_for_eval")
    details["generated_cypher"] = log_entry.get("generated_cypher_for_eval")
    
    summary = eval_data.get("evaluation_summary", {})
    dimensions = eval_data.get("dimensions", {})
    
    details["overall_quality_score"] = summary.get("overall_quality_score_cypher")
    details["main_strength"] = summary.get("main_strength_cypher")
    details["main_weakness"] = summary.get("main_weakness_cypher")
    
    syntax = dimensions.get("syntactic_correctness", {})
    details["syntax_score"] = syntax.get("score")
    details["syntax_reasoning"] = syntax.get("reasoning")
    
    schema = dimensions.get("schema_adherence", {})
    details["schema_overall_score"] = schema.get("overall_score")
    details["schema_node_label_correct"] = schema.get("node_label_correctness", {}).get("check_result")
    details["schema_entity_type_correct"] = schema.get("entity_type_property_correctness", {}).get("check_result")
    details["schema_rel_type_correct"] = schema.get("relationship_type_correctness", {}).get("check_result")
    details["schema_prop_name_correct"] = schema.get("property_name_correctness", {}).get("check_result")
    details["schema_hallucinated_present"] = schema.get("hallucinated_schema_elements", {}).get("check_result_hallucination_present")
    details["schema_hallucinated_elements"] = ", ".join(schema.get("hallucinated_schema_elements", {}).get("elements_found", []))
    details["schema_reasoning"] = schema.get("reasoning")
    
    intent = dimensions.get("intent_accuracy", {})
    details["intent_score"] = intent.get("score")
    details["intent_explanation_cypher"] = intent.get("explanation_of_cypher_retrieval")
    details["intent_alignment_notes"] = intent.get("semantic_alignment_with_question")
    details["intent_key_elements_notes"] = intent.get("key_element_coverage_notes")
    details["intent_reasoning"] = intent.get("reasoning")
    
    details["qwen_error_patterns"] = ", ".join(eval_data.get("qwen_error_patterns_identified", []))
    details["gemini_suggestion"] = eval_data.get("suggestion_for_improvement_cypher")

    return details

def perform_cypher_evaluation_analysis(
    evaluation_log_filepath: str,
    output_csv_filepath: str
) -> bool:
    """
    加载Cypher评估日志，进行分析，并保存结果到CSV。

    Args:
        evaluation_log_filepath (str): Cypher评估结果日志文件的路径。
        output_csv_filepath (str): 分析结果CSV文件的保存路径。

    Returns:
        bool: 如果分析和保存成功则返回True，否则返回False。
    """
    analyze_cypher_logger.info(f"Starting Cypher evaluation analysis for log file: {evaluation_log_filepath}")
    analyze_cypher_logger.info(f"Analysis results will be saved to: {output_csv_filepath}")

    # 使用通用函数加载评估日志
    # 注意：evaluate_cypher_with_gemini 保存的日志中 task_type 是 "cypher_evaluation_by_gemini"
    # load_jsonl_file 不关心 task_type，它会加载所有行
    evaluation_logs = load_jsonl_file(evaluation_log_filepath)

    if not evaluation_logs:
        analyze_cypher_logger.warning(f"No evaluation logs found or loaded from {evaluation_log_filepath}. Analysis aborted.")
        return False

    extracted_details_list = []
    for log_entry in evaluation_logs:
        # 确保只处理Cypher评估结果
        if log_entry.get("task_type") == "cypher_evaluation_by_gemini":
            details = extract_cypher_evaluation_details(log_entry)
            if details: # extract_cypher_evaluation_details 可能会返回 None
                extracted_details_list.append(details)
        else:
            analyze_cypher_logger.debug(f"Skipping log entry with task_type '{log_entry.get('task_type')}' as it's not 'cypher_evaluation_by_gemini'.")


    if not extracted_details_list:
        analyze_cypher_logger.info("No valid Cypher evaluation details extracted from the logs. No CSV will be generated.")
        return False

    df = pd.DataFrame(extracted_details_list)
    
    score_columns = ["overall_quality_score", "syntax_score", "schema_overall_score", "intent_score"]
    for col in score_columns:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')

    analyze_cypher_logger.info(f"\n--- Preliminary Cypher Evaluation Analysis (from {len(extracted_details_list)} entries) ---")
    analyze_cypher_logger.info(f"Total evaluation entries processed: {len(df)}")

    if "overall_quality_score" in df.columns and not df["overall_quality_score"].isnull().all():
        analyze_cypher_logger.info("\n1. Overall Quality Score:")
        analyze_cypher_logger.info(f"{df['overall_quality_score'].describe()}")
        analyze_cypher_logger.info("\nScore Distribution:")
        analyze_cypher_logger.info(f"{df['overall_quality_score'].value_counts(dropna=False).sort_index()}")
    else:
        analyze_cypher_logger.info("\n1. Overall Quality Score: No data or all NaN.")


    if "schema_overall_score" in df.columns and not df["schema_overall_score"].isnull().all():
        analyze_cypher_logger.info("\n2. Schema Adherence Overall Score:")
        analyze_cypher_logger.info(f"{df['schema_overall_score'].describe()}")
        analyze_cypher_logger.info("\nScore Distribution:")
        analyze_cypher_logger.info(f"{df['schema_overall_score'].value_counts(dropna=False).sort_index()}")
        
        schema_sub_checks = [
            "schema_node_label_correct", "schema_entity_type_correct", 
            "schema_rel_type_correct", "schema_prop_name_correct", 
            "schema_hallucinated_present"
        ]
        analyze_cypher_logger.info("\nSchema Adherence Sub-item Issues (False means issue, Hallucinated True means issue):")
        for check in schema_sub_checks:
            if check in df.columns:
                if check == "schema_hallucinated_present":
                    issue_count = df[df[check] == True].shape[0]
                    analyze_cypher_logger.info(f"  - {check} (Hallucination Present): {issue_count} entries")
                else:
                    issue_count = df[df[check] == False].shape[0]
                    analyze_cypher_logger.info(f"  - {check} (Incorrect): {issue_count} entries")
    else:
        analyze_cypher_logger.info("\n2. Schema Adherence Overall Score: No data or all NaN.")


    if "intent_score" in df.columns and not df["intent_score"].isnull().all():
        analyze_cypher_logger.info("\n3. Intent Accuracy Score:")
        analyze_cypher_logger.info(f"{df['intent_score'].describe()}")
        analyze_cypher_logger.info("\nScore Distribution:")
        analyze_cypher_logger.info(f"{df['intent_score'].value_counts(dropna=False).sort_index()}")
    else:
        analyze_cypher_logger.info("\n3. Intent Accuracy Score: No data or all NaN.")


    if "qwen_error_patterns" in df.columns and not df["qwen_error_patterns"].isnull().all():
        analyze_cypher_logger.info("\n4. Identified Qwen Error Patterns (Top 5):")
        all_patterns = []
        for pattern_list_str in df["qwen_error_patterns"].dropna():
            if pattern_list_str and isinstance(pattern_list_str, str):
                all_patterns.extend([p.strip() for p in pattern_list_str.split(",") if p.strip()])
        pattern_counts = Counter(all_patterns)
        analyze_cypher_logger.info(f"{pattern_counts.most_common(5)}")
    else:
        analyze_cypher_logger.info("\n4. Identified Qwen Error Patterns: No data.")
        
    try:
        # Ensure output directory exists
        os.makedirs(os.path.dirname(output_csv_filepath), exist_ok=True)
        df.to_csv(output_csv_filepath, index=False, encoding='utf-8-sig')
        analyze_cypher_logger.info(f"\nAnalysis results saved to: {output_csv_filepath}")
        return True
    except Exception as e:
        analyze_cypher_logger.error(f"\nFailed to save CSV file: {e}", exc_info=True)
        return False

if __name__ == "__main__":
    # --- Configuration for running the analysis ---
    EVALUATION_NAME_FOR_CYPHER = "cypher_gemini_flash" # Must match the name used in batch_eval_cypher.py / evaluator.py

    # Try to find the latest log file for the given evaluation name
    # This requires a naming convention for eval logs, e.g., eval_results_<name>_<date>.jsonl
    # For simplicity, we'll construct a potential filename based on today's date,
    # but in a real scenario, you might want a more robust way to find the latest.
    
    # For demonstration, let's try to find a log from a recent specific date if today's doesn't exist.
    # You might need to adjust this logic or manually specify the file.
    
    # We will try to use the file name you provided in the previous run's log:
    # eval_results_cypher_gemini_flash_20250530.jsonl
    # This assumes the "date" part of the filename is consistent.
    
    # Let's try to find the log file used in the last successful Cypher evaluation run (20250530)
    # This is a placeholder, in a real system you might have a more robust way to get this.
    target_date_str = "20250530" # From your previous successful run log
    
    log_file_name_cypher = f"eval_results_{EVALUATION_NAME_FOR_CYPHER}_{target_date_str}.jsonl"
    log_file_path_cypher = os.path.join(EVALUATION_RESULTS_LOGS_DIR, log_file_name_cypher)

    output_csv_name_cypher = f"analysis_{EVALUATION_NAME_FOR_CYPHER}_{target_date_str}.csv"
    output_csv_path_cypher = os.path.join(EVALUATION_RESULTS_LOGS_DIR, output_csv_name_cypher)

    if not os.path.exists(log_file_path_cypher):
        analyze_cypher_logger.error(f"Cypher evaluation log file for analysis not found: {log_file_path_cypher}")
        analyze_cypher_logger.info("Please ensure the filename and date match an existing evaluation log.")
        # As a fallback, you could try finding the *absolute* latest eval log if the dated one isn't found,
        # but that might not always be what you want.
        # Example:
        # eval_logs_pattern = os.path.join(EVALUATION_RESULTS_LOGS_DIR, f"eval_results_{EVALUATION_NAME_FOR_CYPHER}_*.jsonl")
        # all_eval_logs = sorted(glob.glob(eval_logs_pattern), key=os.path.getmtime, reverse=True)
        # if all_eval_logs:
        #     log_file_path_cypher = all_eval_logs[0]
        #     date_part_from_filename = os.path.basename(log_file_path_cypher).split('_')[-1].split('.')[0]
        #     output_csv_path_cypher = os.path.join(EVALUATION_RESULTS_LOGS_DIR, f"analysis_{EVALUATION_NAME_FOR_CYPHER}_{date_part_from_filename}.csv")
        #     analyze_cypher_logger.info(f"Falling back to latest available Cypher eval log: {log_file_path_cypher}")
        # else:
        #     analyze_cypher_logger.error(f"No Cypher evaluation logs found matching pattern: {eval_logs_pattern}")
        #     log_file_path_cypher = None # Ensure it's None if no fallback
    
    if log_file_path_cypher and os.path.exists(log_file_path_cypher) : # Check again if fallback was attempted
        perform_cypher_evaluation_analysis(
            evaluation_log_filepath=log_file_path_cypher,
            output_csv_filepath=output_csv_path_cypher
        )
    else:
        analyze_cypher_logger.info("Cypher evaluation analysis will not run as no suitable log file was identified.")
    --- END OF FILE CONTENT ---

  File: batch_eval_answer.py
    --- START OF FILE CONTENT ---
# zhz_rag/evaluation/batch_eval_answer.py
import asyncio
import json
import os
from typing import List, Dict, Any, Optional, TYPE_CHECKING
import glob
from datetime import datetime

# --- 从项目中导入必要的模块 ---
try:
    from zhz_rag.evaluation.evaluator import evaluate_answer_with_gemini
    from zhz_rag.utils.common_utils import (
        find_latest_rag_interaction_log,
        load_jsonl_file,
        RAG_INTERACTION_LOGS_DIR
    )
    from zhz_rag.config.pydantic_models import RetrievedDocument
except ImportError as e:
    # ... (错误处理保持不变) ...
    print(f"ERROR: Could not import necessary modules in batch_eval_answer.py: {e}")
    print("Make sure this script is run in an environment where 'zhz_rag' package is accessible.")
    exit(1)

# --- 类型检查时导入资源类 ---
if TYPE_CHECKING:
    from zhz_rag_pipeline_dagster.zhz_rag_pipeline.resources import GeminiAPIResource

import logging

# --- 配置此脚本的logger ---
batch_answer_eval_logger = logging.getLogger("BatchAnswerEvaluationLogger")
batch_answer_eval_logger.setLevel(logging.INFO)
if not batch_answer_eval_logger.hasHandlers():
    _console_handler = logging.StreamHandler()
    _formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s - %(filename)s:%(lineno)d - %(message)s')
    _console_handler.setFormatter(_formatter)
    batch_answer_eval_logger.addHandler(_console_handler)
    batch_answer_eval_logger.propagate = False
batch_answer_eval_logger.info("--- BatchAnswerEvaluationLogger configured ---")


def format_contexts_for_evaluation(context_docs_raw: List[Dict[str, Any]]) -> str:
    """
    将从日志中解析出的上下文文档列表格式化为单一字符串，以便传递给评估LLM。
    这个函数与您之前在 batch_eval_answer.py 中的版本保持一致。
    """
    formatted_contexts = []
    if not context_docs_raw or not isinstance(context_docs_raw, list):
        batch_answer_eval_logger.warning("format_contexts_for_evaluation received no context or invalid format.")
        return "No context provided or context in unexpected format."

    for i, doc_data in enumerate(context_docs_raw):
        try:
            # 尝试使用RetrievedDocument模型解析，如果原始日志中已经是这个结构
            # 或者直接从字典中获取字段
            content = doc_data.get("content", "[Content not available]")
            source_type = doc_data.get("source_type", "unknown_source")
            score = doc_data.get("score")
            metadata = doc_data.get("metadata", {})
            chunk_id = metadata.get("chunk_id") or metadata.get("id") # 兼容不同日志格式

            context_str = f"--- Context Snippet {i+1} ---\n"
            context_str += f"Source Type: {source_type}\n"
            if score is not None:
                try:
                    context_str += f"Original Score: {float(score):.4f}\n"
                except (ValueError, TypeError):
                    context_str += f"Original Score: {score}\n" # 如果分数不是数字，直接用原始值
            if chunk_id:
                 context_str += f"Chunk ID: {chunk_id}\n"
            context_str += f"Content: {content}\n"
            formatted_contexts.append(context_str)
        except Exception as e:
            batch_answer_eval_logger.warning(f"Could not parse a context document fully in format_contexts_for_evaluation: {doc_data}. Error: {e}")
            content = doc_data.get("content", "[Content not available]")
            source_type = doc_data.get("source_type", "unknown_source")
            formatted_contexts.append(f"--- Context Snippet {i+1} (Parsing Warning) ---\nSource Type: {source_type}\nContent: {content}\n")
            
    return "\n\n".join(formatted_contexts) if formatted_contexts else "No context provided."


async def run_answer_batch_evaluation(
    gemini_resource_for_evaluator: 'GeminiAPIResource', # <--- 新增参数
    rag_interaction_log_filepath: str,
    app_version: str = "0.1.0",
    use_simulated_api: bool = False,
    api_call_delay: float = 4.1
) -> Dict[str, int]:
    """
    从指定的RAG交互日志文件中读取记录，筛选并评估最终答案。

    Args:
        rag_interaction_log_filepath (str): RAG交互日志文件的路径。
        app_version (str): 当前应用的日志版本标签。
        use_simulated_api (bool): 是否使用模拟的Gemini API响应。
        api_call_delay (float): 真实API调用之间的延迟秒数。

    Returns:
        Dict[str, int]: 包含评估统计信息的字典。
    """
    batch_answer_eval_logger.info(f"Starting batch Answer evaluation for log file: {rag_interaction_log_filepath}")
    batch_answer_eval_logger.info(f"Parameters: app_version='{app_version}', use_simulated_api={use_simulated_api}, api_call_delay={api_call_delay}s")

    processed_count = 0
    evaluated_count = 0
    failed_to_extract_count = 0
    skipped_missing_data_count = 0 # 用于记录因数据不全而跳过的情况

    if use_simulated_api:
        batch_answer_eval_logger.warning("Batch Answer evaluation is USING SIMULATED Gemini responses.")
    else:
        batch_answer_eval_logger.info("Batch Answer evaluation is using REAL Gemini API calls.")

    # 使用新的通用函数加载日志数据
    interaction_logs = load_jsonl_file(rag_interaction_log_filepath)

    if not interaction_logs:
        batch_answer_eval_logger.error(f"No data loaded from RAG interaction log file: {rag_interaction_log_filepath}. Exiting.")
        return {"processed": 0, "evaluated": 0, "skipped_missing_data": 0, "failed_extract": 0, "file_not_found_or_empty": 1}

    for line_number, interaction_log in enumerate(interaction_logs, 1):
        processed_count += 1
        # 我们关注的是成功完成RAG查询处理的日志条目
        if interaction_log.get("task_type") == "rag_query_processing_success":
            user_question = interaction_log.get("user_query")
            generated_answer = interaction_log.get("processed_llm_output") # RAG的最终答案
            original_id = interaction_log.get("interaction_id")
            
            # retrieved_context_docs 应该是由 FusionEngine 融合重排后的最终上下文文档列表
            # 在 rag_mcp_service.py 中，它被记录在 "retrieved_context_docs" 字段下
            context_docs_raw = interaction_log.get("retrieved_context_docs")

            if not context_docs_raw and interaction_log.get("debug_info"): # 备用方案，以防万一
                context_docs_raw = interaction_log.get("debug_info",{}).get("retrieved_context_docs")

            if user_question and generated_answer and original_id and context_docs_raw and isinstance(context_docs_raw, list):
                retrieved_contexts_str_for_eval = format_contexts_for_evaluation(context_docs_raw)
                
                batch_answer_eval_logger.info(f"Evaluating Answer for interaction_id: {original_id} - User Question: {user_question[:50]}...")
                
                evaluation_result = await evaluate_answer_with_gemini(
                    gemini_resource=gemini_resource_for_evaluator, # <--- 传递资源实例
                    user_question=user_question,
                    retrieved_contexts=retrieved_contexts_str_for_eval,
                    generated_answer=generated_answer,
                    original_interaction_id=original_id,
                    app_version=app_version
                )

                if evaluation_result:
                    evaluated_count += 1
                    summary = evaluation_result.get("evaluation_summary", {})
                    overall_score = summary.get("overall_answer_quality_score", "N/A")
                    batch_answer_eval_logger.info(f"Successfully evaluated Answer for interaction_id: {original_id}. Overall Score: {overall_score}")
                else:
                    batch_answer_eval_logger.warning(f"Answer evaluation returned None or failed for interaction_id: {original_id}")
                
                if not use_simulated_api:
                    batch_answer_eval_logger.info(f"Waiting for {api_call_delay} seconds before next API call...")
                    await asyncio.sleep(api_call_delay)
            else:
                skipped_missing_data_count += 1
                log_preview = {k: v for k, v in interaction_log.items() if k in ["interaction_id", "task_type", "user_query"]}
                log_preview["generated_answer_present"] = bool(generated_answer)
                log_preview["context_docs_present_and_list"] = isinstance(context_docs_raw, list) if context_docs_raw else False
                batch_answer_eval_logger.warning(f"Skipping RAG success log entry {line_number} due to missing critical data. Details: {log_preview}")
        
        if processed_count > 0 and processed_count % 10 == 0: # 日志打印频率
            batch_answer_eval_logger.info(f"Progress: Processed {processed_count} log entries. Evaluated {evaluated_count} answers so far. Skipped (missing data): {skipped_missing_data_count}.")

    summary = {
        "total_processed_from_log": processed_count,
        "answers_evaluated": evaluated_count,
        "skipped_due_to_missing_data": skipped_missing_data_count,
        "failed_to_extract_fields_for_eval": failed_to_extract_count # 这个字段可能在此脚本中意义不大，因为我们主要按task_type筛选
    }
    batch_answer_eval_logger.info(f"Batch Answer evaluation finished. Summary: {summary}")
    return summary


if __name__ == "__main__":
    # 1. 自动查找最新的原始RAG交互日志文件
    log_file_to_evaluate = find_latest_rag_interaction_log(RAG_INTERACTION_LOGS_DIR)

    # 2. 从环境变量决定是否模拟API调用 和 配置API调用延迟
    use_simulated_env = os.getenv("USE_SIMULATED_GEMINI_ANSWER_EVAL", "false").lower() == "true"
    api_delay_env = float(os.getenv("GEMINI_API_CALL_DELAY_SECONDS", "4.1"))

    app_version_tag_env = os.getenv("APP_VERSION_TAG", "0.1.3_batch_answer_refactored")
    if use_simulated_env:
        app_version_tag_env += "_simulated"

    if log_file_to_evaluate:
        batch_answer_eval_logger.info(f"Found RAG interaction log to process for answer evaluation: {log_file_to_evaluate}")
        asyncio.run(run_answer_batch_evaluation(
            rag_interaction_log_filepath=log_file_to_evaluate,
            app_version=app_version_tag_env,
            use_simulated_api=use_simulated_env,
            api_call_delay=api_delay_env
        ))
    elif use_simulated_env:
        batch_answer_eval_logger.warning(f"RAG interaction log file not found, but USE_SIMULATED_GEMINI_ANSWER_EVAL is true. Running with a dummy path (will process 0 entries).")
        asyncio.run(run_answer_batch_evaluation(
            rag_interaction_log_filepath="dummy_non_existent_file.jsonl",
            app_version=app_version_tag_env + "_no_file",
            use_simulated_api=use_simulated_env,
            api_call_delay=api_delay_env
        ))
    else:
        batch_answer_eval_logger.warning(f"No suitable RAG interaction log file found in '{RAG_INTERACTION_LOGS_DIR}' and not using simulated responses. Batch Answer evaluation will not run.")
    --- END OF FILE CONTENT ---

  File: batch_eval_cypher.py
    --- START OF FILE CONTENT ---
# zhz_rag/evaluation/batch_eval_cypher.py
import asyncio
import json
import os
from typing import List, Dict, Any, Optional, TYPE_CHECKING # <--- 确保导入 TYPE_CHECKING
import glob
from datetime import datetime

# --- 从项目中导入必要的模块 ---
try:
    from zhz_rag.evaluation.evaluator import evaluate_cypher_with_gemini
    from zhz_rag.utils.common_utils import (
        find_latest_rag_interaction_log,
        load_jsonl_file
    )
    from zhz_rag.utils.common_utils import RAG_INTERACTION_LOGS_DIR
except ImportError as e:
    print(f"ERROR: Could not import necessary modules in batch_eval_cypher.py: {e}")
    print("Make sure this script is run in an environment where 'zhz_rag' package is accessible.")
    exit(1)

# --- 类型检查时导入资源类 ---
if TYPE_CHECKING:
    from zhz_rag_pipeline_dagster.zhz_rag_pipeline.resources import GeminiAPIResource

import logging

# --- 配置此脚本的logger ---
batch_cypher_eval_logger = logging.getLogger("BatchCypherEvaluationLogger")
batch_cypher_eval_logger.setLevel(logging.INFO)
if not batch_cypher_eval_logger.hasHandlers():
    _console_handler = logging.StreamHandler()
    _formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s - %(filename)s:%(lineno)d - %(message)s')
    _console_handler.setFormatter(_formatter)
    batch_cypher_eval_logger.addHandler(_console_handler)
    batch_cypher_eval_logger.propagate = False # 通常不希望 utils 模块的日志传播到根
batch_cypher_eval_logger.info("--- BatchCypherEvaluationLogger configured ---")


async def run_cypher_batch_evaluation(
    gemini_resource_for_evaluator: 'GeminiAPIResource', # <--- 新增参数
    rag_interaction_log_filepath: str,
    app_version: str = "0.1.0",
    use_simulated_api: bool = False,
    api_call_delay: float = 4.1
) -> Dict[str, int]:
    """
    从指定的RAG交互日志文件中读取记录，筛选并评估Cypher查询。

    Args:
        rag_interaction_log_filepath (str): RAG交互日志文件的路径。
        app_version (str): 当前应用的日志版本标签。
        use_simulated_api (bool): 是否使用模拟的Gemini API响应。
        api_call_delay (float): 真实API调用之间的延迟秒数。

    Returns:
        Dict[str, int]: 包含评估统计信息的字典。
    """
    batch_cypher_eval_logger.info(f"Starting batch Cypher evaluation for log file: {rag_interaction_log_filepath}")
    batch_cypher_eval_logger.info(f"Parameters: app_version='{app_version}', use_simulated_api={use_simulated_api}, api_call_delay={api_call_delay}s")

    processed_count = 0
    evaluated_count = 0
    failed_to_extract_count = 0
    skipped_no_cypher_count = 0

    if use_simulated_api:
        batch_cypher_eval_logger.warning("Batch Cypher evaluation is USING SIMULATED Gemini responses.")
    else:
        batch_cypher_eval_logger.info("Batch Cypher evaluation is using REAL Gemini API calls.")

    # 使用新的通用函数加载日志数据
    interaction_logs = load_jsonl_file(rag_interaction_log_filepath)

    if not interaction_logs:
        batch_cypher_eval_logger.error(f"No data loaded from RAG interaction log file: {rag_interaction_log_filepath}. Exiting.")
        return {"processed": 0, "evaluated": 0, "skipped_no_cypher": 0, "failed_extract": 0, "file_not_found_or_empty": 1}

    for line_number, interaction_log in enumerate(interaction_logs, 1):
        processed_count += 1
        if interaction_log.get("task_type") == "cypher_generation":
            user_question = interaction_log.get("user_query")
            generated_cypher = interaction_log.get("processed_llm_output") # Qwen的原始输出
            original_id = interaction_log.get("interaction_id")

            if user_question and original_id: # 确保关键字段存在
                # 检查 generated_cypher 是否为空或表示无法生成
                if not generated_cypher or \
                   generated_cypher.strip() == "无法生成Cypher查询." or \
                   not generated_cypher.strip():
                    batch_cypher_eval_logger.info(f"Skipping evaluation for interaction_id '{original_id}' as Qwen indicated it couldn't generate Cypher or Cypher is empty. Content: '{generated_cypher}'")
                    skipped_no_cypher_count += 1
                    continue # 跳过此条记录

                batch_cypher_eval_logger.info(f"Evaluating Cypher for interaction_id: {original_id} - User Question: {user_question[:50]}...")
                
                evaluation_result = await evaluate_cypher_with_gemini(
                    gemini_resource=gemini_resource_for_evaluator, # <--- 传递资源实例
                    user_question=user_question,
                    generated_cypher=generated_cypher,
                    original_interaction_id=original_id,
                    app_version=app_version
                )

                if evaluation_result:
                    evaluated_count += 1
                    # 尝试从嵌套结构中获取 overall_quality_score_cypher
                    summary = evaluation_result.get("evaluation_summary", {})
                    overall_score = summary.get("overall_quality_score_cypher", "N/A")
                    batch_cypher_eval_logger.info(f"Successfully evaluated Cypher for interaction_id: {original_id}. Overall Score: {overall_score}")
                else:
                    batch_cypher_eval_logger.warning(f"Cypher evaluation returned None or failed for interaction_id: {original_id}")
                
                if not use_simulated_api:
                    batch_cypher_eval_logger.info(f"Waiting for {api_call_delay} seconds before next API call...")
                    await asyncio.sleep(api_call_delay)
            else:
                failed_to_extract_count += 1
                batch_cypher_eval_logger.warning(f"Skipping cypher_generation log entry {line_number} due to missing user_query or interaction_id. Log content: {str(interaction_log)[:200]}...")
        
        if processed_count > 0 and processed_count % 20 == 0: # 日志打印频率
            batch_cypher_eval_logger.info(f"Progress: Processed {processed_count} log entries. Evaluated {evaluated_count} Cypher queries so far. Skipped (no cypher/cannot generate): {skipped_no_cypher_count}. Failed to extract key fields: {failed_to_extract_count}.")

    summary = {
        "total_processed_from_log": processed_count,
        "cypher_queries_evaluated": evaluated_count,
        "skipped_qwen_could_not_generate": skipped_no_cypher_count,
        "failed_to_extract_fields_for_eval": failed_to_extract_count
    }
    batch_cypher_eval_logger.info(f"Batch Cypher evaluation finished. Summary: {summary}")
    return summary


if __name__ == "__main__":
    # 1. 自动查找最新的原始RAG交互日志文件
    # RAG_INTERACTION_LOGS_DIR 已从 common_utils 导入
    log_file_to_evaluate = find_latest_rag_interaction_log(RAG_INTERACTION_LOGS_DIR)

    # 2. 从环境变量决定是否模拟API调用 和 配置API调用延迟
    use_simulated_env = os.getenv("USE_SIMULATED_GEMINI_CYPHER_EVAL", "false").lower() == "true"
    api_delay_env = float(os.getenv("GEMINI_API_CALL_DELAY_SECONDS", "4.1")) # 从环境变量读取延迟

    app_version_tag_env = os.getenv("APP_VERSION_TAG", "0.1.3_batch_cypher_refactored")
    if use_simulated_env:
        app_version_tag_env += "_simulated"

    if log_file_to_evaluate:
        batch_cypher_eval_logger.info(f"Found RAG interaction log to process: {log_file_to_evaluate}")
        asyncio.run(run_cypher_batch_evaluation(
            rag_interaction_log_filepath=log_file_to_evaluate,
            app_version=app_version_tag_env,
            use_simulated_api=use_simulated_env,
            api_call_delay=api_delay_env
        ))
    # 如果文件不存在但明确要求模拟 (通常用于测试脚本本身，虽然没有输入数据意义不大)
    elif use_simulated_env:
        batch_cypher_eval_logger.warning(f"RAG interaction log file not found, but USE_SIMULATED_GEMINI_CYPHER_EVAL is true. Running with a dummy path (will process 0 entries).")
        asyncio.run(run_cypher_batch_evaluation(
            rag_interaction_log_filepath="dummy_non_existent_file.jsonl", # 传递一个虚拟路径
            app_version=app_version_tag_env + "_no_file",
            use_simulated_api=use_simulated_env,
            api_call_delay=api_delay_env
        ))
    else:
        batch_cypher_eval_logger.warning(f"No suitable RAG interaction log file found in '{RAG_INTERACTION_LOGS_DIR}' and not using simulated responses. Batch Cypher evaluation will not run.")
    --- END OF FILE CONTENT ---

  File: evaluator.py
    --- START OF FILE CONTENT ---
# zhz_rag/evaluation/evaluator.py
import os
import json
import traceback
from typing import Dict, Any, Optional, TYPE_CHECKING

# 导入共享的Schema描述 和 通用日志函数
from zhz_rag.config.constants import NEW_KG_SCHEMA_DESCRIPTION as KG_SCHEMA_FOR_EVALUATION
from zhz_rag.utils.common_utils import log_interaction_data

# --- 类型检查时导入资源类，避免循环导入 ---
if TYPE_CHECKING:
    from zhz_rag_pipeline_dagster.zhz_rag_pipeline.resources import GeminiAPIResource

import logging

# --- 配置此模块的logger ---
eval_logger = logging.getLogger("EvaluationLogger")
eval_logger.setLevel(logging.INFO)
eval_logger.propagate = False
if not eval_logger.hasHandlers():
    _eval_console_handler = logging.StreamHandler()
    _eval_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s - %(filename)s:%(lineno)d - %(message)s')
    _eval_console_handler.setFormatter(_eval_formatter)
    eval_logger.addHandler(_eval_console_handler)
    eval_logger.info("--- EvaluationLogger configured ---")

CYPHER_EVALUATION_PROMPT_V1 = """You are an expert Neo4j Cypher query evaluator and debugging assistant. Your primary task is to meticulously analyze a Cypher query that was generated by another AI model (Qwen2.5-3B, a 3 billion parameter model) in response to a user's natural language question. Your evaluation must be based on the provided knowledge graph schema and the specific evaluation criteria outlined below.

**IMPORTANT SCHEMA CONTEXT (KG_SCHEMA_DESCRIPTION):**
Use code with caution.
Python
{{KG_SCHEMA_DESCRIPTION}}
**USER'S NATURAL LANGUAGE QUESTION:**
Use code with caution.
{{USER_QUESTION}}
**GENERATED CYPHER QUERY TO EVALUATE:**
Use code with caution.
{{GENERATED_CYPHER}}
**EVALUATION TASK:**

Please evaluate the "GENERATED CYPHER QUERY" based on the following criteria. Provide your evaluation in a **valid JSON format** strictly adhering to the structure specified at the end.

**EVALUATION CRITERIA:**

1.  **Syntactic Correctness:**
    *   Is the Cypher query syntactically valid and parsable by Neo4j?
    *   Score (1-5): 1 = Major syntax errors, unparsable; 3 = Minor issues, likely parsable with warnings; 5 = Syntactically perfect.
    *   Reasoning: Explain your score. If errors exist, briefly describe them.

2.  **Schema Adherence (Strictly based on the provided KG_SCHEMA_DESCRIPTION):**
    *   **Node Label Correctness:**
        *   Check: Does the query exclusively use ':ExtractedEntity' for all node patterns? (True/False)
        *   Detail: Briefly explain.
    *   **Entity Type via `label` Property Correctness:**
        *   Check: Are entity types (e.g., 'PERSON', 'ORGANIZATION', 'TASK') correctly queried using the `label` property of ':ExtractedEntity' nodes (e.g., `WHERE n.label = 'PERSON'`)? (True/False)
        *   Detail: Briefly explain.
    *   **Relationship Type and Direction Correctness:**
        *   Check: Does the query use only defined relationship types (e.g., `:WORKS_AT`, `:ASSIGNED_TO`) and their correct directions as specified in the schema? (True/False)
        *   Detail: Briefly explain.
    *   **Property Name Correctness:**
        *   Check: Does the query use only valid property names for nodes and relationships (e.g., `text`, `label` for nodes)? (True/False)
        *   Detail: Briefly explain.
    *   **Hallucinated Schema Elements:**
        *   Check: Does the query reference any labels, relationship types, or properties NOT defined in the schema? (True/False - True if hallucination is present)
        *   Detail: List any hallucinated elements.
    *   **Overall Schema Adherence Score (1-5):** Based on the sub-checks above, provide an overall schema adherence score. Explain your reasoning, considering the severity and number of any deviations. Perfect adherence means all sub-checks are True and no hallucinations are present. 1 = Gross violations; 3 = Some minor deviations; 5 = Perfectly adheres to schema.
    *   Reasoning for Overall Schema Adherence Score: Provide the explanation here.

3.  **Intent Accuracy (Semantic Correctness):**
    *   Score (1-5): 1 = Completely misses user intent; 3 = Partially addresses intent but has significant gaps or inaccuracies; 5 = Accurately and fully captures user intent.
    *   Explanation of Cypher Retrieval: In simple natural language that an average office worker could understand, what information would this Cypher query retrieve from a graph that matches the schema?
    *   Alignment with User Question: How well does this retrieved information align with what the user was asking in their "USER'S NATURAL LANGUAGE QUESTION"?
    *   Key Element Coverage: Does the Cypher query attempt to address all key entities, relationships, and conditions mentioned in the user's question? If not, what specific parts of the question seem to be missing or misinterpreted in the Cypher query?
    *   Reasoning: Explain your intent accuracy score, considering the explanation, alignment, and key element coverage.

4.  **Identification of Potential Qwen2.5-3B Error Patterns (Optional but helpful):**
    *   Based on your knowledge of smaller LLMs, does this query exhibit any common error patterns such as:
        *   Over-simplification of complex conditions?
        *   Incorrect handling of the ':ExtractedEntity' and 'label' property convention?
        *   Ignoring multiple constraints from the user question?
        *   Other (please specify)?
    *   Observed Patterns: List any observed patterns from the predefined list, or provide an empty list [] if none of the predefined patterns are clearly observed.

**OUTPUT JSON STRUCTURE (Strictly follow this format):**
```json
{
  "evaluation_summary": {
    "overall_quality_score_cypher": "<Integer score 1-5, your overall judgment of the Cypher query's quality. **Crucially, assign higher weight to 'Schema Adherence' and 'Intent Accuracy'.** A query with perfect syntax but critical flaws in schema adherence or intent accuracy should NOT receive a high overall score.>",
    "main_strength_cypher": "<Briefly describe the main strength of this Cypher query, if any>",
    "main_weakness_cypher": "<Briefly describe the main weakness or most critical issue>"
  },
  "dimensions": {
    "syntactic_correctness": {
      "score": "<Integer score 1-5>",
      "parsable_prediction": "<Boolean: true/false>",
      "reasoning": "<Text explanation>"
    },
    "schema_adherence": {
      "overall_score": "<Integer score 1-5>",
      "node_label_correctness": { "check_result": "<Boolean>", "detail": "<Text>" },
      "entity_type_property_correctness": { "check_result": "<Boolean>", "detail": "<Text>" },
      "relationship_type_correctness": { "check_result": "<Boolean>", "detail": "<Text>" },
      "property_name_correctness": { "check_result": "<Boolean>", "detail": "<Text>" },
      "hallucinated_schema_elements": { "check_result_hallucination_present": "<Boolean>", "elements_found": ["<List of strings or empty list>"] },
      "reasoning": "<Text explanation for overall schema adherence score>"
    },
    "intent_accuracy": {
      "score": "<Integer score 1-5>",
      "explanation_of_cypher_retrieval": "<Text>",
      "semantic_alignment_with_question": "<Text>",
      "key_element_coverage_notes": "<Text describing coverage of key elements, and what's missing/misinterpreted, if any>",
      "reasoning": "<Text explanation for intent accuracy score>"
    }
  },
  "qwen_error_patterns_identified": ["<List of strings describing observed patterns, or empty list>"],
  "suggestion_for_improvement_cypher": "<Actionable suggestions to improve this specific Cypher query, if applicable>"
}
```"""

async def evaluate_cypher_with_gemini(
    gemini_resource: 'GeminiAPIResource', # <--- 修改：接收 GeminiAPIResource 实例
    user_question: str,
    generated_cypher: str,
    original_interaction_id: Optional[str] = None,
    app_version: str = "0.1.0"
) -> Optional[Dict[str, Any]]:
    eval_logger.info(f"Starting Cypher evaluation. User question: '{user_question[:50]}...', Cypher: '{generated_cypher[:100]}...'")

    prompt_to_gemini = CYPHER_EVALUATION_PROMPT_V1.replace(
        "{{KG_SCHEMA_DESCRIPTION}}", KG_SCHEMA_FOR_EVALUATION
    ).replace(
        "{{USER_QUESTION}}", user_question
    ).replace(
        "{{GENERATED_CYPHER}}", generated_cypher
    )

    messages_for_gemini = [{"role": "user", "content": prompt_to_gemini}]
    evaluation_result_json: Optional[Dict[str, Any]] = None
    raw_gemini_output: Optional[str] = None
    error_info: Optional[str] = None

    # 模拟API调用的逻辑保持不变，但实际API调用将通过gemini_resource
    USE_SIMULATED_GEMINI_RESPONSE = os.getenv("USE_SIMULATED_GEMINI_CYPHER_EVAL", "false").lower() == "true"

    if USE_SIMULATED_GEMINI_RESPONSE:
        eval_logger.warning("USING SIMULATED GEMINI RESPONSE FOR CYPHER EVALUATION")
        simulated_json_output = {
            "evaluation_summary": {
                "overall_quality_score_cypher": 4,
                "main_strength_cypher": "Good attempt at capturing intent.",
                "main_weakness_cypher": "Minor schema deviation in node label."
            },
            "dimensions": {
                "syntactic_correctness": {"score": 5, "parsable_prediction": True, "reasoning": "Query appears syntactically valid."},
                "schema_adherence": {
                    "overall_score": 3,
                    "node_label_correctness": { "check_result": False, "detail": "Used :Person instead of :ExtractedEntity for one node." },
                    "entity_type_property_correctness": { "check_result": True, "detail": "Correctly used label property." },
                    "relationship_type_correctness": { "check_result": True, "detail": "Used defined relationships correctly." },
                    "property_name_correctness": { "check_result": True, "detail": "Used valid properties." },
                    "hallucinated_schema_elements": { "check_result_hallucination_present": False, "elements_found": [] },
                    "reasoning": "One instance of incorrect node label, otherwise good."
                },
                "intent_accuracy": {
                    "score": 4,
                    "explanation_of_cypher_retrieval": "The query attempts to find the organization where '张三' works.",
                    "semantic_alignment_with_question": "Well-aligned with the user's question about '张三's' workplace.",
                    "key_element_coverage_notes": "All key elements seem to be covered.",
                    "reasoning": "Good intent capture, minor improvement could be ensuring organization type is also filtered if ambiguous."
                }
            },
            "qwen_error_patterns_identified": ["Incorrect handling of the ':ExtractedEntity' and 'label' property convention"],
            "suggestion_for_improvement_cypher": "Change MATCH (p:Person...) to MATCH (p:ExtractedEntity {label: 'PERSON'})..."
        }
        raw_gemini_output = json.dumps(simulated_json_output)
        try:
            evaluation_result_json = json.loads(raw_gemini_output)
        except json.JSONDecodeError as e:
            eval_logger.error(f"Error decoding simulated JSON: {e}")
            error_info = f"Simulated JSON decode error: {str(e)}"
    else:
        try:
            eval_logger.info(f"Calling Gemini for Cypher evaluation via GeminiAPIResource. Model: {gemini_resource.model_name}. Prompt length: {len(prompt_to_gemini)}")
            # --- 修改：通过 gemini_resource 调用 ---
            raw_gemini_output = await gemini_resource.call_completion(
                messages=messages_for_gemini
                # temperature 和 max_tokens 将使用 gemini_resource 的默认值或配置值
            )
            if raw_gemini_output:
                eval_logger.info(f"Raw Gemini output for Cypher eval (first 300 chars): {raw_gemini_output[:300]}...")
                cleaned_output = raw_gemini_output.strip()
                if cleaned_output.startswith("```json"):
                    cleaned_output = cleaned_output[len("```json"):].strip()
                if cleaned_output.endswith("```"):
                    cleaned_output = cleaned_output[:-len("```")].strip()
                evaluation_result_json = json.loads(cleaned_output)
                eval_logger.info("Successfully parsed Gemini evaluation result for Cypher.")
            else:
                eval_logger.error("Gemini call via resource returned None or empty for Cypher evaluation.")
                error_info = "Gemini call via resource returned None/empty"
        except json.JSONDecodeError as e_json:
            eval_logger.error(f"Failed to decode JSON from Gemini Cypher evaluation. Raw output: {raw_gemini_output[:500] if raw_gemini_output else 'N/A'}", exc_info=True)
            error_info = f"JSONDecodeError: {str(e_json)}"
        except Exception as e_gen: # 更通用的异常捕获，因为 call_completion 可能自己处理了 LiteLLM 异常
            eval_logger.error(f"Unexpected error during Cypher evaluation with Gemini resource: {e_gen}", exc_info=True)
            error_info = f"Unexpected error with Gemini resource: {str(e_gen)}"
            if raw_gemini_output is None: # 如果 call_completion 返回 None 且没有设置 raw_gemini_output
                raw_gemini_output = error_info

    eval_log_data = {
        "task_type": "cypher_evaluation_by_gemini",
        "original_interaction_id_ref": original_interaction_id,
        "user_question_for_eval": user_question,
        "generated_cypher_for_eval": generated_cypher,
        "eval_llm_input_prompt_char_count": len(prompt_to_gemini),
        "eval_llm_model": gemini_resource.model_name, # <--- 修改：从资源获取模型名称
        "eval_llm_raw_output": raw_gemini_output,
        "eval_llm_processed_output_json": evaluation_result_json,
        "eval_error_info": error_info,
        "application_version": app_version
    }
    await log_interaction_data(
        eval_log_data,
        is_evaluation_result=True,
        evaluation_name_for_file="cypher_gemini_flash"
    )
    if evaluation_result_json:
        eval_logger.info(f"Cypher evaluation completed. Overall score: {evaluation_result_json.get('evaluation_summary', {}).get('overall_quality_score_cypher')}")
    else:
        eval_logger.warning("Cypher evaluation did not produce a valid JSON result.")
        
    return evaluation_result_json


# V1 Answer Evaluation Prompt
ANSWER_EVALUATION_PROMPT_V1 = """
You are an expert AI Answer Evaluator, specializing in assessing the quality of responses from a Retrieval Augmented Generation (RAG) system designed as an "Office Worker Assistant". Your evaluation must be objective, strictly based on the provided user question, the context the RAG system used, and the generated answer.

**USER'S NATURAL LANGUAGE QUESTION:**
Use code with caution.
Python
{{USER_QUESTION}}
**CONTEXT PROVIDED TO THE RAG SYSTEM'S GENERATION MODEL (this is the information the AI had to base its answer on):**
Use code with caution.
{{RETRIEVED_CONTEXTS}}
**AI-GENERATED ANSWER TO EVALUATE:**
Use code with caution.
{{GENERATED_ANSWER}}
**EVALUATION TASK:**

Please evaluate the "AI-GENERATED ANSWER" based on the following criteria. For each dimension, provide a score from 1 to 5 (where 5 is best) and a brief reasoning for your score. Also, if applicable, identify specific phrases or sentences in the answer that exemplify an issue.

**EVALUATION DIMENSIONS & SCORING GUIDELINES:**

1.  **Faithfulness/Traceability (Score 1-5):**
    *   Is all factual information in the answer directly supported by the "CONTEXT PROVIDED"?
    *   Does the answer avoid making up information (hallucinations) or contradicting the context?
    *   **5 (Completely Faithful):** All key factual claims in the answer are directly and accurately supported by the context. No external information introduced.
    *   **4 (Mostly Faithful):** The vast majority of factual claims are supported. May contain very minor, reasonable inferences closely tied to the context, but no direct contradictions.
    *   **3 (Partially Faithful):** Some key claims are supported, but there are noticeable unsupported claims, slight misinterpretations of the context, or minor, non-critical hallucinations.
    *   **2 (Minimally Faithful):** Significant portions of the answer are not supported by the context, or there are clear contradictions or misleading hallucinations.
    *   **1 (Not Faithful):** The answer is largely based on information 외부 from the context, contains severe hallucinations, or directly contradicts the context.

2.  **Relevance to User Query (Score 1-5):**
    *   Does the answer directly and precisely address the "USER'S NATURAL LANGUAGE QUESTION"?
    *   **5 (Perfectly Relevant):** Directly and fully answers the user's core question(s).
    *   **4 (Highly Relevant):** Accurately answers the main aspects of the question; minor aspects might be less directly addressed.
    *   **3 (Moderately Relevant):** Addresses parts of the question but may miss key aspects or include some less relevant information.
    *   **2 (Slightly Relevant):** Touches upon the topic of the question but largely misses the core intent.
    *   **1 (Not Relevant):** Does not answer the user's question at all.

3.  **Completeness (Score 1-5):**
    *   **First, assess Context Sufficiency:** Based *only* on the "CONTEXT PROVIDED", does it seem to contain enough information to fully answer the "USER'S NATURAL LANGUAGE QUESTION"? (Answer: "Sufficient", "Partially Sufficient", or "Insufficient"). Provide a brief reason for your assessment of context sufficiency.
    *   **Then, score Completeness based on the answer's performance given the context:**
        *   Does the answer address all aspects of the user's query, making good use of the relevant information available in the context?
        *   If the context was insufficient, does the answer appropriately acknowledge this or focus on what can be answered?
        *   **5 (Very Complete):** (If context sufficient) Fully addresses all aspects of the query using all relevant context. (If context insufficient) Makes the best use of available context and clearly indicates limitations.
        *   **4 (Mostly Complete):** (If context sufficient) Addresses main aspects, minor details from context might be missed. (If context insufficient) Good use of available context, fair indication of limitations.
        *   **3 (Partially Complete):** (If context sufficient) Misses some important aspects or underutilizes relevant context. (If context insufficient) Poor use of available context or unclear about limitations.
        *   **2 (Slightly Complete):** (If context sufficient) Addresses only a small part, much relevant context ignored. (If context insufficient) Very poor use of limited context.
        *   **1 (Not Complete):** Fails to address the query meaningfully, even if relevant context was available.

4.  **Coherence/Fluency (Score 1-5):**
    *   Is the answer well-written, grammatically correct, logically structured, and easy to understand?
    *   **5 (Very Fluent):** Perfectly written, clear, natural, and easy to understand. No grammatical errors.
    *   **4 (Fluent):** Well-written, mostly clear, minor or no grammatical errors.
    *   **3 (Moderately Fluent):** Understandable, but may have some awkward phrasing or minor grammatical errors that don't impede core understanding.
    *   **2 (Slightly Fluent):** Difficult to understand due to grammatical errors, awkward phrasing, or poor logical flow.
    *   **1 (Not Fluent):** Largely incomprehensible.

5.  **Actionability & Usability (for an Office Worker Assistant) (Score 1-5):**
    *   Does the answer provide clear, practical, and easy-to-understand steps, information, or suggestions that would directly help an office worker achieve their task or make a decision?
    *   **5 (Highly Actionable & Usable):** Provides clear, specific, and immediately applicable steps/information. Language is professional and easy for an office worker to understand. Format facilitates quick information retrieval.
    *   **4 (Mostly Actionable & Usable):** Provides generally clear guidance or useful information. Might require minor clarification for full actionability, or presentation could be slightly improved, but core content is helpful.
    *   **3 (Partially Actionable & Usable):** Offers some relevant information or suggestions, but lacks specific steps, is too vague for direct action, or requires significant effort to understand/apply.
    *   **2 (Minimally Actionable & Usable):** Contains some related information but no clear action plan, is impractical, or very difficult to understand/use. Offers little practical help.
    *   **1 (Not Actionable & Unusable):** Provides no actionable information, is irrelevant to practical office tasks, or is misleading/confusing.

**OUTPUT JSON STRUCTURE (Strictly follow this format):**
```json
{
  "evaluation_summary": {
    "overall_answer_quality_score": "<Integer score 1-5, your overall judgment of the answer's quality, considering all dimensions. Faithfulness and Relevance are most critical.>",
    "main_strengths_answer": "<Briefly describe the main strength(s) of this answer, if any. Be specific.>",
    "main_weaknesses_answer": "<Briefly describe the main weakness(es) or most critical issue(s) with this answer. Be specific.>"
  },
  "dimensions": {
    "faithfulness": {
      "score": "<Integer score 1-5>",
      "reasoning": "<Text explanation for faithfulness score. If not fully faithful, specify which parts are unsupported or hallucinated, referencing the answer text.>",
      "problematic_answer_segments_faithfulness": ["<List of specific phrases/sentences from the answer that are not faithful, or empty list if none>"]
    },
    "relevance": {
      "score": "<Integer score 1-5>",
      "reasoning": "<Text explanation for relevance score. Explain how well it addresses the user's core question.>"
    },
    "completeness": {
      "context_sufficiency_assessment": "<String: 'Sufficient', 'Partially Sufficient', or 'Insufficient'>",
      "context_sufficiency_reasoning": "<Brief reason for the context sufficiency assessment. If not sufficient, what key information is missing from the context?>",
      "score": "<Integer score 1-5, based on how well the answer uses the available context to address the query>",
      "reasoning": "<Text explanation for completeness score. If not fully complete, what aspects of the query were missed, or what relevant context was underutilized? If context was insufficient, how well did the answer handle this?>"
    },
    "coherence_fluency": {
      "score": "<Integer score 1-5>",
      "reasoning": "<Text explanation for coherence/fluency score. Note any grammatical issues or awkward phrasing.>"
    },
    "actionability_usability": {
      "score": "<Integer score 1-5>",
      "reasoning": "<Text explanation for actionability/usability score, considering an office worker context.>"
    }
  },
  "suggestion_for_answer_improvement": "<Provide specific, actionable suggestions on how this AI-generated answer could be improved, if applicable. If excellent, state 'No improvement needed'.>"
}
Use code with caution.
FEW-SHOT EXAMPLES:
Example 1: Good Answer
USER'S NATURAL LANGUAGE QUESTION:
如何申请本年度的带薪年假，并确保符合公司规定？
Use code with caution.
CONTEXT PROVIDED TO THE RAG SYSTEM'S GENERATION MODEL:
上下文片段1 (来源: 公司政策文档):
员工每年享有15天带薪年假。申请年假需通过公司内部HRM系统提交，并至少提前两周提出。所有年假申请必须得到直属经理的批准。未经批准的休假将按事假处理。

上下文片段2 (来源: HRM系统操作指南):
HRM系统年假申请流程：1. 登录HRM门户 (hrm.example-company.com)。 2. 导航至“我的假期”->“假期申请”。 3. 选择“年假”类型，填写休假起止日期和休假天数。 4. 在备注中简要说明休假事由（可选）。 5. 提交申请，等待经理审批。审批状态可在系统中实时查看。

上下文片段3 (来源: 知识图谱精确信息):
事实: 年假政策规定 -> 提前申请周期: 2周。
事实: 年假政策规定 -> 审批人: 直属经理。
事实: 年假政策规定 -> 年假天数上限: 15天/年。
Use code with caution.
AI-GENERATED ANSWER TO EVALUATE:
您可以按照以下步骤申请本年度的带薪年假并确保符合公司规定：

1.  **提前规划与提交：** 根据公司政策，您需要至少提前两周提交年假申请。
2.  **通过HRM系统申请：**
    *   登录公司HRM门户网站：hrm.example-company.com
    *   进入“我的假期”模块，然后选择“假期申请”。
    *   选择“年假”类型，并准确填写您希望休假的起止日期和天数。
3.  **获取经理批准：** 所有年假申请都必须得到您直属经理的批准。提交申请后，请留意系统中的审批状态。
4.  **年假额度：** 请注意，公司规定员工每年享有15天带薪年假。

请确保您的申请符合以上规定，以顺利安排您的休假。
Use code with caution.
EXPECTED EVALUATION JSON OUTPUT:
{
  "evaluation_summary": {
    "overall_answer_quality_score": 5,
    "main_strengths_answer": "答案准确、完整、步骤清晰，非常实用。",
    "main_weaknesses_answer": "无明显缺点。"
  },
  "dimensions": {
    "faithfulness": {
      "score": 5,
      "reasoning": "答案中的所有信息点（提前两周、HRM系统操作、经理批准、15天年假）均能在提供的上下文中找到明确依据，无任何捏造。",
      "problematic_answer_segments_faithfulness": []
    },
    "relevance": {
      "score": 5,
      "reasoning": "答案完美地回应了用户关于年假申请流程和合规性的问题。"
    },
    "completeness": {
      "context_sufficiency_assessment": "Sufficient",
      "context_sufficiency_reasoning": "上下文提供了申请年假所需的所有核心信息（流程、提前时间、审批人、额度）。",
      "score": 5,
      "reasoning": "答案全面覆盖了用户问题的各个方面，并充分利用了上下文中的所有关键信息，包括操作步骤和政策规定。"
    },
    "coherence_fluency": {
      "score": 5,
      "reasoning": "答案语言表达清晰、专业，逻辑步骤明确，易于理解。"
    },
    "actionability_usability": {
      "score": 5,
      "reasoning": "答案提供了非常清晰、可直接执行的申请步骤，并点明了关键的合规性要求，对办公室员工非常实用且易于操作。"
    }
  },
  "suggestion_for_answer_improvement": "No improvement needed."
}
Use code with caution.
Json
Example 2: Answer with Hallucination
USER'S NATURAL LANGUAGE QUESTION:
我们公司最新的季度IT安全演练是什么时候举行的，主要发现了哪些问题？
Use code with caution.
CONTEXT PROVIDED TO THE RAG SYSTEM'S GENERATION MODEL:
上下文片段1 (来源: 内部邮件):
主题：关于第三季度IT安全意识培训的通知
内容：各位同事，为提升全员信息安全意识，公司计划于8月15日举行第三季度IT安全意识培训，主要内容包括密码安全、钓鱼邮件识别等。请大家准时参加。

上下文片段2 (来源: IT部门公告):
IT服务台提醒：近期发现多起针对财务部门的仿冒邮件，请大家提高警惕，不要点击不明链接。如有疑问，请及时联系IT支持。演练活动将在下月进行。
Use code with caution.
AI-GENERATED ANSWER TO EVALUATE:
公司最新的季度IT安全演练已于上个月（7月）成功举行。演练主要发现了两个问题：一是部分员工的办公电脑未及时更新防病毒软件，二是演练中模拟的钓鱼邮件成功欺骗了约15%的员工。后续将加强相关培训。
Use code with caution.
EXPECTED EVALUATION JSON OUTPUT:
{
  "evaluation_summary": {
    "overall_answer_quality_score": 1,
    "main_strengths_answer": "答案结构尚可。",
    "main_weaknesses_answer": "答案内容完全是编造的（幻觉），与提供的上下文信息完全不符，具有严重误导性。"
  },
  "dimensions": {
    "faithfulness": {
      "score": 1,
      "reasoning": "答案中关于演练已于7月举行、发现的两个具体问题（未更新防病毒软件、15%员工被钓鱼邮件欺骗）在上下文中完全找不到任何依据，是严重的幻觉。",
      "problematic_answer_segments_faithfulness": ["演练已于上个月（7月）成功举行。", "演练主要发现了两个问题：一是部分员工的办公电脑未及时更新防病毒软件，二是演练中模拟的钓鱼邮件成功欺骗了约15%的员工。"]
    },
    "relevance": {
      "score": 2,
      "reasoning": "答案表面上回应了问题（演练时间和问题），但由于内容是虚假的，其实际相关性很低。"
    },
    "completeness": {
      "context_sufficiency_assessment": "Partially Sufficient",
      "context_sufficiency_reasoning": "上下文提到了计划中的培训和演练（下月进行），以及一些安全问题（仿冒邮件），但没有给出已完成演练的具体时间和发现的问题。",
      "score": 1,
      "reasoning": "答案完全没有利用上下文中的有效信息（如计划中的培训和演练），而是编造了内容。"
    },
    "coherence_fluency": {
      "score": 4,
      "reasoning": "答案的语言表达本身是通顺的，语法基本正确。"
    },
    "actionability_usability": {
      "score": 1,
      "reasoning": "虚假的信息完全不可用，且具有误导性，对办公室工作有害无益。"
    }
  },
  "suggestion_for_answer_improvement": "AI模型必须严格基于提供的上下文生成答案，严禁编造任何上下文中未提及的事实。如果上下文信息不足，应明确指出。"
}
Use code with caution.
Json
Example 3: Incomplete Answer
USER'S NATURAL LANGUAGE QUESTION:
请总结一下我们和ABC公司最近一次会议的主要议题和达成的三项关键共识。
Use code with caution.
CONTEXT PROVIDED TO THE RAG SYSTEM'S GENERATION MODEL:
上下文片段1 (来源: 会议纪要 - ABC公司会议_20250515.docx):
会议日期：2025年5月15日
与会方：我方（李明、王芳），ABC公司（张总、赵经理）
主要议题：
1.  回顾Q1合作项目进展。
2.  讨论Q2新产品联合推广计划。
3.  探讨长期战略合作框架。
关键共识：
1.  双方同意Q1项目按计划完成，成果符合预期。
2.  Q2新产品联合推广预算初定为50万，具体方案下周讨论。
3.  双方均表达了加强长期战略合作的意愿，将成立联合工作组进一步商议。
4.  下次会议暂定于6月初。
Use code with caution.
AI-GENERATED ANSWER TO EVALUATE:
我们和ABC公司最近一次会议（2025年5月15日）的主要议题包括回顾Q1项目进展和讨论Q2新产品联合推广计划。会议达成的一项关键共识是双方同意Q1项目按计划完成。
Use code with caution.
EXPECTED EVALUATION JSON OUTPUT:
{
  "evaluation_summary": {
    "overall_answer_quality_score": 3,
    "main_strengths_answer": "答案忠实于上下文，相关性较好，语言通顺。",
    "main_weaknesses_answer": "答案在完整性方面有明显不足，遗漏了多个重要议题和关键共识。"
  },
  "dimensions": {
    "faithfulness": {
      "score": 5,
      "reasoning": "答案中提到的信息点（会议日期、部分议题、一项共识）均能在上下文中找到准确依据。",
      "problematic_answer_segments_faithfulness": []
    },
    "relevance": {
      "score": 4,
      "reasoning": "答案回应了用户关于会议议题和共识的问题，但不够全面。"
    },
    "completeness": {
      "context_sufficiency_assessment": "Sufficient",
      "context_sufficiency_reasoning": "上下文详细列出了3个主要议题和4项关键共识，足以完整回答用户问题。",
      "score": 2,
      "reasoning": "答案严重不完整。议题方面遗漏了“探讨长期战略合作框架”。关键共识方面，用户要求三项，但答案只给出了一项，遗漏了“Q2推广预算初定”、“加强长期战略合作意愿将成立工作组”这两项重要共识（甚至还有第四项共识也未提及）。"
    },
    "coherence_fluency": {
      "score": 5,
      "reasoning": "答案语言表达清晰、语法正确。"
    },
    "actionability_usability": {
      "score": 3,
      "reasoning": "答案提供了一些信息，但由于信息不完整，其实用性打了折扣。用户可能需要再次查找才能获得全部关键信息。"
    }
  },
  "suggestion_for_answer_improvement": "答案应更全面地从上下文中提取信息。应完整列出所有主要议题，并至少满足用户要求的三个关键共识。例如，可以补充：'其他主要议题还包括探讨长期战略合作框架。达成的其他关键共识有：Q2新产品联合推广预算初定为50万；双方将成立联合工作组进一步商议加强长期战略合作的意愿。'"
}
Use code with caution.
Json
NOW, EVALUATE THE FOLLOWING:
USER'S NATURAL LANGUAGE QUESTION:
{{USER_QUESTION}}
Use code with caution.
CONTEXT PROVIDED TO THE RAG SYSTEM'S GENERATION MODEL (this is the information the AI had to base its answer on):
{{RETRIEVED_CONTEXTS}}
Use code with caution.
AI-GENERATED ANSWER TO EVALUATE:
{{GENERATED_ANSWER}}
Use code with caution.
YOUR EVALUATION (Strictly in the JSON format defined above):
// Your JSON output here
Use code with caution.
Json
"""

async def evaluate_answer_with_gemini(
    gemini_resource: 'GeminiAPIResource', # <--- 修改：接收 GeminiAPIResource 实例
    user_question: str,
    retrieved_contexts: str,
    generated_answer: str,
    original_interaction_id: Optional[str] = None,
    app_version: str = "0.1.0"
) -> Optional[Dict[str, Any]]:
    eval_logger.info(f"Starting Answer evaluation. User question: '{user_question[:50]}...', Answer: '{generated_answer[:50]}...'")

    prompt_to_gemini = ANSWER_EVALUATION_PROMPT_V1.replace(
        "{{USER_QUESTION}}", user_question
    ).replace(
        "{{RETRIEVED_CONTEXTS}}", retrieved_contexts
    ).replace(
        "{{GENERATED_ANSWER}}", generated_answer
    )

    messages_for_gemini = [{"role": "user", "content": prompt_to_gemini}]
    evaluation_result_json: Optional[Dict[str, Any]] = None
    raw_gemini_output: Optional[str] = None
    error_info: Optional[str] = None

    USE_SIMULATED_GEMINI_RESPONSE = os.getenv("USE_SIMULATED_GEMINI_ANSWER_EVAL", "false").lower() == "true"

    if USE_SIMULATED_GEMINI_RESPONSE:
        eval_logger.warning("USING SIMULATED GEMINI RESPONSE FOR ANSWER EVALUATION")
        simulated_json_output = {
            "evaluation_summary": {
                "overall_answer_quality_score": 4,
                "main_strengths_answer": "Answer is mostly faithful and relevant.",
                "main_weaknesses_answer": "Could be more complete by utilizing more context."
            },
            "dimensions": {
                "faithfulness": {
                    "score": 4,
                    "reasoning": "Most claims are supported by context.",
                    "problematic_answer_segments_faithfulness": []
                },
                "relevance": {
                    "score": 5,
                    "reasoning": "Directly addresses the user's question."
                },
                "completeness": {
                    "context_sufficiency_assessment": "Partially Sufficient",
                    "context_sufficiency_reasoning": "Context provides some info but lacks specific detail X.",
                    "score": 3,
                    "reasoning": "Answer uses available context but misses detail Y which was present."
                },
                "coherence_fluency": {
                    "score": 5,
                    "reasoning": "Well-written and easy to understand."
                },
                "actionability_usability": {
                    "score": 4,
                    "reasoning": "Provides useful information, could have more direct steps."
                }
            },
            "suggestion_for_answer_improvement": "Consider adding detail Y from context if relevant."
        }
        raw_gemini_output = json.dumps(simulated_json_output)
        try:
            evaluation_result_json = json.loads(raw_gemini_output)
        except json.JSONDecodeError as e:
            eval_logger.error(f"Error decoding simulated JSON for answer eval: {e}")
            error_info = f"Simulated JSON decode error for answer: {str(e)}"
    else:
        try:
            eval_logger.info(f"Calling Gemini for Answer evaluation via GeminiAPIResource. Model: {gemini_resource.model_name}. Prompt length: {len(prompt_to_gemini)}")
            # --- 修改：通过 gemini_resource 调用 ---
            raw_gemini_output = await gemini_resource.call_completion(
                messages=messages_for_gemini
            )
            if raw_gemini_output:
                eval_logger.info(f"Raw Gemini output for Answer eval (first 300 chars): {raw_gemini_output[:300]}...")
                cleaned_output = raw_gemini_output.strip()
                if cleaned_output.startswith("```json"):
                    cleaned_output = cleaned_output[len("```json"):].strip()
                if cleaned_output.endswith("```"):
                    cleaned_output = cleaned_output[:-len("```")].strip()
                evaluation_result_json = json.loads(cleaned_output)
                eval_logger.info("Successfully parsed Gemini evaluation result for Answer.")
            else:
                eval_logger.error("Gemini call via resource returned None or empty for Answer evaluation.")
                error_info = "Gemini call via resource returned None/empty for answer"
        except json.JSONDecodeError as e_json:
            eval_logger.error(f"Failed to decode JSON from Gemini Answer evaluation. Raw output: {raw_gemini_output[:500] if raw_gemini_output else 'N/A'}", exc_info=True)
            error_info = f"JSONDecodeError for answer: {str(e_json)}"
        except Exception as e_gen:
            eval_logger.error(f"Unexpected error during Answer evaluation with Gemini resource: {e_gen}", exc_info=True)
            error_info = f"Unexpected error for answer with Gemini resource: {str(e_gen)}"
            if raw_gemini_output is None:
                raw_gemini_output = error_info

    eval_log_data = {
        "task_type": "answer_evaluation_result",
        "original_interaction_id_ref": original_interaction_id,
        "user_question_for_eval": user_question,
        "retrieved_contexts_for_eval_char_count": len(retrieved_contexts),
        "generated_answer_for_eval": generated_answer,
        "eval_llm_input_prompt_char_count": len(prompt_to_gemini),
        "eval_llm_model": gemini_resource.model_name, # <--- 修改：从资源获取模型名称
        "eval_llm_raw_output": raw_gemini_output,
        "eval_llm_processed_output_json": evaluation_result_json,
        "eval_error_info": error_info,
        "application_version": app_version
    }
    await log_interaction_data(
        eval_log_data,
        is_evaluation_result=True,
        evaluation_name_for_file="answer_gemini_flash"
    )

    if evaluation_result_json:
        eval_logger.info(f"Answer evaluation completed. Overall score: {evaluation_result_json.get('evaluation_summary', {}).get('overall_answer_quality_score')}")
    else:
        eval_logger.warning("Answer evaluation did not produce a valid JSON result.")
        
    return evaluation_result_json

if __name__ == '__main__':
    import asyncio

    # --- 模拟一个 GeminiAPIResource 实例用于测试 ---
    # 在实际的 Dagster 环境中，这个资源会被正确注入
    # 为了让这里的测试能跑通，我们需要一个模拟的资源或配置
    
    class MockGeminiAPIResource:
        def __init__(self, api_key, model_name, proxy_url=None, temp=0.1, max_tokens=1024):
            self.api_key = api_key
            self.model_name = model_name
            self.proxy_url = proxy_url
            self.default_temperature = temp
            self.default_max_tokens = max_tokens
            self._logger = eval_logger # 使用eval_logger进行模拟
            self._logger.info("MockGeminiAPIResource initialized for testing.")
            if not self.api_key:
                 self._logger.warning("MockGeminiAPIResource: API key is missing!")


        async def call_completion(self, messages: List[Dict[str, str]], **kwargs) -> Optional[str]:
            self._logger.info(f"MockGeminiAPIResource.call_completion called with {len(messages)} messages.")
            # 这是一个非常简化的模拟，实际测试时可能需要更复杂的模拟响应
            # 或者直接依赖环境变量 USE_SIMULATED_GEMINI_..._EVAL 来触发 evaluator 内部的模拟
            if "cypher" in messages[0]["content"].lower():
                return json.dumps({
                    "evaluation_summary": {"overall_quality_score_cypher": 5, "main_strength_cypher": "Mocked Cypher OK", "main_weakness_cypher": "None"},
                    "dimensions": {}, "qwen_error_patterns_identified": [], "suggestion_for_improvement_cypher": "Mocked suggestion"
                })
            else:
                return json.dumps({
                     "evaluation_summary": {"overall_answer_quality_score": 5, "main_strengths_answer": "Mocked Answer OK", "main_weaknesses_answer": "None"},
                     "dimensions": {}, "suggestion_for_answer_improvement": "Mocked suggestion for answer"
                })

    async def test_evaluators_with_mock_resource():
        eval_logger.info("--- Running tests for evaluators with MockGeminiAPIResource ---")
        
        mock_api_key = os.getenv("GEMINI_API_KEY") or "MOCK_API_KEY_IF_NOT_SET"
        mock_resource = MockGeminiAPIResource(
            api_key=mock_api_key,
            model_name="gemini-1.5-flash-latest" # 与资源默认值一致
        )

        # --- Test Cypher Evaluation ---
        eval_logger.info("\n--- Testing Cypher Evaluation with Mock Resource ---")
        cypher_result = await evaluate_cypher_with_gemini(
            gemini_resource=mock_resource,
            user_question="Test Cypher Question?",
            generated_cypher="MATCH (n) RETURN n",
            original_interaction_id="test_cypher_eval_001"
        )
        if cypher_result:
            eval_logger.info(f"Mocked Cypher Eval Result: {json.dumps(cypher_result, indent=2, ensure_ascii=False)}")
        else:
            eval_logger.warning("Mocked Cypher Eval returned None.")

        # --- Test Answer Evaluation ---
        eval_logger.info("\n--- Testing Answer Evaluation with Mock Resource ---")
        answer_result = await evaluate_answer_with_gemini(
            gemini_resource=mock_resource,
            user_question="Test Answer Question?",
            retrieved_contexts="Some sample context.",
            generated_answer="A sample answer based on context.",
            original_interaction_id="test_answer_eval_001"
        )
        if answer_result:
            eval_logger.info(f"Mocked Answer Eval Result: {json.dumps(answer_result, indent=2, ensure_ascii=False)}")
        else:
            eval_logger.warning("Mocked Answer Eval returned None.")

    # 如果希望在直接运行 evaluator.py 时执行测试：
    # asyncio.run(test_evaluators_with_mock_resource())
    
    # 保留您之前的测试代码（如果需要独立运行并实际调用API，但要注意资源注入）
    # os.environ["USE_SIMULATED_GEMINI_ANSWER_EVAL"] = "true"
    # asyncio.run(test_answer_evaluation()) # 您之前的测试函数名
    pass # 通常 evaluator.py 不会直接运行，而是被其他脚本调用
    --- END OF FILE CONTENT ---


Directory: zhz_rag/api/
  File: __init__.py
    --- File is empty ---

  File: main_api.py
    --- START OF FILE CONTENT ---
# zhz_agent/main.py
from fastapi import FastAPI
from contextlib import asynccontextmanager
import uvicorn
import logging
from typing import Type, List, Dict, Any, Optional, ClassVar

# --- [修改] 导入 -> 改为绝对导入 ---
from zhz_rag.utils.db_utils import database, sqlalchemy_engine, Base, get_scheduler
from zhz_rag.api.task_manager_api import router as tasks_router
from zhz_rag.task_management import db_models # 确保 SQLAlchemy 模型被导入

@asynccontextmanager
async def lifespan(app_instance: FastAPI):
    print("--- Main FastAPI 应用启动 (已集成任务管理API 和 APScheduler) ---") # [修改] 更新了描述

    # --- 数据库初始化 ---
    await database.connect()
    print("数据库已连接。")
    try:
        Base.metadata.create_all(bind=sqlalchemy_engine)
        print("数据库表已执行 create_all。")
        from sqlalchemy import inspect
        inspector = inspect(sqlalchemy_engine)
        if inspector.has_table("tasks"):
            print("'tasks' 表已成功创建/存在于数据库中。")
        else:
            print("警告: 'tasks' 表在 create_all 之后仍未找到！这通常意味着模型没有在 create_all 之前被正确导入。")
            print(f"   已知的表: {inspector.get_table_names()}") # 打印所有实际创建的表
            print(f"   Base.metadata.tables: {Base.metadata.tables.keys()}") # 打印 SQLAlchemy 元数据中已注册的表
    except Exception as e:
        print(f"创建或检查数据库表时出错: {e}")
        import traceback
        traceback.print_exc() # 打印详细的异常堆栈


    # --- [修改] APScheduler 初始化 (使用 get_scheduler) ---
    current_scheduler = get_scheduler() # <--- 获取调度器实例
    try:
        logging.getLogger('apscheduler').setLevel(logging.DEBUG) # 设置为 DEBUG 级别

        if not current_scheduler.running: # <--- 只有在未运行时才启动
            current_scheduler.start()
            print("APScheduler 已启动并使用数据库作业存储。")
        else:
            print("APScheduler 已在运行。")
    except Exception as e:
        print(f"APScheduler 启动失败: {e}")

    print("RAG 组件的初始化和管理在 zhz_agent_mcp_server.py。")
    print("任务管理API已在 /tasks 路径下可用。")

    yield # FastAPI 应用在此运行

    print("--- Main FastAPI 应用关闭 ---")
    current_scheduler_on_shutdown = get_scheduler() # <--- 再次获取以确保是同一个实例
    if current_scheduler_on_shutdown and current_scheduler_on_shutdown.running:
        current_scheduler_on_shutdown.shutdown()
        print("APScheduler 已关闭。")
    await database.disconnect()
    print("数据库已断开连接。")
    print("RAG 组件的清理在 zhz_agent_mcp_server.py。")

# --- App 定义 (保持不变) ---
app = FastAPI(
    title="Hybrid RAG Backend with Task Management",
    description="主 FastAPI 应用，负责接收请求、编排 Agent，并提供任务管理API。",
    version="0.2.1",
    lifespan=lifespan
)

app.include_router(tasks_router)

@app.get("/")
async def read_root():
    return {
        "message": "Welcome to the Hybrid RAG Backend Main App.",
        "available_services": {
            "task_management": "/tasks/docs",
            "rag_via_mcpo": "mcpo proxy at port 8006 (see mcpo_servers.json)"
        }
    }

if __name__ == "__main__":
    print("--- 启动 Main FastAPI 服务器 (包含任务管理API) ---")
    uvicorn.run("zhz_agent.main:app", host="0.0.0.0", port=8000, reload=True) # Ensure correct run command
    --- END OF FILE CONTENT ---

  File: rag_mcp_service.py
    --- START OF FILE CONTENT ---
# zhz_agent/rag_service.py

import os
import json
import asyncio
import traceback
from contextlib import asynccontextmanager
from typing import List, Dict, Any, Optional, AsyncIterator
from dataclasses import dataclass, field # 确保导入 field
import time
import logging
import sys
import hashlib # <--- 添加
from datetime import datetime, timezone # <--- 添加
import uuid # <--- 添加


# MCP 框架导入
from mcp.server.fastmcp import FastMCP, Context

# --- 配置 rag_service 的专用日志 ---
_rag_service_py_dir = os.path.dirname(os.path.abspath(__file__))
_rag_service_log_file = os.path.join(_rag_service_py_dir, 'rag_service_debug.log')

rag_logger = logging.getLogger("RagServiceLogger")
rag_logger.setLevel(logging.DEBUG)
rag_logger.propagate = False

if rag_logger.hasHandlers():
    rag_logger.handlers.clear()

try:
    _file_handler = logging.FileHandler(_rag_service_log_file, mode='w')
    _file_handler.setLevel(logging.DEBUG)
    _formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s - %(filename)s:%(lineno)d - %(message)s')
    _file_handler.setFormatter(_formatter)
    rag_logger.addHandler(_file_handler)
    rag_logger.info("--- RagServiceLogger configured to write to rag_service_debug.log ---")
except Exception as e:
    print(f"CRITICAL: Failed to configure RagServiceLogger: {e}")


# --- 从项目内部导入所有 RAG 模块 ---
from zhz_rag.config.pydantic_models import QueryRequest, HybridRAGResponse, RetrievedDocument
from zhz_rag.llm.sglang_wrapper import (
    generate_answer_from_context,
    generate_expanded_queries,
    generate_cypher_query,
    generate_clarification_question,
    generate_intent_classification,
    NO_ANSWER_PHRASE_ANSWER_CLEAN
)
from zhz_rag.core_rag.retrievers.chromadb_retriever import ChromaDBRetriever
from zhz_rag.core_rag.retrievers.file_bm25_retriever import FileBM25Retriever
from zhz_rag.core_rag.kg_retriever import KGRetriever
from zhz_rag.core_rag.fusion_engine import FusionEngine
from zhz_rag.utils.common_utils import log_interaction_data

from dotenv import load_dotenv

# 加载 .env 文件
# __file__ 是当前 rag_service.py 的路径: /home/zhz/zhz_agent/rag_service.py
# os.path.dirname(os.path.abspath(__file__)) 是 /home/zhz/zhz_agent 目录
# .env 文件与 rag_service.py 在同一个目录下 (zhz_agent 目录)
current_dir = os.path.dirname(os.path.abspath(__file__))
dotenv_path = os.path.join(current_dir, '.env')

if os.path.exists(dotenv_path):
    load_dotenv(dotenv_path=dotenv_path)
    rag_logger.info(f"Loaded .env file from: {dotenv_path}")
else:
    rag_logger.warning(f".env file not found at {dotenv_path}, will rely on environment variables or defaults.")
    # 仍然尝试加载，因为python-dotenv的默认行为是查找当前工作目录和上级目录的.env
    load_dotenv()

# --- 应用上下文 Dataclass ---
@dataclass
class AppContext:
    # vector_retriever: VectorRetriever # 旧的
    chroma_retriever: Optional[ChromaDBRetriever] = None # 新的
    kg_retriever: Optional[KGRetriever] = None
    # bm25_retriever: BM25Retriever # 旧的
    file_bm25_retriever: Optional[FileBM25Retriever] = None # 新的
    fusion_engine: Optional[FusionEngine] = None
    # llm_generator: Optional[Any] = None # LLMGenerator在您的代码中没有被实例化并放入AppContext

# --- MCP 服务器生命周期管理 ---
@asynccontextmanager
async def app_lifespan_for_rag_service(server: FastMCP) -> AsyncIterator[AppContext]:
    rag_logger.info("--- RAG Service (FastMCP): 正在初始化 RAG 组件 (新版) ---")
    
    chroma_retriever_instance: Optional[ChromaDBRetriever] = None
    kg_retriever_instance: Optional[KGRetriever] = None
    file_bm25_retriever_instance: Optional[FileBM25Retriever] = None
    fusion_engine_instance: Optional[FusionEngine] = None

    # 初始化 ChromaDB Retriever
    try:
        # 这些路径和名称应该与Dagster流水线中配置的一致
        # 优先从环境变量读取，如果不存在则使用默认值（如果适用）
        chroma_persist_dir = os.getenv("CHROMA_PERSIST_DIRECTORY", "/home/zhz/dagster_home/chroma_data")
        chroma_collection_name = os.getenv("CHROMA_COLLECTION_NAME", "rag_documents")
        embedding_model_path = os.getenv("EMBEDDING_MODEL_PATH", "/home/zhz/models/bge-small-zh-v1.5")

        if not os.path.isdir(chroma_persist_dir):
             rag_logger.warning(f"ChromaDB persist directory '{chroma_persist_dir}' not found. Retrieval may fail or use an in-memory DB if ChromaDBRetriever handles this.")
        if not os.path.exists(embedding_model_path): # embedding_model_path 应该是目录
            rag_logger.warning(f"Embedding model path '{embedding_model_path}' not found. ChromaDBRetriever initialization might fail.")

        chroma_retriever_instance = ChromaDBRetriever(
            collection_name=chroma_collection_name,
            persist_directory=chroma_persist_dir,
            embedding_model_name_or_path=embedding_model_path
        )
        rag_logger.info("RAG Service: ChromaDBRetriever 初始化成功。")
    except Exception as e:
        rag_logger.error(f"RAG Service: ChromaDBRetriever 初始化失败: {e}", exc_info=True)
        # 不在此处抛出异常，允许服务在部分组件失败时仍能启动（如果设计如此）
    
    # 初始化 File BM25 Retriever
    try:
        bm25_index_dir = os.getenv("BM25_INDEX_DIRECTORY", "/home/zhz/dagster_home/bm25_index_data/")
        if not os.path.isdir(bm25_index_dir):
            rag_logger.warning(f"BM25 index directory '{bm25_index_dir}' not found. FileBM25Retriever initialization might fail.")
            
        file_bm25_retriever_instance = FileBM25Retriever(
            index_directory_path=bm25_index_dir
        )
        rag_logger.info("RAG Service: FileBM25Retriever 初始化成功。")
    except Exception as e:
        rag_logger.error(f"RAG Service: FileBM25Retriever 初始化失败: {e}", exc_info=True)

    # 初始化 KG Retriever
    try:
        # KGRetriever 内部会从环境变量读取NEO4J配置
        # generate_cypher_query 是从 zhz_agent.llm 导入的
        kg_retriever_instance = KGRetriever(llm_cypher_generator_func=generate_cypher_query)
        rag_logger.info("RAG Service: KGRetriever 初始化成功。")
    except Exception as e:
        rag_logger.error(f"RAG Service: KGRetriever 初始化失败: {e}", exc_info=True)
        if kg_retriever_instance and hasattr(kg_retriever_instance, 'close'): # 确保在失败前尝试关闭
            kg_retriever_instance.close()
            
    # 初始化 Fusion Engine
    try:
        fusion_engine_instance = FusionEngine(logger=rag_logger)
        rag_logger.info("RAG Service: FusionEngine 初始化成功。")
    except Exception as e:
        rag_logger.error(f"RAG Service: FusionEngine 初始化失败: {e}", exc_info=True)

    rag_logger.info("--- RAG Service (FastMCP): RAG 组件初始化尝试完成。---")

    ctx = AppContext(
        chroma_retriever=chroma_retriever_instance,
        kg_retriever=kg_retriever_instance,
        file_bm25_retriever=file_bm25_retriever_instance,
        fusion_engine=fusion_engine_instance
    )
    try:
        yield ctx
    finally:
        rag_logger.info("--- RAG Service (FastMCP): 正在清理资源 ---")
        if kg_retriever_instance: # 确保只在成功初始化后才调用close
            kg_retriever_instance.close() 
        rag_logger.info("--- RAG Service (FastMCP): 清理完成 ---")

# --- 初始化 FastMCP 应用 ---
rag_mcp_application = FastMCP(
    name="zhz_agent_rag_service", # 修改了服务名称以区分
    description="Upgraded Hybrid RAG 服务，使用持久化知识库。",
    lifespan=app_lifespan_for_rag_service,
)

# --- MCP 工具定义 ---
@rag_mcp_application.tool()
async def query_rag_v2( # 重命名工具函数以避免与旧的混淆 (如果需要)
    ctx: Context,
    query: str, # 直接使用 query 作为输入，而不是 QueryRequest 对象
    top_k_vector: int = 3,
    top_k_kg: int = 2,
    top_k_bm25: int = 3,
    top_k_final: int = 3 # 最终融合后返回的文档数
) -> str: 
    rag_logger.info(f"\n--- RAG Service (query_rag_v2): 接收到查询: '{query}' ---")
    rag_logger.info(f"    Params: top_k_vector={top_k_vector}, top_k_kg={top_k_kg}, top_k_bm25={top_k_bm25}, top_k_final={top_k_final}")
    start_time_total = time.time()

    app_ctx: AppContext = ctx.request_context.lifespan_context
    response_payload = {} 
    original_query_for_response = query 
    final_json_output = ""

    try:
        # --- 1. LLM 驱动的意图分类和澄清触发 (保持不变) ---
        rag_logger.info(f"--- [TIME] 开始意图分类 at {time.time() - start_time_total:.2f}s ---")
        start_time_intent = time.time()
        intent_classification_result = await generate_intent_classification(query)
        rag_logger.info(f"--- [TIME] 结束意图分类, 耗时: {time.time() - start_time_intent:.2f}s. Result: {intent_classification_result}")

        if intent_classification_result.get("clarification_needed"):
            uncertainty_reason = intent_classification_result.get("reason", "查询可能存在歧义或信息不足。")
            clarification_question_text = await generate_clarification_question(query, uncertainty_reason)
            response_payload = {
                "status": "clarification_needed",
                "clarification_question": clarification_question_text,
                "original_query": original_query_for_response,
                "debug_info": {"uncertainty_reason": uncertainty_reason, "source": "intent_classification"}
            }
            rag_logger.info(f"--- 需要澄清，返回: {response_payload}")
            final_json_output = json.dumps(response_payload, ensure_ascii=False)
            sys.stdout.flush(); sys.stderr.flush()
            return final_json_output

        # --- 2. 查询扩展 (保持不变) ---
        rag_logger.info(f"--- 查询清晰，无需澄清。开始查询扩展 for: {query} ---")
        start_time_expansion = time.time()
        expanded_queries = await generate_expanded_queries(query) # 假设返回 List[str]
        rag_logger.info(f"--- 扩展查询列表 (共 {len(expanded_queries)} 个): {expanded_queries}. 耗时: {time.time() - start_time_expansion:.2f}s ---")
        
        all_raw_retrievals: List[RetrievedDocument] = []
        
        # --- 3. 并行多路召回 (使用新的检索器) ---
        # 我们将为原始查询和每个扩展查询都执行三路召回
        queries_to_process = [query] + expanded_queries 
        # 或者，如果觉得扩展查询过多，可以只用原始查询或选择性使用扩展查询
        # queries_to_process = [query] # 简化：仅使用原始查询进行召回

        rag_logger.info(f"--- [TIME] 开始并行召回 for {len(queries_to_process)} queries at {time.time() - start_time_total:.2f}s ---")
        start_time_retrieval = time.time()

        for current_query_text in queries_to_process:
            rag_logger.info(f"Processing retrievals for query: '{current_query_text}'")
            
            # 向量检索 (ChromaDB)
            if app_ctx.chroma_retriever:
                try:
                    chroma_docs_raw = app_ctx.chroma_retriever.retrieve(query_text=current_query_text, n_results=top_k_vector)
                    for doc_raw in chroma_docs_raw:
                        all_raw_retrievals.append(
                            RetrievedDocument(
                                source_type="vector_chroma",
                                content=doc_raw.get("text", ""),
                                score=doc_raw.get("score", 0.0),
                                metadata={**doc_raw.get("metadata", {}), "original_query_part": current_query_text} # 添加原始查询部分
                            )
                        )
                    rag_logger.info(f"  ChromaDB for '{current_query_text}': found {len(chroma_docs_raw)} docs.")
                except Exception as e_chroma:
                    rag_logger.error(f"  Error during ChromaDB retrieval for '{current_query_text}': {e_chroma}", exc_info=True)
            
            # 关键词检索 (BM25)
            if app_ctx.file_bm25_retriever:
                try:
                    bm25_docs_raw = app_ctx.file_bm25_retriever.retrieve(query_text=current_query_text, n_results=top_k_bm25)
                    # BM25只返回ID和分数，我们需要补充文本。
                    # 策略：尝试从已有的ChromaDB召回结果中匹配ID补充文本，或标记为待补充。
                    for doc_raw_bm25 in bm25_docs_raw:
                        bm25_chunk_id = doc_raw_bm25.get("id")
                        text_content_for_bm25 = f"[BM25: Text for ID {bm25_chunk_id} pending]"
                        # 简单的补充逻辑：
                        found_in_chroma = False
                        for chroma_doc in all_raw_retrievals: # 检查已有的（主要是chroma的）
                            if chroma_doc.metadata.get("chunk_id") == bm25_chunk_id or chroma_doc.metadata.get("id") == bm25_chunk_id : # ChromaDBRetriever的id是chunk_id
                                text_content_for_bm25 = chroma_doc.content
                                found_in_chroma = True
                                break
                        if not found_in_chroma and app_ctx.chroma_retriever: # 如果没找到，尝试从ChromaDB单独获取
                            try:
                                # 假设ChromaDB存储时ID就是chunk_id
                                # get()方法返回更完整的文档信息
                                specific_chroma_doc = app_ctx.chroma_retriever._collection.get(ids=[bm25_chunk_id], include=["metadatas"])
                                if specific_chroma_doc and specific_chroma_doc.get("metadatas") and specific_chroma_doc.get("metadatas")[0]:
                                    text_content_for_bm25 = specific_chroma_doc["metadatas"][0].get("chunk_text", text_content_for_bm25)
                            except Exception as e_chroma_get:
                                rag_logger.warning(f"  Failed to get text for BM25 ID {bm25_chunk_id} from Chroma: {e_chroma_get}")
                                
                        all_raw_retrievals.append(
                            RetrievedDocument(
                                source_type="keyword_bm25s",
                                content=text_content_for_bm25,
                                score=doc_raw_bm25.get("score", 0.0),
                                metadata={"chunk_id": bm25_chunk_id, "original_query_part": current_query_text}
                            )
                        )
                    rag_logger.info(f"  BM25s for '{current_query_text}': found {len(bm25_docs_raw)} potential docs.")
                except Exception as e_bm25:
                    rag_logger.error(f"  Error during BM25 retrieval for '{current_query_text}': {e_bm25}", exc_info=True)

            # 知识图谱检索 (Neo4j)
            if app_ctx.kg_retriever:
                try:
                    rag_logger.info(f"  Performing KG retrieval for query: '{current_query_text}'") # 添加日志
                    kg_docs = await app_ctx.kg_retriever.retrieve_with_llm_cypher(
                        query=current_query_text, # <--- 修改这里
                        top_k=top_k_kg
                    )
                    # retrieve_with_llm_cypher 已经返回 List[RetrievedDocument]
                    for kg_doc in kg_docs: # 添加原始查询部分到元数据
                        if kg_doc.metadata:
                            kg_doc.metadata["original_query_part"] = current_query_text
                        else:
                            kg_doc.metadata = {"original_query_part": current_query_text}
                    all_raw_retrievals.extend(kg_docs)
                    rag_logger.info(f"  KG Retrieval for '{current_query_text}': found {len(kg_docs)} results.")
                except Exception as e_kg:
                    rag_logger.error(f"  Error during KG retrieval for '{current_query_text}': {e_kg}", exc_info=True)
        
        rag_logger.info(f"--- [TIME] 结束所有召回, 耗时: {time.time() - start_time_retrieval:.2f}s ---")
        rag_logger.info(f"--- 总计从各路召回（所有查询处理后）的结果数: {len(all_raw_retrievals)} ---")
        for i_doc, doc_retrieved in enumerate(all_raw_retrievals[:10]): # 日志只打印前10条
            rag_logger.debug(f"  Raw Doc {i_doc}: type={doc_retrieved.source_type}, score={doc_retrieved.score}, content='{str(doc_retrieved.content)[:100]}...'")

        if not all_raw_retrievals: 
            # ... (无召回结果的处理，与您之前的代码类似) ...
            response_payload = {
                "status": "success", 
                "final_answer": "抱歉，根据您提供的查询，未能从知识库中找到相关信息。",
                "original_query": original_query_for_response,
                "debug_info": {"message": "No documents retrieved from any source."}
            }
            final_json_output = json.dumps(response_payload, ensure_ascii=False)
            sys.stdout.flush(); sys.stderr.flush()
            return final_json_output

        # --- 4. 结果融合与重排序 (使用FusionEngine) ---
        rag_logger.info(f"--- [TIME] 开始结果融合与重排序 at {time.time() - start_time_total:.2f}s ---")
        start_time_fusion = time.time()
        if not app_ctx.fusion_engine:
            rag_logger.error("FusionEngine not available! Skipping fusion and reranking.")
            # 如果没有融合引擎，直接使用原始召回结果（可能需要截断和简单排序）
            # 这里简化处理：直接取 all_raw_retrievals，按分数初排（如果分数可比）
            # 或者只用向量检索结果
            # 为了演示，我们假设至少需要向量结果，或者返回错误
            final_context_docs = sorted(all_raw_retrievals, key=lambda d: d.score, reverse=True)[:top_k_final]
        else:
            # FusionEngine的 fuse_results 方法在您的代码中是异步的
            final_context_docs = await app_ctx.fusion_engine.fuse_results(
                all_raw_retrievals, 
                original_query_for_response, # 传递原始查询给融合引擎
                top_n_final=top_k_final # 传递最终需要的文档数
            ) 
        rag_logger.info(f"--- [TIME] 结束结果融合与重排序, 耗时: {time.time() - start_time_fusion:.2f}s. Final context docs: {len(final_context_docs)} ---")
        
        # --- 5. 准备上下文并生成答案 (与您之前的代码类似) ---
        # 注意：您的FusionEngine.fuse_results 返回的是融合后的文本字符串，而不是RetrievedDocument列表
        # 我们需要调整这里，或者调整FusionEngine使其返回RetrievedDocument列表
        # 假设FusionEngine返回的是RetrievedDocument列表 (需要修改FusionEngine)
        
        if not final_context_docs: # 如果融合后没有文档
            fused_context_text_for_llm = "未在知识库中找到相关信息。"
            final_answer_from_llm = "根据现有知识，未能找到您查询的相关信息。"
            response_payload = {
                "status": "success",
                "final_answer": final_answer_from_llm,
                "original_query": original_query_for_response,
                "debug_info": {"message": "No relevant context found after fusion."}
            }
        else:
            # 假设 final_context_docs 是 List[RetrievedDocument]
            context_strings_for_llm = [
                f"Source Type: {doc.source_type}, Score: {doc.score:.4f}\nContent: {doc.content}" 
                for doc in final_context_docs
            ]
            fused_context_text_for_llm = "\n\n---\n\n".join(context_strings_for_llm)

            rag_logger.info(f"\n--- FUSED CONTEXT for LLM (length: {len(fused_context_text_for_llm)} chars) ---")
            rag_logger.info(f"{fused_context_text_for_llm[:1000]}...") # 日志打印部分上下文
            rag_logger.info(f"--- END OF FUSED CONTEXT ---\n")

            rag_logger.info(f"--- [TIME] 开始最终答案生成 at {time.time() - start_time_total:.2f}s ---")
            start_time_answer_gen = time.time()
            final_answer_from_llm = await generate_answer_from_context(query, fused_context_text_for_llm)
            rag_logger.info(f"--- [TIME] 结束最终答案生成, 耗时: {time.time() - start_time_answer_gen:.2f}s ---")

            if not final_answer_from_llm or final_answer_from_llm.strip() == NO_ANSWER_PHRASE_ANSWER_CLEAN:
                final_answer_from_llm = "根据您提供的信息，我暂时无法给出明确的回答。"
            
            response_payload = {
                "status": "success",
                "final_answer": final_answer_from_llm,
                "original_query": original_query_for_response,
                "retrieved_context_docs": [doc.model_dump() for doc in final_context_docs], # 返回用于生成答案的文档
                "debug_info": {"total_raw_retrievals_count": len(all_raw_retrievals)}
            }

        # --- 添加顶层RAG交互日志记录 (新添加) ---
        if response_payload.get("status") == "success" and final_answer_from_llm and final_context_docs:
            try:
                context_content_for_hash = " ".join(sorted([doc.content for doc in final_context_docs]))
                context_hash = hashlib.md5(context_content_for_hash.encode('utf-8')).hexdigest()
                current_app_version = "0.1.0" # 假设的应用版本，后续可以从配置读取

                top_level_rag_log_data = {
                    "timestamp_utc": datetime.now(timezone.utc).isoformat(),
                    "interaction_id": str(uuid.uuid4()),
                    "task_type": "rag_query_processing_success",
                    "user_query": original_query_for_response,
                    "processed_llm_output": final_answer_from_llm, # RAG的最终答案
                    "retrieved_context_hash": context_hash,
                    "retrieved_documents_summary": [ # 摘要信息
                        {"source": doc.source_type, "score": doc.score, "id": doc.metadata.get("chunk_id") if doc.metadata else doc.metadata.get("id") if doc.metadata else None, "content_preview": doc.content[:50] + "..." if doc.content else ""}
                        for doc in final_context_docs
                    ],
                    "retrieved_context_docs": [doc.model_dump() for doc in final_context_docs], # <<<--- 添加这一行，存储完整的上下文文档
                    "final_context_docs_count": len(final_context_docs),
                    "application_version": current_app_version
                }
                # await log_interaction_data(top_level_rag_log_data) # 如果已经改成通用日志函数
                rag_logger.info(f"TOP_LEVEL_RAG_SUCCESS_LOG: {json.dumps(top_level_rag_log_data, ensure_ascii=False)}")
                await log_interaction_data(top_level_rag_log_data)
            except Exception as e_log_rag:
                rag_logger.error(f"Error during top-level RAG success logging: {e_log_rag}", exc_info=True)
        elif response_payload.get("status") == "clarification_needed":
            try:
                current_app_version = "0.1.0"
                top_level_rag_log_data = {
                    "timestamp_utc": datetime.now(timezone.utc).isoformat(),
                    "interaction_id": str(uuid.uuid4()),
                    "task_type": "rag_clarification_needed",
                    "user_query": original_query_for_response,
                    "clarification_question": response_payload.get("clarification_question"),
                    "uncertainty_reason": response_payload.get("debug_info", {}).get("uncertainty_reason"),
                    "application_version": current_app_version
                }
                # rag_logger.info(f"TOP_LEVEL_RAG_CLARIFICATION_LOG: {json.dumps(top_level_rag_log_data, ensure_ascii=False)}")
                await log_interaction_data(top_level_rag_log_data)
            except Exception as e_log_clarify:
                rag_logger.error(f"Error during top-level RAG clarification logging: {e_log_clarify}", exc_info=True)
        # --- 结束顶层RAG交互日志记录 ---

        final_json_output = json.dumps(response_payload, ensure_ascii=False)
        rag_logger.info(f"--- 'query_rag_v2' 成功执行完毕, 总耗时: {time.time() - start_time_total:.2f}s. 返回JSON响应 ---")
        
        sys.stdout.flush(); sys.stderr.flush() #确保在 try 块内，return 前
        return final_json_output

    except Exception as e_main:
        rag_logger.error(f"RAG Service CRITICAL ERROR in 'query_rag_v2' (main try-except): {type(e_main).__name__} - {str(e_main)}", exc_info=True)
        
        # 确保 original_query_for_response 在此作用域内有效
        # 如果 query_rag_v2 的参数就是 query，且 original_query_for_response 在 try 开始时被赋值为 query
        user_query_for_err_log = original_query_for_response if 'original_query_for_response' in locals() and original_query_for_response else query
        
        response_payload = {
            "status": "error",
            "error_code": "RAG_SERVICE_INTERNAL_ERROR",
            "error_message": f"RAG服务内部发生未预期错误: {str(e_main)}",
            "original_query": user_query_for_err_log,
            "debug_info": {"exception_type": type(e_main).__name__}
        }

        # --- 添加顶层RAG错误日志记录 ---
        try:
            current_app_version = "0.1.0"
            top_level_rag_error_log_data = {
                "timestamp_utc": datetime.now(timezone.utc).isoformat(),
                "interaction_id": str(uuid.uuid4()),
                "task_type": "rag_query_processing_error",
                "user_query": user_query_for_err_log,
                "error_message": str(e_main),
                "error_type": type(e_main).__name__,
                "traceback": traceback.format_exc(),
                "application_version": current_app_version
            }
            # rag_logger.info(f"TOP_LEVEL_RAG_ERROR_LOG: {json.dumps(top_level_rag_error_log_data, ensure_ascii=False)}")
            await log_interaction_data(top_level_rag_error_log_data)
        except Exception as e_log_err_inner:
            rag_logger.error(f"CRITICAL: Error during top-level RAG error logging itself: {e_log_err_inner}", exc_info=True)
        # --- 结束顶层RAG错误日志记录 ---

        final_json_output = json.dumps(response_payload, ensure_ascii=False)
    sys.stdout.flush(); sys.stderr.flush()
    return final_json_output

# --- 用于本地独立测试的 main 部分 ---
async def local_rag_test():
    rag_logger.info("--- Starting Local RAG Test ---")
    # 确保所有服务（ChromaDB数据存在, BM25索引文件存在, Neo4j运行, SGLang运行）都准备好
    
    # 模拟FastMCP的Context和AppContext
    class MockLifespanContext:
        def __init__(self):
            self.chroma_retriever = AppContext().chroma_retriever
            self.file_bm25_retriever = AppContext().file_bm25_retriever
            self.kg_retriever = AppContext().kg_retriever
            self.fusion_engine = AppContext().fusion_engine
            # self.llm_generator = AppContext().llm_generator # 不在AppContext中

    class MockRequestContext:
        def __init__(self):
            self.lifespan_context = MockLifespanContext()

    class MockContext: # 模拟FastMCP的Context
        def __init__(self):
            self.request_context = MockRequestContext()
            self.tool_name = "query_rag_v2" # 假设
            self.call_id = "local_test_call"
            # logger 可以设为 rag_logger
            # self.logger = rag_logger 
            # 但工具函数内部的 app_ctx: AppContext = ctx.request_context.lifespan_context
            # 我们需要确保 lifespan_context 正确填充了检索器

    # 实际的app_lifespan_for_rag_service 会在FastMCP启动时填充AppContext
    # 为了本地测试，我们需要手动模拟这个填充过程，或者直接使用全局初始化的检索器
    # 更简单的方式是，让 query_rag_v2 直接使用全局初始化的检索器（如果它们在模块级别）
    # 但FastMCP的推荐做法是通过lifespan管理上下文。

    # 为了本地测试能跑通，我们先假设app_lifespan_for_rag_service在模块加载时已执行
    # 并填充了全局的检索器实例（虽然这不是FastMCP的典型用法）
    # 或者，我们直接在测试函数内调用 app_lifespan_for_rag_service
    
    async with app_lifespan_for_rag_service(None) as app_context_instance: # 传入None作为server参数
        
        # 构建一个模拟的 request_context，它需要有一个 lifespan_context 属性
        class DummyRequestContext:
            def __init__(self, lifespan_ctx):
                self.lifespan_context = lifespan_ctx
        
        mock_req_context = DummyRequestContext(app_context_instance)

        # 创建 FastMCP Context 实例时，直接传入所有必需的参数
        mock_mcp_context = Context(
            request_context=mock_req_context, # <--- 在这里传入
            tool_name="query_rag_v2",
            call_id="local_test_call",
            logger=rag_logger # 使用我们已配置的 rag_logger
        )
        # 不再需要下面这行，因为它会导致 AttributeError
        # mock_mcp_context.request_context = DummyRequestContext() 
        # mock_mcp_context.request_context.lifespan_context = app_context_instance


    # --- 使用新的测试查询列表 ---
        test_queries = [
            # --- 基本的单实体、单关系查询 ---
            "张三在哪里工作？", 
            "项目Alpha的文档编写任务分配给了谁？", 
            "李四负责哪些任务？",
            "市场部有哪些员工？", 
            "列出所有类型为TASK的实体。",
            "查询所有在创新科技公司工作的员工。",

            # --- 测试对 :ExtractedEntity 和 label 属性的正确使用 ---
            "查找所有人员的名称。", 
            "有多少个组织类型的实体？",

            # --- 稍微复杂一点的查询 ---
            "王五既在A公司工作，又负责了项目B吗？", 
            "列出所有被分配了任务的员工。", 

            # --- 明确指定实体类型的问题 ---
            "名为“市场调研报告”的任务分配给了哪个PERSON？",
            "名为“战略规划部”的ORGANIZATION有哪些PERSON在里面工作？",

            # --- 可能会让Qwen困惑或生成不优查询的问题 ---
            "告诉我关于张三和他的工作单位的信息。", 
            "谁在谷歌工作，并且也负责了项目Alpha的文档编写任务？",

            # --- 测试Schema中不存在的关系或属性 ---
            "张三的年龄是多少？", 
            "项目Alpha的预算有多少？", 
            "李四和王五是同事吗？", 
            "谷歌公司是什么时候成立的？", 
        ]
    # --- 结束新的测试查询列表 ---
        # ... (后续的测试循环代码保持不变) ...
        for t_query in test_queries:
            print(f"\n\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>")
            print(f"EXECUTING LOCAL TEST FOR QUERY: {t_query}")
            print(f">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n")
            response_str = await query_rag_v2(mock_mcp_context, query=t_query, top_k_final=2)
            
            print("\n--- RAG Service Local Test Response ---")
            try:
                response_data = json.loads(response_str)
                print(f"Query: {response_data.get('original_query')}")
                print(f"Answer: {response_data.get('final_answer')}")
                print(f"Status: {response_data.get('status')}")
                if response_data.get('status') == 'success' and response_data.get('retrieved_context_docs'):
                    print("\nRetrieved & Reranked Documents for Context:")
                    for i, doc_dict in enumerate(response_data.get('retrieved_context_docs', [])):
                        # 确保doc_dict是字典才解包
                        if isinstance(doc_dict, dict):
                            doc_obj = RetrievedDocument(**doc_dict) 
                            print(f"  Doc {i+1} (Source: {doc_obj.source_type}, Score: {doc_obj.score:.4f}):")
                            print(f"    Content: {doc_obj.content[:150]}...")
                        else:
                            print(f"  Doc {i+1}: (Unexpected format: {type(doc_dict)}) - {str(doc_dict)[:150]}...")
                elif response_data.get('status') == 'clarification_needed':
                     print(f"Clarification Question: {response_data.get('clarification_question')}")

            except json.JSONDecodeError:
                print("Error decoding JSON response from RAG service.")
                print(f"Raw response string: {response_str}")
            print("---------------------------------------\n")

if __name__ == "__main__":
    if os.getenv("RUN_RAG_SERVICE_LOCAL_TEST") == "true":
        asyncio.run(local_rag_test())
    else:
        rag_logger.info("--- Starting RAG Service (FastMCP for mcpo via direct run) ---")
        rag_mcp_application.run() # 这会启动FastAPI Uvicorn服务器
    --- END OF FILE CONTENT ---

  File: task_manager_api.py
    --- START OF FILE CONTENT ---
# zhz_agent/task_manager_service.py
from fastapi import APIRouter, HTTPException, Depends, Body, Query, Path, status
from typing import List, Optional, Any, cast
from datetime import datetime, timedelta
import uuid
import traceback # 导入 traceback
import pytz

# --- [修改] 从 pydantic_models 导入我们定义的模型 -> 改为绝对导入 ---
from zhz_rag.config.pydantic_models import TaskModel, CreateTaskRequest, UpdateTaskRequest, TaskStatus, ReminderMethod

# --- [修改] 从 database_models 导入 SQLAlchemy 表模型 -> 改为绝对导入 ---
from zhz_rag.task_management.db_models import TaskDB

# --- [修改] 从新的 database.py 导入 database 对象 和 get_scheduler -> 改为绝对导入 ---
from zhz_rag.utils.db_utils import database, get_scheduler # 将 db_utils 修改为 database

# --- [修改] 从 .task_jobs 导入作业函数 -> 改为绝对导入 ---
from zhz_rag.task_management.jobs import send_task_reminder, execute_task_action
from apscheduler.triggers.date import DateTrigger # 用于指定精确的运行时间
from apscheduler.jobstores.base import JobLookupError # <--- [修改] 导入 JobLookupError 的正确路径

# APIRouter 实例
router = APIRouter(
    prefix="/tasks",
    tags=["Task Management"],
    responses={404: {"description": "Not found"}},
)

def _ensure_utc(dt: datetime) -> datetime:
    """确保 datetime 对象是 UTC 时区感知的。"""
    if dt.tzinfo is None:
        return pytz.utc.localize(dt) # 如果是朴素时间，假定它是UTC并设为UTC
    return dt.astimezone(pytz.utc) # 如果是其他时区，转换为UTC

def _schedule_task_jobs(task: TaskModel):
    current_scheduler = get_scheduler() # 获取 scheduler 实例
    print(f"DEBUG SCHEDULER: _schedule_task_jobs called. Scheduler instance: {current_scheduler}, Is running: {current_scheduler.running if current_scheduler else 'N/A'}")
    if not current_scheduler or not current_scheduler.running:
        print("SCHEDULER_ERROR: APScheduler 未运行，无法调度作业。")
        return

    # 提醒作业
    if task.reminder_time and task.status == TaskStatus.PENDING:
        reminder_job_id = f"reminder_{task.id}"
        try:
            reminder_methods_list = task.reminder_methods
            reminder_utc = _ensure_utc(task.reminder_time)
            print(f"SCHEDULER DEBUG: Passing reminder_methods to job: {reminder_methods_list}") # 添加日志

            current_scheduler.add_job(
                send_task_reminder,
                trigger=DateTrigger(run_date=reminder_utc),
                args=[task.id, task.title, reminder_methods_list], # <--- [修复] 直接传递列表
                id=reminder_job_id,
                name=f"Reminder for task {task.title[:20]}",
                replace_existing=True
            )
            print(f"SCHEDULER: 已为任务 '{task.id}' 添加/更新提醒作业，运行于 {task.reminder_time}")
        except Exception as e:
            print(f"SCHEDULER_ERROR: 添加提醒作业失败 for task '{task.id}': {e}")
            traceback.print_exc() # 打印详细错误堆栈

    # 执行作业
    if task.due_date and task.status == TaskStatus.PENDING:
        execution_job_id = f"execution_{task.id}"
        try:
            due_utc = _ensure_utc(task.due_date) # <--- [新增] 确保时间是 UTC 感知的
            print(f"SCHEDULER DEBUG: Adding execution job at {due_utc} ({due_utc.tzinfo})") # <--- [新增] 添加时区日志
            current_scheduler.add_job(
                execute_task_action,
                trigger=DateTrigger(run_date=due_utc),
                args=[task.id, task.action_type, task.action_payload],
                id=execution_job_id,
                name=f"Execution for task {task.title[:20]}",
                replace_existing=True
            )
            print(f"SCHEDULER: 已为任务 '{task.id}' 添加/更新执行作业，运行于 {task.due_date}")
        except Exception as e:
            print(f"SCHEDULER_ERROR: 添加执行作业失败 for task '{task.id}': {e}")

def _cancel_task_jobs(task_id: str):
    """从 APScheduler 取消作业"""
    current_scheduler = get_scheduler()
    if not current_scheduler or not current_scheduler.running:
        print("SCHEDULER_ERROR: APScheduler 未运行，无法取消作业。")
        return

    reminder_job_id = f"reminder_{task_id}"
    execution_job_id = f"execution_{task_id}"

    try:
        current_scheduler.remove_job(reminder_job_id)
        print(f"SCHEDULER: 已移除提醒作业 for task '{task_id}'")
    except JobLookupError:
        print(f"SCHEDULER_INFO: 提醒作业 '{reminder_job_id}' 未找到，无需移除。")
    except Exception as e:
        print(f"SCHEDULER_ERROR: 移除提醒作业失败 for task '{task_id}': {e}")

    try:
        current_scheduler.remove_job(execution_job_id)
        print(f"SCHEDULER: 已移除执行作业 for task '{task_id}'")
    except JobLookupError:
        print(f"SCHEDULER_INFO: 执行作业 '{execution_job_id}' 未找到，无需移除。")
    except Exception as e:
        print(f"SCHEDULER_ERROR: 移除执行作业失败 for task '{task_id}': {e}")

@router.post("/", response_model=TaskModel, status_code=status.HTTP_201_CREATED)
async def create_task(task_request: CreateTaskRequest = Body(...)):
    """
    创建一个新任务。
    """
    now = datetime.utcnow()
    task_id = str(uuid.uuid4())

    reminder_time_val = None
    if task_request.due_date and task_request.reminder_offset_minutes is not None:
        reminder_time_val = task_request.due_date - timedelta(minutes=task_request.reminder_offset_minutes)

    reminder_methods_values = [
        method.value if hasattr(method, 'value') else str(method)
        for method in (task_request.reminder_methods or [ReminderMethod.NOTIFICATION])
    ]

    insert_query = TaskDB.__table__.insert().values(
        id=task_id,
        title=task_request.title,
        description=task_request.description,
        status=TaskStatus.PENDING,
        created_at=now,
        updated_at=now,
        due_date=task_request.due_date,
        reminder_time=reminder_time_val,
        reminder_offset_minutes=task_request.reminder_offset_minutes,
        reminder_methods=reminder_methods_values, # <--- 确保存入的是字符串列表
        priority=task_request.priority or 0,
        tags=task_request.tags or [],
        action_type=task_request.action_type,
        action_payload=task_request.action_payload or {}
    )

    try:
        await database.execute(insert_query)
    except Exception as e:
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Failed to create task in database: {e}")

    created_task_db = await database.fetch_one(TaskDB.__table__.select().where(TaskDB.id == task_id))
    if not created_task_db:
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to retrieve task after creation")

    response_task = TaskModel.model_validate(dict(created_task_db))

    response_task.reminder_methods = [
        m.value if hasattr(m, 'value') else str(m)
        for m in response_task.reminder_methods
    ]

    _schedule_task_jobs(response_task)
    print(f"TASK_MANAGER: Created task '{response_task.id}' with title '{response_task.title}' in DB")
    return response_task

@router.get("/", response_model=List[TaskModel])
async def list_tasks(
    status_filter: Optional[TaskStatus] = Query(None, alias="status"),
    priority_filter: Optional[int] = Query(None, alias="priority"),
    skip: int = Query(0, ge=0),
    limit: int = Query(10, ge=1, le=100)
):
    """
    获取任务列表，支持过滤和分页。
    """
    query = TaskDB.__table__.select()
    if status_filter:
        query = query.where(TaskDB.status == status_filter)
    if priority_filter is not None:
        query = query.where(TaskDB.priority == priority_filter)

    query = query.order_by(TaskDB.created_at.desc()).offset(skip).limit(limit)

    db_tasks = await database.fetch_all(query)
    return [TaskModel.model_validate(dict(task)) for task in db_tasks]

@router.get("/{task_id}", response_model=TaskModel)
async def get_task(task_id: str = Path(..., description="要获取的任务ID")):
    """
    根据ID获取单个任务的详细信息。
    """
    query = TaskDB.__table__.select().where(TaskDB.id == task_id)
    db_task = await database.fetch_one(query)
    if not db_task:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Task not found")
    return TaskModel.model_validate(dict(db_task))

@router.put("/{task_id}", response_model=TaskModel)
async def update_task(
    task_id: str = Path(..., description="要更新的任务ID"),
    task_update: UpdateTaskRequest = Body(...)
):
    """
    更新现有任务。
    """
    existing_task_query = TaskDB.__table__.select().where(TaskDB.id == task_id)
    db_task = await database.fetch_one(existing_task_query)
    if not db_task:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Task not found")

    update_data = task_update.model_dump(exclude_unset=True)
    update_data["updated_at"] = datetime.utcnow()

    if "reminder_methods" in update_data and update_data["reminder_methods"] is not None:
        update_data["reminder_methods"] = [
            method.value if hasattr(method, 'value') else str(method)
            for method in update_data["reminder_methods"]
        ]

    current_due_date = update_data.get("due_date", cast(Optional[datetime], db_task.due_date))
    current_offset = update_data.get("reminder_offset_minutes", cast(Optional[int], db_task.reminder_offset_minutes))

    if current_due_date and current_offset is not None:
        update_data["reminder_time"] = current_due_date - timedelta(minutes=current_offset)
    elif "due_date" in update_data and current_offset is None:
         update_data["reminder_time"] = None


    update_query = TaskDB.__table__.update().where(TaskDB.id == task_id).values(**update_data)
    await database.execute(update_query)

    updated_db_task = await database.fetch_one(existing_task_query)
    if not updated_db_task:
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to retrieve task after update")

    response_task = TaskModel.model_validate(dict(updated_db_task))

    response_task.reminder_methods = [
        m.value if hasattr(m, 'value') else str(m)
        for m in response_task.reminder_methods
    ]

    _cancel_task_jobs(task_id)
    _schedule_task_jobs(response_task)
    print(f"TASK_MANAGER: Updated task '{response_task.id}' in DB")
    return response_task

@router.delete("/{task_id}", status_code=status.HTTP_204_NO_CONTENT)
async def delete_task(task_id: str = Path(..., description="要删除的任务ID")):
    """
    删除一个任务。
    """
    existing_task_query = TaskDB.__table__.select().where(TaskDB.id == task_id)
    db_task = await database.fetch_one(existing_task_query)
    if not db_task:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Task not found")

    delete_query = TaskDB.__table__.delete().where(TaskDB.id == task_id)
    await database.execute(delete_query)

    _cancel_task_jobs(task_id)
    print(f"TASK_MANAGER: Deleted task '{task_id}' from DB")
    return None

@router.post("/{task_id}/complete", response_model=TaskModel)
async def mark_task_as_complete(task_id: str = Path(..., description="要标记为完成的任务ID")):
    """
    将任务标记为已完成。
    """
    existing_task_query = TaskDB.__table__.select().where(TaskDB.id == task_id)
    db_task_row = await database.fetch_one(existing_task_query)
    if not db_task_row:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Task not found")

    db_task = TaskModel.model_validate(dict(db_task_row))
    if db_task.status == TaskStatus.COMPLETED:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Task is already completed")

    update_data = {
        "status": TaskStatus.COMPLETED,
        "updated_at": datetime.utcnow()
    }
    update_query = TaskDB.__table__.update().where(TaskDB.id == task_id).values(**update_data)
    await database.execute(update_query)

    completed_db_task = await database.fetch_one(existing_task_query)
    if not completed_db_task:
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to retrieve task after marking complete")

    response_task = TaskModel.model_validate(dict(completed_db_task))
    _cancel_task_jobs(task_id)
    print(f"TASK_MANAGER: Marked task '{response_task.id}' as completed in DB")
    return response_task
    --- END OF FILE CONTENT ---


Directory: data/
  File: sample_documents.json
    --- START OF FILE CONTENT ---
[
  {
    "id": "doc_sales_q1",
    "content": "2024年第一季度销售报告显示，华东区域销售额增长最快，达到46.5万元，主要得益于新产品A的推出。华北区域总销售额为36.5万元，但利润率有所下降。",
    "metadata": {"source": "Q1_Sales_Report.xlsx", "date": "2024-04-15", "type": "sales_report"}
  },
  {
    "id": "doc_hr_policy",
    "content": "公司最新人力资源政策规定，员工每年享有15天带薪年假，病假需提供医生证明。弹性工作制适用于部分岗位，需部门经理批准。",
    "metadata": {"source": "HR_Policy_2024.pdf", "date": "2024-01-01", "type": "HR_policy"}
  },
  {
    "id": "doc_it_security",
    "content": "IT安全指南强调，所有员工必须定期更换密码，并启用双因素认证。任何可疑邮件应立即报告给IT部门。",
    "metadata": {"source": "IT_Security_Guide.docx", "date": "2023-11-20", "type": "IT_guideline"}
  },
  {
    "id": "doc_meeting_notes",
    "content": "周例会纪要：讨论了项目X的进度，张三负责市场调研，李四负责技术开发。王五提出了关于预算优化的建议。下周将进行客户演示。",
    "metadata": {"source": "Weekly_Meeting_2024-05-10.txt", "date": "2024-05-10", "type": "meeting_notes"}
  },
  {
    "id": "doc_product_launch",
    "content": "新产品A的发布取得了巨大成功，市场反馈积极。预计将在下半年推出产品B，进一步扩大市场份额。",
    "metadata": {"source": "Product_Launch_Review.pptx", "date": "2024-05-01", "type": "product_review"}
  }
]
    --- END OF FILE CONTENT ---

  File: sample_kg.json
    --- START OF FILE CONTENT ---
{
  "schema_description": "这是一个关于公司内部实体和关系的简化知识图谱。\n节点类型包括：\n- Person (人): 属性例如 name (姓名, String类型, 唯一)。\n- Product (产品): 属性例如 name (产品名称, String类型, 唯一)。\n- Region (区域): 属性例如 name (区域名称, String类型, 唯一, 如 '华东', '华北')。\n- Project (项目): 属性例如 name (项目名称, String类型, 唯一)。\n- Document (文档): 属性例如 id (文档ID, String类型, 唯一), content (内容摘要, String类型)。\n- SalesAmount (销售额记录): 属性例如 numeric_amount (数字金额, Float类型), unit (单位, String类型, 如 '万元'), period (时期, String类型, 如 '2024年第一季度')。\n\n关系类型包括：\n- WORKS_ON (人参与项目): (Person)-[:WORKS_ON]->(Project)。\n- AUTHORED_BY (文档由人撰写): (Document)-[:AUTHORED_BY]->(Person)。\n- LOCATED_IN (实体位于区域): 例如 (Person)-[:LOCATED_IN]->(Region)。\n- HAS_SALES_PRODUCT (区域销售了产品): (Region)-[:HAS_SALES_PRODUCT]->(Product)。\n- HAS_SALES_AMOUNT (区域有销售额记录): (Region)-[:HAS_SALES_AMOUNT]->(SalesAmount)。\n- RELATED_TO (实体间相关): 例如 (Product)-[:RELATED_TO]->(Document)。",
  "data_summary": "知识图谱中包含以下关键事实：\n- 人物：张三、李四、王五。\n- 产品：新产品A、产品B。\n- 区域：华东、华北。\n- 项目：项目X。\n- 关系：张三参与项目X，李四参与项目X。华东区域有新产品A的销售额。新产品A的发布文档是doc_product_launch。华东区域2024年第一季度销售额为46.5万元，华北区域2024年第一季度销售额为36.5万元。",
  "facts": [
    {"subject": "张三", "relation": "WORKS_ON", "object": "项目X", "type": "person_project"},
    {"subject": "李四", "relation": "WORKS_ON", "object": "项目X", "type": "person_project"},
    {"subject": "王五", "relation": "PROPOSED_IDEA", "object": "预算优化", "type": "person_idea"}, 
    {"subject": "华东", "relation": "HAS_SALES_PRODUCT", "object": "新产品A", "type": "region_product"},
    {"subject": "新产品A", "relation": "RELATED_TO", "object": "doc_product_launch", "type": "product_document"},
    {"subject": "华东", "relation": "HAS_SALES_AMOUNT", "object": "46.5万元", "type": "region_sales_amount", "period": "2024年第一季度"},
    {"subject": "华北", "relation": "HAS_SALES_AMOUNT", "object": "36.5万元", "type": "region_sales_amount", "period": "2024年第一季度"}
  ]
}
    --- END OF FILE CONTENT ---

  File (skipped, extension not included): test.xlsx

Directory: data/raw_documents/
  File: doc1.txt
    --- START OF FILE CONTENT ---
项目Alpha的文档编写任务分配给了张三。张三在谷歌工作。
    --- END OF FILE CONTENT ---

  File: doc2.txt
    --- START OF FILE CONTENT ---
第二个文档讨论了自然语言处理技术。

    --- END OF FILE CONTENT ---


Directory: scripts/

Directory: scripts/manual_tests/
  File: test_kuzu.py
    --- START OF FILE CONTENT ---
# test_kuzu.py
import kuzu
import os
import pandas as pd
import re # <--- 添加导入
import unicodedata # <--- 添加导入

def normalize_text_for_id(text: str) -> str:
    if not isinstance(text, str):
        return str(text)
    try:
        normalized_text = unicodedata.normalize('NFKD', text)
        normalized_text = normalized_text.lower()
        normalized_text = normalized_text.strip()
        normalized_text = re.sub(r'\s+', ' ', normalized_text)
        return normalized_text
    except Exception as e:
        return text

DB_PATH = "/home/zhz/zhz_agent/zhz_rag/stored_data/kuzu_default_db"

def run_queries(conn: kuzu.Connection):
    print("\n--- Querying Data ---")

    # 规范化查询条件中的文本
    task_text_orig = "项目Alpha的文档编写任务"
    person_text_orig = "张三"
    org_text_orig = "谷歌"

    task_text_norm = normalize_text_for_id(task_text_orig)
    person_text_norm = normalize_text_for_id(person_text_orig)
    org_text_norm = normalize_text_for_id(org_text_orig)

    print(f"Normalized for query: '{task_text_orig}' -> '{task_text_norm}'")
    print(f"Normalized for query: '{person_text_orig}' -> '{person_text_norm}'")
    print(f"Normalized for query: '{org_text_orig}' -> '{org_text_norm}'")


    queries_to_run = {
        "Total ExtractedEntity Nodes": "MATCH (n:ExtractedEntity) RETURN count(n) AS total_entities;",
        "All ExtractedEntity Nodes (Limit 5)": "MATCH (n:ExtractedEntity) RETURN n.id_prop, n.text, n.label LIMIT 5;",
        # 使用规范化后的文本进行查询
        "Specific Entity (张三 - normalized)": f"MATCH (n:ExtractedEntity {{text: '{person_text_norm}', label: 'PERSON'}}) RETURN n.id_prop, n.text, n.label;",
        "Specific Entity (项目Alpha... - normalized)": f"MATCH (n:ExtractedEntity {{text: '{task_text_norm}', label: 'TASK'}}) RETURN n.id_prop, n.text, n.label;",
        "Specific Entity (谷歌 - normalized)": f"MATCH (n:ExtractedEntity {{text: '{org_text_norm}', label: 'ORGANIZATION'}}) RETURN n.id_prop, n.text, n.label;",
        
        "Total WorksAt Relationships": "MATCH ()-[r:WorksAt]->() RETURN count(r) AS total_works_at_rels;",
        "Total AssignedTo Relationships": "MATCH ()-[r:AssignedTo]->() RETURN count(r) AS total_assigned_to_rels;",
        
        # 关系查询也使用规范化文本（如果条件中包含文本）
        "Who works at 谷歌? (normalized)": f"MATCH (p:ExtractedEntity {{label: 'PERSON'}})-[r:WorksAt]->(o:ExtractedEntity {{text: '{org_text_norm}', label: 'ORGANIZATION'}}) RETURN p.text AS person_name;",
        "Where does 张三 work? (normalized)": f"MATCH (p:ExtractedEntity {{text: '{person_text_norm}', label: 'PERSON'}})-[r:WorksAt]->(o:ExtractedEntity {{label: 'ORGANIZATION'}}) RETURN o.text AS organization_name;",
        "What task is assigned to 张三? (normalized)": f"MATCH (t:ExtractedEntity {{label: 'TASK'}})-[r:AssignedTo]->(p:ExtractedEntity {{text: '{person_text_norm}', label: 'PERSON'}}) RETURN t.text AS task_name;",
        "Who is the task '项目Alpha...' assigned to? (normalized)": f"MATCH (t:ExtractedEntity {{text: '{task_text_norm}', label: 'TASK'}})-[r:AssignedTo]->(p:ExtractedEntity {{label: 'PERSON'}}) RETURN p.text AS person_name;",
        
        "All WorksAt Relationships (Source and Target Text)": "MATCH (src:ExtractedEntity)-[r:WorksAt]->(tgt:ExtractedEntity) RETURN src.text AS source_text, src.label AS source_label, tgt.text AS target_text, tgt.label AS target_label;",
        "All AssignedTo Relationships (Source and Target Text)": "MATCH (src:ExtractedEntity)-[r:AssignedTo]->(tgt:ExtractedEntity) RETURN src.text AS source_text, src.label AS source_label, tgt.text AS target_text, tgt.label AS target_label;",
    }

    for description, query_str in queries_to_run.items():
        print(f"\nExecuting Query: {description}")
        print(f"Cypher: {query_str}")
        try:
            results = conn.execute(query_str)
            # 使用 pandas 显示结果更美观
            df = pd.DataFrame(results.get_as_df())
            if not df.empty:
                print(df.to_string())
            else:
                print("  Query returned no results.")
            results.close() # 记得关闭结果集
        except Exception as e:
            print(f"  Error executing query: {e}")

def main():
    print(f"Kuzu Python client version: {kuzu.__version__}")
    print(f"Attempting to connect to KuzuDB at: {DB_PATH}")

    if not os.path.exists(DB_PATH):
        print(f"ERROR: Database directory not found at {DB_PATH}")
        print("Please ensure the Dagster KuzuDB pipeline has run successfully and created the database.")
        return

    db = None
    conn = None
    try:
        # --- 连接到已存在的数据库 (只读模式足够用于查询) ---
        # 如果需要执行写操作（例如，在测试中临时修改），可以使用 read_only=False
        db = kuzu.Database(DB_PATH, read_only=True)
        conn = kuzu.Connection(db)
        print(f"Successfully connected to KuzuDB. Database path: {os.path.abspath(DB_PATH)}")

        # --- 列出所有表 (使用我们从研究报告中知道的方法) ---
        print("\n--- Listing Tables ---")
        try:
            node_tables = conn._get_node_table_names()
            print(f"Node Tables: {node_tables}")
            rel_tables_info = conn._get_rel_table_names()
            rel_tables = [info['name'] for info in rel_tables_info]
            print(f"Rel Tables: {rel_tables}")
            all_tables = node_tables + rel_tables
            print(f"All Tables: {all_tables}")

            # 验证核心表是否存在
            expected_tables = ["ExtractedEntity", "WorksAt", "AssignedTo"]
            missing = [t for t in expected_tables if t not in all_tables]
            if not missing:
                print("Core tables (ExtractedEntity, WorksAt, AssignedTo) are present.")
            else:
                print(f"WARNING: Missing core tables: {missing}")

        except Exception as e_list_tables:
            print(f"Error listing tables: {e_list_tables}")
            print("This might indicate an issue with the KuzuDB connection or version compatibility for these internal methods.")

        # --- 执行查询 ---
        if conn: # 确保连接有效
            run_queries(conn)

    except Exception as e:
        print(f"An error occurred: {e}")
        import traceback
        traceback.print_exc()
    finally:
        print("\nKuzuDB test script finished.")
        # Kuzu Connection 没有显式的 close() 方法
        # Kuzu Database 对象在其 __del__ 方法中处理关闭
        if db is not None:
            del db # 确保数据库对象被垃圾回收，从而关闭

if __name__ == "__main__":
    main()
    --- END OF FILE CONTENT ---

  File: test_litellm_local.py
    --- START OF FILE CONTENT ---
# test_litellm_local.py
import litellm
import os
import traceback
import json

# 不再依赖 LITELLM_CONFIG_PATH 来测试这个本地模型
# if "LITELLM_CONFIG_PATH" in os.environ:
#     del os.environ["LITELLM_CONFIG_PATH"] # 确保它不干扰

litellm.set_verbose = True 

messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "中国的首都是哪里？请用中文回答。并简要介绍一下它。"}
]

custom_llm_model_name_in_litellm = "local/qwen3-1.7b-gguf" 
custom_llm_api_base = "http://localhost:8088/v1"        
custom_llm_api_key = "nokey"                            

print("--- Test Case: Calling local LLM via LiteLLM with direct parameters ---")
try:
    print(f"Attempting to call '{custom_llm_model_name_in_litellm}' via LiteLLM...")
    print(f"  Target API Base: {custom_llm_api_base}")
    print(f"  Using API Key: {custom_llm_api_key}")
    print(f"  Messages: {json.dumps(messages, ensure_ascii=False, indent=2)}")
    
    response = litellm.completion(
        model=custom_llm_model_name_in_litellm,
        messages=messages,
        max_tokens=1024, 
        temperature=0.7,
        custom_llm_provider="openai", 
        api_base=custom_llm_api_base,
        api_key=custom_llm_api_key 
    )
    
    print(f"\n--- Response from '{custom_llm_model_name_in_litellm}' ---")
    if response.choices and response.choices[0].message and response.choices[0].message.content is not None:
        print("\nProcessed Content (from LiteLLM response):")
        print(response.choices[0].message.content)
    else:
        print("\nNo content found in LiteLLM response choices.")
        print("Full Response (if any):")
        print(response)

    print("\nUsage Information (from LiteLLM response):")
    if response.usage:
        print(f"  Prompt Tokens: {response.usage.prompt_tokens}")
        print(f"  Completion Tokens: {response.usage.completion_tokens}")
        print(f"  Total Tokens: {response.usage.total_tokens}")
    else:
        print("  Usage information not available.")

except Exception as e:
    print(f"\n--- ERROR ---")
    print(f"Error calling '{custom_llm_model_name_in_litellm}' via LiteLLM: {e}")
    traceback.print_exc()

print("\n--- test_litellm_local.py finished ---")
    --- END OF FILE CONTENT ---

  File: test_llama_cpp.py
    --- START OF FILE CONTENT ---
from llama_cpp import Llama
import os

MODEL_DIR = "/home/zhz/models/Qwen3-1.7B-GGUF" # 您存放模型的目录
# 列出该目录下所有的 .gguf 文件，让用户选择或自动选择一个
gguf_files = [f for f in os.listdir(MODEL_DIR) if f.endswith(".gguf")]

if not gguf_files:
    print(f"No GGUF models found in {MODEL_DIR}")
    exit()

print("Available GGUF models:")
for i, fname in enumerate(gguf_files):
    print(f"{i+1}. {fname}")

# 为了测试，我们直接使用您下载的 Qwen 模型文件名
# 您可以根据实际文件名修改，或者实现一个选择逻辑
# 假设您的模型文件名中包含 "Qwen1.7B-GGUF" 或类似标识
qwen_model_filename = None
for fname in gguf_files:
    if "Qwen" in fname and "1.7B" in fname and fname.endswith(".gguf"): # 简单匹配
        qwen_model_filename = fname
        break

if not qwen_model_filename:
    print("Could not automatically find a Qwen 1.7B GGUF model. Please specify one.")
    # 或者让用户输入选择：
    # choice = int(input(f"Select a model by number (1-{len(gguf_files)}): ")) - 1
    # qwen_model_filename = gguf_files[choice]
    exit()

MODEL_PATH = os.path.join(MODEL_DIR, qwen_model_filename)
print(f"\nUsing model: {MODEL_PATH}")

# --- LLM 初始化参数 ---
# n_gpu_layers: 设置为 > 0 可以将部分层卸载到 GPU (如果兼容且已安装 GPU 支持的 llama.cpp 版本)
# 设置为 0 则完全使用 CPU。对于 RTX 3060 (12GB)，可以尝试设置一个较大的值，例如 20-30，具体取决于模型大小和VRAM。
# 对于1.7B模型，如果VRAM足够，可以尝试更高的值，甚至 -1 (全部卸载)。
# 我们先从 CPU 开始测试，n_gpu_layers=0
N_GPU_LAYERS = 0
N_CTX = 2048 #模型的上下文窗口大小，Qwen1.7B 可能支持更长的，具体查阅模型卡片
N_BATCH = 512 # 提示处理的批处理大小

try:
    print(f"Initializing Llama model from: {MODEL_PATH}...")
    print(f"Parameters: n_gpu_layers={N_GPU_LAYERS}, n_ctx={N_CTX}, n_batch={N_BATCH}")
    
    llm = Llama(
        model_path=MODEL_PATH,
        n_gpu_layers=N_GPU_LAYERS,
        n_ctx=N_CTX,
        n_batch=N_BATCH,
        verbose=True # 打印更多加载信息
    )
    print("Llama model initialized successfully.")

    # --- 测试 1: 简单文本生成 ---
    prompt_simple = "中国的首都是哪里？请用中文回答。"
    print(f"\n--- Test 1: Simple Text Generation ---")
    print(f"Prompt: {prompt_simple}")
    output_simple = llm(
        prompt_simple,
        max_tokens=50, # 生成的最大 token 数
        stop=["\n", " Human:", " Assistant:"], # 停止词
        echo=False # 不回显 prompt
    )
    print(f"LLM Output: {output_simple['choices'][0]['text'].strip()}")

    # --- 测试 2: Text-to-Cypher (初步) ---
    # 使用简化的 Schema 和问题进行测试
    # 您可以将 NEW_KG_SCHEMA_DESCRIPTION 从 constants.py 复制过来或导入
    # 这里为了独立性，我们先用一个极简的描述
    kg_schema_simple = """
    节点标签: ExtractedEntity (属性: text, label)
    关系类型: WORKS_AT (从 PERSON 到 ORGANIZATION), ASSIGNED_TO (从 TASK 到 PERSON)
    实体标签值: PERSON, ORGANIZATION, TASK
    """
    user_question_cypher = "张三在哪里工作？"
    prompt_cypher = f"""
    你是一个将自然语言问题转换为Cypher查询的助手。
    严格根据以下Schema生成Cypher查询：
    {kg_schema_simple}
    用户问题: {user_question_cypher}
    Cypher查询: MATCH (p:ExtractedEntity {{text: '张三', label: 'PERSON'}})-[:WORKS_AT]->(o:ExtractedEntity {{label: 'ORGANIZATION'}}) RETURN o.text
    用户问题: 项目Alpha分配给了谁？
    Cypher查询: MATCH (t:ExtractedEntity {{text: '项目Alpha', label: 'TASK'}})-[:ASSIGNED_TO]->(p:ExtractedEntity {{label: 'PERSON'}}) RETURN p.text
    用户问题: {user_question_cypher}
    Cypher查询:""" # Few-shot prompting

    print(f"\n--- Test 2: Text-to-Cypher (Simple) ---")
    print(f"User question for Cypher: {user_question_cypher}")
    # print(f"Cypher Prompt (simplified): {prompt_cypher}") # Prompt 可能很长
    
    output_cypher = llm(
        prompt_cypher,
        max_tokens=150,
        stop=["\n", "用户问题:"],
        temperature=0.1, # 对于代码生成，低temperature通常更好
        echo=False
    )
    generated_cypher = output_cypher['choices'][0]['text'].strip()
    print(f"Generated Cypher: {generated_cypher}")

    # --- 测试 3: 上下文问答 (初步) ---
    context_qa = "根据KuzuDB的文档，它是一个嵌入式的图数据库，支持Cypher查询语言。"
    user_question_qa = "KuzuDB支持什么查询语言？"
    prompt_qa = f"""
    根据以下上下文回答问题。
    上下文: {context_qa}
    问题: {user_question_qa}
    答案:"""

    print(f"\n--- Test 3: Contextual QA (Simple) ---")
    print(f"Context: {context_qa}")
    print(f"User question for QA: {user_question_qa}")
    output_qa = llm(
        prompt_qa,
        max_tokens=100,
        stop=["\n", "问题:"],
        temperature=0.2,
        echo=False
    )
    generated_answer_qa = output_qa['choices'][0]['text'].strip()
    print(f"Generated Answer: {generated_answer_qa}")

except Exception as e:
    print(f"An error occurred with Llama.cpp: {e}")
    import traceback
    traceback.print_exc()
finally:
    print("\nLlama.cpp test script finished.")
    if 'llm' in locals() and hasattr(llm, 'close'): # llama_cpp Llama对象没有close方法
         pass # llm对象在Python中通常通过垃圾回收来释放资源
    --- END OF FILE CONTENT ---


Directory: kuzu_test_db/
  File (skipped, extension not included): .lock
  File (skipped, extension not included): .shadow
  File (skipped, extension not included): .wal
  File (skipped, extension not included): catalog.kz
  File (skipped, extension not included): data.kz
  File (skipped, extension not included): metadata.kz
  File (skipped, extension not included): n-0.hindex
  File (skipped, extension not included): n-0.hindex.ovf

Directory: utils/
  File: __init__.py
    --- File is empty ---

  File: common_utils.py
    --- START OF FILE CONTENT ---
# /home/zhz/zhz_agent/utils/common_utils.py

import httpx
import json
import traceback
import os
import logging

# --- 日志配置 ---
logger = logging.getLogger(__name__)
# (您可以根据需要添加更详细的日志配置)

# --- MCP 配置 ---
MCPO_BASE_URL = os.getenv("MCPO_BASE_URL", "http://localhost:8006")

async def call_mcpo_tool(tool_name_with_prefix: str, payload: dict) -> dict:
    """
    异步调用MCP工具服务。
    tool_name_with_prefix 例如: "zhz_rag_mcp_service/query_rag_v2" 或 "ddgsearch/search"
    payload 是传递给MCP工具的参数字典。
    返回一个字典，成功时包含工具的输出，失败时包含 "error" 键。
    """
    api_url = f"{MCPO_BASE_URL}/{tool_name_with_prefix}"
    cleaned_payload = {k: v for k, v in (payload or {}).items() if v is not None}

    logger.info(f"Calling MCP endpoint: POST {api_url} with payload: {json.dumps(cleaned_payload, ensure_ascii=False)}")

    async with httpx.AsyncClient(timeout=120.0) as client: # 增加超时
        response = None
        try:
            headers = {"Content-Type": "application/json"}
            response = await client.post(api_url, json=cleaned_payload, headers=headers)
            logger.info(f"MCP status code for {tool_name_with_prefix}: {response.status_code}")

            if response.status_code == 200:
                try:
                    result_data = response.json()
                    # 检查 MCP 服务本身是否返回了错误结构 (例如 MCP 框架的错误包装)
                    if isinstance(result_data, dict) and result_data.get("isError"): # 假设 MCP 错误格式
                        error_text = result_data.get("content", [{"text": "Unknown error from MCP tool"}])[0].get("text")
                        logger.error(f"MCP Tool '{tool_name_with_prefix}' execution failed (isError=true): {error_text}")
                        return {"error": f"Tool '{tool_name_with_prefix}' failed via MCP: {error_text}"}
                    return result_data # 假设成功时直接返回工具的 JSON 输出
                except json.JSONDecodeError:
                    logger.warning(f"MCP call to '{tool_name_with_prefix}' returned status 200 but response is not JSON. Raw text: {response.text[:500]}...")
                    return {"error": "Non-JSON response from MCP tool", "raw_response": response.text}
            else:
                error_text = f"MCP call to '{tool_name_with_prefix}' failed with status {response.status_code}. Response: {response.text[:500]}..."
                logger.error(error_text)
                return {"error": error_text, "status_code": response.status_code}

        except httpx.RequestError as exc:
            error_msg = f"HTTP RequestError calling MCP tool '{tool_name_with_prefix}': {type(exc).__name__} - {exc}"
            logger.error(error_msg, exc_info=True)
            return {"error": error_msg, "exception_type": type(exc).__name__}
        except Exception as exc:
            error_msg = f"Unexpected error calling MCP tool '{tool_name_with_prefix}': {type(exc).__name__} - {exc}"
            response_text_snippet = response.text[:500] if response and hasattr(response, 'text') else "N/A"
            logger.error(f"{error_msg}. Response snippet: {response_text_snippet}", exc_info=True)
            return {"error": error_msg, "exception_type": type(exc).__name__}

# 确保 utils 目录也有一个 __init__.py 文件
# touch /home/zhz/zhz_agent/utils/__init__.py (如果不存在)
    --- END OF FILE CONTENT ---


Directory: stored_data/

Directory: stored_data/rag_interaction_logs/

Directory: local_agent/
  File: local_agent_app.py
    --- START OF FILE CONTENT ---
# /home/zhz/zhz_agent/local_agent/local_agent_app.py

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from typing import Dict, Any, List, Optional
import pandas as pd # 用于处理 Excel 数据
from pandasql import PandaSQL # 用于在 Pandas DataFrame 上执行 SQL 查询
import os
import logging # 用于日志记录
import traceback # 用于更详细的错误信息

# --- [新增] 导入 winotify 用于发送 Windows 桌面通知 ---
from winotify import Notification #

# --- 配置常量 ---
LOCAL_AGENT_PORT = 8003 # 本地代理服务监听的端口
LOG_LEVEL = logging.INFO # 日志级别

# --- 日志配置 ---
# 配置日志记录器，方便调试和追踪
logging.basicConfig(level=LOG_LEVEL, format='%(asctime)s - %(levelname)s - LocalAgent - %(message)s') #
logger = logging.getLogger(__name__) #

# --- FastAPI 应用实例 ---
app = FastAPI(
    title="ZhzAI Local Agent", #
    description="本地代理程序，提供处理本地文件（如Excel）和执行特定本地任务（如桌面通知）的MCP服务。", #
    version="0.1.1" # 更新版本号以反映添加了通知功能
)

# --- Pydantic 模型定义 ---

# 用于 Excel SQO (Structured Query Object) 操作的请求体
class ExecuteSQORequest(BaseModel): #
    sqo: Dict[str, Any] = Field(description="必需。一个结构化查询对象 (SQO) 的JSON字典，用于描述要对Excel执行的操作。") #

# Excel SQO 操作的通用响应体
class SQOResponse(BaseModel): #
    success: bool # 操作是否成功
    result: Any = None # 成功时的结果数据
    error: Optional[str] = None # 失败时的简要错误信息
    error_details: Optional[str] = None # 失败时的详细技术错误信息或堆栈

# 用于桌面通知的请求体
class NotificationRequest(BaseModel): #
    title: str = Field(default="任务提醒", description="通知的标题") #
    message: str = Field(description="通知的主要内容") #
    app_name: str = Field(default="终端大脑助手", description="显示在通知来源的应用名称") #
    # icon_path: Optional[str] = Field(None, description="通知图标的绝对路径 (可选)") #

# 桌面通知操作的响应体
class NotificationResponse(BaseModel): #
    success: bool # 操作是否成功 #
    message: str # 返回的消息，成功或失败的说明 #

# --- 核心功能函数 ---

def apply_filters_to_dataframe(df: pd.DataFrame, filters: List[Dict[str, Any]]) -> pd.DataFrame: #
    """
    将一系列过滤器应用于 Pandas DataFrame。
    这是 Excel SQO 操作的核心辅助函数，用于在执行聚合、查询等操作前筛选数据。
    """
    if not filters: #
        return df #

    df_filtered = df.copy() #
    for f_obj in filters: #
        column = f_obj.get("column") #
        operator = f_obj.get("operator") #
        value = f_obj.get("value") #
        is_date = f_obj.get("is_date", False) #

        if not all([column, operator, value is not None]): #
            logger.warning(f"Skipping invalid filter object: {f_obj}") #
            continue #

        if column not in df_filtered.columns: #
            logger.warning(f"Filter column '{column}' not found in DataFrame. Available: {df_filtered.columns.tolist()}. Skipping filter: {f_obj}") #
            continue #

        try: #
            series_to_filter = df_filtered[column] # 操作副本以避免 SettingWithCopyWarning #
            
            # 尝试转换日期，如果失败则记录警告并可能跳过
            if is_date: #
                try: #
                    series_to_filter = pd.to_datetime(series_to_filter, errors='coerce') #
                    filter_value_dt = pd.to_datetime(value, errors='coerce') #
                    # 如果日期转换失败且操作符不是处理列表的类型（列表值在后面处理）
                    if pd.isna(filter_value_dt) and not (isinstance(value, list) and operator in ["in", "is_in_list", "not in", "is_not_in_list"]): #
                        logger.warning(f"Cannot convert filter value '{value}' to date for column '{column}'. Skipping filter.") #
                        continue #
                    value = filter_value_dt # 更新 value 为日期对象或 NaT #
                except Exception as e_date: #
                    logger.warning(f"Error converting column '{column}' or value '{value}' to datetime: {e_date}. Skipping filter.") #
                    continue #
            
            condition = None #
            # 根据操作符构建筛选条件
            if operator == "equals" or operator == "==": #
                condition = (series_to_filter == value) #
            elif operator == "not_equals" or operator == "!=": #
                condition = (series_to_filter != value) #
            elif operator == "greater_than" or operator == ">": #
                condition = (series_to_filter > value) #
            elif operator == "greater_than_or_equals" or operator == ">=": #
                condition = (series_to_filter >= value) #
            elif operator == "less_than" or operator == "<": #
                condition = (series_to_filter < value) #
            elif operator == "less_than_or_equals" or operator == "<=": #
                condition = (series_to_filter <= value) #
            elif operator == "contains": #
                if is_date: #
                    logger.warning(f"'contains' operator is not directly applicable to date column '{column}'. Skipping filter.") #
                    continue #
                condition = (series_to_filter.astype(str).str.contains(str(value), case=False, na=False)) #
            elif operator == "not_contains": #
                if is_date: #
                    logger.warning(f"'not_contains' operator is not directly applicable to date column '{column}'. Skipping filter.") #
                    continue #
                condition = (~series_to_filter.astype(str).str.contains(str(value), case=False, na=False)) #
            elif operator == "is_in_list" or operator == "in": #
                if not isinstance(value, list): #
                    logger.warning(f"'is_in_list' operator expects a list value for column '{column}'. Skipping filter.") #
                    continue #
                if is_date: #
                    list_value_dt = pd.to_datetime(value, errors='coerce').dropna().tolist() #
                    if not list_value_dt: #
                        logger.warning(f"Cannot convert list values to dates for 'is_in_list' on column '{column}'. Skipping filter.") #
                        continue #
                    condition = (series_to_filter.isin(list_value_dt)) #
                else: #
                    condition = (series_to_filter.isin(value)) #
            elif operator == "is_not_in_list" or operator == "not in": #
                if not isinstance(value, list): #
                    logger.warning(f"'is_not_in_list' operator expects a list value for column '{column}'. Skipping filter.") #
                    continue #
                if is_date: #
                    list_value_dt = pd.to_datetime(value, errors='coerce').dropna().tolist() #
                    if not list_value_dt: #
                         logger.warning(f"Cannot convert list values to dates for 'is_not_in_list' on column '{column}'. Skipping filter.") #
                         continue #
                    condition = (~series_to_filter.isin(list_value_dt)) #
                else: #
                    condition = (~series_to_filter.isin(value)) #
            elif operator == "between": #
                if not (isinstance(value, list) and len(value) == 2): #
                    logger.warning(f"'between' operator expects a list of two values for column '{column}'. Skipping filter.") #
                    continue #
                val1, val2 = value #
                if is_date: #
                    val1_dt = pd.to_datetime(val1, errors='coerce') #
                    val2_dt = pd.to_datetime(val2, errors='coerce') #
                    if pd.isna(val1_dt) or pd.isna(val2_dt): #
                        logger.warning(f"Cannot convert 'between' values to dates for column '{column}'. Skipping filter.") #
                        continue #
                    condition = (series_to_filter.between(min(val1_dt, val2_dt), max(val1_dt, val2_dt))) #
                else: #
                    condition = (series_to_filter.between(min(val1, val2), max(val1, val2))) #
            elif operator == "is_null" or operator == "isnull": #
                condition = (series_to_filter.isnull()) #
            elif operator == "is_not_null" or operator == "notnull": #
                condition = (series_to_filter.notnull()) #
            else: #
                logger.warning(f"Unsupported filter operator '{operator}' for column '{column}'. Skipping filter.") #
                continue # 跳过不支持的操作符 #

            if condition is not None: #
                 df_filtered = df_filtered[condition] #
            else: #
                logger.warning(f"Condition was None for filter {f_obj}. This should not happen if operator is supported.") #

        except Exception as e_filter: #
            logger.error(f"Error applying filter {f_obj} on column '{column}': {e_filter}", exc_info=True) #
            # 根据策略，可以选择跳过此过滤器或在此处引发异常/返回错误
            # 为保持流程继续，我们选择跳过错误的过滤器
            continue #
            
    return df_filtered #

# --- FastAPI 端点 ---

@app.post("/notify", response_model=NotificationResponse) #
async def send_desktop_notification(req: NotificationRequest): #
    """
    接收通知请求并在 Windows 桌面上显示一个通知。
    """
    logger.info(f"Received notification request: Title='{req.title}', Message='{req.message}'") #
    try: #
        toast = Notification( #
            app_id=req.app_name, #
            title=req.title, #
            msg=req.message, #
            # duration="long", # 可选 #
            # icon=req.icon_path if req.icon_path and os.path.exists(req.icon_path) else "" # 可选 #
        )
        toast.show() #
        
        logger.info(f"Desktop notification successfully shown: '{req.title}'") #
        return NotificationResponse(success=True, message="Notification successfully shown.") #
    except Exception as e: #
        logger.error(f"Failed to show desktop notification: {e}", exc_info=True) #
        raise HTTPException(status_code=500, detail=f"Failed to show notification: {str(e)}") #


@app.post("/excel_sqo_mcp/execute_operation", response_model=SQOResponse) #
async def execute_excel_sqo_operation(request_data: ExecuteSQORequest): #
    """
    执行 Excel 结构化查询对象 (SQO) 操作。
    这个端点负责根据传入的 SQO 对指定的 Excel 文件进行数据读取、筛选、聚合等操作。
    """
    sqo = request_data.sqo #
    operation_type = sqo.get("operation_type") #
    file_path = sqo.get("file_path") #
    sheet_name = sqo.get("sheet_name", 0) # 默认为第一个工作表 #

    logger.info(f"Received SQO request: operation='{operation_type}', file='{file_path}', sheet='{sheet_name}'") #
    logger.debug(f"Full SQO received: {sqo}") #

    if not file_path or not operation_type: #
        logger.error("SQO missing 'file_path' or 'operation_type'.") #
        return SQOResponse(success=False, error="SQO中缺少 'file_path' 或 'operation_type' 参数。") #

    # 安全性提示：在生产环境中，需要对 file_path 进行严格校验，防止路径遍历等安全风险。
    # 例如，限制只能访问特定目录下的文件。
    if not os.path.exists(file_path): #
        logger.error(f"Excel file not found: {file_path}") #
        return SQOResponse(success=False, error=f"Excel文件未找到 '{file_path}'") #

    try: #
        # 读取 Excel 文件到 Pandas DataFrame
        df = pd.read_excel(file_path, sheet_name=sheet_name) #
        logger.info(f"Successfully loaded DataFrame. Shape: {df.shape}, Columns: {df.columns.tolist()}") #

        result_data = None #

        # --- 根据操作类型执行不同逻辑 ---

        if operation_type == "get_unique_values": #
            column_name = sqo.get("column_name") #
            if not column_name or column_name not in df.columns: #
                error_msg = f"'get_unique_values' 操作缺少有效 'column_name' 或列 '{column_name}' 不存在。可用列: {df.columns.tolist()}" #
                logger.error(error_msg) #
                return SQOResponse(success=False, error=error_msg) #
            
            df_to_process = df.copy() #
            filters_from_sqo = sqo.get("filters") #
            if filters_from_sqo and isinstance(filters_from_sqo, list): #
                logger.info(f"Applying filters for get_unique_values: {filters_from_sqo}") #
                df_to_process = apply_filters_to_dataframe(df_to_process, filters_from_sqo) #
                logger.info(f"DataFrame shape after filtering for get_unique_values: {df_to_process.shape}") #

            unique_values_series = df_to_process[column_name].unique() #
            if sqo.get('options', {}).get('drop_na', False): # 默认为 False #
                unique_values = pd.Series(unique_values_series).dropna().tolist() #
            else: #
                unique_values = unique_values_series.tolist() #
            result_data = unique_values #

        elif operation_type == "group_by_aggregate": #
            group_by_cols = sqo.get("group_by_columns") #
            agg_col = sqo.get("aggregation_column") #
            agg_func = sqo.get("aggregation_function") #
            if not (group_by_cols and agg_col and agg_func): #
                error_msg = "'group_by_aggregate' 操作缺少 'group_by_columns', 'aggregation_column', 或 'aggregation_function' 参数。" #
                logger.error(error_msg) #
                return SQOResponse(success=False, error=error_msg) #
            
            columns_to_check = [] #
            if isinstance(group_by_cols, list): columns_to_check.extend(group_by_cols) #
            elif isinstance(group_by_cols, str): columns_to_check.append(group_by_cols) #
            if agg_col: columns_to_check.append(agg_col) #
            for col in columns_to_check: #
                if col not in df.columns: #
                    error_msg = f"列 '{col}' 在Excel中未找到。可用列: {df.columns.tolist()}" #
                    logger.error(error_msg) #
                    return SQOResponse(success=False, error=error_msg) #
            
            df_to_group = df.copy() #
            filters_from_sqo = sqo.get("filters") #
            if filters_from_sqo and isinstance(filters_from_sqo, list): #
                logger.info(f"Applying filters for group_by_aggregate: {filters_from_sqo}") #
                df_to_group = apply_filters_to_dataframe(df_to_group, filters_from_sqo) #
                logger.info(f"DataFrame shape after filtering: {df_to_group.shape}") #
            elif "filters" in sqo and sqo["filters"]: #
                 logger.warning(f"SQO中的 'filters' 字段格式不正确（期望列表），将被忽略。Filters: {sqo['filters']}") #

            grouped_data = df_to_group.groupby(group_by_cols)[agg_col].agg(agg_func) #
            output_col_name = sqo.get('options', {}).get('output_column_name') #
            if output_col_name: #
                if isinstance(grouped_data, pd.Series): grouped_data = grouped_data.rename(output_col_name) #
                elif isinstance(grouped_data, pd.DataFrame) and len(grouped_data.columns)==1: grouped_data.columns = [output_col_name] #
            result_data = grouped_data.reset_index().to_dict(orient='records') #

        elif operation_type == "find_top_n_rows": #
            select_columns = sqo.get("select_columns") #
            condition_col = sqo.get("condition_column") #
            sort_order_str = sqo.get("sort_order", "descending").lower() #
            n_rows_param = sqo.get("n_rows", 1) # 使用 n_rows_param 避免与内置名称冲突 #
            if not (select_columns and condition_col): #
                error_msg = "'find_top_n_rows' 操作缺少 'select_columns' 或 'condition_column' 参数。" #
                logger.error(error_msg) #
                return SQOResponse(success=False, error=error_msg) #
            
            columns_to_check_top_n = [] # 使用不同变量名以避免作用域问题 #
            if isinstance(select_columns, list): columns_to_check_top_n.extend(select_columns) #
            elif isinstance(select_columns, str): columns_to_check_top_n.append(select_columns) #
            if condition_col: columns_to_check_top_n.append(condition_col) #
            for col_top_n in columns_to_check_top_n: # 使用不同迭代变量 #
                 if col_top_n not in df.columns: #
                    error_msg = f"列 '{col_top_n}' 在Excel中未找到。可用列: {df.columns.tolist()}" #
                    logger.error(error_msg) #
                    return SQOResponse(success=False, error=error_msg) #

            if sort_order_str not in ['ascending', 'descending']: #
                error_msg = f"无效的 sort_order: {sort_order_str}" #
                logger.error(error_msg) #
                return SQOResponse(success=False, error=error_msg) #
            if not isinstance(n_rows_param, int) or n_rows_param <= 0: #
                error_msg = f"n_rows 必须是正整数，但收到: {n_rows_param}" #
                logger.error(error_msg) #
                return SQOResponse(success=False, error=error_msg) #

            df_to_sort = df.copy() #
            filters_from_sqo_top_n = sqo.get("filters") # 使用不同变量名 #
            if filters_from_sqo_top_n and isinstance(filters_from_sqo_top_n, list): #
                logger.info(f"Applying filters for find_top_n_rows: {filters_from_sqo_top_n}") #
                df_to_sort = apply_filters_to_dataframe(df_to_sort, filters_from_sqo_top_n) #
                logger.info(f"DataFrame shape after filtering: {df_to_sort.shape}") #
            elif "filters" in sqo and sqo["filters"]: #
                 logger.warning(f"SQO中的 'filters' 字段格式不正确（期望列表），将被忽略。Filters: {sqo['filters']}") #
            
            ascending_order = True if sort_order_str == 'ascending' else False #
            sorted_df = df_to_sort.sort_values(by=condition_col, ascending=ascending_order) #
            result_df = sorted_df.head(n_rows_param) # 使用 n_rows_param #
            result_data = result_df[select_columns].to_dict(orient='records') #
        
        elif operation_type == "direct_sql_query": #
            sql_query_from_sqo = sqo.get("sql_query") #
            if not sql_query_from_sqo: #
                error_msg = "'direct_sql_query' 操作缺少 'sql_query' 参数。" #
                logger.error(error_msg) #
                return SQOResponse(success=False, error=error_msg) #
            
            pdsql = PandaSQL(persist=False) #
            logger.debug(f"Executing direct_sql_query: {sql_query_from_sqo} on columns: {df.columns.tolist()}") #
            # 在执行SQL之前，对DataFrame应用过滤器（如果提供了）
            df_for_sql = df.copy() #
            filters_for_sql = sqo.get("filters") #
            if filters_for_sql and isinstance(filters_for_sql, list): #
                logger.info(f"Applying filters before direct_sql_query: {filters_for_sql}") #
                df_for_sql = apply_filters_to_dataframe(df_for_sql, filters_for_sql) #
                logger.info(f"DataFrame shape after filtering for direct_sql_query: {df_for_sql.shape}") #

            query_result_df = pdsql(sql_query_from_sqo, env={'df': df_for_sql}) # 在过滤后的df上执行 #
            
            if query_result_df is None: #
                result_data = "SQL查询成功执行，但没有返回数据。" #
            elif query_result_df.empty: #
                result_data = "SQL查询成功执行，但未找到符合条件的数据。" #
            else: #
                result_list_of_dicts = query_result_df.to_dict(orient='records') #
                if len(result_list_of_dicts) == 1: #
                    if len(result_list_of_dicts[0]) == 1: result_data = list(result_list_of_dicts[0].values())[0] #
                    else: result_data = result_list_of_dicts[0] #
                else: #
                    if result_list_of_dicts and len(result_list_of_dicts[0]) == 1: # 添加检查 result_list_of_dicts 是否为空 #
                        single_col_name = list(result_list_of_dicts[0].keys())[0] #
                        result_data = [row[single_col_name] for row in result_list_of_dicts] #
                    else: result_data = result_list_of_dicts #
        else: #
            error_msg = f"不支持的操作类型 '{operation_type}'。" #
            logger.error(error_msg) #
            return SQOResponse(success=False, error=error_msg) #

        logger.info(f"SQO operation '{operation_type}' executed successfully.") #
        return SQOResponse(success=True, result=result_data) #

    except ImportError: #
        logger.critical("Pandas或PandaSQL未正确安装。") #
        return SQOResponse(success=False, error="执行Excel查询所需的库 (Pandas/PandaSQL) 未安装。", error_details=traceback.format_exc()) #
    except FileNotFoundError as e_fnf: # 更具体的异常捕获 #
        logger.error(f"File not found during operation: {e_fnf}", exc_info=True) #
        return SQOResponse(success=False, error=str(e_fnf), error_details=traceback.format_exc()) #
    except pd.errors.EmptyDataError as e_empty: #
        logger.error(f"Pandas EmptyDataError for file {file_path}, sheet {sheet_name}: {e_empty}", exc_info=True) #
        return SQOResponse(success=False, error=f"无法读取Excel文件 '{os.path.basename(file_path)}' (工作表: {sheet_name})，文件可能为空或格式不正确。", error_details=traceback.format_exc()) #
    except KeyError as e_key: # 捕获列名不存在等错误 #
        logger.error(f"KeyError during operation '{operation_type}': {e_key}. SQO: {sqo}", exc_info=True) #
        return SQOResponse(success=False, error=f"操作失败：列名 '{str(e_key)}' 可能不存在或不正确。请检查SQO参数和Excel列名。可用列: {df.columns.tolist() if 'df' in locals() else '未知'}", error_details=traceback.format_exc()) #
    except Exception as e: #
        error_message = f"执行SQO操作 '{operation_type}' 时发生内部错误: {type(e).__name__} - {str(e)}" #
        logger.error(error_message, exc_info=True) #
        return SQOResponse(success=False, error=error_message, error_details=traceback.format_exc()) #


# --- 用于本地直接运行测试此本地代理服务 ---
if __name__ == "__main__": #
    import uvicorn #
    logger.info(f"Starting Local Agent server on http://0.0.0.0:{LOCAL_AGENT_PORT}") #
    uvicorn.run("local_agent_app:app", host="0.0.0.0", port=LOCAL_AGENT_PORT, reload=True) # 添加 reload=True #

    --- END OF FILE CONTENT ---

  File: local_agent_app.py.txt
    --- START OF FILE CONTENT ---
# /home/zhz/zhz_agent/local_agent/local_agent_app.py

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from typing import Dict, Any, List, Optional
import pandas as pd # 用于处理 Excel 数据
from pandasql import PandaSQL # 用于在 Pandas DataFrame 上执行 SQL 查询
import os
import logging # 用于日志记录
import traceback # 用于更详细的错误信息

# --- [新增] 导入 winotify 用于发送 Windows 桌面通知 ---
from winotify import Notification #

# --- 配置常量 ---
LOCAL_AGENT_PORT = 8003 # 本地代理服务监听的端口
LOG_LEVEL = logging.INFO # 日志级别

# --- 日志配置 ---
# 配置日志记录器，方便调试和追踪
logging.basicConfig(level=LOG_LEVEL, format='%(asctime)s - %(levelname)s - LocalAgent - %(message)s') #
logger = logging.getLogger(__name__) #

# --- FastAPI 应用实例 ---
app = FastAPI(
    title="ZhzAI Local Agent", #
    description="本地代理程序，提供处理本地文件（如Excel）和执行特定本地任务（如桌面通知）的MCP服务。", #
    version="0.1.1" # 更新版本号以反映添加了通知功能
)

# --- Pydantic 模型定义 ---

# 用于 Excel SQO (Structured Query Object) 操作的请求体
class ExecuteSQORequest(BaseModel): #
    sqo: Dict[str, Any] = Field(description="必需。一个结构化查询对象 (SQO) 的JSON字典，用于描述要对Excel执行的操作。") #

# Excel SQO 操作的通用响应体
class SQOResponse(BaseModel): #
    success: bool # 操作是否成功
    result: Any = None # 成功时的结果数据
    error: Optional[str] = None # 失败时的简要错误信息
    error_details: Optional[str] = None # 失败时的详细技术错误信息或堆栈

# 用于桌面通知的请求体
class NotificationRequest(BaseModel): #
    title: str = Field(default="任务提醒", description="通知的标题") #
    message: str = Field(description="通知的主要内容") #
    app_name: str = Field(default="终端大脑助手", description="显示在通知来源的应用名称") #
    # icon_path: Optional[str] = Field(None, description="通知图标的绝对路径 (可选)") #

# 桌面通知操作的响应体
class NotificationResponse(BaseModel): #
    success: bool # 操作是否成功 #
    message: str # 返回的消息，成功或失败的说明 #

# --- 核心功能函数 ---

def apply_filters_to_dataframe(df: pd.DataFrame, filters: List[Dict[str, Any]]) -> pd.DataFrame: #
    """
    将一系列过滤器应用于 Pandas DataFrame。
    这是 Excel SQO 操作的核心辅助函数，用于在执行聚合、查询等操作前筛选数据。
    """
    if not filters: #
        return df #

    df_filtered = df.copy() #
    for f_obj in filters: #
        column = f_obj.get("column") #
        operator = f_obj.get("operator") #
        value = f_obj.get("value") #
        is_date = f_obj.get("is_date", False) #

        if not all([column, operator, value is not None]): #
            logger.warning(f"Skipping invalid filter object: {f_obj}") #
            continue #

        if column not in df_filtered.columns: #
            logger.warning(f"Filter column '{column}' not found in DataFrame. Available: {df_filtered.columns.tolist()}. Skipping filter: {f_obj}") #
            continue #

        try: #
            series_to_filter = df_filtered[column] # 操作副本以避免 SettingWithCopyWarning #
            
            # 尝试转换日期，如果失败则记录警告并可能跳过
            if is_date: #
                try: #
                    series_to_filter = pd.to_datetime(series_to_filter, errors='coerce') #
                    filter_value_dt = pd.to_datetime(value, errors='coerce') #
                    # 如果日期转换失败且操作符不是处理列表的类型（列表值在后面处理）
                    if pd.isna(filter_value_dt) and not (isinstance(value, list) and operator in ["in", "is_in_list", "not in", "is_not_in_list"]): #
                        logger.warning(f"Cannot convert filter value '{value}' to date for column '{column}'. Skipping filter.") #
                        continue #
                    value = filter_value_dt # 更新 value 为日期对象或 NaT #
                except Exception as e_date: #
                    logger.warning(f"Error converting column '{column}' or value '{value}' to datetime: {e_date}. Skipping filter.") #
                    continue #
            
            condition = None #
            # 根据操作符构建筛选条件
            if operator == "equals" or operator == "==": #
                condition = (series_to_filter == value) #
            elif operator == "not_equals" or operator == "!=": #
                condition = (series_to_filter != value) #
            elif operator == "greater_than" or operator == ">": #
                condition = (series_to_filter > value) #
            elif operator == "greater_than_or_equals" or operator == ">=": #
                condition = (series_to_filter >= value) #
            elif operator == "less_than" or operator == "<": #
                condition = (series_to_filter < value) #
            elif operator == "less_than_or_equals" or operator == "<=": #
                condition = (series_to_filter <= value) #
            elif operator == "contains": #
                if is_date: #
                    logger.warning(f"'contains' operator is not directly applicable to date column '{column}'. Skipping filter.") #
                    continue #
                condition = (series_to_filter.astype(str).str.contains(str(value), case=False, na=False)) #
            elif operator == "not_contains": #
                if is_date: #
                    logger.warning(f"'not_contains' operator is not directly applicable to date column '{column}'. Skipping filter.") #
                    continue #
                condition = (~series_to_filter.astype(str).str.contains(str(value), case=False, na=False)) #
            elif operator == "is_in_list" or operator == "in": #
                if not isinstance(value, list): #
                    logger.warning(f"'is_in_list' operator expects a list value for column '{column}'. Skipping filter.") #
                    continue #
                if is_date: #
                    list_value_dt = pd.to_datetime(value, errors='coerce').dropna().tolist() #
                    if not list_value_dt: #
                        logger.warning(f"Cannot convert list values to dates for 'is_in_list' on column '{column}'. Skipping filter.") #
                        continue #
                    condition = (series_to_filter.isin(list_value_dt)) #
                else: #
                    condition = (series_to_filter.isin(value)) #
            elif operator == "is_not_in_list" or operator == "not in": #
                if not isinstance(value, list): #
                    logger.warning(f"'is_not_in_list' operator expects a list value for column '{column}'. Skipping filter.") #
                    continue #
                if is_date: #
                    list_value_dt = pd.to_datetime(value, errors='coerce').dropna().tolist() #
                    if not list_value_dt: #
                         logger.warning(f"Cannot convert list values to dates for 'is_not_in_list' on column '{column}'. Skipping filter.") #
                         continue #
                    condition = (~series_to_filter.isin(list_value_dt)) #
                else: #
                    condition = (~series_to_filter.isin(value)) #
            elif operator == "between": #
                if not (isinstance(value, list) and len(value) == 2): #
                    logger.warning(f"'between' operator expects a list of two values for column '{column}'. Skipping filter.") #
                    continue #
                val1, val2 = value #
                if is_date: #
                    val1_dt = pd.to_datetime(val1, errors='coerce') #
                    val2_dt = pd.to_datetime(val2, errors='coerce') #
                    if pd.isna(val1_dt) or pd.isna(val2_dt): #
                        logger.warning(f"Cannot convert 'between' values to dates for column '{column}'. Skipping filter.") #
                        continue #
                    condition = (series_to_filter.between(min(val1_dt, val2_dt), max(val1_dt, val2_dt))) #
                else: #
                    condition = (series_to_filter.between(min(val1, val2), max(val1, val2))) #
            elif operator == "is_null" or operator == "isnull": #
                condition = (series_to_filter.isnull()) #
            elif operator == "is_not_null" or operator == "notnull": #
                condition = (series_to_filter.notnull()) #
            else: #
                logger.warning(f"Unsupported filter operator '{operator}' for column '{column}'. Skipping filter.") #
                continue # 跳过不支持的操作符 #

            if condition is not None: #
                 df_filtered = df_filtered[condition] #
            else: #
                logger.warning(f"Condition was None for filter {f_obj}. This should not happen if operator is supported.") #

        except Exception as e_filter: #
            logger.error(f"Error applying filter {f_obj} on column '{column}': {e_filter}", exc_info=True) #
            # 根据策略，可以选择跳过此过滤器或在此处引发异常/返回错误
            # 为保持流程继续，我们选择跳过错误的过滤器
            continue #
            
    return df_filtered #

# --- FastAPI 端点 ---

@app.post("/notify", response_model=NotificationResponse) #
async def send_desktop_notification(req: NotificationRequest): #
    """
    接收通知请求并在 Windows 桌面上显示一个通知。
    """
    logger.info(f"Received notification request: Title='{req.title}', Message='{req.message}'") #
    try: #
        toast = Notification( #
            app_id=req.app_name, #
            title=req.title, #
            msg=req.message, #
            # duration="long", # 可选 #
            # icon=req.icon_path if req.icon_path and os.path.exists(req.icon_path) else "" # 可选 #
        )
        toast.show() #
        
        logger.info(f"Desktop notification successfully shown: '{req.title}'") #
        return NotificationResponse(success=True, message="Notification successfully shown.") #
    except Exception as e: #
        logger.error(f"Failed to show desktop notification: {e}", exc_info=True) #
        raise HTTPException(status_code=500, detail=f"Failed to show notification: {str(e)}") #


@app.post("/excel_sqo_mcp/execute_operation", response_model=SQOResponse) #
async def execute_excel_sqo_operation(request_data: ExecuteSQORequest): #
    """
    执行 Excel 结构化查询对象 (SQO) 操作。
    这个端点负责根据传入的 SQO 对指定的 Excel 文件进行数据读取、筛选、聚合等操作。
    """
    sqo = request_data.sqo #
    operation_type = sqo.get("operation_type") #
    file_path = sqo.get("file_path") #
    sheet_name = sqo.get("sheet_name", 0) # 默认为第一个工作表 #

    logger.info(f"Received SQO request: operation='{operation_type}', file='{file_path}', sheet='{sheet_name}'") #
    logger.debug(f"Full SQO received: {sqo}") #

    if not file_path or not operation_type: #
        logger.error("SQO missing 'file_path' or 'operation_type'.") #
        return SQOResponse(success=False, error="SQO中缺少 'file_path' 或 'operation_type' 参数。") #

    # 安全性提示：在生产环境中，需要对 file_path 进行严格校验，防止路径遍历等安全风险。
    # 例如，限制只能访问特定目录下的文件。
    if not os.path.exists(file_path): #
        logger.error(f"Excel file not found: {file_path}") #
        return SQOResponse(success=False, error=f"Excel文件未找到 '{file_path}'") #

    try: #
        # 读取 Excel 文件到 Pandas DataFrame
        df = pd.read_excel(file_path, sheet_name=sheet_name) #
        logger.info(f"Successfully loaded DataFrame. Shape: {df.shape}, Columns: {df.columns.tolist()}") #

        result_data = None #

        # --- 根据操作类型执行不同逻辑 ---

        if operation_type == "get_unique_values": #
            column_name = sqo.get("column_name") #
            if not column_name or column_name not in df.columns: #
                error_msg = f"'get_unique_values' 操作缺少有效 'column_name' 或列 '{column_name}' 不存在。可用列: {df.columns.tolist()}" #
                logger.error(error_msg) #
                return SQOResponse(success=False, error=error_msg) #
            
            df_to_process = df.copy() #
            filters_from_sqo = sqo.get("filters") #
            if filters_from_sqo and isinstance(filters_from_sqo, list): #
                logger.info(f"Applying filters for get_unique_values: {filters_from_sqo}") #
                df_to_process = apply_filters_to_dataframe(df_to_process, filters_from_sqo) #
                logger.info(f"DataFrame shape after filtering for get_unique_values: {df_to_process.shape}") #

            unique_values_series = df_to_process[column_name].unique() #
            if sqo.get('options', {}).get('drop_na', False): # 默认为 False #
                unique_values = pd.Series(unique_values_series).dropna().tolist() #
            else: #
                unique_values = unique_values_series.tolist() #
            result_data = unique_values #

        elif operation_type == "group_by_aggregate": #
            group_by_cols = sqo.get("group_by_columns") #
            agg_col = sqo.get("aggregation_column") #
            agg_func = sqo.get("aggregation_function") #
            if not (group_by_cols and agg_col and agg_func): #
                error_msg = "'group_by_aggregate' 操作缺少 'group_by_columns', 'aggregation_column', 或 'aggregation_function' 参数。" #
                logger.error(error_msg) #
                return SQOResponse(success=False, error=error_msg) #
            
            columns_to_check = [] #
            if isinstance(group_by_cols, list): columns_to_check.extend(group_by_cols) #
            elif isinstance(group_by_cols, str): columns_to_check.append(group_by_cols) #
            if agg_col: columns_to_check.append(agg_col) #
            for col in columns_to_check: #
                if col not in df.columns: #
                    error_msg = f"列 '{col}' 在Excel中未找到。可用列: {df.columns.tolist()}" #
                    logger.error(error_msg) #
                    return SQOResponse(success=False, error=error_msg) #
            
            df_to_group = df.copy() #
            filters_from_sqo = sqo.get("filters") #
            if filters_from_sqo and isinstance(filters_from_sqo, list): #
                logger.info(f"Applying filters for group_by_aggregate: {filters_from_sqo}") #
                df_to_group = apply_filters_to_dataframe(df_to_group, filters_from_sqo) #
                logger.info(f"DataFrame shape after filtering: {df_to_group.shape}") #
            elif "filters" in sqo and sqo["filters"]: #
                 logger.warning(f"SQO中的 'filters' 字段格式不正确（期望列表），将被忽略。Filters: {sqo['filters']}") #

            grouped_data = df_to_group.groupby(group_by_cols)[agg_col].agg(agg_func) #
            output_col_name = sqo.get('options', {}).get('output_column_name') #
            if output_col_name: #
                if isinstance(grouped_data, pd.Series): grouped_data = grouped_data.rename(output_col_name) #
                elif isinstance(grouped_data, pd.DataFrame) and len(grouped_data.columns)==1: grouped_data.columns = [output_col_name] #
            result_data = grouped_data.reset_index().to_dict(orient='records') #

        elif operation_type == "find_top_n_rows": #
            select_columns = sqo.get("select_columns") #
            condition_col = sqo.get("condition_column") #
            sort_order_str = sqo.get("sort_order", "descending").lower() #
            n_rows_param = sqo.get("n_rows", 1) # 使用 n_rows_param 避免与内置名称冲突 #
            if not (select_columns and condition_col): #
                error_msg = "'find_top_n_rows' 操作缺少 'select_columns' 或 'condition_column' 参数。" #
                logger.error(error_msg) #
                return SQOResponse(success=False, error=error_msg) #
            
            columns_to_check_top_n = [] # 使用不同变量名以避免作用域问题 #
            if isinstance(select_columns, list): columns_to_check_top_n.extend(select_columns) #
            elif isinstance(select_columns, str): columns_to_check_top_n.append(select_columns) #
            if condition_col: columns_to_check_top_n.append(condition_col) #
            for col_top_n in columns_to_check_top_n: # 使用不同迭代变量 #
                 if col_top_n not in df.columns: #
                    error_msg = f"列 '{col_top_n}' 在Excel中未找到。可用列: {df.columns.tolist()}" #
                    logger.error(error_msg) #
                    return SQOResponse(success=False, error=error_msg) #

            if sort_order_str not in ['ascending', 'descending']: #
                error_msg = f"无效的 sort_order: {sort_order_str}" #
                logger.error(error_msg) #
                return SQOResponse(success=False, error=error_msg) #
            if not isinstance(n_rows_param, int) or n_rows_param <= 0: #
                error_msg = f"n_rows 必须是正整数，但收到: {n_rows_param}" #
                logger.error(error_msg) #
                return SQOResponse(success=False, error=error_msg) #

            df_to_sort = df.copy() #
            filters_from_sqo_top_n = sqo.get("filters") # 使用不同变量名 #
            if filters_from_sqo_top_n and isinstance(filters_from_sqo_top_n, list): #
                logger.info(f"Applying filters for find_top_n_rows: {filters_from_sqo_top_n}") #
                df_to_sort = apply_filters_to_dataframe(df_to_sort, filters_from_sqo_top_n) #
                logger.info(f"DataFrame shape after filtering: {df_to_sort.shape}") #
            elif "filters" in sqo and sqo["filters"]: #
                 logger.warning(f"SQO中的 'filters' 字段格式不正确（期望列表），将被忽略。Filters: {sqo['filters']}") #
            
            ascending_order = True if sort_order_str == 'ascending' else False #
            sorted_df = df_to_sort.sort_values(by=condition_col, ascending=ascending_order) #
            result_df = sorted_df.head(n_rows_param) # 使用 n_rows_param #
            result_data = result_df[select_columns].to_dict(orient='records') #
        
        elif operation_type == "direct_sql_query": #
            sql_query_from_sqo = sqo.get("sql_query") #
            if not sql_query_from_sqo: #
                error_msg = "'direct_sql_query' 操作缺少 'sql_query' 参数。" #
                logger.error(error_msg) #
                return SQOResponse(success=False, error=error_msg) #
            
            pdsql = PandaSQL(persist=False) #
            logger.debug(f"Executing direct_sql_query: {sql_query_from_sqo} on columns: {df.columns.tolist()}") #
            # 在执行SQL之前，对DataFrame应用过滤器（如果提供了）
            df_for_sql = df.copy() #
            filters_for_sql = sqo.get("filters") #
            if filters_for_sql and isinstance(filters_for_sql, list): #
                logger.info(f"Applying filters before direct_sql_query: {filters_for_sql}") #
                df_for_sql = apply_filters_to_dataframe(df_for_sql, filters_for_sql) #
                logger.info(f"DataFrame shape after filtering for direct_sql_query: {df_for_sql.shape}") #

            query_result_df = pdsql(sql_query_from_sqo, env={'df': df_for_sql}) # 在过滤后的df上执行 #
            
            if query_result_df is None: #
                result_data = "SQL查询成功执行，但没有返回数据。" #
            elif query_result_df.empty: #
                result_data = "SQL查询成功执行，但未找到符合条件的数据。" #
            else: #
                result_list_of_dicts = query_result_df.to_dict(orient='records') #
                if len(result_list_of_dicts) == 1: #
                    if len(result_list_of_dicts[0]) == 1: result_data = list(result_list_of_dicts[0].values())[0] #
                    else: result_data = result_list_of_dicts[0] #
                else: #
                    if result_list_of_dicts and len(result_list_of_dicts[0]) == 1: # 添加检查 result_list_of_dicts 是否为空 #
                        single_col_name = list(result_list_of_dicts[0].keys())[0] #
                        result_data = [row[single_col_name] for row in result_list_of_dicts] #
                    else: result_data = result_list_of_dicts #
        else: #
            error_msg = f"不支持的操作类型 '{operation_type}'。" #
            logger.error(error_msg) #
            return SQOResponse(success=False, error=error_msg) #

        logger.info(f"SQO operation '{operation_type}' executed successfully.") #
        return SQOResponse(success=True, result=result_data) #

    except ImportError: #
        logger.critical("Pandas或PandaSQL未正确安装。") #
        return SQOResponse(success=False, error="执行Excel查询所需的库 (Pandas/PandaSQL) 未安装。", error_details=traceback.format_exc()) #
    except FileNotFoundError as e_fnf: # 更具体的异常捕获 #
        logger.error(f"File not found during operation: {e_fnf}", exc_info=True) #
        return SQOResponse(success=False, error=str(e_fnf), error_details=traceback.format_exc()) #
    except pd.errors.EmptyDataError as e_empty: #
        logger.error(f"Pandas EmptyDataError for file {file_path}, sheet {sheet_name}: {e_empty}", exc_info=True) #
        return SQOResponse(success=False, error=f"无法读取Excel文件 '{os.path.basename(file_path)}' (工作表: {sheet_name})，文件可能为空或格式不正确。", error_details=traceback.format_exc()) #
    except KeyError as e_key: # 捕获列名不存在等错误 #
        logger.error(f"KeyError during operation '{operation_type}': {e_key}. SQO: {sqo}", exc_info=True) #
        return SQOResponse(success=False, error=f"操作失败：列名 '{str(e_key)}' 可能不存在或不正确。请检查SQO参数和Excel列名。可用列: {df.columns.tolist() if 'df' in locals() else '未知'}", error_details=traceback.format_exc()) #
    except Exception as e: #
        error_message = f"执行SQO操作 '{operation_type}' 时发生内部错误: {type(e).__name__} - {str(e)}" #
        logger.error(error_message, exc_info=True) #
        return SQOResponse(success=False, error=error_message, error_details=traceback.format_exc()) #


# --- 用于本地直接运行测试此本地代理服务 ---
if __name__ == "__main__": #
    import uvicorn #
    logger.info(f"Starting Local Agent server on http://0.0.0.0:{LOCAL_AGENT_PORT}") #
    uvicorn.run("local_agent_app:app", host="0.0.0.0", port=LOCAL_AGENT_PORT, reload=True) # 添加 reload=True #

    --- END OF FILE CONTENT ---


Directory: core/
  File: __init__.py
    --- File is empty ---

  File: llm_manager.py
    --- START OF FILE CONTENT ---
# /home/zhz/zhz_agent/core/llm_manager.py

import os
from typing import Any, Optional

# 从相对路径导入包装器
from .llms.custom_litellm_wrapper import CustomLiteLLMWrapper

# --- 配置常量 (可以从项目级配置文件或环境变量加载) ---
# 本地 LLM 服务地址 (Qwen3)
LOCAL_QWEN_API_BASE = os.getenv("LOCAL_LLM_API_BASE", "http://localhost:8088/v1")
LOCAL_QWEN_MODEL_NAME_FOR_LITELLM = os.getenv("LOCAL_LLM_MODEL_NAME_FOR_LITELLM", "local/qwen3-1.7b-gguf") # 与 LiteLLM 调用匹配的名称

# 云端 LiteLLM 网关地址 (用于 Gemini 等)
CLOUD_LITELLM_GW_API_BASE = os.getenv("CLOUD_LITELLM_GW_API_BASE", "YOUR_CLOUD_LITELLM_GATEWAY_URL_HERE/v1")
GEMINI_MODEL_NAME_FOR_LITELLM = os.getenv("CLOUD_LLM_MODEL_NAME_FOR_LITELLM", "gemini/gemini-1.5-flash-latest")
CLOUD_LITELLM_GATEWAY_API_KEY = os.getenv("CLOUD_LITELLM_GATEWAY_API_KEY") # 网关本身可能需要的 API Key

# 默认 LLM 参数
DEFAULT_TEMPERATURE_LOCAL = 0.7
DEFAULT_MAX_TOKENS_LOCAL = 2048

DEFAULT_TEMPERATURE_CLOUD = 0.5
DEFAULT_MAX_TOKENS_CLOUD = 4096


def get_local_qwen_llm(
    temperature: Optional[float] = None,
    max_tokens: Optional[int] = None,
    agent_tools: Optional[list] = None, # CrewAI Agent 的工具列表
    tool_config: Optional[dict] = None  # Gemini 风格的 tool_config
) -> CustomLiteLLMWrapper:
    """
    获取配置好的本地 Qwen3 LLM 实例 (CrewAI 兼容)。
    """
    temp = temperature if temperature is not None else DEFAULT_TEMPERATURE_LOCAL
    mt = max_tokens if max_tokens is not None else DEFAULT_MAX_TOKENS_LOCAL

    print(f"LLM Manager: Creating Local Qwen LLM instance.")
    print(f"  Model: {LOCAL_QWEN_MODEL_NAME_FOR_LITELLM}, API Base: {LOCAL_QWEN_API_BASE}")
    print(f"  Temp: {temp}, Max Tokens: {mt}")
    
    return CustomLiteLLMWrapper(
        model=LOCAL_QWEN_MODEL_NAME_FOR_LITELLM,
        api_base=LOCAL_QWEN_API_BASE,
        api_key="nokey", # 本地服务通常不需要 key
        custom_llm_provider="openai", # 因为我们的本地服务是 OpenAI 兼容的
        temperature=temp,
        max_tokens=mt,
        agent_tools=agent_tools,
        tool_config=tool_config
    )

def get_cloud_gemini_llm(
    temperature: Optional[float] = None,
    max_tokens: Optional[int] = None,
    agent_tools: Optional[list] = None, # CrewAI Agent 的工具列表
    tool_config: Optional[dict] = None  # Gemini 风格的 tool_config
) -> Optional[CustomLiteLLMWrapper]:
    """
    获取配置好的云端 Gemini LLM 实例 (CrewAI 兼容)，通过 LiteLLM 网关调用。
    如果网关未配置，则返回 None。
    """
    temp = temperature if temperature is not None else DEFAULT_TEMPERATURE_CLOUD
    mt = max_tokens if max_tokens is not None else DEFAULT_MAX_TOKENS_CLOUD

    print(f"LLM Manager: Creating Cloud Gemini LLM instance via Gateway.")
    print(f"  Model: {GEMINI_MODEL_NAME_FOR_LITELLM}, Gateway API Base: {CLOUD_LITELLM_GW_API_BASE}")
    print(f"  Temp: {temp}, Max Tokens: {mt}")

    if CLOUD_LITELLM_GW_API_BASE == "YOUR_CLOUD_LITELLM_GATEWAY_URL_HERE/v1":
        print("LLM Manager WARNING: CLOUD_LITELLM_GW_API_BASE is not configured. Cannot create cloud LLM instance.")
        return None
    
    return CustomLiteLLMWrapper(
        model=GEMINI_MODEL_NAME_FOR_LITELLM,
        api_base=CLOUD_LITELLM_GW_API_BASE,
        api_key=CLOUD_LITELLM_GATEWAY_API_KEY, # 网关本身可能需要的 key
        # custom_llm_provider 在通过网关调用时通常不需要，除非网关本身是 OpenAI 兼容的代理
        temperature=temp,
        max_tokens=mt,
        agent_tools=agent_tools,
        tool_config=tool_config
    )

# --- (可选) 一个选择 LLM 的辅助函数 ---
def get_llm_instance(
    llm_type: str = "local_qwen", # "local_qwen" 或 "cloud_gemini"
    **kwargs # 其他传递给具体 LLM 创建函数的参数
) -> Optional[CustomLiteLLMWrapper]:
    if llm_type == "local_qwen":
        return get_local_qwen_llm(**kwargs)
    elif llm_type == "cloud_gemini":
        return get_cloud_gemini_llm(**kwargs)
    else:
        print(f"LLM Manager ERROR: Unknown LLM type '{llm_type}'. Returning None.")
        return None

if __name__ == "__main__":
    # 测试
    print("--- Testing LLM Manager ---")
    
    print("\n--- Getting Local Qwen LLM ---")
    local_llm = get_llm_instance("local_qwen", temperature=0.2)
    if local_llm:
        print(f"Local LLM instance: {local_llm.model_name}, Temp: {local_llm.litellm_params.get('temperature')}")
        # 可以在这里尝试调用，但需要运行 local_llm_service
        # try:
        #     response = local_llm.call(messages=[{"role":"user", "content":"你好"}])
        #     print(f"Test call to local_llm: {response}")
        # except Exception as e:
        #     print(f"Error calling local_llm: {e}")
    
    print("\n--- Getting Cloud Gemini LLM ---")
    # 需要设置环境变量 CLOUD_LITELLM_GW_API_BASE 和 CLOUD_LITELLM_GATEWAY_API_KEY
    # os.environ["CLOUD_LITELLM_GW_API_BASE"] = "http://your-gateway-url/v1" 
    # os.environ["CLOUD_LITELLM_GATEWAY_API_KEY"] = "your_gateway_key"
    cloud_llm = get_llm_instance("cloud_gemini", max_tokens=100)
    if cloud_llm:
        print(f"Cloud LLM instance: {cloud_llm.model_name}, Max Tokens: {cloud_llm.litellm_params.get('max_tokens')}")
    else:
        print("Cloud LLM instance could not be created (check gateway config).")
    --- END OF FILE CONTENT ---


Directory: core/agents/
  File: __init__.py
    --- File is empty ---


Directory: core/tools/
  File: __init__.py
    --- File is empty ---

  File: enhanced_rag_tool.py
    --- START OF FILE CONTENT ---
# /home/zhz/zhz_agent/core/tools/enhanced_rag_tool.py

import asyncio
from typing import Type, Optional, Dict, Any
from pydantic import BaseModel, Field
from crewai.tools import BaseTool

# 假设 call_mcpo_tool 在 utils.common_utils 中
# 如果 agent_orchestrator_service.py 和 core 在同一个父级 zhz_agent 下
# 我们可以用 from ....utils import common_utils
# 或者更明确 from zhz_agent.utils.common_utils import call_mcpo_tool (如果PYTHONPATH设置正确或运行方式支持)
# 为了简单和在工具类内部直接可用，我们先用相对导入（如果目录结构支持）或绝对导入
from utils.common_utils import call_mcpo_tool # 假设 zhz_agent 在PYTHONPATH中或者运行上下文支持

# --- 日志记录 ---
import logging
logger = logging.getLogger(__name__)


class EnhancedRAGToolInput(BaseModel):
    query: str = Field(description="用户提出的原始查询文本。")
    top_k_vector: int = Field(default=5, description="期望检索的向量搜索结果数量。")
    top_k_kg: int = Field(default=3, description="期望检索的知识图谱结果数量。")
    top_k_bm25: int = Field(default=3, description="期望检索的 BM25 关键词搜索结果数量。")
    # top_k_final: int = Field(default=3, description="融合后最终返回的文档数。") # 这个参数通常在RAG服务内部处理或由FusionEngine处理

class EnhancedRAGTool(BaseTool):
    name: str = "enhanced_rag_tool"
    description: str = "【核心RAG工具】用于从本地知识库查找信息、回答复杂问题，整合了向量、关键词和图谱检索。"
    args_schema: Type[BaseModel] = EnhancedRAGToolInput
    # MCP 服务中 RAG 服务的名称和端点路径
    mcp_service_name: str = "zhz_rag_mcp_service" # 与 mcp_servers.json 中定义的服务名一致
    mcp_tool_path: str = "query_rag_v2" # RAG 服务提供的端点

    def _run(
        self,
        query: str,
        top_k_vector: int = 5,
        top_k_kg: int = 3,
        top_k_bm25: int = 3,
        **kwargs: Any # 捕获其他可能的参数
    ) -> str:
        """
        同步执行方法，CrewAI Agent 会调用这个。
        内部调用异步的 _arun 方法。
        """
        logger.info(f"EnhancedRAGTool._run called with query: '{query}'")
        payload = {
            "query": query,
            "top_k_vector": top_k_vector,
            "top_k_kg": top_k_kg,
            "top_k_bm25": top_k_bm25,
        }
        # CrewAI 的同步工具执行通常在一个单独的线程中运行 asyncio.run
        # 或者我们可以直接在这里使用 asyncio.run
        try:
            loop = asyncio.get_event_loop()
            if loop.is_running():
                # 如果已经在运行的loop中，不能直接用 asyncio.run
                # 这种情况下，理想的做法是让 Agent 的执行流程本身是异步的
                # 但 CrewAI Agent 的 _run 通常是同步的。
                # 一个 hacky 的方法是创建一个新的线程来运行新的loop
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
                    future = executor.submit(asyncio.run, self._acall_mcp(payload))
                    result = future.result(timeout=120) # 设置超时
            else:
                result = asyncio.run(self._acall_mcp(payload))
        except Exception as e:
            logger.error(f"Error running EnhancedRAGTool for query '{query}': {e}", exc_info=True)
            return f"Error executing RAG tool: {str(e)}"
        
        # _handle_mcp_result 应该返回一个字符串
        return self._handle_mcp_result(result)

    async def _acall_mcp(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """
        实际调用 MCP 服务的异步方法。
        """
        tool_path_on_mcp = f"{self.mcp_service_name}/{self.mcp_tool_path}"
        logger.info(f"EnhancedRAGTool: Calling MCP endpoint '{tool_path_on_mcp}' with payload: {payload}")
        mcp_response = await call_mcpo_tool(tool_path_on_mcp, payload)
        return mcp_response

    def _handle_mcp_result(self, mcp_response: Dict[str, Any]) -> str:
        """
        处理来自 MCP 服务的响应。
        RAG 服务成功时应该返回类似 HybridRAGResponse 的结构。
        """
        if mcp_response.get("error"):
            error_msg = f"Enhanced RAG tool failed: {mcp_response['error']}"
            logger.error(error_msg)
            return error_msg

        # 假设 RAG 服务成功时返回的 JSON 包含 "final_answer" 和 "retrieved_context_docs"
        final_answer = mcp_response.get("final_answer")
        retrieved_docs_raw = mcp_response.get("retrieved_context_docs")

        if final_answer is None:
            no_answer_msg = "RAG service did not provide a final answer."
            logger.warning(no_answer_msg)
            # 可以选择返回一个更友好的提示，或者包含调试信息
            # return f"{no_answer_msg} Raw MCP response: {json.dumps(mcp_response, ensure_ascii=False, indent=2)}"
            # 对于 Agent，可能直接返回一个指示性的字符串更好
            return "未能从知识库获取明确答案。"


        # CrewAI 工具的 _run 方法通常期望返回一个字符串
        # 我们可以将 RAG 的核心答案和一些上下文摘要组合起来
        # 或者只返回 final_answer，让 Agent 自行决定是否需要更多细节
        
        response_parts = [f"RAG Answer: {final_answer}"]
        if retrieved_docs_raw and isinstance(retrieved_docs_raw, list):
            response_parts.append("\n\nSupporting Context Snippets:")
            for i, doc_data in enumerate(retrieved_docs_raw[:2]): # 最多显示2个上下文片段的摘要
                content = doc_data.get("content", "N/A")
                source = doc_data.get("source_type", "N/A")
                score = doc_data.get("score", 0.0)
                response_parts.append(f"  - Source: {source}, Score: {score:.2f}, Content: {content[:100]}...")
        
        return "\n".join(response_parts)

# 确保 core/tools 目录也有一个 __init__.py 文件
# touch /home/zhz/zhz_agent/core/tools/__init__.py (如果不存在)
    --- END OF FILE CONTENT ---

  File: excel_tool.py
    --- START OF FILE CONTENT ---
# /home/zhz/zhz_agent/core/tools/excel_tool.py

import httpx # 用于直接 HTTP 调用本地代理
import json
from typing import Type, Dict, Any, Union, List, Optional
from pydantic import BaseModel, Field
from crewai.tools import BaseTool
import  os

# --- 日志记录 ---
import logging
logger = logging.getLogger(__name__)

# 本地 Excel 代理服务的地址
# LOCAL_AGENT_BASE_URL = "http://localhost:8003" # 这个端口需要与 local_agent_app.py 中的一致
# 为了使其更灵活，从环境变量读取，并提供默认值
WINDOWS_HOST_IP = os.getenv("WINDOWS_HOST_IP_FOR_WSL", "192.168.3.11") # 确保这个IP正确
LOCAL_AGENT_PORT = os.getenv("LOCAL_AGENT_PORT", "8003")
LOCAL_AGENT_EXCEL_SQO_ENDPOINT = f"http://{WINDOWS_HOST_IP}:{LOCAL_AGENT_PORT}/excel_sqo_mcp/execute_operation"


class ExcelOperationToolInput(BaseModel):
    # Worker Agent 会迭代 Manager 生成的 SQO 列表，
    # 每次调用这个工具时，传递一个 SQO 字典，以及 file_path 和 sheet_name
    sqo_dict: Dict[str, Any] = Field(description="单个结构化查询对象 (SQO) 的JSON字典。")
    file_path: str = Field(description="目标Excel文件的绝对路径。")
    sheet_name: Union[str, int] = Field(default=0, description="目标工作表的名称或索引 (0-based)。")

class ExcelOperationTool(BaseTool):
    name: str = "excel_operation_tool"
    description: str = ("【Excel操作工具】通过结构化查询对象(SQO)对Excel文件执行复杂的数据查询、筛选、聚合等操作。"
                        "此工具接收单个SQO以及文件路径和工作表名，并调用本地代理执行。")
    args_schema: Type[BaseModel] = ExcelOperationToolInput

    def _run(
        self,
        sqo_dict: Dict[str, Any],
        file_path: str,
        sheet_name: Union[str, int] = 0,
        **kwargs: Any
    ) -> str:
        """
        同步执行方法，调用本地代理执行单个Excel SQO。
        """
        logger.info(f"ExcelOperationTool._run called with file_path: '{file_path}', sheet_name: '{sheet_name}'")
        logger.debug(f"SQO to execute: {sqo_dict}")

        if not isinstance(sqo_dict, dict):
            return "错误：传递给 ExcelOperationTool 的 sqo_dict 参数必须是一个字典。"
        if not sqo_dict.get("operation_type"):
            return "错误：SQO字典中缺少 'operation_type' 字段。"

        # 构造发送给 local_agent_app.py 的请求体
        # local_agent_app.py 的 /excel_sqo_mcp/execute_operation 端点期望的请求体是 ExecuteSQORequest 模型，
        # 它有一个名为 'sqo' 的字段，其值才是我们这里的 sqo_dict (已经包含了 operation_type, file_path, sheet_name)
        
        # 我们需要确保传递给本地代理的 SQO 中包含 file_path 和 sheet_name，
        # 因为 Manager Agent 生成的原始 SQO 列表中的字典不包含它们。
        # Worker Agent 在调用此工具前，应该已经将它们补充完整。
        # 但为了工具的健壮性，我们在这里也检查一下，并可以覆盖或添加。
        
        sqo_for_local_agent = sqo_dict.copy() # 创建副本以修改
        sqo_for_local_agent["file_path"] = file_path # 确保或覆盖 file_path
        sqo_for_local_agent["sheet_name"] = sheet_name # 确保或覆盖 sheet_name

        request_payload_to_local_agent = {"sqo": sqo_for_local_agent}

        logger.info(f"Sending request to Local Excel Agent: {LOCAL_AGENT_EXCEL_SQO_ENDPOINT}")
        logger.debug(f"Payload to Local Excel Agent: {request_payload_to_local_agent}")

        try:
            # 使用 httpx 进行同步调用
            with httpx.Client(timeout=60.0) as client:
                response = client.post(LOCAL_AGENT_EXCEL_SQO_ENDPOINT, json=request_payload_to_local_agent)
            
            logger.info(f"Local Excel Agent response status: {response.status_code}")
            response_json = response.json() # local_agent_app.py 返回的是 SQOResponse 模型

            if response.status_code == 200 and response_json.get("success"):
                result = response_json.get("result")
                logger.info(f"Excel operation successful. Result type: {type(result)}")
                # 将结果转换为字符串以便 Agent 处理
                if isinstance(result, (list, dict)):
                    try:
                        return json.dumps(result, ensure_ascii=False, indent=2)
                    except TypeError: # 处理无法JSON序列化的类型，例如某些Pandas特殊类型
                        return str(result)
                return str(result)
            else:
                error_message = response_json.get("error", "未知错误")
                error_details = response_json.get("error_details")
                full_error = f"本地Excel代理错误: {error_message}"
                if error_details:
                    full_error += f" | 详情: {str(error_details)[:200]}" # 限制详情长度
                logger.error(full_error)
                return full_error

        except httpx.RequestError as e:
            error_msg = f"请求本地Excel代理时出错: {e}"
            logger.error(error_msg, exc_info=True)
            return error_msg
        except json.JSONDecodeError as e:
            error_msg = f"解析本地Excel代理响应JSON时出错: {e}. 响应文本: {response.text[:200]}"
            logger.error(error_msg, exc_info=True)
            return error_msg
        except Exception as e:
            error_msg = f"执行Excel操作时发生未知错误: {e}"
            logger.error(error_msg, exc_info=True)
            return error_msg

# 确保 core/tools 目录也有一个 __init__.py 文件
# touch /home/zhz/zhz_agent/core/tools/__init__.py (如果不存在)
    --- END OF FILE CONTENT ---

  File: search_tool.py
    --- START OF FILE CONTENT ---
# /home/zhz/zhz_agent/core/tools/search_tool.py

import asyncio
from typing import Type, Optional, Dict, Any, List
from pydantic import BaseModel, Field
from crewai.tools import BaseTool
import json
from utils.common_utils import call_mcpo_tool

# --- 日志记录 ---
import logging
logger = logging.getLogger(__name__)


class WebSearchToolInput(BaseModel):
    query: str = Field(description="要进行网络搜索的关键词或问题。")
    max_results: Optional[int] = Field(default=5, description="希望返回的最大搜索结果数量。")

class WebSearchTool(BaseTool):
    name: str = "web_search_tool"
    description: str = ("【网络搜索工具】使用DuckDuckGo搜索引擎在互联网上查找与用户查询相关的信息。"
                        "返回搜索结果列表，每个结果包含标题、链接和摘要。")
    args_schema: Type[BaseModel] = WebSearchToolInput
    mcp_service_name: str = "ddgsearch" # 与 mcpo_servers.json 中定义的服务名一致 (如果使用)
    mcp_tool_path: str = "search"      # DuckDuckGo 搜索服务提供的端点

    def _run(
        self,
        query: str,
        max_results: Optional[int] = 5,
        **kwargs: Any
    ) -> str:
        """
        同步执行方法，调用 MCP 的 ddgsearch 服务。
        """
        logger.info(f"WebSearchTool._run called with query: '{query}', max_results: {max_results}")
        payload = {
            "query": query,
            "max_results": max_results,
        }
        
        try:
            loop = asyncio.get_event_loop()
            if loop.is_running():
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
                    future = executor.submit(asyncio.run, self._acall_mcp(payload))
                    result = future.result(timeout=60) 
            else:
                result = asyncio.run(self._acall_mcp(payload))
        except Exception as e:
            logger.error(f"Error running WebSearchTool for query '{query}': {e}", exc_info=True)
            return f"Error executing Web Search tool: {str(e)}"
        
        return self._handle_mcp_result(result)

    async def _acall_mcp(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """
        实际调用 MCP 服务的异步方法。
        """
        tool_path_on_mcp = f"{self.mcp_service_name}/{self.mcp_tool_path}"
        logger.info(f"WebSearchTool: Calling MCP endpoint '{tool_path_on_mcp}' with payload: {payload}")
        mcp_response = await call_mcpo_tool(tool_path_on_mcp, payload)
        return mcp_response

    def _handle_mcp_result(self, mcp_response: Dict[str, Any]) -> str:
        """
        处理来自 MCP ddgsearch 服务的响应。
        ddgsearch 服务成功时应该返回一个包含搜索结果列表的 JSON。
        """
        if mcp_response.get("error"):
            error_msg = f"Web Search tool failed: {mcp_response['error']}"
            logger.error(error_msg)
            return error_msg

        # ddgsearch MCP 服务返回的原始结果可能是一个字典，其中 "results" 键包含列表
        # 或者直接是一个列表（取决于MCP服务的封装）
        # 我们需要查看 ddgsearch 服务的实际输出格式来确定如何解析
        # 假设它返回一个包含 "results" 键的字典，其值为列表，每个列表项是一个包含 "title", "href", "body" 的字典
        
        search_results = mcp_response.get("results") # 假设 MCP 服务返回的 JSON 中有一个 'results' 键
        
        if isinstance(search_results, list):
            if not search_results:
                return "网络搜索没有找到相关结果。"
            
            formatted_results = ["网络搜索结果："]
            for i, res in enumerate(search_results):
                if isinstance(res, dict):
                    title = res.get("title", "无标题")
                    link = res.get("href", "#")
                    snippet = res.get("body", "无摘要")
                    formatted_results.append(f"{i+1}. {title}\n   链接: {link}\n   摘要: {snippet[:150]}...\n")
                else: # 如果列表项不是字典，直接转字符串
                    formatted_results.append(f"{i+1}. {str(res)[:200]}...")

            return "\n".join(formatted_results)
        elif search_results is not None: # 如果 results 存在但不是列表
             return f"网络搜索返回了意外格式的数据: {str(search_results)[:300]}"
        else: # 如果 mcp_response 中没有 "results" 键，或者 "results" 为 None
            logger.warning(f"Web Search tool: 'results' key not found or is None in MCP response. Raw response: {mcp_response}")
            return f"网络搜索未能获取结果。原始响应: {json.dumps(mcp_response, ensure_ascii=False, indent=2)}"

# 确保 core/tools 目录也有一个 __init__.py 文件
# touch /home/zhz/zhz_agent/core/tools/__init__.py (如果不存在)
    --- END OF FILE CONTENT ---


Directory: core/llms/
  File: __init__.py
    --- File is empty ---

  File: custom_litellm_wrapper.py
    --- START OF FILE CONTENT ---
# /home/zhz/zhz_agent/core/llms/custom_litellm_wrapper.py

import os
import json
import traceback
from typing import List, Dict, Any, Optional, Union, Sequence

import litellm
from crewai.llms.base_llm import BaseLLM as CrewAIBaseLLM
from crewai.tools import BaseTool # 用于类型提示

# --- 日志记录 ---
import logging
logger = logging.getLogger(__name__)
# logger.setLevel(logging.DEBUG) # 可以根据需要调整日志级别
# if not logger.hasHandlers():
#     handler = logging.StreamHandler()
#     formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
#     handler.setFormatter(formatter)
#     logger.addHandler(handler)

class CustomLiteLLMWrapper(CrewAIBaseLLM):
    """
    一个通用的 CrewAI LLM 包装器，通过 LiteLLM 调用各种 LLM 服务。
    能够处理本地 OpenAI 兼容的端点和通过 LiteLLM 支持的云端模型。
    """
    model_name: str # LiteLLM 使用的模型名称，例如 "gemini/gemini-1.5-flash-latest" 或 "local/qwen3-1.7b-gguf"
    api_base: Optional[str] = None
    api_key: Optional[str] = None
    custom_llm_provider: Optional[str] = None # 例如 "openai" 用于本地 OpenAI 兼容服务
    
    # LiteLLM 支持的额外参数，例如 temperature, max_tokens, top_p 等
    # 这些参数可以在实例化时传入，或者在调用 call 方法时覆盖
    litellm_params: Dict[str, Any] = {}

    # CrewAI 工具相关的参数
    tool_config: Optional[Dict[str, Any]] = None # 用于控制工具调用的模式，例如 Gemini 的 function_calling_config
    _cached_tools_for_litellm: Optional[List[Dict[str, Any]]] = None # 缓存转换后的工具定义

    def __init__(
        self,
        model: str, # CrewAI BaseLLM 需要 model 参数
        api_base: Optional[str] = None,
        api_key: Optional[str] = None,
        custom_llm_provider: Optional[str] = None,
        temperature: float = 0.7, # 默认温度
        max_tokens: Optional[int] = 2048, # 默认最大 token 数
        top_p: Optional[float] = None,
        stop_sequences: Optional[List[str]] = None,
        tool_config: Optional[Dict[str, Any]] = None, # 例如 {"function_calling_config": {"mode": "AUTO"}}
        agent_tools: Optional[List[BaseTool]] = None, # CrewAI Agent 的工具列表，用于转换为 LiteLLM 格式
        **kwargs: Any # 其他传递给 LiteLLM 的参数
    ):
        super().__init__(model=model) # 调用父类的构造函数
        self.model_name = model
        self.api_base = api_base
        self.api_key = api_key
        self.custom_llm_provider = custom_llm_provider
        
        self.litellm_params = {
            "temperature": temperature,
            "max_tokens": max_tokens,
            "top_p": top_p,
            "stop": stop_sequences,
            **kwargs # 合并其他未知参数
        }
        # 清理 litellm_params 中的 None 值
        self.litellm_params = {k: v for k, v in self.litellm_params.items() if v is not None}

        self.tool_config = tool_config
        if agent_tools:
            self._cached_tools_for_litellm = self._convert_crewai_tools_to_litellm_format(agent_tools)
            logger.info(f"CustomLiteLLMWrapper for '{self.model_name}': Cached {len(self._cached_tools_for_litellm)} tools.")
        else:
            logger.info(f"CustomLiteLLMWrapper for '{self.model_name}': No agent_tools provided for caching.")

    def _remove_unwanted_fields_from_schema(self, schema: Dict[str, Any]) -> Dict[str, Any]:
        """
        递归移除 Pydantic schema 中可能导致某些 LLM (如 Gemini) 报错的字段，
        例如顶层的 'title' 和属性定义中的 'default'。
        也确保 'object' 类型的 schema 包含 'properties' 键。
        """
        if not isinstance(schema, dict):
            return schema

        schema.pop('title', None) # 移除顶层 title

        if "properties" in schema and isinstance(schema["properties"], dict):
            if "type" not in schema: # 确保 object 类型有 type 字段
                schema["type"] = "object"
            for prop_name, prop_def in list(schema["properties"].items()): # 使用 list 进行迭代以允许修改
                if isinstance(prop_def, dict):
                    prop_def.pop('default', None) # 移除属性的 default
                    prop_def.pop('title', None)   # 移除属性的 title
                    self._remove_unwanted_fields_from_schema(prop_def) # 递归处理嵌套 schema
        elif schema.get("type") == "object" and "properties" not in schema:
            # 如果是 object 类型但没有 properties，某些 LLM (如 Gemini) 会报错
            schema["properties"] = {}

        # 移除顶层的 default (如果存在且不应该存在于顶层)
        # 通常 default 应该在属性级别，但以防万一
        # schema.pop('default', None) # 这个可能过于激进，先注释掉

        # 递归处理其他嵌套字典
        for key, value in schema.items():
            if isinstance(value, dict):
                self._remove_unwanted_fields_from_schema(value)
            elif isinstance(value, list):
                for i, item in enumerate(value):
                    if isinstance(item, dict):
                        value[i] = self._remove_unwanted_fields_from_schema(item)
        return schema
        
    def _convert_crewai_tools_to_litellm_format(self, tools: Optional[List[BaseTool]]) -> Optional[List[Dict[str, Any]]]:
        """
        将 CrewAI 的 BaseTool 列表转换为 LiteLLM期望的 "tools" 格式。
        LiteLLM 的格式通常与 OpenAI 的 function calling 格式类似。
        """
        if not tools:
            return None
        
        litellm_tool_definitions = []
        for tool_instance in tools:
            tool_name = tool_instance.name
            tool_description = tool_instance.description
            
            parameters_schema: Dict[str, Any]
            if not hasattr(tool_instance, 'args_schema') or not tool_instance.args_schema:
                # 如果工具没有定义参数 schema，则默认为一个没有参数的 object 类型
                parameters_schema = {"type": "object", "properties": {}}
            else:
                try:
                    # Pydantic V2 使用 model_json_schema(), V1 使用 schema()
                    if hasattr(tool_instance.args_schema, 'model_json_schema'):
                        pydantic_schema = tool_instance.args_schema.model_json_schema()
                    else:
                        pydantic_schema = tool_instance.args_schema.schema() # type: ignore
                    
                    # 清理 schema，移除 'title' 和 'default' 等字段
                    cleaned_schema = self._remove_unwanted_fields_from_schema(pydantic_schema.copy())
                    parameters_schema = cleaned_schema
                except Exception as e:
                    logger.error(f"Error processing schema for tool {tool_name}: {e}. Defaulting to empty params.")
                    parameters_schema = {"type": "object", "properties": {}}
            
            litellm_tool_definitions.append({
                "type": "function", # LiteLLM/OpenAI 的标准类型
                "function": {
                    "name": tool_name,
                    "description": tool_description,
                    "parameters": parameters_schema
                }
            })
        logger.debug(f"Converted CrewAI tools to LiteLLM format: {json.dumps(litellm_tool_definitions, indent=2)}")
        return litellm_tool_definitions

    def call(self, messages: List[Dict[str, str]], tools: Optional[List[Dict[str, Any]]] = None, **kwargs: Any) -> str:
        """
        使用 LiteLLM 调用 LLM。
        CrewAI 的 BaseLLM.call 方法期望返回一个字符串。
        """
        logger.info(f"CustomLiteLLMWrapper.call for '{self.model_name}' invoked.")
        logger.debug(f"  Messages: {json.dumps(messages, indent=2, ensure_ascii=False)}")
        logger.debug(f"  Tools provided to call: {'Yes' if tools else 'No'}")
        logger.debug(f"  kwargs: {kwargs}")

        # 合并参数，调用时传入的 kwargs 优先级更高
        current_litellm_params = {**self.litellm_params, **kwargs}

        litellm_call_args: Dict[str, Any] = {
            "model": self.model_name,
            "messages": messages,
            "api_base": self.api_base,
            "api_key": self.api_key,
            "custom_llm_provider": self.custom_llm_provider,
            **current_litellm_params # temperature, max_tokens, etc.
        }

        # 处理工具（函数调用）
        # CrewAI 在调用 Agent 的 LLM 时，会根据 Agent 的 tools 属性自动准备 tools 参数
        # 我们需要确保这里的 tools 参数与 LiteLLM 兼容
        final_tools_for_litellm = tools # 直接使用 CrewAI 传递过来的 tools
        if not final_tools_for_litellm and self._cached_tools_for_litellm:
            logger.info("  No tools passed to call, using cached tools for LiteLLM.")
            final_tools_for_litellm = self._cached_tools_for_litellm
        
        if final_tools_for_litellm:
            litellm_call_args["tools"] = final_tools_for_litellm
            # 根据 self.tool_config 设置 tool_choice
            if self.tool_config and "function_calling_config" in self.tool_config:
                fc_config = self.tool_config["function_calling_config"]
                mode = fc_config.get("mode", "AUTO").upper() # "AUTO", "ANY", "NONE"
                
                if mode == "ANY" and fc_config.get("allowed_function_names"):
                    # 对于 Gemini，如果 mode 是 ANY 且指定了函数名，tool_choice 应该是一个特定结构
                    # 对于 OpenAI，tool_choice 可以是 {"type": "function", "function": {"name": "my_function"}}
                    # LiteLLM 会尝试适配，我们先按 OpenAI 的方式设置
                    litellm_call_args["tool_choice"] = {
                        "type": "function", 
                        "function": {"name": fc_config["allowed_function_names"][0]} # 假设只取第一个
                    }
                elif mode in ["AUTO", "ANY", "NONE"]: # ANY 在没有指定函数名时，行为类似 AUTO
                    litellm_call_args["tool_choice"] = mode.lower()
                else: # 默认为 auto
                    litellm_call_args["tool_choice"] = "auto"
                logger.debug(f"  Setting tool_choice to: {litellm_call_args['tool_choice']}")
            else: # 如果没有 tool_config，默认 tool_choice 为 auto
                 litellm_call_args["tool_choice"] = "auto"
                 logger.debug(f"  No tool_config, defaulting tool_choice to 'auto'.")


        # 移除值为 None 的参数，因为 litellm.completion 不喜欢 None 的 api_key 等
        litellm_call_args_cleaned = {k: v for k, v in litellm_call_args.items() if v is not None}
        
        logger.info(f"  Attempting to call litellm.completion for model '{self.model_name}'...") # <--- 添加日志
        logger.debug(f"  LiteLLM Call Args (cleaned, messages excluded): "
                    f"{ {k: v for k, v in litellm_call_args_cleaned.items() if k != 'messages'} }")
        
        response = None # <--- 初始化 response
        try:
            response = litellm.completion(**litellm_call_args_cleaned) # <--- 这是关键的调用
            logger.info(f"  litellm.completion call for '{self.model_name}' succeeded.") # <--- 添加日志
            logger.debug(f"  LiteLLM Raw Response object type: {type(response)}")
            if hasattr(response, 'model_dump_json'):
                logger.debug(f"  LiteLLM Raw Response (JSON): {response.model_dump_json(indent=2)}")
            else:
                logger.debug(f"  LiteLLM Raw Response (str): {str(response)[:500]}")

        except Exception as e:
            logger.error(f"LiteLLM completion call FAILED for model '{self.model_name}': {e}", exc_info=True) # <--- 修改日志
            return f"LLM_CALL_ERROR: 调用模型 '{self.model_name}' 失败: {str(e)}"

        # 从 LiteLLM 响应中提取内容或工具调用
        # LiteLLM 的 ModelResponse 结构与 OpenAI 的 ChatCompletion 类似
        llm_message_response = response.choices[0].message
        
        if llm_message_response.tool_calls: # 检查是否有工具调用
            first_tool_call = llm_message_response.tool_calls[0]
            tool_name = first_tool_call.function.name
            tool_arguments_str = first_tool_call.function.arguments # 这是一个JSON字符串
            
            try:
                tool_arguments_dict = json.loads(tool_arguments_str)
            except json.JSONDecodeError:
                logger.error(f"Failed to parse tool arguments JSON: {tool_arguments_str}")
                # 如果参数解析失败，可能需要返回一个错误或一个简化的表示
                return f"LLM_TOOL_CALL_ERROR: 无法解析工具 '{tool_name}' 的参数: {tool_arguments_str}"

            # CrewAI 期望的 ReAct 格式
            # 注意：这里的 action_input 应该是参数的 JSON 字符串形式，而不是解析后的字典
            react_string = f"Action: {tool_name}\nAction Input: {tool_arguments_str}" # 使用原始JSON字符串
            logger.info(f"  LLM requested tool call (ReAct format): {react_string}")
            return react_string
            
        elif llm_message_response.content:
            logger.info(f"  LLM returned text content (first 200 chars): {llm_message_response.content[:200]}")
            return llm_message_response.content
        else:
            logger.warning("  LLM response did not contain content or tool calls.")
            return "" # 返回空字符串或特定错误消息

    def get_token_ids(self, text: str) -> List[int]:
        """
        获取文本的 token ID 列表。
        LiteLLM 提供了 litellm.encode 和 litellm.decode 方法。
        """
        try:
            # 注意：litellm.encode 可能需要 model 参数来确定使用哪个 tokenizer
            return litellm.encode(model=self.model_name, text=text)
        except Exception as e:
            logger.warning(f"get_token_ids failed for model '{self.model_name}': {e}. Returning empty list.")
            # CrewAI 在某些情况下即使这里返回空列表也能继续，但最好能正确实现
            return []

    # --- 添加这个方法 ---
    @property
    def supports_function_calling(self) -> bool:
        # 如果我们的包装器通过 LiteLLM 能够处理工具/函数调用 (通常是的)
        # 那么这里应该返回 True。
        # 如果特定的 LLM (通过 model_name 区分) 不支持，可以在这里做更细致的判断。
        # 例如，检查 self.custom_llm_provider 或 self.model_name
        # 对于 OpenAI 兼容的本地服务和 Gemini，它们都支持工具调用。
        return True
    # --- 添加结束 ---

    # CrewAI 可能还会用到的一些属性
    @property
    def _llm_type(self) -> str:
        return f"custom_litellm_{self.model_name.replace('/', '_')}"

    @property
    def identifying_params(self) -> Dict[str, Any]:
        """返回用于标识此LLM实例的参数字典。"""
        return {
            "model_name": self.model_name,
            "api_base": self.api_base,
            "custom_llm_provider": self.custom_llm_provider,
            **self.litellm_params
        }

# --- 示例用法 (可选，用于测试此文件) ---
async def main_test_wrapper():
    logger.info("--- Testing CustomLiteLLMWrapper ---")

    # 测试本地 Qwen (假设服务在 http://localhost:8088/v1)
    try:
        logger.info("\n--- Testing Local Qwen ---")
        local_qwen_llm = CustomLiteLLMWrapper(
            model="local/qwen3-1.7b-gguf", # 这个名称需要与 LiteLLM 调用时匹配
            api_base="http://localhost:8088/v1",
            api_key="nokey",
            custom_llm_provider="openai",
            temperature=0.1
        )
        messages_qwen = [{"role": "user", "content": "你好，请用中文介绍一下你自己。不要超过50个字。"}]
        # CrewAI 通常是同步调用 call 方法，但我们的 call 内部是同步执行 litellm.completion
        # 如果要测试异步行为，需要 litellm.acompletion 和异步的 call
        response_qwen = local_qwen_llm.call(messages=messages_qwen)
        logger.info(f"Local Qwen Response: {response_qwen}")
        
        # 测试 token_ids
        # token_ids_qwen = local_qwen_llm.get_token_ids("你好，世界")
        # logger.info(f"Token IDs for '你好，世界' from Qwen (via LiteLLM encode): {token_ids_qwen}")

    except Exception as e:
        logger.error(f"Error testing local Qwen: {e}", exc_info=True)

    # 测试云端 Gemini (假设通过配置好的 LiteLLM 网关)
    # 需要设置 CLOUD_LITELLM_GW_API_BASE 环境变量
    # 例如: export CLOUD_LITELLM_GW_API_BASE="http://your-litellm-proxy.com/v1"
    #       export GEMINI_API_KEY="your_actual_gemini_key_if_proxy_doesnt_handle_it_or_proxy_key"
    # CLOUD_LITELLM_GW_API_BASE_TEST = os.getenv("CLOUD_LITELLM_GW_API_BASE_TEST")
    # GEMINI_API_KEY_TEST = os.getenv("GEMINI_API_KEY_TEST") # 或者网关的key

    # if CLOUD_LITELLM_GW_API_BASE_TEST and GEMINI_API_KEY_TEST:
    #     try:
    #         print("\n--- Testing Cloud Gemini via Gateway ---")
    #         gemini_llm = CustomLiteLLMWrapper(
    #             model="gemini/gemini-1.5-flash-latest",
    #             api_base=CLOUD_LITELLM_GW_API_BASE_TEST,
    #             api_key=GEMINI_API_KEY_TEST, # Key for the gateway or Gemini if gateway passes it
    #             temperature=0.5
    #         )
    #         messages_gemini = [{"role": "user", "content": "What is the capital of France?"}]
    #         response_gemini = gemini_llm.call(messages=messages_gemini)
    #         print(f"Cloud Gemini Response: {response_gemini}")
    #     except Exception as e:
    #         print(f"Error testing cloud Gemini: {e}")
    # else:
    #     print("\nSkipping Cloud Gemini test as CLOUD_LITELLM_GW_API_BASE_TEST or GEMINI_API_KEY_TEST is not set.")

if __name__ == "__main__":
    # import asyncio
    # asyncio.run(main_test_wrapper())
    pass
    --- END OF FILE CONTENT ---


--- End of Project Snapshot ---